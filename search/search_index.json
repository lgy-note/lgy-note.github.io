{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"2019/10/15","title":"home"},{"location":"ansible/","text":" ansible - doc - l  ansible - doc   ansible - doc - s    ansible webservers - m command - a free -m ansible webservers - m script - a /home/test.sh 12 34 ansible webservers - m shell - a /home/test.sh copy  ansible webservers - m copy - a src=/home/test.sh dest=/tmp/ owner=root group=root mode=0755 stat  ansible webservers - m stat - a path=/etc/sysctl.conf get_url  ansible webservers - m get_url - a url=http://www.baidu.com dest=/tmp/index.html mode=0440 force=yes  ansible webservers - m apt - a pkg=curl state=latest ansible webservers - m yum - a name=curl state=latest cron  ansible webservers - m cron - a name= check dirs hour= 5,2 job= ls -alh /dev/null mount  ansible webservers - m mount - a name=/mnt/data src=/dev/sd0 fstype=ext3 opts=rostate=present service  ansible webservers - m service - a name=nginx state=stopped ansible webservers - m service - a name=nginx state=restarted ansible webservers - m service - a name=nginx state=reloaded sysctl  sysctl : name = kernel . panic value = 3 sysctl_file =/ etc / sysctl . conf checks = before reload = yes salt * pkg . upgrade user  #  johnd ； ansible webservers - m user - a name=johnd comment= John Doe #  johnd ； ansible webservers - m user - a name=johnd state=absent remove=yes playbook https : // github . com / ansible / ansible - examples   ansible - playbook nginx . yml - f 10 - u REMOTE_USER ： playbook ； -- syntax - check ： playbook ； -- list - hosts playbooks ：； -- step ：， nginx . yml yaml  --- - hosts : 192 . 168 . 8 . 22 #, vars : # worker_processes : 4 num_cpus : 4 max_open_file : 65506 root : / data remote_user : root #， sudo ， sudo : yes tasks : # - name : Install Nginx ...... #， action （） yum : pkg = nginx state = latest - name : write the nginx config file template : src =/ tmp / nginx . conf dest =/ etc / nginx / nginx . conf # key = value ，, / tmp / nginx . conf {{ root }} notify : # handlers  - restart nginx - name : Nginx is running ...... service : name = nginx state = started handlers : #， - name : restart nginx service : name = nginx state = restarted cat / tmp / nginx . conf ...... user nginx ; worker_processes {{ worker_processes }} ; { % if num_cpus == 2 % } worker_cpu_affinity 01 10 ; { % elif num_cpus == 4 % } worker_cpu_affinity 1000 0100 0010 0001 ; { % elif num_cpus = 8 % } worker_cpu_affinity 00000001 00000010 00000100 00001000 00010000 0010000001000000 10000000 ; { % else % } worker_cpu_affinity 1000 0100 0010 0001 ; { % endif % } worker_rlimit_nofile {{ max_open_file }} ; ......  playbook tasks : - include : tasks / foo . yml  ，playbook。 ： - hosts: web_servers tasks: - shell: /usr/bin/foo register: foo_result ignore_errors: True - shell: /usr/bin/bar when: foo_result.rc == 5 foo_result，shell:/usr/bin/foo，ignore_errors:True 。， playbook，when:foo_result.rc==5，shell:/usr/bin/bar ， foo_result.rc/usr/bin/fooresultcode（）。9-8“rc=0”。 tasks: - name: shutdown Debian flavored systems command: /sbin/shutdown -t now when: ansible_os_family == Debian BOOL,Truecommand - command: /bin/something when: result|failed - command: /bin/something_else when: result|success - command: /bin/still/something_else when: result|skipped “when:result|success”result，/bin/something_else ，， successAnsible，Ture。  - name:Install package yum: name= {{ item }} state=installed with_items: - pkg1 - pkg2 with_items，2，pkg1、pkg2， {{ item }}  facts ansible 192.168.1.21 - m setup  ， SaltstackGrains ansible all - m setup - a filter=ansible_hostname  Facts ： {{ ansible_devices . sda . model }} ansible_devicessdakeymodel {{ ansible_hostname }} ansible_hostname --------------------------- Facts  mkdir - pv / etc / ansible / facts . d cd / etc / ansible / facts . d vim preferences . fact [ general ] max_memory_size = 32 max_user_processes = 3730 open_files = 65535  ansible 192.168.8.22 - m setup - a filter=ansible_local ..... ansible_facts : { ansible_local : { preferences : { general : { max_memory_size : 32 , max_user_processes : 3730 , open_files : 65535 } } } } , ........ jinja2 ： {{ | }}。 ： {{ path | basename }} ： {{ path | dirname }} ，“ / etc / profile ”“ profile ”， / tmp / testshell 。 ---- hosts : 192 . 168 . 1 . 21 vars : filename : / etc / profile tasks : - name : shell1 shell : echo {{ filename | basename }} / tmp / testshell  yum install ansible - y vim / etc / ansible / hosts 、， ，： [ webservers ] www [ 01 : 50 ]. example . com http_port = 80 maxRequestsPerChild = 808 [ databases ] db - [ a : f ]. example . com http_port = 303 maxRequestsPerChild = 909 [ databases vars ]  ntp_server = ntp . atlanta . example . com proxy = proxy . atlanta . example . com  Ansible  / etc / ansible / hosts ， YAML ， ：“ / etc / an - sible / group_vars /+ ”“ / etc / ansible / host_vars /+ ” / etc / ansible / group_vars / dbservers / etc / ansible / group_vars / webservers / etc / ansible / host_vars / foosball --------------------------------------------- ansible all - m ping  ssh  ssh - keygen ssh - copy - id - i / root / . ssh / id_rsa . pub root @192.168.1.21 target  ip  one . example . com   IP “ : ” webservers  webservers ，“ : ” All ’ * ’  ~ ( web | db ). * \\ . example \\ . com  192.168.1 . *  IP  webservers : ! 192.168.1.22  webservers  192.168.1.22  IP webservers : dbservers  webservers  dbservers  webservers : ! {{ excluded }} : {{ required }} ","title":"ansible"},{"location":"ansible/#_1","text":"ansible - doc - l  ansible - doc   ansible - doc - s    ansible webservers - m command - a free -m ansible webservers - m script - a /home/test.sh 12 34 ansible webservers - m shell - a /home/test.sh copy  ansible webservers - m copy - a src=/home/test.sh dest=/tmp/ owner=root group=root mode=0755 stat  ansible webservers - m stat - a path=/etc/sysctl.conf get_url  ansible webservers - m get_url - a url=http://www.baidu.com dest=/tmp/index.html mode=0440 force=yes  ansible webservers - m apt - a pkg=curl state=latest ansible webservers - m yum - a name=curl state=latest cron  ansible webservers - m cron - a name= check dirs hour= 5,2 job= ls -alh /dev/null mount  ansible webservers - m mount - a name=/mnt/data src=/dev/sd0 fstype=ext3 opts=rostate=present service  ansible webservers - m service - a name=nginx state=stopped ansible webservers - m service - a name=nginx state=restarted ansible webservers - m service - a name=nginx state=reloaded sysctl  sysctl : name = kernel . panic value = 3 sysctl_file =/ etc / sysctl . conf checks = before reload = yes salt * pkg . upgrade user  #  johnd ； ansible webservers - m user - a name=johnd comment= John Doe #  johnd ； ansible webservers - m user - a name=johnd state=absent remove=yes","title":""},{"location":"ansible/#playbook","text":"https : // github . com / ansible / ansible - examples   ansible - playbook nginx . yml - f 10 - u REMOTE_USER ： playbook ； -- syntax - check ： playbook ； -- list - hosts playbooks ：； -- step ：， nginx . yml yaml  --- - hosts : 192 . 168 . 8 . 22 #, vars : # worker_processes : 4 num_cpus : 4 max_open_file : 65506 root : / data remote_user : root #， sudo ， sudo : yes tasks : # - name : Install Nginx ...... #， action （） yum : pkg = nginx state = latest - name : write the nginx config file template : src =/ tmp / nginx . conf dest =/ etc / nginx / nginx . conf # key = value ，, / tmp / nginx . conf {{ root }} notify : # handlers  - restart nginx - name : Nginx is running ...... service : name = nginx state = started handlers : #， - name : restart nginx service : name = nginx state = restarted cat / tmp / nginx . conf ...... user nginx ; worker_processes {{ worker_processes }} ; { % if num_cpus == 2 % } worker_cpu_affinity 01 10 ; { % elif num_cpus == 4 % } worker_cpu_affinity 1000 0100 0010 0001 ; { % elif num_cpus = 8 % } worker_cpu_affinity 00000001 00000010 00000100 00001000 00010000 0010000001000000 10000000 ; { % else % } worker_cpu_affinity 1000 0100 0010 0001 ; { % endif % } worker_rlimit_nofile {{ max_open_file }} ; ......  playbook tasks : - include : tasks / foo . yml","title":"playbook"},{"location":"ansible/#_2","text":"，playbook。 ： - hosts: web_servers tasks: - shell: /usr/bin/foo register: foo_result ignore_errors: True - shell: /usr/bin/bar when: foo_result.rc == 5 foo_result，shell:/usr/bin/foo，ignore_errors:True 。， playbook，when:foo_result.rc==5，shell:/usr/bin/bar ， foo_result.rc/usr/bin/fooresultcode（）。9-8“rc=0”。 tasks: - name: shutdown Debian flavored systems command: /sbin/shutdown -t now when: ansible_os_family == Debian BOOL,Truecommand - command: /bin/something when: result|failed - command: /bin/something_else when: result|success - command: /bin/still/something_else when: result|skipped “when:result|success”result，/bin/something_else ，， successAnsible，Ture。  - name:Install package yum: name= {{ item }} state=installed with_items: - pkg1 - pkg2 with_items，2，pkg1、pkg2， {{ item }} ","title":""},{"location":"ansible/#facts","text":"ansible 192.168.1.21 - m setup  ， SaltstackGrains ansible all - m setup - a filter=ansible_hostname  Facts ： {{ ansible_devices . sda . model }} ansible_devicessdakeymodel {{ ansible_hostname }} ansible_hostname --------------------------- Facts  mkdir - pv / etc / ansible / facts . d cd / etc / ansible / facts . d vim preferences . fact [ general ] max_memory_size = 32 max_user_processes = 3730 open_files = 65535  ansible 192.168.8.22 - m setup - a filter=ansible_local ..... ansible_facts : { ansible_local : { preferences : { general : { max_memory_size : 32 , max_user_processes : 3730 , open_files : 65535 } } } } , ........","title":"facts"},{"location":"ansible/#jinja2","text":"： {{ | }}。 ： {{ path | basename }} ： {{ path | dirname }} ，“ / etc / profile ”“ profile ”， / tmp / testshell 。 ---- hosts : 192 . 168 . 1 . 21 vars : filename : / etc / profile tasks : - name : shell1 shell : echo {{ filename | basename }} / tmp / testshell","title":"jinja2"},{"location":"ansible/#_3","text":"yum install ansible - y vim / etc / ansible / hosts 、， ，： [ webservers ] www [ 01 : 50 ]. example . com http_port = 80 maxRequestsPerChild = 808 [ databases ] db - [ a : f ]. example . com http_port = 303 maxRequestsPerChild = 909 [ databases vars ]  ntp_server = ntp . atlanta . example . com proxy = proxy . atlanta . example . com  Ansible  / etc / ansible / hosts ， YAML ， ：“ / etc / an - sible / group_vars /+ ”“ / etc / ansible / host_vars /+ ” / etc / ansible / group_vars / dbservers / etc / ansible / group_vars / webservers / etc / ansible / host_vars / foosball --------------------------------------------- ansible all - m ping  ssh  ssh - keygen ssh - copy - id - i / root / . ssh / id_rsa . pub root @192.168.1.21 target  ip  one . example . com   IP “ : ” webservers  webservers ，“ : ” All ’ * ’  ~ ( web | db ). * \\ . example \\ . com  192.168.1 . *  IP  webservers : ! 192.168.1.22  webservers  192.168.1.22  IP webservers : dbservers  webservers  dbservers  webservers : ! {{ excluded }} : {{ required }} ","title":""},{"location":"apache/","text":"apache VirtualHost *: 80 ServerAdmin yunwei @3 mang . com ServerName log .3 mang . com ProxyRequests Off ProxyPreserveHost On Proxy * AuthType Basic allowoverride AuthConfig order allow , deny allow from all AuthName admin AuthUserFile / etc / httpd / . htpassword require valid - user / Proxy ProxyPass / solr http : //127.0.0.1:8983/solr ProxyPass / solr / admin / cores http : //127.0.0.1:8983/solr/admin/cores ProxyPassReverse / solr http : //127.0.0.1:8983/solr / VirtualHost  http: // www . jianshu . com / p / 699 f158b218b apache mod_proxy  ，  ，   # Put this after the other LoadModule directives LoadModule proxy_module / usr / lib / apache2 / modules / mod_proxy . so LoadModule proxy_http_module / usr / lib / apache2 / modules / mod_proxy_http . so # Put this in the main section of your configuration (or desired virtual host, if using # Apache virtual hosts) #  ProxyRequests Off # Http headerHost，Host # ， ProxyPreserveHost On Header add Access-Control-Allow-Origin * Header add Access-Control-Allow-Methods GET, POST, OPTIONS Header add Access-Control-Allow-Headers Content-Type #  Proxy * # Orderdeny  allow # xxyy # xxyyOrder Order deny , allow Allow from all /Proxy #  ProxyPass / confluence http: // app-server . internal . example . com:8090 / confluence # HTTP redirect response Header Location, Content-Location  URI URL # ， ProxyPassReverse / confluence http: // app-server . internal . example . com:8090 / confluence # url Location /confluence Order allow , deny Allow from all /Location tomcat tomcattomcat redirectforward ，   ，  Connector port= 9080 protocol= HTTP/1.1 connectionTimeout= 20000 redirectPort= 9443 proxyName= sample.com proxyPort= 80 / proxyNameproxyPorttomcat 。 servlet  request . getServerName (); request . getSreverPort (); option Options  Apache ， Options  Apache   ( server config ) 、  ( virtual host ) 、 ( directory ) . htaccess 。 Options   。 Options ： Directory / # /  Indexes 、 FollowSymLinks 。 Options Indexes FollowSymLinks AllowOverride all Order allow , deny Allow from all / Directory Options ： Options [ +|- ] option [[ +|- ] option ] ...。， Options  ， 。 Options  ( Apache  ) ： All  MultiViews 。 Options 。 None 。 FollowSymLinks 。 Location ，。 Indexes ， DirectoryIndex  ( ： DirectoryIndex index . html index . php ) ，  mod_autoindex ，  (  ) 。 Options Indexes  MultiViews  mod_negotiation   。， ， 。， file   hello . jpg  hello . html  ， Http : // localhost / file / hello ， file  hello  ， file   hello . * ， hello . jpg  hello . html 。 SymLinksIfOwnerMatch  ID 。， ，。  Location ，。 ExecCGI  mod_cgi  CGI 。 Includes  mod_include 。 IncludesNOEXEC ， #exec cmd  #exec cgi 。 ScriptAlias  #include virtual  CGI 。 apache alias /phpredis /var/www/html/phpredis Directory /var/www/html/phpredis Options Indexes MultiViews AuthType basic AuthName welcome test AuthUserFile /etc/httpd/.htpasswd require valid-user = user test #  test  /Directory htpasswd -c /etc/httpd/.htpasswd  #-c  2，-c htpasswd -m .htpasswd   htpasswd -D .htpasswd   apache ==================================  alias /test01 /data/web/test01/ Directory /data/web/test01 　　Options Indexes MultiViews 　　AuthType basic 　　AuthName welcome test 　　AuthUserFile /etc/httpd/httppwd 　　AuthGroupFile /etc/httpd/httpgrp # 　　require group admin #admin  /Directory  vi /etc/httpd/httpgrp # ：admin:test #test ，， apache2.4 http : // httpd . apache . org / docs / 2 . 4 / upgrading . html In this example , all requests are denied . 2 . 2 configuration : Order deny , allow Deny from all 2 . 4 configuration : Require all denied In this example , all requests are allowed . 2 . 2 configuration : Order allow , deny Allow from all 2 . 4 configuration : Require all granted In the following example , all hosts in the example . org domain are allowed access ; all other hosts are denied access. 2 . 2 configuration : Order Deny , Allow Deny from all Allow from example . org 2 . 4 configuration : Require host example . org In the following example , mixing old and new directives leads to unexpected results . Mixing old and new directives : NOT WORKING AS EXPECTED DocumentRoot /var/www/html Directory / AllowOverride None Order deny , allow Deny from all / Directory Location /server-status SetHandler server - status Require 127 . 0 . 0 . 1 / Location access . log - GET / server - status 403 127 . 0 . 0 . 1 error . log - AH01797 : client denied by server configuration : / var / www / html / server - status Why httpd denies access to servers - status even if the configuration seems to allow it ? Because mod_access_compat directives take precedence over the mod_authz_host one in this configuration merge scenario . This example conversely works as expected : Mixing old and new directives : WORKING AS EXPECTED DocumentRoot /var/www/html Directory / AllowOverride None Require all denied / Directory Location /server-status SetHandler server - status Order deny , allow Deny from all Allow From 127 . 0 . 0 . 1 / Location access . log - GET / server - status 200 127 . 0 . 0 . 1 So even if mixing configuration is still possible , please try to avoid it when upgrading : either keep old directives and then migrate to the new ones on a later stage or just migrate everything in bulk . php apache + php php . ini  short_open_tag = Off short_open_tag = On php index . php ?php phpinfo (); ? apache /etc/httpd/conf/httpd.conf ip VirtualHost 192.168.1.11:80 　　ServerName www.test1.com 　　DocumentRoot /www/test1/ 　　 Directory /www/test1 　　　　Options Indexes FollowSymLinks 　　　　 AllowOverride None 　　　　 Order allow,deny 　　 　　Allow From All 　 /Directory /VirtualHost VirtualHost 192.168.1.12:80 　　ServerName www.test1.com 　　DocumentRoot /www/test2/ 　　 Directory /www/test2 　　　　Options Indexes FollowSymLinks 　　　　 AllowOverride None 　　　　 Order allow,deny 　　 　　Allow From All 　 /Directory /VirtualHost  NameVirtualHost *:80 VirtualHost *:80 　　ServerName www.test1.com 　　DocumentRoot /www/test1/ 　　 Directory /www/test1 　　　　Options Indexes FollowSymLinks 　　　　AllowOverride None 　　　　Order allow,deny 　　　　Allow from all 　　 /Directory /VirtualHost VirtualHost *:80 　　ServerName www.test2.com 　　DocumentRoot /www/test2/ 　　 Directory /www/test2 　　　　Options Indexes FollowSymLinks 　　　　AllowOverride None 　　　　Order allow,deny 　　　　Allow from all 　　 /Directory /VirtualHost ip 192.168.1.11 www.163.com 192.168.1.22 www.263.com %1 %2 %3 %4 %1 %2 %3 VirtualDocumentRootIP /tmp/www/%4 /tmp/www/11 /tmp/www/22  www.163.com 192.168.1.11 www.263.com 192.168.1.12 VirtualDocumentRoot /tmp/www/%2 /tmp/www/163 /tmp/www/263 www.163.com 192.168.1.11 www.263.com 192.168.1.12 mail.163.com VirtualDocumentRoot /tmp/a/%1/%2 /tmp/a/www/163 /tmp/a/www/263 /tmp/a/mail apache tracetrack / etc / httpd / conf / httpd . conf  TraceEnable Off RewriteEngine on RewriteCond % { REQUEST_METHOD } ^ ( TRACE | TRACK ) RewriteRule . * - [ F ] apache vim / etc / httpd / conf / httpd . conf MPM ： 1 、 worker  2 、 prefork （）  tar fzxv httperf - 0 . 9 . 0 cd httperf - 0 . 9 . 0 . / configure make make install vim / tmp / wsesslog # session 1 definition  session ， / index . html / cs . jpg / b . html / x . jgp ： awk - F \\ {print $2} /var/log/httpd/access_log | awk {print $2} | grep html$ | sort | uniq - c | sort - nr | head - n 10 awk $7 ~ html$ {print $7} / var / log / httpd / access_log | sort | uniq - c | sort - nr | head - n 10  httperf -- hog （） -- server = 192 . 168 . 18 . 199 (  ) -- rate (  ) 1 -- wsesslog = 4 , 1 ( thinktime ) , / tmp / wesslog Reply time [ ms ]: response transfer  Ifmodule mod_deflate . c DeflateCompressionLevel 6 AddOutputFilterByType DEFLATE text / html / Ifmodule  1 、 2 、 netstat - ant | grep - i estab | wc - l  estab  3 、 80  4 、 syn estalished Reply status 2  3  4  5  apache  worker （， nginx ） vim / etc / sysconfig / httpd HTTPD =/ usr / sbin / httpd . worker / etc / inint . d / httpd restart ps - eo nlwp , pid , user , comm | grep apache nlwp  apache  1 、（ / dev / null ） 2 、（ 1024 ） 3 、 mkdir - pv / tmp / mm mount - o size = 500 M - t tmpfs none / tmp / mm 500 M ，，， ， （,） apache  I / O 1 、 notime 2 、 BI / O （：、 ） deadline  3 、 raid apache  Memory  apache  awk $3 ~ kB { sum[$1] += $2 } END {for (key in sum) print key,sum[key] KB } smaps 1 、 LoadModule 2 、 apache  httpd  1 、 http  Timeout  10 S 2 、 KeepAlive on  KeepAlive Tmieout 15  Time_wait  echo 1 / proc / sys / net / ipv4 / tcp_tw_recycle echo 1 / proc / sys / net / ipv4 / tcp_tw_reuse ：，。 ， CPU  ： apache  wiki . nginx . org nginx  php （） vim / etc / php . ini max_execution_time = 600 ; ，600S max_input_time = 600 ;  memory_limit = 128 M  - output_buffering = 4096  opcode   xpc apc  PHP : yum install php - y : rpm - ivh php - eaccelerator - 0 . 9 . 5 . 2 - 2 . el5 . i386 . rpm vim / etc / php . d / eaccelerator . ini eaccelerator . shm_sime = 0  ipcs - l eaccelerator . shm_ttl = 3600  eaccelerator . allowed_admin_path = /var/www/html/control.php  eaccelerator . cache_dir = /var/cache/php-eaccelerator  cp / usr / share / doc / php - eaccelerator - 0 . 9 . 5 . 2 / control . php / var / www / html  : ab - n 100 - c 10 http : // 192 . 168 . 18 . 199 / time . php ， vim / etc / security / limits . conf * soft nofile 102400 * soft nofile 102400 su - ulimit - SHn vim / usr / include / bits / typesizes . h # define __FD_SETSIZE 102400 cd httperf - 0 . 9 . 0 . / configure make make install  1 、： httperf -- hog -- server = 192 . 168 . 18 . 199 -- rate 500 -- wsesslog = 5000000 , 1 , / tmp / wesslog 2 、 vim / etc / httpd / conf / httpd . conf IfModule prefork . c StartServers 80 MinSpareServers 50 MaxSpareServers 200 ServerLimit 500 MaxClients 500 MaxRequestsPerChild 4000 / IfModule 3 、 apache   vim / tmp / net netstat - ant | awk $1 ~ ^tcp {sum[$NF] += 1} END {for (key in sum) print key,sum[key]} chmod + x / tmp / net watch - n 1 / tmp / net 4 、 netstat - ant | grep 18 . 113 (  ) | grep - i syn_recv | wc - l netstat - ant | grep 18 . 113 (  ) | grep - i established | wc - l top load average free - m ： 102400 ： avg 14  8900 ＋ established 8900 ＋ established ＋ syn_baklog  3 ","title":"apache"},{"location":"apache/#apache","text":"VirtualHost *: 80 ServerAdmin yunwei @3 mang . com ServerName log .3 mang . com ProxyRequests Off ProxyPreserveHost On Proxy * AuthType Basic allowoverride AuthConfig order allow , deny allow from all AuthName admin AuthUserFile / etc / httpd / . htpassword require valid - user / Proxy ProxyPass / solr http : //127.0.0.1:8983/solr ProxyPass / solr / admin / cores http : //127.0.0.1:8983/solr/admin/cores ProxyPassReverse / solr http : //127.0.0.1:8983/solr / VirtualHost","title":"apache"},{"location":"apache/#_1","text":"http: // www . jianshu . com / p / 699 f158b218b apache mod_proxy  ，  ，   # Put this after the other LoadModule directives LoadModule proxy_module / usr / lib / apache2 / modules / mod_proxy . so LoadModule proxy_http_module / usr / lib / apache2 / modules / mod_proxy_http . so # Put this in the main section of your configuration (or desired virtual host, if using # Apache virtual hosts) #  ProxyRequests Off # Http headerHost，Host # ， ProxyPreserveHost On Header add Access-Control-Allow-Origin * Header add Access-Control-Allow-Methods GET, POST, OPTIONS Header add Access-Control-Allow-Headers Content-Type #  Proxy * # Orderdeny  allow # xxyy # xxyyOrder Order deny , allow Allow from all /Proxy #  ProxyPass / confluence http: // app-server . internal . example . com:8090 / confluence # HTTP redirect response Header Location, Content-Location  URI URL # ， ProxyPassReverse / confluence http: // app-server . internal . example . com:8090 / confluence # url Location /confluence Order allow , deny Allow from all /Location tomcat tomcattomcat redirectforward ，   ，  Connector port= 9080 protocol= HTTP/1.1 connectionTimeout= 20000 redirectPort= 9443 proxyName= sample.com proxyPort= 80 / proxyNameproxyPorttomcat 。 servlet  request . getServerName (); request . getSreverPort ();","title":""},{"location":"apache/#option","text":"Options  Apache ， Options  Apache   ( server config ) 、  ( virtual host ) 、 ( directory ) . htaccess 。 Options   。 Options ： Directory / # /  Indexes 、 FollowSymLinks 。 Options Indexes FollowSymLinks AllowOverride all Order allow , deny Allow from all / Directory Options ： Options [ +|- ] option [[ +|- ] option ] ...。， Options  ， 。 Options  ( Apache  ) ： All  MultiViews 。 Options 。 None 。 FollowSymLinks 。 Location ，。 Indexes ， DirectoryIndex  ( ： DirectoryIndex index . html index . php ) ，  mod_autoindex ，  (  ) 。 Options Indexes  MultiViews  mod_negotiation   。， ， 。， file   hello . jpg  hello . html  ， Http : // localhost / file / hello ， file  hello  ， file   hello . * ， hello . jpg  hello . html 。 SymLinksIfOwnerMatch  ID 。， ，。  Location ，。 ExecCGI  mod_cgi  CGI 。 Includes  mod_include 。 IncludesNOEXEC ， #exec cmd  #exec cgi 。 ScriptAlias  #include virtual  CGI 。","title":"option"},{"location":"apache/#apache_1","text":"alias /phpredis /var/www/html/phpredis Directory /var/www/html/phpredis Options Indexes MultiViews AuthType basic AuthName welcome test AuthUserFile /etc/httpd/.htpasswd require valid-user = user test #  test  /Directory htpasswd -c /etc/httpd/.htpasswd  #-c  2，-c htpasswd -m .htpasswd   htpasswd -D .htpasswd   apache ==================================  alias /test01 /data/web/test01/ Directory /data/web/test01 　　Options Indexes MultiViews 　　AuthType basic 　　AuthName welcome test 　　AuthUserFile /etc/httpd/httppwd 　　AuthGroupFile /etc/httpd/httpgrp # 　　require group admin #admin  /Directory  vi /etc/httpd/httpgrp # ：admin:test #test ，，","title":"apache"},{"location":"apache/#apache24","text":"http : // httpd . apache . org / docs / 2 . 4 / upgrading . html In this example , all requests are denied . 2 . 2 configuration : Order deny , allow Deny from all 2 . 4 configuration : Require all denied In this example , all requests are allowed . 2 . 2 configuration : Order allow , deny Allow from all 2 . 4 configuration : Require all granted In the following example , all hosts in the example . org domain are allowed access ; all other hosts are denied access. 2 . 2 configuration : Order Deny , Allow Deny from all Allow from example . org 2 . 4 configuration : Require host example . org In the following example , mixing old and new directives leads to unexpected results . Mixing old and new directives : NOT WORKING AS EXPECTED DocumentRoot /var/www/html Directory / AllowOverride None Order deny , allow Deny from all / Directory Location /server-status SetHandler server - status Require 127 . 0 . 0 . 1 / Location access . log - GET / server - status 403 127 . 0 . 0 . 1 error . log - AH01797 : client denied by server configuration : / var / www / html / server - status Why httpd denies access to servers - status even if the configuration seems to allow it ? Because mod_access_compat directives take precedence over the mod_authz_host one in this configuration merge scenario . This example conversely works as expected : Mixing old and new directives : WORKING AS EXPECTED DocumentRoot /var/www/html Directory / AllowOverride None Require all denied / Directory Location /server-status SetHandler server - status Order deny , allow Deny from all Allow From 127 . 0 . 0 . 1 / Location access . log - GET / server - status 200 127 . 0 . 0 . 1 So even if mixing configuration is still possible , please try to avoid it when upgrading : either keep old directives and then migrate to the new ones on a later stage or just migrate everything in bulk .","title":"apache2.4"},{"location":"apache/#php","text":"apache + php php . ini  short_open_tag = Off short_open_tag = On php index . php ?php phpinfo (); ?","title":"php"},{"location":"apache/#apache_2","text":"/etc/httpd/conf/httpd.conf ip VirtualHost 192.168.1.11:80 　　ServerName www.test1.com 　　DocumentRoot /www/test1/ 　　 Directory /www/test1 　　　　Options Indexes FollowSymLinks 　　　　 AllowOverride None 　　　　 Order allow,deny 　　 　　Allow From All 　 /Directory /VirtualHost VirtualHost 192.168.1.12:80 　　ServerName www.test1.com 　　DocumentRoot /www/test2/ 　　 Directory /www/test2 　　　　Options Indexes FollowSymLinks 　　　　 AllowOverride None 　　　　 Order allow,deny 　　 　　Allow From All 　 /Directory /VirtualHost  NameVirtualHost *:80 VirtualHost *:80 　　ServerName www.test1.com 　　DocumentRoot /www/test1/ 　　 Directory /www/test1 　　　　Options Indexes FollowSymLinks 　　　　AllowOverride None 　　　　Order allow,deny 　　　　Allow from all 　　 /Directory /VirtualHost VirtualHost *:80 　　ServerName www.test2.com 　　DocumentRoot /www/test2/ 　　 Directory /www/test2 　　　　Options Indexes FollowSymLinks 　　　　AllowOverride None 　　　　Order allow,deny 　　　　Allow from all 　　 /Directory /VirtualHost ip 192.168.1.11 www.163.com 192.168.1.22 www.263.com %1 %2 %3 %4 %1 %2 %3 VirtualDocumentRootIP /tmp/www/%4 /tmp/www/11 /tmp/www/22  www.163.com 192.168.1.11 www.263.com 192.168.1.12 VirtualDocumentRoot /tmp/www/%2 /tmp/www/163 /tmp/www/263 www.163.com 192.168.1.11 www.263.com 192.168.1.12 mail.163.com VirtualDocumentRoot /tmp/a/%1/%2 /tmp/a/www/163 /tmp/a/www/263 /tmp/a/mail","title":"apache"},{"location":"apache/#apache_3","text":"tracetrack / etc / httpd / conf / httpd . conf  TraceEnable Off RewriteEngine on RewriteCond % { REQUEST_METHOD } ^ ( TRACE | TRACK ) RewriteRule . * - [ F ]","title":"apache"},{"location":"apache/#apache_4","text":"vim / etc / httpd / conf / httpd . conf MPM ： 1 、 worker  2 、 prefork （）  tar fzxv httperf - 0 . 9 . 0 cd httperf - 0 . 9 . 0 . / configure make make install vim / tmp / wsesslog # session 1 definition  session ， / index . html / cs . jpg / b . html / x . jgp ： awk - F \\ {print $2} /var/log/httpd/access_log | awk {print $2} | grep html$ | sort | uniq - c | sort - nr | head - n 10 awk $7 ~ html$ {print $7} / var / log / httpd / access_log | sort | uniq - c | sort - nr | head - n 10  httperf -- hog （） -- server = 192 . 168 . 18 . 199 (  ) -- rate (  ) 1 -- wsesslog = 4 , 1 ( thinktime ) , / tmp / wesslog Reply time [ ms ]: response transfer  Ifmodule mod_deflate . c DeflateCompressionLevel 6 AddOutputFilterByType DEFLATE text / html / Ifmodule  1 、 2 、 netstat - ant | grep - i estab | wc - l  estab  3 、 80  4 、 syn estalished Reply status 2  3  4  5  apache  worker （， nginx ） vim / etc / sysconfig / httpd HTTPD =/ usr / sbin / httpd . worker / etc / inint . d / httpd restart ps - eo nlwp , pid , user , comm | grep apache nlwp  apache  1 、（ / dev / null ） 2 、（ 1024 ） 3 、 mkdir - pv / tmp / mm mount - o size = 500 M - t tmpfs none / tmp / mm 500 M ，，， ， （,） apache  I / O 1 、 notime 2 、 BI / O （：、 ） deadline  3 、 raid apache  Memory  apache  awk $3 ~ kB { sum[$1] += $2 } END {for (key in sum) print key,sum[key] KB } smaps 1 、 LoadModule 2 、 apache  httpd  1 、 http  Timeout  10 S 2 、 KeepAlive on  KeepAlive Tmieout 15  Time_wait  echo 1 / proc / sys / net / ipv4 / tcp_tw_recycle echo 1 / proc / sys / net / ipv4 / tcp_tw_reuse ：，。 ， CPU  ： apache  wiki . nginx . org nginx  php （） vim / etc / php . ini max_execution_time = 600 ; ，600S max_input_time = 600 ;  memory_limit = 128 M  - output_buffering = 4096  opcode   xpc apc  PHP : yum install php - y : rpm - ivh php - eaccelerator - 0 . 9 . 5 . 2 - 2 . el5 . i386 . rpm vim / etc / php . d / eaccelerator . ini eaccelerator . shm_sime = 0  ipcs - l eaccelerator . shm_ttl = 3600  eaccelerator . allowed_admin_path = /var/www/html/control.php  eaccelerator . cache_dir = /var/cache/php-eaccelerator  cp / usr / share / doc / php - eaccelerator - 0 . 9 . 5 . 2 / control . php / var / www / html  : ab - n 100 - c 10 http : // 192 . 168 . 18 . 199 / time . php ， vim / etc / security / limits . conf * soft nofile 102400 * soft nofile 102400 su - ulimit - SHn vim / usr / include / bits / typesizes . h # define __FD_SETSIZE 102400 cd httperf - 0 . 9 . 0 . / configure make make install  1 、： httperf -- hog -- server = 192 . 168 . 18 . 199 -- rate 500 -- wsesslog = 5000000 , 1 , / tmp / wesslog 2 、 vim / etc / httpd / conf / httpd . conf IfModule prefork . c StartServers 80 MinSpareServers 50 MaxSpareServers 200 ServerLimit 500 MaxClients 500 MaxRequestsPerChild 4000 / IfModule 3 、 apache   vim / tmp / net netstat - ant | awk $1 ~ ^tcp {sum[$NF] += 1} END {for (key in sum) print key,sum[key]} chmod + x / tmp / net watch - n 1 / tmp / net 4 、 netstat - ant | grep 18 . 113 (  ) | grep - i syn_recv | wc - l netstat - ant | grep 18 . 113 (  ) | grep - i established | wc - l top load average free - m ： 102400 ： avg 14  8900 ＋ established 8900 ＋ established ＋ syn_baklog  3 ","title":"apache"},{"location":"bind/","text":"bind yum install bind bind - utils - y  vi / etc / named . conf listen - on port 53 { any ; } ; //  any , 。 listen - on - v6 port 53 { any ; } ; allow - query { any ; } ; //  any ,  zone xx.com IN { type master ; file xx.com.zone ; allow - update { none ; } ; } ; //  xx . com //  file （ / var / named ，）  zone  cd / var / named cp named . localhost xx . com . zone chmod 644 xx . com . zone //  named  vi xx . com . zone // ， NS @ A 192 . 168 . 128 . 133 AAAA :: 1 www A 192 . 168 . 128 . 133 * . ic A 10 . 215 . 105 . 7 statics . ic A 10 . 215 . 105 . 7 // 。 A  IPv4  AAAA  IPv6 。 //  A 192 . 168 . 128 . 133 AAAA :: 1 ，。。  vi / etc / named . rfc1912 . zones //  DNS  // ，。 zone 128.168.192.in-addr.arpa IN { type master ; file 128.168.192.zone ; allow - update { none ; } ; } ; // ， IP ，，，。 // “ . in - addr . arpa ”  。 // ，，。 // 。 cd / var / named cp named . localhost 128 . 168 . 192 . zone chmod 644 128 . 168 . 192 . zone  vi 128 . 168 . 192 . zone 133 PTR www . xx . com . //  ，。。 ， service named restart bind edns https : //blog.gnuers.org/?p=1379 yum install GeoIP GeoIP - devel . / configure -- prefix =/ usr / local / bind9 .12.0 -- with - geoip =/ usr / share / GeoIP / -- enable - threads make make install . / sbin / rndc - confgen - r / dev / urandom etc / rndc . conf dig  dig  / root / bind - 9.12.1 - P2 / bin / dig / dig . / bin / dig / dig @127.0.0.1 a . test . com + subnet = 172.1.1.1 / 24  OPT PSEUDOSECTION  edns acl zone1 { ecs 10.0.0.0 / 8 ; 10.0.0.0 / 8 ; }; acl zone2 { ecs 172.0.0.0 / 8 ; 172.0.0.0 / 8 ; }; acl ecs - zone1 { ecs 10.0.0.0 / 8 ; }; acl ecs - zone2 { ecs 172.0.0.0 / 8 ;}; view ecs-zone1 { match - clients { ecs - zone1 ;}; zone test.org { type master ; file ecszone/test.org ;}; }; view ecs-zone2 { match - clients { ecs - zone2 ;}; zone test.org { type master ; file ecszone2/test.org ;}; }; view zone1 { match - clients { zone1 ;}; zone test.org { type master ; file zone/test.org ;}; }; view zone2 { match - clients { zone2 ;}; zone test.org { type master ; file zone2/test.org ;}; }; dig @10.10.0.15 test100 . test . org dig @172.18.0.6 test100 . test . org dig @10.10.0.15 test100 . test . org + subnet = 172.1.1.1 / 24 dig @10.10.0.15 test100 . test . org + subnet = 10.1.1.1 / 24 dig @172.18.0.6 test100 . test . org + subnet = 10.1.1.1 / 24 dig @172.18.0.6 test100 . test . org + subnet = 172.1.1.1 / 24 cat / etc / init . d / named #!/bin/bash # named a network name service. # chkconfig: 345 35 75 # description: a name server PIDFILE = / var / named / named . pid BASEDIR = / usr / local / bind9 .12.0 if [ ` id - u ` - ne 0 ]; then echo ERROR:For bind to port 53,must run as root. exit 1 fi case $1 in start ) if [ - x $ BASEDIR / sbin / named ]; then if [ - e $ PIDFILE ]; then echo BIND9 already started else $ BASEDIR / sbin / named - u named - c / etc / named . conf echo . echo BIND9 server started fi fi ;; stop ) if [ - e $ PIDFILE ]; then / bin / kill - 9 ` cat $ PIDFILE ` echo . echo BIND9 server stopped else echo BIND9 already stopped fi rm $ PIDFILE - f ;; restart ) echo . echo Restart BIND9 server $ 0 stop sleep 3 $ 0 start ;; reload ) $ BASEDIR / sbin / rndc reload ;; status ) $ BASEDIR / sbin / rndc status ;; * ) echo $0 start | stop | restart |reload |status ;; esac","title":"bind"},{"location":"bind/#bind","text":"yum install bind bind - utils - y  vi / etc / named . conf listen - on port 53 { any ; } ; //  any , 。 listen - on - v6 port 53 { any ; } ; allow - query { any ; } ; //  any ,  zone xx.com IN { type master ; file xx.com.zone ; allow - update { none ; } ; } ; //  xx . com //  file （ / var / named ，）  zone  cd / var / named cp named . localhost xx . com . zone chmod 644 xx . com . zone //  named  vi xx . com . zone // ， NS @ A 192 . 168 . 128 . 133 AAAA :: 1 www A 192 . 168 . 128 . 133 * . ic A 10 . 215 . 105 . 7 statics . ic A 10 . 215 . 105 . 7 // 。 A  IPv4  AAAA  IPv6 。 //  A 192 . 168 . 128 . 133 AAAA :: 1 ，。。  vi / etc / named . rfc1912 . zones //  DNS  // ，。 zone 128.168.192.in-addr.arpa IN { type master ; file 128.168.192.zone ; allow - update { none ; } ; } ; // ， IP ，，，。 // “ . in - addr . arpa ”  。 // ，，。 // 。 cd / var / named cp named . localhost 128 . 168 . 192 . zone chmod 644 128 . 168 . 192 . zone  vi 128 . 168 . 192 . zone 133 PTR www . xx . com . //  ，。。 ， service named restart","title":"bind"},{"location":"bind/#bind-edns","text":"https : //blog.gnuers.org/?p=1379 yum install GeoIP GeoIP - devel . / configure -- prefix =/ usr / local / bind9 .12.0 -- with - geoip =/ usr / share / GeoIP / -- enable - threads make make install . / sbin / rndc - confgen - r / dev / urandom etc / rndc . conf dig  dig  / root / bind - 9.12.1 - P2 / bin / dig / dig . / bin / dig / dig @127.0.0.1 a . test . com + subnet = 172.1.1.1 / 24  OPT PSEUDOSECTION  edns acl zone1 { ecs 10.0.0.0 / 8 ; 10.0.0.0 / 8 ; }; acl zone2 { ecs 172.0.0.0 / 8 ; 172.0.0.0 / 8 ; }; acl ecs - zone1 { ecs 10.0.0.0 / 8 ; }; acl ecs - zone2 { ecs 172.0.0.0 / 8 ;}; view ecs-zone1 { match - clients { ecs - zone1 ;}; zone test.org { type master ; file ecszone/test.org ;}; }; view ecs-zone2 { match - clients { ecs - zone2 ;}; zone test.org { type master ; file ecszone2/test.org ;}; }; view zone1 { match - clients { zone1 ;}; zone test.org { type master ; file zone/test.org ;}; }; view zone2 { match - clients { zone2 ;}; zone test.org { type master ; file zone2/test.org ;}; }; dig @10.10.0.15 test100 . test . org dig @172.18.0.6 test100 . test . org dig @10.10.0.15 test100 . test . org + subnet = 172.1.1.1 / 24 dig @10.10.0.15 test100 . test . org + subnet = 10.1.1.1 / 24 dig @172.18.0.6 test100 . test . org + subnet = 10.1.1.1 / 24 dig @172.18.0.6 test100 . test . org + subnet = 172.1.1.1 / 24 cat / etc / init . d / named #!/bin/bash # named a network name service. # chkconfig: 345 35 75 # description: a name server PIDFILE = / var / named / named . pid BASEDIR = / usr / local / bind9 .12.0 if [ ` id - u ` - ne 0 ]; then echo ERROR:For bind to port 53,must run as root. exit 1 fi case $1 in start ) if [ - x $ BASEDIR / sbin / named ]; then if [ - e $ PIDFILE ]; then echo BIND9 already started else $ BASEDIR / sbin / named - u named - c / etc / named . conf echo . echo BIND9 server started fi fi ;; stop ) if [ - e $ PIDFILE ]; then / bin / kill - 9 ` cat $ PIDFILE ` echo . echo BIND9 server stopped else echo BIND9 already stopped fi rm $ PIDFILE - f ;; restart ) echo . echo Restart BIND9 server $ 0 stop sleep 3 $ 0 start ;; reload ) $ BASEDIR / sbin / rndc reload ;; status ) $ BASEDIR / sbin / rndc status ;; * ) echo $0 start | stop | restart |reload |status ;; esac","title":"bind edns"},{"location":"command/","text":"find  find vipkid / media /* -mtime -1 | xargs du -sm | awk {sum +=$1}END{print sum}  find . -empty  find . /home.txt find /home -name *.txt ， find /home -iname *.txt .txt.pdf find . \\( -name *.txt -o -name *.pdf \\)  find . -name *.txt -o -name *.pdf  find /usr/ -path *local*  find . -regex .*\\(\\.txt\\|\\.pdf\\)$ ， find . -iregex .*\\(\\.txt\\|\\.pdf\\)$ /home.txt find /home ! -name *.txt  find . -type  ： f  l  d  c  b  s  p Fifo  3 find . -maxdepth 3 -type f 2 find . -mindepth 2 -type f  find . -type f  UNIX/Linux： （-atime/，-amin/）：, ls, more ,  chmod, chown, ls, stat ,  ls -utl ; （-mtime/，-mmin/）：,  vi , , atime  ctime  （-ctime/，-cmin/）：（）, chmod, chown ,  stat file ; ---(+n)----------|----------(n)----------|----------(-n)--- (n+1)*24H| (n+1)*24H~n*24H |n*24H -ctime -n  n*24H  -ctime n  n*24H , (n+1)*24H  -ctime +n  (n+1)*24H  ： linux ，， 。 #ls -lt /home/admin #  #ls -lut /home/admin #  ( -r)  find . -type f -atime -7  find . -type f -atime 7  find . -type f -atime +7 10 find . -type f -amin +10 file.log find . -type f -newer file.log  find . -type f -size  ： b —— （512） c ——  w ——  （2） k ——  M ——  G ——  10KB find . -type f -size +10k 10KB find . -type f -size -10k 10KB find . -type f -size 10k  .txt find . -type f -name *.txt -delete -exec root，tom find .-type f -user root -exec chown tom {} \\; ，{} -exec，。 .txt find $HOME/. -name *.txt -ok rm {} \\ ; ，-ok-exec，，。 .txtall.txt find . -type f -name *.txt -exec cat {} \\ ; all.txt 30.logold find . -type f -mtime +30 -name *.log -exec cp {} old \\ ; .txt“File:” find . -type f -name *.txt -exec printf File: %s\\n {} \\ ; -exec，-exec -exec ./text.sh {} \\;  .txt，sk find . -path ./sk -prune -o -name *.txt -print find http://man.linuxde.net date # ： 2016 - 10 - 24 11 : 20 : 30  1  50  time1 = $ ( date +% s - d 2016-10-24 11:20:30 ) #  # time1 = $ ( date +% s ) #  time2 = $ (( 1 * 60 * 60 + 50 * 60 )) # 1  50  timesnmp1 = $ (( $ time1 + $ time2 )) echo $ ( date + %F %T - d 1970-01-01 UTC $timesnmp1 seconds ) timesnmp2 = $ (( $ time1 - $ time2 )) echo $ ( date + %F %T - d 1970-01-01 UTC $timesnmp2 seconds ) tar Linux  tar ， tar （ tape archive ）， ， 。 tar 。， ， 。 1 .  - z , --gzip：gzip（），.gz - c , --create：tar，.tar - f , --file=： - x , --extract：，-c - p ： - g ： - C ： --exclude：，  - X , --exclude-from：（--exclude=） - t , --list：，-c、-x - j , --bzip2：bzip2（），.bz2 - P ：， - v ：（）， 2 . （） （）， ， tar  ，， - g 。 ， 。  # tar - g / tmp / snapshot_data . snap - zcpf / tmp / data01 . tar . gz .  # tar - zxpf / tmp / data01 . tar . gz - C . - g ，， / tmp / snapshot_data . snap ， 。，（ ），  - g ，，， 。 ，“”，， （）， 。，。，  ，。 ，：  / tmp / data ， cache  （ 4 G ），（ 1 G ） ， # cd / tmp / data  # rm - f / tmp / snapshot_data . snap # tar - g / tmp / snapshot_data . snap - zcpf - --exclude=./cache ./ | split -b 1024M - /tmp/bak_data$(date -I).tar.gz_  aa , ab , ac ,... ， bak_data2014 - 12 - 07 . tar . gz_aa bak_data2014 - 12 - 07 . tar . gz_ab bak_data2014 - 12 - 07 . tar . gz_ac ...  ，，，  ， split  aa , ab ，（），  ：（ ，$ ( date +% Y -% m -% d_ % H ) ） # tar - g / tmp / snapshot_data . snap - zcpf / tmp / bak_data2014 - 12 - 07 . tar . gz --exclude=./cache ./  # tar - g / tmp / snapshot_data . snap - zcpf / tmp / bak_data2014 - 12 - 08 . tar . gz --exclude=./cache ./    / tmp / data /  # cat / tmp / bak_data2014 - 12 - 07 . tar . gz_ * | tar - zxpf - - C / tmp / data /  $ tar – zxpf / tmp / bak_data2014 - 12 - 07 . tar . gz - C / tmp / data / $ tar – zxpf / tmp / bak_data2014 - 12 - 08 . tar . gz - C / tmp / data / ... ， ，，， crontab 。 3 .  ， cpio , rsync , dump , tar ， tar  Linux ，。  Linux （ CentOS ）， / proc 、 / lost + found 、 / sys 、 / mnt 、 / media 、 / dev 、 / proc 、 / tmp ，  / dev / st0 ， / backup ， ， NFS  。  # vi / backup / backup_tar_exclude . list / backup / proc / lost + found / sys / mnt / media / dev / tmp $ tar - zcpf / backup / backup_full . tar . gz - g / backup / tar_snapshot . snap --exclude-from=/backup/tar_exclude.list / 4 .   tar ，。 tar  atime ，  ID ， USERID ，  Linux  Linux ，， Linux  ？ Netflix ，。  ， 1 。 uptime dmesg | tail vmstat 1 mpstat - P ALL 1 pidstat 1 iostat - xz 1 free - m sar - n DEV 1 sar - n TCP , ETCP 1 top  sysstat ， procps 。， ， （ CPU 、、 IO ）（ utilization ）、（ saturation ）（ error ） ， USE 。 ，，。 uptime $ uptime 23 : 51 : 26 up 21 : 31 , 1 user , load average : 30.02 , 26.43 , 19.02 。 Linux ， CPU   IO （ D ） 。。  1 、 5 、 15 。， 。  1 ， 15 ，，  CPU 。 ， 15 ， 1 ， CPU 。 ， 1 ， 15 ，  。 vmstat 、 mpstat 。 dmesg | tail $ dmesg | tail [ 1880957.563150 ] perl invoked oom - killer : gfp_mask = 0x280da , order = 0 , oom_score_adj = 0 [...] [ 1880957.563400 ] Out of memory : Kill process 18694 ( perl ) score 246 or sacrifice child [ 1880957.563408 ] Killed process 18694 ( perl ) total - vm : 1972392 kB , anon - rss : 1953348 kB , file - rss : 0 kB [ 2320864.954447 ] TCP : Possible SYN flooding on port 7001. Dropping request . Check SNMP counters .  10 。， oom kill  TCP 。 。 。 vmstat 1 $ vmstat 1 procs --------- memory ---------- --- swap -- ----- io ---- - system -- ------ cpu ----- r b swpd free buff cache si so bi bo in cs us sy id wa st 34 0 0 200889792 73708 591828 0 0 0 5 6 10 96 1 3 0 0 32 0 0 200889920 73708 591860 0 0 0 592 13284 4282 98 1 1 0 0 32 0 0 200890112 73708 591860 0 0 0 0 9501 2154 99 1 0 0 0 32 0 0 200889568 73712 591856 0 0 0 48 11900 2459 99 0 0 0 0 32 0 0 200890208 73712 591860 0 0 0 0 15898 4840 98 1 1 0 0 ^ C vmstat ( 8 ) ，，。  1 ，， ，： r ： CPU 。 CPU ， IO 。 CPU ，  CPU 。 free ：（），，。  free ， 。 si , so ：。 0 ，（ swap ）， 。 us , sy , id , wa , st ： CPU ，（ user ）、（） （ sys ）、（ idle ）、 IO （ wait ）（ stolen ，）。  CPU ， CPU 。， ， CPU 。  IO ， IO 。 ， CPU ， CPU 。 ， r ，。 mpstat - P ALL 1 $ mpstat - P ALL 1 Linux 3.13.0 - 49 - generic ( titanclusters - xxxxx ) 07 / 14 / 2015 _x86_64_ ( 32 CPU ) 07 : 38 : 49 PM CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle 07 : 38 : 50 PM all 98.47 0.00 0.75 0.00 0.00 0.00 0.00 0.00 0.00 0.78 07 : 38 : 50 PM 0 96.04 0.00 2.97 0.00 0.00 0.00 0.00 0.00 0.00 0.99 07 : 38 : 50 PM 1 97.00 0.00 1.00 0.00 0.00 0.00 0.00 0.00 0.00 2.00 07 : 38 : 50 PM 2 98.00 0.00 1.00 0.00 0.00 0.00 0.00 0.00 0.00 1.00 07 : 38 : 50 PM 3 96.97 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 3.03 [...]  CPU ， CPU ，。 pidstat 1 $ pidstat 1 Linux 3.13.0 - 49 - generic ( titanclusters - xxxxx ) 07 / 14 / 2015 _x86_64_ ( 32 CPU ) 07 : 41 : 02 PM UID PID %usr %system %guest % CPU CPU Command 07 : 41 : 03 PM 0 9 0.00 0.94 0.00 0.94 1 rcuos / 0 07 : 41 : 03 PM 0 4214 5.66 5.66 0.00 11.32 15 mesos - slave 07 : 41 : 03 PM 0 4354 0.94 0.94 0.00 1.89 8 java 07 : 41 : 03 PM 0 6521 1596.23 1.89 0.00 1598.11 27 java 07 : 41 : 03 PM 0 6564 1571.70 7.55 0.00 1579.25 28 java 07 : 41 : 03 PM 60004 60154 0.94 4.72 0.00 5.66 9 pidstat 07 : 41 : 03 PM UID PID %usr %system %guest % CPU CPU Command 07 : 41 : 04 PM 0 4214 6.00 2.00 0.00 8.00 15 mesos - slave 07 : 41 : 04 PM 0 6521 1590.00 1.00 0.00 1591.00 27 java 07 : 41 : 04 PM 0 6564 1573.00 10.00 0.00 1583.00 28 java 07 : 41 : 04 PM 108 6718 1.00 0.00 0.00 1.00 0 snmp - pass 07 : 41 : 04 PM 60004 60154 1.00 4.00 0.00 5.00 9 pidstat ^ C pidstat  CPU ，，，。，  JAVA  1600 %  CPU ， 16  CPU 。 iostat - xz 1 $ iostat - xz 1 Linux 3.13.0 - 49 - generic ( titanclusters - xxxxx ) 07 / 14 / 2015 _x86_64_ ( 32 CPU ) avg - cpu : %user %nice %system %iowait %steal %idle 73.96 0.00 3.73 0.03 0.06 22.21 Device : rrqm / s wrqm / s r / s w / s rkB / s wkB / s avgrq - sz avgqu - sz await r_await w_await svctm %util xvda 0.00 0.23 0.21 0.18 4.52 2.08 34.37 0.00 9.98 13.80 5.42 2.44 0.09 xvdb 0.01 0.00 1.02 8.94 127.97 598.53 145.79 0.00 0.43 1.78 0.28 0.25 0.25 xvdc 0.01 0.00 1.02 8.86 127.79 595.94 146.50 0.00 0.45 1.82 0.30 0.27 0.26 dm - 0 0.00 0.00 0.69 2.32 10.47 31.69 28.01 0.01 3.23 0.71 3.98 0.13 0.04 dm - 1 0.00 0.00 0.00 0.94 0.01 3.78 8.00 0.33 345.84 0.04 346.81 0.01 0.00 dm - 2 0.00 0.00 0.09 0.07 1.35 0.36 22.50 0.00 2.55 0.23 5.62 1.78 0.03 [...] ^ C iostat  IO 。，： r / s , w / s , rkB / s , wkB / s ：（）。， 。 await ： IO ，。，，  IO 。 ，。 avgqu - sz ：。 1 ， （）。 %util ：。， 60 ， IO  （ IO ）。  100 % ，。 ，。，  IO ， ，、。 free – m $ free - m total used free shared buffers cached Mem : 245998 24545 221453 83 59 541 -/+ buffers / cache : 23944 222053 Swap : 0 0 0 free ， - m 。 IO ， 。， -/+ buffers / cache ，。 Linux ，， ，。， 。 ，（）， IO  （ iostat ），。 sar - n DEV 1 $ sar - n DEV 1 Linux 3.13.0 - 49 - generic ( titanclusters - xxxxx ) 07 / 14 / 2015 _x86_64_ ( 32 CPU ) 12 : 16 : 48 AM IFACE rxpck / s txpck / s rxkB / s txkB / s rxcmp / s txcmp / s rxmcst / s %ifutil 12 : 16 : 49 AM eth0 18763.00 5032.00 20686.42 478.30 0.00 0.00 0.00 0.00 12 : 16 : 49 AM lo 14.00 14.00 1.36 1.36 0.00 0.00 0.00 0.00 12 : 16 : 49 AM docker0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 12 : 16 : 49 AM IFACE rxpck / s txpck / s rxkB / s txkB / s rxcmp / s txcmp / s rxmcst / s %ifutil 12 : 16 : 50 AM eth0 19763.00 5101.00 21999.10 482.56 0.00 0.00 0.00 0.00 12 : 16 : 50 AM lo 20.00 20.00 3.25 3.25 0.00 0.00 0.00 0.00 12 : 16 : 50 AM docker0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ^ C sar 。，， 。， eth0 ， 22 Mbytes / s ， 176 Mbits / sec ， 1 Gbit / sec 。 sar - n TCP , ETCP 1 $ sar - n TCP , ETCP 1 Linux 3.13.0 - 49 - generic ( titanclusters - xxxxx ) 07 / 14 / 2015 _x86_64_ ( 32 CPU ) 12 : 17 : 19 AM active / s passive / s iseg / s oseg / s 12 : 17 : 20 AM 1.00 0.00 10233.00 18846.00 12 : 17 : 19 AM atmptf / s estres / s retrans / s isegerr / s orsts / s 12 : 17 : 20 AM 0.00 0.00 0.00 0.00 0.00 12 : 17 : 20 AM active / s passive / s iseg / s oseg / s 12 : 17 : 21 AM 1.00 0.00 8359.00 6039.00 12 : 17 : 20 AM atmptf / s estres / s retrans / s isegerr / s orsts / s 12 : 17 : 21 AM 0.00 0.00 0.00 0.00 0.00 ^ C sar  TCP ，： active / s ： TCP ， connect  TCP ； passive / s ： TCP ， accept  TCP ； retrans / s ： TCP ； TCP ，， 。 TCP  ，。 top $ top top - 00 : 15 : 40 up 21 : 56 , 1 user , load average : 31.09 , 29.87 , 29.92 Tasks : 871 total , 1 running , 868 sleeping , 0 stopped , 2 zombie % Cpu ( s ) : 96.8 us , 0.4 sy , 0.0 ni , 2.7 id , 0.1 wa , 0.0 hi , 0.0 si , 0.0 st KiB Mem : 25190241 + total , 24921688 used , 22698073 + free , 60448 buffers KiB Swap : 0 total , 0 used , 0 free . 554208 cached Mem PID USER PR NI VIRT RES SHR S % CPU % MEM TIME + COMMAND 20248 root 20 0 0.227 t 0.012 t 18748 S 3090 5.2 29812 : 58 java 4213 root 20 0 2722544 64640 44232 S 23.5 0.0 233 : 35.37 mesos - slave 66128 titancl + 20 0 24344 2332 1172 R 1.0 0.0 0 : 00.07 top 5235 root 20 0 38.227 g 547004 49996 S 0.7 0.2 2 : 02.74 java 4299 root 20 0 20.015 g 2.682 g 16836 S 0.3 1.1 33 : 14.42 java 1 root 20 0 33620 2920 1496 S 0.0 0.0 0 : 03.82 init 2 root 20 0 0 0 0 S 0.0 0.0 0 : 00.02 kthreadd 3 root 20 0 0 0 0 S 0.0 0.0 0 : 05.35 ksoftirqd / 0 5 root 0 - 20 0 0 0 S 0.0 0.0 0 : 00.00 kworker / 0 : 0 H 6 root 20 0 0 0 0 S 0.0 0.0 0 : 06.94 kworker / u256 : 0 8 root 20 0 0 0 0 S 0.0 0.0 2 : 38.05 rcu_sched top 。（ uptime ）、 （ free ）、 CPU （ vmstat ）。 ，。， top ， ， 、 CPU 。 ， top ，，，。  top ， 。   Linux ，，。 ，  JAVA  CPU ，。 ntpdate cp / usr / share / zoneinfo / Asia / Shanghai / etc / localtime 0 */ 1 * * * / usr / sbin / ntpdate 202 . 120 . 2 . 101 / dev / null 0 */ 1 * * * / usr / sbin / ntpdate 202 . 120 . 2 . 101 / dev / null 2 1 ntpdate 202 . 120 . 2 . 101 ntpdate s2m . time . edu . cn  Unix ： time1 - 7 . aliyun . com Windows ： time . pool . aliyun . com ntp2 . aliyun . com echo */10 * * * * /usr/sbin/ntpdate pool.ntp.org /dev/null 2 1 / var / spool / cron / root clock - w  crontab , ，，  crontab , ， / var / spool / mail  / var / spool / clientmqueue 。 wget # wget - r - p - np - k http : // xxx . edu . cn - r ,,,, , wget , - np ,. - np . - k . - p ,. - E  -- html - extension  URL “. html ” +++++++++++++++++++++++++++++++++++++++ # wget - c - t 0 - O rhel6_x86_64 . iso http : // zs . kan115 . com : 8080 / rhel6_x86_64 . iso - c  - t 0 ， 0  - O rhel6_x86_64 . iso  rhel6_x86_64 . iso http : // zs . kan115 . com : 8080 / rhel6_x86_64 . iso  ： wget  wget ，，，。。 。 ， 。 1 、 wget url + filename      2 、 O  wget - O save_name url 。 ： wget - O xx . zip http : // www . vim . org / scripts / download_script . php ? src_id = 7701  - O 。 ls - al  132 drwxr - xr - x 2 root root 4096 07 - 12 10 : 43 . drwxr - xr - x 4 root root 4096 07 - 11 16 : 26 .. - rw - r -- r -- 1 root root 50243 07 - 12 10 : 43 download_script . php ? src_id = 7701 - rw - r -- r -- 1 root root 50243 07 - 12 10 : 43 xx . zip ，。 - O ，。 - O 。 mv download_script.php?src_id=7701 yy . zip 3 、  wget -- limit - rate wget ， 。  -- limit - rate  wget -- limit - rate = 200 k http : // www . openss7 . org / repos / tarballs / strx25 - 0 . 9 . 2 . 1 . tar . bz2 4 、  wget - c  ， ^ c 。 ， - c 。 ： - c ，. 1 。 5 、 ： - b  wget - b url / filename 。 wget - log 。  tail - f wget - log  6 、 。 -- user - agent  wget -- user - agent = Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.3) Gecko / 2008092416 Firefox / 3 . 0 . 3 URL-TO-DOWNLOAD 7 、 : -- spider ，。 wget -- spider DOWNLOAD - URL  OK ，！ ： wget -- spider http://ip138.com/ips.asp?ip=58.251.193.137 action=2 Spider mode enabled . Check if remote file exists . -- 2010 - 07 - 12 11 : 36 : 32 -- http : // ip138 . com / ips . asp ? ip = 58 . 251 . 193 . 137 action = 2  ip138 . com ... 221 . 5 . 47 . 136 Connecting to ip138 . com | 221 . 5 . 47 . 136 | : 80 ... 。  HTTP ，... 200 OK ： 7817 ( 7 . 6 K ) [ text / html ] Remote file exists and could contain further links , but recursion is disabled -- not retrieving . 8 、 ： -- tries = 1000 ，，  wget  20 。  75 ， wget -- tires = 75 DOWNLOAD - URL 9 、 wget - i  download - file - list . txt ，： wget - i download - file - list . txt 10 、 ： -- mirror  ， wget -- mirror - p -- convert - links - P . / LOCAL - DIR WEBSITE - URL ： -- mirror ： - p ： html  -- convert - links ：， - P . / LOCAL - DIR ： 11 、 ， gif 。 wget -- reject = gif WEBSITE - TO - BE - DOWNLOADED 12 、 ： o wget - o xx . html . log - O xx . html http://ip138.com/ips.asp?ip=58.251.193.137 action = 2 ： [ root @ localhost opt ]# cat xx . html . log -- 2010 - 07 - 12 11 : 57 : 22 -- http : // ip138 . com / ips . asp ? ip = 58 . 251 . 193 . 137 action = 2  ip138 . com ... 221 . 5 . 47 . 136 Connecting to ip138 . com | 221 . 5 . 47 . 136 | : 80 ... 。  HTTP ，... 200 OK ： 7817 ( 7 . 6 K ) [ text / html ] Saving to : ` xx . html 0 K ....... 100 % 65 . 5 K = 0 . 1 s 2010 - 07 - 12 11 : 57 : 22 ( 65 . 5 KB / s ) - ` xx . html saved [7817/7817] 13 、 9 。 wget - Q5m - i FILE - WHICH - HAS - URLS  5 ，。 ：，， 。 14 、 11 ，   pdf ： wget - r - A . pdf http : // url - to - webpage - with - pdfs / 15 、 wget  ftp    ftp  http ： wget ftp - url 。 ，： wget -- ftp - user = USERNAME -- ftp - password = PASSWORD DOWNLOAD - URL chattr lsattr chattr chattr [ -RVf ] [ -v version ] [ mode ] files …  [ mode ]  ， [ mode ]  +-=  [ ASacDdIijsTtu ]  ，    。 + ：  ，  。 - ：  ，  。 = ：  。 A ：  atime ( access time )  ( modified ),  I / O 。 S ： I / O ， sync 。 a ： append ，  ，  ，  ，   ， root 。 c ： compresse ，  。  。 d ： no dump ， dump 。 i ：  、  、  ，  。 i  。 j ： journal ， mount ： data = ordered  data = writeback   ，  ( journal ) 。 filesystem data = journal ，  。 s ：  ，  。 u ： s ， u ，  ， undeletion 。 ai 。 a ，  。 i ， superuser ( root ) CAP_LINUX_IMMUTABLE （  ）  。 iperf 1 、 UDP   iperf - u - s  iperf - u - c 192 . 168 . 1 . 1 - b 100 M - t 60  udp ， 100 Mbps ， 192 . 168 . 1 . 1 ， 60 。 iperf - u - c 192 . 168 . 1 . 1 - b 5 M - P 30 - t 60  30 ， 5 Mbps 。 iperf - u - c 192 . 168 . 1 . 1 - b 100 M - d - t 60  100 M ，。 2 、 TCP   iperf - s  iperf - c 192 . 168 . 1 . 1 - t 60  tcp ， 192 . 168 . 1 . 1 ， 60 。 iperf - c 192 . 168 . 1 . 1 - P 30 - t 60  30 。 iperf - c 192 . 168 . 1 . 1 - d - t 60 。 ， - p  - w tcp  ethtool ethtool - p eth1 N ，， ethX ，  port  led ； N ， ps ps - eo pid , comm , lstart  pid ，， - C  ：，。 - H ：，。 ss  TCP  ss - t - a  TCP  ss - u - a  Sockets  ss - s  ss - l  socket ss - pl - h ：； - V ：； - n ：，； - a ：； - l ：； - o ：； - m ：； - p ：； - i ： TCP ； - 4 ： ipv4 ； - 6 ： ipv6 ； - t ： tcp ； - u ： udp ； - d ： DCCP ； - w ： RAW ； - x ： UNIX 。 iostat yum install sysstat iostat - x 1 Linux 2.6.32 - 504. el6 . x86_64 ( centos2 ) 12 / 26 / 2015 _x86_64_ ( 1 CPU ) avg - cpu : %user %nice %system %iowait %steal %idle 0.04 0.02 0.18 0.37 0.00 99.39 Device : rrqm / s wrqm / s r / s w / s rsec / s wsec / s avgrq - sz avgqu - sz await svctm %util sda 0.27 1.42 1.01 0.17 38.07 12.73 43.18 0.01 10.81 3.73 0.44 dm - 0 0.00 0.00 1.22 1.59 37.47 12.73 17.88 0.11 37.78 1.55 0.43 dm - 1 0.00 0.00 0.02 0.00 0.18 0.00 8.00 0.00 6.62 3.45 0.01 ，  CPU （ mpstat ）。 Device  rrqm / s  wrqm / s  r / s  w / s  rsec / s  wsec / s  rkB / s ， KB wkB / s ， KB avgrq - sz  avgqu - sz  await  I / O （ milliseconds ） svctm I / O  %util  I / O  CPU  vmstat vmstat  1 ： # vmstat 1 procs ———– memory ——— - — swap – —– io — - – system – — - cpu — - r b swpd free buff cache si so bi bo in cs us sy id wa 0 0 104300 16800 95328 72200 0 0 5 26 7 14 4 1 95 0 0 0 104300 16800 95328 72200 0 0 0 24 1021 64 1 1 98 0 0 0 104300 16800 95328 72200 0 0 0 0 1009 59 1 1 98 0 r  .  ,  CPU  . b  IO  in  cs  kernel system  ,  us  sys  wa  IO  idCPU  cp - a ： -dpR ； - d ：，， ； - f ：，； - i ：； - l ：，； - p ：； - R / r ：，； - s ：，； - u ：，； - S ：，“ SUFFIX ”； - b ：； - v ：。 \\ cp - vupf ，，\\ cp  alias cp = cp -i rsync 。 SRC  DES  : 。 rsync - a / data / backup  shell  (  rsh 、 ssh ) 。  DST  : 。 rsync - avz * . c foo : src  shell  (  rsh 、 ssh ) 。  SRC  : 。 rsync - avz foo : src / bar / data  rsync 。 SRC  :: 。 rsync - av root @192.168.78.192 :: www / databack  rsync 。 DST  :: 。 rsync - av / databack root @192.168.78.192 :: www - v , -- verbose 。 - q , -- quiet 。 - c , -- checksum ，。 - a , -- archive ，，， - rlptgoD 。 - r , -- recursive 。 - R , -- relative 。 - b , -- backup ，，  ~ filename 。 -- suffix 。 -- backup - dir  (  ~ filename ) 。 - suffix = SUFFIX 。 - u , -- update ， DST ， ，。 - l , -- links 。 - L , -- copy - links 。 -- copy - unsafe - links  SRC 。 -- safe - links  SRC 。 - H , -- hard - links 。 - p , -- perms 。 - o , -- owner 。 - g , -- group 。 - D , -- devices 。 - t , -- times 。 - S , -- sparse  DST 。 - n , -- dry - run 。 - w , -- whole - file ，。 - x , -- one - file - system 。 - B , -- block - size = SIZE ， 700 。 - e , -- rsh = command  rsh 、 ssh 。 -- rsync - path = PATH  rsync 。 - C , -- cvs - exclude  CVS ，。 -- existing  DST ，。 -- delete  DST  SRC 。 -- delete - excluded 。 -- delete - after 。 -- ignore - errors  IO 。 -- max - delete = NUM  NUM 。 -- partial ，。 -- force ，。 -- numeric - ids  id 。 -- timeout = time ip ，。 - I , -- ignore - times 。 -- size - only ，。 -- modify - window = NUM ， 0 。 - T -- temp - dir = DIR  DIR 。 -- compare - dest = DIR  DIR 。 - P  -- partial 。 -- progress 。 - z , -- compress 。 -- exclude = PATTERN 。 -- include = PATTERN 。 -- exclude - from = FILE  FILE 。 -- include - from = FILE  FILE 。 -- version 。 -- address 。 -- config = FILE ， rsyncd . conf 。 -- port = PORT  rsync 。 -- blocking - io  shell  IO 。 - stats 。 -- progress 。 -- log - format = formAT 。 -- password - file = FILE  FILE 。 -- bwlimit = KBPS  I / O ， KBytes per second 。  1 install yum install rsync vim / etc / rsyncd / rsyncd . conf uid = root gid = root port = 873 max connections = 0 # limit client conection log file =/ var / log / rsyncd . log pid file =/ var / run / rsyncd . pid lock file =/ var / run / rsyncd . lock motd file = / etc / rsyncd / rsyncd . motd read only = yes  ####limit user conn###### hosts allow = 192.168.18.0 / 255.255.255.0 hosts deny =* #transfer logging = yes #log format = %t %a %m %f %b #syslog facility = local3 #timeout = 300 [ www ] path = / tmp / www / list = yes ignore errors auth users = www ###username secrets file = / etc / rsyncd / rsyncd . secrets comment = www directory exclude = a / b / ##### a , b directory not backup [ root @ www rsyncd ] # cat rsyncd . motd ##################### www . vfast . com rsync ##################### [ root @ www rsyncd ] # cat rsyncd . secrets www : 123 [ root @ www rsyncd ] # chmod 600 rsyncd . secrets 4 start [ root @ www rsyncd ] # rsync -- daemon -- config =/ etc / rsyncd / rsyncd . conf [ root @ www rsyncd ] # lsof - i : 873 COMMAND PID USER FD TYPE DEVICE SIZE NODE NAME rsync 8043 root 4u IPv6 22013 TCP *: rsync ( LISTEN ) rsync 8043 root 5u IPv4 22014 TCP *: rsync ( LISTEN ) 5 check log tail - f / var / log / rsyncd . log client : 192.168.18.146 echo 123 / etc / rsync . password chmod 600 / etc / rsync . password mkdir - pv / tmp / www rsync - avzP -- delete -- password - file =/ etc / rsync . password www @192.168.18.254 :: www / tmp / www ##################### www . vfast . com rsync ##################### receiving file list ... 3 files to consider deleting f / deleting d / deleting abcd / deleting c / 3 deleting c / 2 deleting c / 1 . / c / c / c1 6 100 % 5.86 kB / s 0 : 00 : 00 ( xfer # 1 , to - check = 0 / 3 ) sent 129 bytes received 260 bytes 778.00 bytes / sec total size is 6 speedup is 0.02 146 # cd / tmp / www / 146 # tree . ` -- c ` -- c1 1 directory , 1 file 192.168.18.254 server rm - fr / tmp / c / c1 146 # rsync - avzP -- delete -- password - file =/ etc / rsync . password www @192.168.18.254 :: www / tmp / www ##################### www . vfast . com rsync ##################### receiving file list ... 2 files to consider deleting c / c1 c / sent 101 bytes received 191 bytes 194.67 bytes / sec total size is 0 speedup is 0.00 146 # tree . ` -- c 1 directory , 0 files crontab - e 10 2 * * * rsync - avzP -- delete -- password - file =/ etc / rsync . password www @192.168.18.254 :: www / tmp / www  server sersync2 + rsync 192.168.18.254 client rsync 192.168.18.146 apache - server [ root @ www tmp ] # tar fvxz sersync . tar . gz GNU - Linux - x86 / GNU - Linux - x86 / sersync2 GNU - Linux - x86 / confxml . xml [ root @ www tmp ] # cd GNU - Linux - x86 / vim confxml . xml sersync localpath watch = /tmp/www remote ip = 192.168.18.146 name = www / commonParams params = -artuz / auth start = true users = kyo passwordfile = /etc/146rsync.pass / failLog path = /tmp/rsync_fail_log timeToExecute = 60 / !-- default every 60 mins execute once -- ; client 192.168.18.146 146 # chmod 600 / etc / rsyncd / rsyncd . secrets 146 # cat / etc / rsyncd / rsyncd . secrets kyo : 123 146 # cat / etc / rsyncd / rsyncd . conf uid = root gid = root port = 873 max connections = 0 # limit client conection use chroot = no log file =/ var / log / rsyncd . log pid file =/ var / run / rsyncd . pid lock file =/ var / run / rsyncd . lock motd file = / etc / rsyncd / rsyncd . motd read only = no ############### !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! ####limit user conn###### hosts allow = 192.168.18.0 / 255.255.255.0 hosts deny =* #transfer logging = yes #log format = %t %a %m %f %b #syslog facility = local3 #timeout = 300 [ www ] path = / tmp / www list = yes ignore errors auth users = kyo ###username!! secrets file = / etc / rsyncd / rsyncd . secrets comment = www directory read only = no 146 # rsync -- daemon -- config =/ etc / rsyncd / rsyncd . conf 146 # lsof - i : 873 COMMAND PID USER FD TYPE DEVICE SIZE NODE NAME rsync 4356 root 4u IPv6 14561 TCP *: rsync ( LISTEN ) rsync 4356 root 5u IPv4 14562 TCP *: rsync ( LISTEN ) server 192.168.18.254 [ root @ www GNU - Linux - x86 ] # cat / etc / 146 rsync . pass 123 [ root @ www GNU - Linux - x86 ] # chmod 600 / etc / 146 rsync . pass [ root @ www www ] # ps axu | grep rsync root 8043 0.0 0.0 5252 480 ? Ss 11 : 08 0 : 00 rsync -- daemon -- config =/ etc / rsyncd / rsyncd . conf root 8191 0.6 2.3 82416 24024 pts / 7 S + 11 : 17 0 : 11 gedit rsync . txt root 8668 0.0 0.0 5024 696 pts / 3 S + 11 : 46 0 : 00 grep rsync [ root @ www www ] # kill - 9 8043 test [ root @ www GNU - Linux - x86 ] # pwd / tmp / GNU - Linux - x86 # ./sersync2 -r #run first! [ root @ www GNU - Linux - x86 ] # . / sersync2 set the system param execute ： echo 50000000 / proc / sys / fs / inotify / max_user_watches execute ： echo 327679 / proc / sys / fs / inotify / max_queued_events parse the command param daemon thread num : 10 parse xml config file host ip : localhost host port : 8008 use rsync password - file : user is kyo passwordfile is / etc / 146 rsync . pass config xml parse success please set / etc / rsyncd . conf max connections = 0 Manually sersync working thread 12 = 1 ( primary thread ) + 1 ( fail retry thread ) + 10 ( daemon sub threads ) Max threads numbers is : 22 = 12 ( Thread pool nums ) + 10 ( Sub threads ) please according your cpu ， use - n param to adjust the cpu rate run the sersync : watch path is : / tmp / www snmpwalk yum install net-snmp-utils -y snmpwalk -c public -v 2c 172.31.38.23 ifDescr  snmpwalk -c public -v 2c 172.31.38.23 IF-MIB::ifInOctets  snmpwalk -c public -v 2c 172.31.38.23 IF-MIB::ifOutOctets  snmpwalk -c public -v 2c 172.31.38.23 IF-MIB::ifInOctets.13  snmpwalk -c public -v 2c 172.31.38.23 IF-MIB::ifHCInOctets.13 64, snmpwalk -c public -v 2c 172.31.38.23 IF-MIB::ifHCOutOctets.13 64, （count32），(-)/，   # !/ usr / bin / env bash api = http : // 127 . 0 . 0 . 1 : 1988 / v1 / push ts = $ ( date +% s ) [ - d / tmp / snmp ] || mkdir / tmp / snmp cd / usr / local / open - falcon / switch - custom snmpuser = user snmppwd = pass # snmpwalk - v 3 - u user - a MD5 - A pass 172 . 19 . 2 . 30 ifDescr IF - MIB :: ifInOctets . 13 # awk {print $NF*8} stat = $ ( curl http : // 127 . 0 . 0 . 1 : 1988 - o / dev / null - s - w % { http_code } ) if [ $ stat - ne 404 ] ;then exit fi getflow () { snmpwalk - l auth - v 3 - u $ snmpuser - a MD5 - A $ snmppwd $2 ifDescr | grep - vi VLAN / tmp / snmp / $1 _port snmpwalk - l auth - v 3 - u $ snmpuser - a MD5 - A $ snmppwd $2 IF - MIB :: ifHCInOctets / tmp / snmp / $1 _in snmpwalk - l auth - v 3 - u $ snmpuser - a MD5 - A $ snmppwd $2 IF - MIB :: ifHCOutOctets / tmp / snmp / $1 _out result = while read snport do port_name = $ ( echo $ snport | awk {print $NF} ) port_id = $ ( echo $ snport | awk {print $1} | grep - Po \\d+ ) net_in = $ ( awk /IF-MIB::ifHCInOctets.$port_id = / {print $NF*8} / tmp / snmp / $1 _in ) net_out = $ ( awk /IF-MIB::ifHCOutOctets.$port_id = / {print $NF*8} / tmp / snmp / $1 _out ) # echo $ port_name ,$ port_id ,$ net_in ,$ net_out net_all = {\\ metric \\ : \\ switch . if . In \\ , \\ endpoint \\ : \\ $1 \\ , \\ timestamp \\ : $ts,\\ step \\ : 60,\\ value \\ : $net_in, \\ counterType\\ : \\ COUNTER\\ ,\\ tags\\ : \\ ifName=$port_name\\ },{\\ metric\\ : \\ switch.if.Out\\ , \\ endpoint\\ : \\ $1\\ , \\ timestamp\\ : $ ts ,\\ step\\ : 60 ,\\ value\\ : $ net_out ,\\ counterType\\ : \\ COUNTER\\ ,\\ tags\\ : \\ ifName=$port_name\\ } curl - s - X POST - d [$net_all] $a pi / dev / null # echo $ net_all # result = $ result $ net_all done / tmp / snmp / $1 _port # echo $ result | sed s/,$//g # curl - s - X POST - d [$(echo $result | sed s / ,$ // g )] $a pi / dev / null } while read line do getflow $ line # getflow $ line done sw - host . txt iptables iptables - t  - A  lt ;-i/o  gt; -p  lt;-s IP/ gt; --sport  lt;-d IP/ gt; --dport  -j  - A ：； - D ：； - I ：； - L ：； ： raw ：，：。 mangle ：（ QOS ），。 nat ：，。 filter ：，。 ： INPUT ：。 OUTPUT ：。 PORWARD ：。 PREROUTING ：（ DNAT ）。 POSTOUTING ：（ SNAT ）。 ： ACCEPT ：。 REJECT ：。 DROP ：。 REDIRECT ：、、。 SNAT ：。 DNAT ：。 MASQUERADE ： IP （ NAT ）， ADSL 。 LOG ：。  iptables  iptables - F iptables - X iptables - Z  chain  iptables - P INPUT DROP iptables - P FORWARD ACCEPT iptables - P OUTPUT ACCEPT  iptables - A INPUT - m state -- state ESTABLISHED , RELATED - j ACCEPT  ( ， ) iptables - A INPUT - s 127 . 0 . 0 . 1 - d 127 . 0 . 0 . 1 - j ACCEPT  (  ) iptables - A OUTPUT - j ACCEPT  iptables - A INPUT - p tcp -- dport 22 - j ACCEPT -- dport 8000 : 10000   22  iptables - A INPUT - j reject  iptables - A FORWARD - j REJECT   IP iptables - I INPUT - s 123 . 45 . 6 . 7 - j DROP  IP  iptables - I INPUT - s 123 . 0 . 0 . 0 / 8 - j DROP  123 . 0 . 0 . 1  123 . 255 . 255 . 254   iptables  iptables - L - n - v  iptables - nL -- line - number  iptables - D FORWARD 2  FORWARD  2 ，。 nat ， - t nat iptables - D INPUT - j REJECT -- reject - with icmp - host - prohibited ，， iptables : No chain / target / match by that name .  iptables - A INPUT - m state – state INVALID - j DROP iptables - A OUTPUT - m state – state INVALID - j DROP iptables - A FORWARD - m state – state INVALID - j DROP 2 . 1   ip_forward ,: # echo 1 gt ; /proc/sys/net/ipv4/ip_forward //  # vi / ect / sysctl . conf //  # sysctl - p  # iptables - t nat - A PREROUTING - p tcp - m tcp -- dport 80 - j REDIRECT -- to - ports 8080  iptables  ， INPUT ，（）， 8080 ， 80 ： # iptables - A INPUT - s 172 . 29 . 88 . 0 / 24 - p tcp - m state -- state NEW - m tcp -- dport 8080 - j ACCEPT  http  80  8080 （），， curl  firfox  http : // localhost : 80  http : // doman . com : 80 （），， OUTPUT ： iptables - t nat - A OUTPUT - p tcp -- dport 80 - j REDIRECT -- to - ports 8080 ： iptables - t nat - A PREROUTING - p tcp - i eth0 - d $ YOUR_HOST_IP -- dport 80 - j DNAT -- to $ YOUR_HOST_IP : 8080 iptables - t nat - A OUTPUT - p tcp - d $ YOUR_HOST_IP -- dport 80 - j DNAT -- to 127 . 0 . 0 . 1 : 8080 iptables - t nat - A OUTPUT - p tcp - d 127 . 0 . 0 . 1 -- dport 80 - j DNAT -- to 127 . 0 . 0 . 1 : 8080  ，， IP (  PC )  iptables 。（， linux  ）  192 . 168 . 10 . 100 : 8000 ， 172 . 29 . 88 . 56 : 80 ， 192 . 168 . 10 . 100 : iptables - t nat - A PREROUTING - i eth0 - p tcp - d 192 . 168 . 10 . 100 -- dport 8000 - j DNAT -- to - destination 172 . 29 . 88 . 56 : 80 iptables - t nat - A POSTROUTING - o eth0 - j SNAT -- to - source 192 . 168 . 10 . 100  iptables - t nat - A PREROUTING - d 192 . 168 . 10 . 100 - p tcp -- dport 8000 - j DNAT -- to 172 . 29 . 88 . 56 : 80 iptables - t nat - A POSTROUTING - d 172 . 29 . 88 . 56 - p tcp -- dport 80 - j SNAT -- to - source 192 . 168 . 10 . 100 ， FORWARD  DROP ， FORWARD ： iptables - A FORWARD - d 172 . 29 . 88 . 56 - p tcp -- dport 80 - j ACCEPT iptables - A FORWARD - s 172 . 29 . 88 . 56 - p tcp - j ACCEPT 2 . 2   22  INPUT ， input  1 ， / var / log / message ， -- limit ： iptables - R INPUT 1 - p tcp -- dport 22 - m limit -- limit 3 / minute -- limit - burst 8 - j LOG vi / etc / rsyslog . conf ， kern . = notice / var / log / iptables . log ，。 service rsyslog restart # 2 . 3  DoS  SYN  SYN  DoS ， DoS ： ipt - tcp . sh ： iptables - N syn - flood ( “ : syn - flood - [ 0 : 0 ] ”， ) iptables - A INPUT - p tcp -- syn - j syn - flood iptables - I syn - flood - p tcp - m limit -- limit 2 / s -- limit - burst 5 - j RETURN iptables - A syn - flood - j REJECT #  DOS , IP  15 , #  iptables v1 . 4 . 19 ： iptables - V iptables - A INPUT - p tcp -- syn - i eth0 -- dport 80 - m connlimit -- connlimit - above 20 -- connlimit - mask 24 - j DROP # Iptables  DDOS (  ) iptables - A INPUT - p tcp -- syn - m limit -- limit 5 / s -- limit - burst 10 - j ACCEPT iptables - A FORWARD - p tcp -- syn - m limit -- limit 1 / s - j ACCEPT iptables - A FORWARD - p icmp - m limit -- limit 2 / s -- limit - burst 10 - j ACCEPT iptables - A INPUT - p icmp -- icmp - type 0 - s ! 172 . 29 . 73 . 0 / 24 - j DROP  iptables - save gt ; iptales.bak cat iptables . bak | iptables - restore / etc / init . d / iptables save (  ) centos 7 yum install - y iptables iptables - services / usr / libexec / iptables / iptables . init save logrotate 1 . (  rotate . conf ，。 ) / usr / sbin / logrotate - v / etc / logrotate . conf 2 . (  rotate . conf ，,， debug  ) / usr / sbin / logrotate - d / etc / logrotate . conf 3 . (  log  ) vi / var / lib / logrotate . status 4 . (  rpm  logrotate  ) ls / etc / logrotate . d /  vim / etc / logrotate . d / tomcat / usr / local / tomcat_pingtai / logs / catalina . out { copytruncate daily dateext rotate 30 missingok } logtotate - d / etc / logrotate . d / tomcat    compress  gzip  nocompress ， copytruncate ， nocopytruncate  create mode owner group ， nocreate  delaycompress  compress ， nodelaycompress  delaycompress ，。 errors address  Email  ifempty ， logrotate 。 notifempty ， mail address  E - mail  nomail  olddir directory ， noolddir  prerotate / endscript ， postrotate / endscript ， daily  weekly  monthly  rotate count ， 0 ， 5  5  tabootext [ + ] list  logrotate ，：. rpm - orig , . rpmsave , v ,  ~ size size ， Size  bytes (  )  K ( sizek )  M ( sizem ) . ： 1 . log does not need rotating logrotate ： configure  1 。 logrotate  rotate 。， logrotate  status  rotate ，  status ，。， rotate ，。 ：， 3 ，，。 - s  status ,。 2 .  log  rotate  rpm ， conf  / etc / logrotate . d / ， cron . daily 。 ： / etc / logrotate . d /  3 . compress 、 copytruncate 、 delaycompress 、 dateext ：  ( name - 20090713 ) ，， ， log  rotate ，。 name - 20090714 ， (  rotate n  ) ,。","title":"command"},{"location":"command/#find","text":" find vipkid / media /* -mtime -1 | xargs du -sm | awk {sum +=$1}END{print sum}  find . -empty  find . /home.txt find /home -name *.txt ， find /home -iname *.txt .txt.pdf find . \\( -name *.txt -o -name *.pdf \\)  find . -name *.txt -o -name *.pdf  find /usr/ -path *local*  find . -regex .*\\(\\.txt\\|\\.pdf\\)$ ， find . -iregex .*\\(\\.txt\\|\\.pdf\\)$ /home.txt find /home ! -name *.txt  find . -type  ： f  l  d  c  b  s  p Fifo  3 find . -maxdepth 3 -type f 2 find . -mindepth 2 -type f  find . -type f  UNIX/Linux： （-atime/，-amin/）：, ls, more ,  chmod, chown, ls, stat ,  ls -utl ; （-mtime/，-mmin/）：,  vi , , atime  ctime  （-ctime/，-cmin/）：（）, chmod, chown ,  stat file ; ---(+n)----------|----------(n)----------|----------(-n)--- (n+1)*24H| (n+1)*24H~n*24H |n*24H -ctime -n  n*24H  -ctime n  n*24H , (n+1)*24H  -ctime +n  (n+1)*24H  ： linux ，， 。 #ls -lt /home/admin #  #ls -lut /home/admin #  ( -r)  find . -type f -atime -7  find . -type f -atime 7  find . -type f -atime +7 10 find . -type f -amin +10 file.log find . -type f -newer file.log  find . -type f -size  ： b —— （512） c ——  w ——  （2） k ——  M ——  G ——  10KB find . -type f -size +10k 10KB find . -type f -size -10k 10KB find . -type f -size 10k  .txt find . -type f -name *.txt -delete -exec root，tom find .-type f -user root -exec chown tom {} \\; ，{} -exec，。 .txt find $HOME/. -name *.txt -ok rm {} \\ ; ，-ok-exec，，。 .txtall.txt find . -type f -name *.txt -exec cat {} \\ ; all.txt 30.logold find . -type f -mtime +30 -name *.log -exec cp {} old \\ ; .txt“File:” find . -type f -name *.txt -exec printf File: %s\\n {} \\ ; -exec，-exec -exec ./text.sh {} \\;  .txt，sk find . -path ./sk -prune -o -name *.txt -print find http://man.linuxde.net","title":"find"},{"location":"command/#date","text":"# ： 2016 - 10 - 24 11 : 20 : 30  1  50  time1 = $ ( date +% s - d 2016-10-24 11:20:30 ) #  # time1 = $ ( date +% s ) #  time2 = $ (( 1 * 60 * 60 + 50 * 60 )) # 1  50  timesnmp1 = $ (( $ time1 + $ time2 )) echo $ ( date + %F %T - d 1970-01-01 UTC $timesnmp1 seconds ) timesnmp2 = $ (( $ time1 - $ time2 )) echo $ ( date + %F %T - d 1970-01-01 UTC $timesnmp2 seconds )","title":"date"},{"location":"command/#tar","text":"Linux  tar ， tar （ tape archive ）， ， 。 tar 。， ， 。 1 .  - z , --gzip：gzip（），.gz - c , --create：tar，.tar - f , --file=： - x , --extract：，-c - p ： - g ： - C ： --exclude：，  - X , --exclude-from：（--exclude=） - t , --list：，-c、-x - j , --bzip2：bzip2（），.bz2 - P ：， - v ：（）， 2 . （） （）， ， tar  ，， - g 。 ， 。  # tar - g / tmp / snapshot_data . snap - zcpf / tmp / data01 . tar . gz .  # tar - zxpf / tmp / data01 . tar . gz - C . - g ，， / tmp / snapshot_data . snap ， 。，（ ），  - g ，，， 。 ，“”，， （）， 。，。，  ，。 ，：  / tmp / data ， cache  （ 4 G ），（ 1 G ） ， # cd / tmp / data  # rm - f / tmp / snapshot_data . snap # tar - g / tmp / snapshot_data . snap - zcpf - --exclude=./cache ./ | split -b 1024M - /tmp/bak_data$(date -I).tar.gz_  aa , ab , ac ,... ， bak_data2014 - 12 - 07 . tar . gz_aa bak_data2014 - 12 - 07 . tar . gz_ab bak_data2014 - 12 - 07 . tar . gz_ac ...  ，，，  ， split  aa , ab ，（），  ：（ ，$ ( date +% Y -% m -% d_ % H ) ） # tar - g / tmp / snapshot_data . snap - zcpf / tmp / bak_data2014 - 12 - 07 . tar . gz --exclude=./cache ./  # tar - g / tmp / snapshot_data . snap - zcpf / tmp / bak_data2014 - 12 - 08 . tar . gz --exclude=./cache ./    / tmp / data /  # cat / tmp / bak_data2014 - 12 - 07 . tar . gz_ * | tar - zxpf - - C / tmp / data /  $ tar – zxpf / tmp / bak_data2014 - 12 - 07 . tar . gz - C / tmp / data / $ tar – zxpf / tmp / bak_data2014 - 12 - 08 . tar . gz - C / tmp / data / ... ， ，，， crontab 。 3 .  ， cpio , rsync , dump , tar ， tar  Linux ，。  Linux （ CentOS ）， / proc 、 / lost + found 、 / sys 、 / mnt 、 / media 、 / dev 、 / proc 、 / tmp ，  / dev / st0 ， / backup ， ， NFS  。  # vi / backup / backup_tar_exclude . list / backup / proc / lost + found / sys / mnt / media / dev / tmp $ tar - zcpf / backup / backup_full . tar . gz - g / backup / tar_snapshot . snap --exclude-from=/backup/tar_exclude.list / 4 .   tar ，。 tar  atime ，  ID ， USERID ， ","title":"tar"},{"location":"command/#linux","text":" Linux ，， Linux  ？ Netflix ，。  ， 1 。 uptime dmesg | tail vmstat 1 mpstat - P ALL 1 pidstat 1 iostat - xz 1 free - m sar - n DEV 1 sar - n TCP , ETCP 1 top  sysstat ， procps 。， ， （ CPU 、、 IO ）（ utilization ）、（ saturation ）（ error ） ， USE 。 ，，。 uptime $ uptime 23 : 51 : 26 up 21 : 31 , 1 user , load average : 30.02 , 26.43 , 19.02 。 Linux ， CPU   IO （ D ） 。。  1 、 5 、 15 。， 。  1 ， 15 ，，  CPU 。 ， 15 ， 1 ， CPU 。 ， 1 ， 15 ，  。 vmstat 、 mpstat 。 dmesg | tail $ dmesg | tail [ 1880957.563150 ] perl invoked oom - killer : gfp_mask = 0x280da , order = 0 , oom_score_adj = 0 [...] [ 1880957.563400 ] Out of memory : Kill process 18694 ( perl ) score 246 or sacrifice child [ 1880957.563408 ] Killed process 18694 ( perl ) total - vm : 1972392 kB , anon - rss : 1953348 kB , file - rss : 0 kB [ 2320864.954447 ] TCP : Possible SYN flooding on port 7001. Dropping request . Check SNMP counters .  10 。， oom kill  TCP 。 。 。 vmstat 1 $ vmstat 1 procs --------- memory ---------- --- swap -- ----- io ---- - system -- ------ cpu ----- r b swpd free buff cache si so bi bo in cs us sy id wa st 34 0 0 200889792 73708 591828 0 0 0 5 6 10 96 1 3 0 0 32 0 0 200889920 73708 591860 0 0 0 592 13284 4282 98 1 1 0 0 32 0 0 200890112 73708 591860 0 0 0 0 9501 2154 99 1 0 0 0 32 0 0 200889568 73712 591856 0 0 0 48 11900 2459 99 0 0 0 0 32 0 0 200890208 73712 591860 0 0 0 0 15898 4840 98 1 1 0 0 ^ C vmstat ( 8 ) ，，。  1 ，， ，： r ： CPU 。 CPU ， IO 。 CPU ，  CPU 。 free ：（），，。  free ， 。 si , so ：。 0 ，（ swap ）， 。 us , sy , id , wa , st ： CPU ，（ user ）、（） （ sys ）、（ idle ）、 IO （ wait ）（ stolen ，）。  CPU ， CPU 。， ， CPU 。  IO ， IO 。 ， CPU ， CPU 。 ， r ，。 mpstat - P ALL 1 $ mpstat - P ALL 1 Linux 3.13.0 - 49 - generic ( titanclusters - xxxxx ) 07 / 14 / 2015 _x86_64_ ( 32 CPU ) 07 : 38 : 49 PM CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle 07 : 38 : 50 PM all 98.47 0.00 0.75 0.00 0.00 0.00 0.00 0.00 0.00 0.78 07 : 38 : 50 PM 0 96.04 0.00 2.97 0.00 0.00 0.00 0.00 0.00 0.00 0.99 07 : 38 : 50 PM 1 97.00 0.00 1.00 0.00 0.00 0.00 0.00 0.00 0.00 2.00 07 : 38 : 50 PM 2 98.00 0.00 1.00 0.00 0.00 0.00 0.00 0.00 0.00 1.00 07 : 38 : 50 PM 3 96.97 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 3.03 [...]  CPU ， CPU ，。 pidstat 1 $ pidstat 1 Linux 3.13.0 - 49 - generic ( titanclusters - xxxxx ) 07 / 14 / 2015 _x86_64_ ( 32 CPU ) 07 : 41 : 02 PM UID PID %usr %system %guest % CPU CPU Command 07 : 41 : 03 PM 0 9 0.00 0.94 0.00 0.94 1 rcuos / 0 07 : 41 : 03 PM 0 4214 5.66 5.66 0.00 11.32 15 mesos - slave 07 : 41 : 03 PM 0 4354 0.94 0.94 0.00 1.89 8 java 07 : 41 : 03 PM 0 6521 1596.23 1.89 0.00 1598.11 27 java 07 : 41 : 03 PM 0 6564 1571.70 7.55 0.00 1579.25 28 java 07 : 41 : 03 PM 60004 60154 0.94 4.72 0.00 5.66 9 pidstat 07 : 41 : 03 PM UID PID %usr %system %guest % CPU CPU Command 07 : 41 : 04 PM 0 4214 6.00 2.00 0.00 8.00 15 mesos - slave 07 : 41 : 04 PM 0 6521 1590.00 1.00 0.00 1591.00 27 java 07 : 41 : 04 PM 0 6564 1573.00 10.00 0.00 1583.00 28 java 07 : 41 : 04 PM 108 6718 1.00 0.00 0.00 1.00 0 snmp - pass 07 : 41 : 04 PM 60004 60154 1.00 4.00 0.00 5.00 9 pidstat ^ C pidstat  CPU ，，，。，  JAVA  1600 %  CPU ， 16  CPU 。 iostat - xz 1 $ iostat - xz 1 Linux 3.13.0 - 49 - generic ( titanclusters - xxxxx ) 07 / 14 / 2015 _x86_64_ ( 32 CPU ) avg - cpu : %user %nice %system %iowait %steal %idle 73.96 0.00 3.73 0.03 0.06 22.21 Device : rrqm / s wrqm / s r / s w / s rkB / s wkB / s avgrq - sz avgqu - sz await r_await w_await svctm %util xvda 0.00 0.23 0.21 0.18 4.52 2.08 34.37 0.00 9.98 13.80 5.42 2.44 0.09 xvdb 0.01 0.00 1.02 8.94 127.97 598.53 145.79 0.00 0.43 1.78 0.28 0.25 0.25 xvdc 0.01 0.00 1.02 8.86 127.79 595.94 146.50 0.00 0.45 1.82 0.30 0.27 0.26 dm - 0 0.00 0.00 0.69 2.32 10.47 31.69 28.01 0.01 3.23 0.71 3.98 0.13 0.04 dm - 1 0.00 0.00 0.00 0.94 0.01 3.78 8.00 0.33 345.84 0.04 346.81 0.01 0.00 dm - 2 0.00 0.00 0.09 0.07 1.35 0.36 22.50 0.00 2.55 0.23 5.62 1.78 0.03 [...] ^ C iostat  IO 。，： r / s , w / s , rkB / s , wkB / s ：（）。， 。 await ： IO ，。，，  IO 。 ，。 avgqu - sz ：。 1 ， （）。 %util ：。， 60 ， IO  （ IO ）。  100 % ，。 ，。，  IO ， ，、。 free – m $ free - m total used free shared buffers cached Mem : 245998 24545 221453 83 59 541 -/+ buffers / cache : 23944 222053 Swap : 0 0 0 free ， - m 。 IO ， 。， -/+ buffers / cache ，。 Linux ，， ，。， 。 ，（）， IO  （ iostat ），。 sar - n DEV 1 $ sar - n DEV 1 Linux 3.13.0 - 49 - generic ( titanclusters - xxxxx ) 07 / 14 / 2015 _x86_64_ ( 32 CPU ) 12 : 16 : 48 AM IFACE rxpck / s txpck / s rxkB / s txkB / s rxcmp / s txcmp / s rxmcst / s %ifutil 12 : 16 : 49 AM eth0 18763.00 5032.00 20686.42 478.30 0.00 0.00 0.00 0.00 12 : 16 : 49 AM lo 14.00 14.00 1.36 1.36 0.00 0.00 0.00 0.00 12 : 16 : 49 AM docker0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 12 : 16 : 49 AM IFACE rxpck / s txpck / s rxkB / s txkB / s rxcmp / s txcmp / s rxmcst / s %ifutil 12 : 16 : 50 AM eth0 19763.00 5101.00 21999.10 482.56 0.00 0.00 0.00 0.00 12 : 16 : 50 AM lo 20.00 20.00 3.25 3.25 0.00 0.00 0.00 0.00 12 : 16 : 50 AM docker0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ^ C sar 。，， 。， eth0 ， 22 Mbytes / s ， 176 Mbits / sec ， 1 Gbit / sec 。 sar - n TCP , ETCP 1 $ sar - n TCP , ETCP 1 Linux 3.13.0 - 49 - generic ( titanclusters - xxxxx ) 07 / 14 / 2015 _x86_64_ ( 32 CPU ) 12 : 17 : 19 AM active / s passive / s iseg / s oseg / s 12 : 17 : 20 AM 1.00 0.00 10233.00 18846.00 12 : 17 : 19 AM atmptf / s estres / s retrans / s isegerr / s orsts / s 12 : 17 : 20 AM 0.00 0.00 0.00 0.00 0.00 12 : 17 : 20 AM active / s passive / s iseg / s oseg / s 12 : 17 : 21 AM 1.00 0.00 8359.00 6039.00 12 : 17 : 20 AM atmptf / s estres / s retrans / s isegerr / s orsts / s 12 : 17 : 21 AM 0.00 0.00 0.00 0.00 0.00 ^ C sar  TCP ，： active / s ： TCP ， connect  TCP ； passive / s ： TCP ， accept  TCP ； retrans / s ： TCP ； TCP ，， 。 TCP  ，。 top $ top top - 00 : 15 : 40 up 21 : 56 , 1 user , load average : 31.09 , 29.87 , 29.92 Tasks : 871 total , 1 running , 868 sleeping , 0 stopped , 2 zombie % Cpu ( s ) : 96.8 us , 0.4 sy , 0.0 ni , 2.7 id , 0.1 wa , 0.0 hi , 0.0 si , 0.0 st KiB Mem : 25190241 + total , 24921688 used , 22698073 + free , 60448 buffers KiB Swap : 0 total , 0 used , 0 free . 554208 cached Mem PID USER PR NI VIRT RES SHR S % CPU % MEM TIME + COMMAND 20248 root 20 0 0.227 t 0.012 t 18748 S 3090 5.2 29812 : 58 java 4213 root 20 0 2722544 64640 44232 S 23.5 0.0 233 : 35.37 mesos - slave 66128 titancl + 20 0 24344 2332 1172 R 1.0 0.0 0 : 00.07 top 5235 root 20 0 38.227 g 547004 49996 S 0.7 0.2 2 : 02.74 java 4299 root 20 0 20.015 g 2.682 g 16836 S 0.3 1.1 33 : 14.42 java 1 root 20 0 33620 2920 1496 S 0.0 0.0 0 : 03.82 init 2 root 20 0 0 0 0 S 0.0 0.0 0 : 00.02 kthreadd 3 root 20 0 0 0 0 S 0.0 0.0 0 : 05.35 ksoftirqd / 0 5 root 0 - 20 0 0 0 S 0.0 0.0 0 : 00.00 kworker / 0 : 0 H 6 root 20 0 0 0 0 S 0.0 0.0 0 : 06.94 kworker / u256 : 0 8 root 20 0 0 0 0 S 0.0 0.0 2 : 38.05 rcu_sched top 。（ uptime ）、 （ free ）、 CPU （ vmstat ）。 ，。， top ， ， 、 CPU 。 ， top ，，，。  top ， 。   Linux ，，。 ，  JAVA  CPU ，。","title":"Linux"},{"location":"command/#ntpdate","text":"cp / usr / share / zoneinfo / Asia / Shanghai / etc / localtime 0 */ 1 * * * / usr / sbin / ntpdate 202 . 120 . 2 . 101 / dev / null 0 */ 1 * * * / usr / sbin / ntpdate 202 . 120 . 2 . 101 / dev / null 2 1 ntpdate 202 . 120 . 2 . 101 ntpdate s2m . time . edu . cn  Unix ： time1 - 7 . aliyun . com Windows ： time . pool . aliyun . com ntp2 . aliyun . com echo */10 * * * * /usr/sbin/ntpdate pool.ntp.org /dev/null 2 1 / var / spool / cron / root clock - w  crontab , ，，  crontab , ， / var / spool / mail  / var / spool / clientmqueue 。","title":"ntpdate"},{"location":"command/#wget","text":"# wget - r - p - np - k http : // xxx . edu . cn - r ,,,, , wget , - np ,. - np . - k . - p ,. - E  -- html - extension  URL “. html ” +++++++++++++++++++++++++++++++++++++++ # wget - c - t 0 - O rhel6_x86_64 . iso http : // zs . kan115 . com : 8080 / rhel6_x86_64 . iso - c  - t 0 ， 0  - O rhel6_x86_64 . iso  rhel6_x86_64 . iso http : // zs . kan115 . com : 8080 / rhel6_x86_64 . iso  ： wget  wget ，，，。。 。 ， 。 1 、 wget url + filename      2 、 O  wget - O save_name url 。 ： wget - O xx . zip http : // www . vim . org / scripts / download_script . php ? src_id = 7701  - O 。 ls - al  132 drwxr - xr - x 2 root root 4096 07 - 12 10 : 43 . drwxr - xr - x 4 root root 4096 07 - 11 16 : 26 .. - rw - r -- r -- 1 root root 50243 07 - 12 10 : 43 download_script . php ? src_id = 7701 - rw - r -- r -- 1 root root 50243 07 - 12 10 : 43 xx . zip ，。 - O ，。 - O 。 mv download_script.php?src_id=7701 yy . zip 3 、  wget -- limit - rate wget ， 。  -- limit - rate  wget -- limit - rate = 200 k http : // www . openss7 . org / repos / tarballs / strx25 - 0 . 9 . 2 . 1 . tar . bz2 4 、  wget - c  ， ^ c 。 ， - c 。 ： - c ，. 1 。 5 、 ： - b  wget - b url / filename 。 wget - log 。  tail - f wget - log  6 、 。 -- user - agent  wget -- user - agent = Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.3) Gecko / 2008092416 Firefox / 3 . 0 . 3 URL-TO-DOWNLOAD 7 、 : -- spider ，。 wget -- spider DOWNLOAD - URL  OK ，！ ： wget -- spider http://ip138.com/ips.asp?ip=58.251.193.137 action=2 Spider mode enabled . Check if remote file exists . -- 2010 - 07 - 12 11 : 36 : 32 -- http : // ip138 . com / ips . asp ? ip = 58 . 251 . 193 . 137 action = 2  ip138 . com ... 221 . 5 . 47 . 136 Connecting to ip138 . com | 221 . 5 . 47 . 136 | : 80 ... 。  HTTP ，... 200 OK ： 7817 ( 7 . 6 K ) [ text / html ] Remote file exists and could contain further links , but recursion is disabled -- not retrieving . 8 、 ： -- tries = 1000 ，，  wget  20 。  75 ， wget -- tires = 75 DOWNLOAD - URL 9 、 wget - i  download - file - list . txt ，： wget - i download - file - list . txt 10 、 ： -- mirror  ， wget -- mirror - p -- convert - links - P . / LOCAL - DIR WEBSITE - URL ： -- mirror ： - p ： html  -- convert - links ：， - P . / LOCAL - DIR ： 11 、 ， gif 。 wget -- reject = gif WEBSITE - TO - BE - DOWNLOADED 12 、 ： o wget - o xx . html . log - O xx . html http://ip138.com/ips.asp?ip=58.251.193.137 action = 2 ： [ root @ localhost opt ]# cat xx . html . log -- 2010 - 07 - 12 11 : 57 : 22 -- http : // ip138 . com / ips . asp ? ip = 58 . 251 . 193 . 137 action = 2  ip138 . com ... 221 . 5 . 47 . 136 Connecting to ip138 . com | 221 . 5 . 47 . 136 | : 80 ... 。  HTTP ，... 200 OK ： 7817 ( 7 . 6 K ) [ text / html ] Saving to : ` xx . html 0 K ....... 100 % 65 . 5 K = 0 . 1 s 2010 - 07 - 12 11 : 57 : 22 ( 65 . 5 KB / s ) - ` xx . html saved [7817/7817] 13 、 9 。 wget - Q5m - i FILE - WHICH - HAS - URLS  5 ，。 ：，， 。 14 、 11 ，   pdf ： wget - r - A . pdf http : // url - to - webpage - with - pdfs / 15 、 wget  ftp    ftp  http ： wget ftp - url 。 ，： wget -- ftp - user = USERNAME -- ftp - password = PASSWORD DOWNLOAD - URL","title":"wget"},{"location":"command/#chattr","text":"lsattr chattr chattr [ -RVf ] [ -v version ] [ mode ] files …  [ mode ]  ， [ mode ]  +-=  [ ASacDdIijsTtu ]  ，    。 + ：  ，  。 - ：  ，  。 = ：  。 A ：  atime ( access time )  ( modified ),  I / O 。 S ： I / O ， sync 。 a ： append ，  ，  ，  ，   ， root 。 c ： compresse ，  。  。 d ： no dump ， dump 。 i ：  、  、  ，  。 i  。 j ： journal ， mount ： data = ordered  data = writeback   ，  ( journal ) 。 filesystem data = journal ，  。 s ：  ，  。 u ： s ， u ，  ， undeletion 。 ai 。 a ，  。 i ， superuser ( root ) CAP_LINUX_IMMUTABLE （  ）  。","title":"chattr"},{"location":"command/#iperf","text":"1 、 UDP   iperf - u - s  iperf - u - c 192 . 168 . 1 . 1 - b 100 M - t 60  udp ， 100 Mbps ， 192 . 168 . 1 . 1 ， 60 。 iperf - u - c 192 . 168 . 1 . 1 - b 5 M - P 30 - t 60  30 ， 5 Mbps 。 iperf - u - c 192 . 168 . 1 . 1 - b 100 M - d - t 60  100 M ，。 2 、 TCP   iperf - s  iperf - c 192 . 168 . 1 . 1 - t 60  tcp ， 192 . 168 . 1 . 1 ， 60 。 iperf - c 192 . 168 . 1 . 1 - P 30 - t 60  30 。 iperf - c 192 . 168 . 1 . 1 - d - t 60 。 ， - p  - w tcp ","title":"iperf"},{"location":"command/#ethtool","text":"ethtool - p eth1 N ，， ethX ，  port  led ； N ，","title":"ethtool"},{"location":"command/#ps","text":"ps - eo pid , comm , lstart  pid ，， - C  ：，。 - H ：，。","title":"ps"},{"location":"command/#ss","text":" TCP  ss - t - a  TCP  ss - u - a  Sockets  ss - s  ss - l  socket ss - pl - h ：； - V ：； - n ：，； - a ：； - l ：； - o ：； - m ：； - p ：； - i ： TCP ； - 4 ： ipv4 ； - 6 ： ipv6 ； - t ： tcp ； - u ： udp ； - d ： DCCP ； - w ： RAW ； - x ： UNIX 。","title":"ss"},{"location":"command/#iostat","text":"yum install sysstat iostat - x 1 Linux 2.6.32 - 504. el6 . x86_64 ( centos2 ) 12 / 26 / 2015 _x86_64_ ( 1 CPU ) avg - cpu : %user %nice %system %iowait %steal %idle 0.04 0.02 0.18 0.37 0.00 99.39 Device : rrqm / s wrqm / s r / s w / s rsec / s wsec / s avgrq - sz avgqu - sz await svctm %util sda 0.27 1.42 1.01 0.17 38.07 12.73 43.18 0.01 10.81 3.73 0.44 dm - 0 0.00 0.00 1.22 1.59 37.47 12.73 17.88 0.11 37.78 1.55 0.43 dm - 1 0.00 0.00 0.02 0.00 0.18 0.00 8.00 0.00 6.62 3.45 0.01 ，  CPU （ mpstat ）。 Device  rrqm / s  wrqm / s  r / s  w / s  rsec / s  wsec / s  rkB / s ， KB wkB / s ， KB avgrq - sz  avgqu - sz  await  I / O （ milliseconds ） svctm I / O  %util  I / O  CPU ","title":"iostat"},{"location":"command/#vmstat","text":"vmstat  1 ： # vmstat 1 procs ———– memory ——— - — swap – —– io — - – system – — - cpu — - r b swpd free buff cache si so bi bo in cs us sy id wa 0 0 104300 16800 95328 72200 0 0 5 26 7 14 4 1 95 0 0 0 104300 16800 95328 72200 0 0 0 24 1021 64 1 1 98 0 0 0 104300 16800 95328 72200 0 0 0 0 1009 59 1 1 98 0 r  .  ,  CPU  . b  IO  in  cs  kernel system  ,  us  sys  wa  IO  idCPU ","title":"vmstat"},{"location":"command/#cp","text":"- a ： -dpR ； - d ：，， ； - f ：，； - i ：； - l ：，； - p ：； - R / r ：，； - s ：，； - u ：，； - S ：，“ SUFFIX ”； - b ：； - v ：。 \\ cp - vupf ，，\\ cp  alias cp = cp -i","title":"cp"},{"location":"command/#rsync","text":"。 SRC  DES  : 。 rsync - a / data / backup  shell  (  rsh 、 ssh ) 。  DST  : 。 rsync - avz * . c foo : src  shell  (  rsh 、 ssh ) 。  SRC  : 。 rsync - avz foo : src / bar / data  rsync 。 SRC  :: 。 rsync - av root @192.168.78.192 :: www / databack  rsync 。 DST  :: 。 rsync - av / databack root @192.168.78.192 :: www - v , -- verbose 。 - q , -- quiet 。 - c , -- checksum ，。 - a , -- archive ，，， - rlptgoD 。 - r , -- recursive 。 - R , -- relative 。 - b , -- backup ，，  ~ filename 。 -- suffix 。 -- backup - dir  (  ~ filename ) 。 - suffix = SUFFIX 。 - u , -- update ， DST ， ，。 - l , -- links 。 - L , -- copy - links 。 -- copy - unsafe - links  SRC 。 -- safe - links  SRC 。 - H , -- hard - links 。 - p , -- perms 。 - o , -- owner 。 - g , -- group 。 - D , -- devices 。 - t , -- times 。 - S , -- sparse  DST 。 - n , -- dry - run 。 - w , -- whole - file ，。 - x , -- one - file - system 。 - B , -- block - size = SIZE ， 700 。 - e , -- rsh = command  rsh 、 ssh 。 -- rsync - path = PATH  rsync 。 - C , -- cvs - exclude  CVS ，。 -- existing  DST ，。 -- delete  DST  SRC 。 -- delete - excluded 。 -- delete - after 。 -- ignore - errors  IO 。 -- max - delete = NUM  NUM 。 -- partial ，。 -- force ，。 -- numeric - ids  id 。 -- timeout = time ip ，。 - I , -- ignore - times 。 -- size - only ，。 -- modify - window = NUM ， 0 。 - T -- temp - dir = DIR  DIR 。 -- compare - dest = DIR  DIR 。 - P  -- partial 。 -- progress 。 - z , -- compress 。 -- exclude = PATTERN 。 -- include = PATTERN 。 -- exclude - from = FILE  FILE 。 -- include - from = FILE  FILE 。 -- version 。 -- address 。 -- config = FILE ， rsyncd . conf 。 -- port = PORT  rsync 。 -- blocking - io  shell  IO 。 - stats 。 -- progress 。 -- log - format = formAT 。 -- password - file = FILE  FILE 。 -- bwlimit = KBPS  I / O ， KBytes per second 。  1 install yum install rsync vim / etc / rsyncd / rsyncd . conf uid = root gid = root port = 873 max connections = 0 # limit client conection log file =/ var / log / rsyncd . log pid file =/ var / run / rsyncd . pid lock file =/ var / run / rsyncd . lock motd file = / etc / rsyncd / rsyncd . motd read only = yes  ####limit user conn###### hosts allow = 192.168.18.0 / 255.255.255.0 hosts deny =* #transfer logging = yes #log format = %t %a %m %f %b #syslog facility = local3 #timeout = 300 [ www ] path = / tmp / www / list = yes ignore errors auth users = www ###username secrets file = / etc / rsyncd / rsyncd . secrets comment = www directory exclude = a / b / ##### a , b directory not backup [ root @ www rsyncd ] # cat rsyncd . motd ##################### www . vfast . com rsync ##################### [ root @ www rsyncd ] # cat rsyncd . secrets www : 123 [ root @ www rsyncd ] # chmod 600 rsyncd . secrets 4 start [ root @ www rsyncd ] # rsync -- daemon -- config =/ etc / rsyncd / rsyncd . conf [ root @ www rsyncd ] # lsof - i : 873 COMMAND PID USER FD TYPE DEVICE SIZE NODE NAME rsync 8043 root 4u IPv6 22013 TCP *: rsync ( LISTEN ) rsync 8043 root 5u IPv4 22014 TCP *: rsync ( LISTEN ) 5 check log tail - f / var / log / rsyncd . log client : 192.168.18.146 echo 123 / etc / rsync . password chmod 600 / etc / rsync . password mkdir - pv / tmp / www rsync - avzP -- delete -- password - file =/ etc / rsync . password www @192.168.18.254 :: www / tmp / www ##################### www . vfast . com rsync ##################### receiving file list ... 3 files to consider deleting f / deleting d / deleting abcd / deleting c / 3 deleting c / 2 deleting c / 1 . / c / c / c1 6 100 % 5.86 kB / s 0 : 00 : 00 ( xfer # 1 , to - check = 0 / 3 ) sent 129 bytes received 260 bytes 778.00 bytes / sec total size is 6 speedup is 0.02 146 # cd / tmp / www / 146 # tree . ` -- c ` -- c1 1 directory , 1 file 192.168.18.254 server rm - fr / tmp / c / c1 146 # rsync - avzP -- delete -- password - file =/ etc / rsync . password www @192.168.18.254 :: www / tmp / www ##################### www . vfast . com rsync ##################### receiving file list ... 2 files to consider deleting c / c1 c / sent 101 bytes received 191 bytes 194.67 bytes / sec total size is 0 speedup is 0.00 146 # tree . ` -- c 1 directory , 0 files crontab - e 10 2 * * * rsync - avzP -- delete -- password - file =/ etc / rsync . password www @192.168.18.254 :: www / tmp / www  server sersync2 + rsync 192.168.18.254 client rsync 192.168.18.146 apache - server [ root @ www tmp ] # tar fvxz sersync . tar . gz GNU - Linux - x86 / GNU - Linux - x86 / sersync2 GNU - Linux - x86 / confxml . xml [ root @ www tmp ] # cd GNU - Linux - x86 / vim confxml . xml sersync localpath watch = /tmp/www remote ip = 192.168.18.146 name = www / commonParams params = -artuz / auth start = true users = kyo passwordfile = /etc/146rsync.pass / failLog path = /tmp/rsync_fail_log timeToExecute = 60 / !-- default every 60 mins execute once -- ; client 192.168.18.146 146 # chmod 600 / etc / rsyncd / rsyncd . secrets 146 # cat / etc / rsyncd / rsyncd . secrets kyo : 123 146 # cat / etc / rsyncd / rsyncd . conf uid = root gid = root port = 873 max connections = 0 # limit client conection use chroot = no log file =/ var / log / rsyncd . log pid file =/ var / run / rsyncd . pid lock file =/ var / run / rsyncd . lock motd file = / etc / rsyncd / rsyncd . motd read only = no ############### !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! ####limit user conn###### hosts allow = 192.168.18.0 / 255.255.255.0 hosts deny =* #transfer logging = yes #log format = %t %a %m %f %b #syslog facility = local3 #timeout = 300 [ www ] path = / tmp / www list = yes ignore errors auth users = kyo ###username!! secrets file = / etc / rsyncd / rsyncd . secrets comment = www directory read only = no 146 # rsync -- daemon -- config =/ etc / rsyncd / rsyncd . conf 146 # lsof - i : 873 COMMAND PID USER FD TYPE DEVICE SIZE NODE NAME rsync 4356 root 4u IPv6 14561 TCP *: rsync ( LISTEN ) rsync 4356 root 5u IPv4 14562 TCP *: rsync ( LISTEN ) server 192.168.18.254 [ root @ www GNU - Linux - x86 ] # cat / etc / 146 rsync . pass 123 [ root @ www GNU - Linux - x86 ] # chmod 600 / etc / 146 rsync . pass [ root @ www www ] # ps axu | grep rsync root 8043 0.0 0.0 5252 480 ? Ss 11 : 08 0 : 00 rsync -- daemon -- config =/ etc / rsyncd / rsyncd . conf root 8191 0.6 2.3 82416 24024 pts / 7 S + 11 : 17 0 : 11 gedit rsync . txt root 8668 0.0 0.0 5024 696 pts / 3 S + 11 : 46 0 : 00 grep rsync [ root @ www www ] # kill - 9 8043 test [ root @ www GNU - Linux - x86 ] # pwd / tmp / GNU - Linux - x86 # ./sersync2 -r #run first! [ root @ www GNU - Linux - x86 ] # . / sersync2 set the system param execute ： echo 50000000 / proc / sys / fs / inotify / max_user_watches execute ： echo 327679 / proc / sys / fs / inotify / max_queued_events parse the command param daemon thread num : 10 parse xml config file host ip : localhost host port : 8008 use rsync password - file : user is kyo passwordfile is / etc / 146 rsync . pass config xml parse success please set / etc / rsyncd . conf max connections = 0 Manually sersync working thread 12 = 1 ( primary thread ) + 1 ( fail retry thread ) + 10 ( daemon sub threads ) Max threads numbers is : 22 = 12 ( Thread pool nums ) + 10 ( Sub threads ) please according your cpu ， use - n param to adjust the cpu rate run the sersync : watch path is : / tmp / www","title":"rsync"},{"location":"command/#snmpwalk","text":"yum install net-snmp-utils -y snmpwalk -c public -v 2c 172.31.38.23 ifDescr  snmpwalk -c public -v 2c 172.31.38.23 IF-MIB::ifInOctets  snmpwalk -c public -v 2c 172.31.38.23 IF-MIB::ifOutOctets  snmpwalk -c public -v 2c 172.31.38.23 IF-MIB::ifInOctets.13  snmpwalk -c public -v 2c 172.31.38.23 IF-MIB::ifHCInOctets.13 64, snmpwalk -c public -v 2c 172.31.38.23 IF-MIB::ifHCOutOctets.13 64, （count32），(-)/，   # !/ usr / bin / env bash api = http : // 127 . 0 . 0 . 1 : 1988 / v1 / push ts = $ ( date +% s ) [ - d / tmp / snmp ] || mkdir / tmp / snmp cd / usr / local / open - falcon / switch - custom snmpuser = user snmppwd = pass # snmpwalk - v 3 - u user - a MD5 - A pass 172 . 19 . 2 . 30 ifDescr IF - MIB :: ifInOctets . 13 # awk {print $NF*8} stat = $ ( curl http : // 127 . 0 . 0 . 1 : 1988 - o / dev / null - s - w % { http_code } ) if [ $ stat - ne 404 ] ;then exit fi getflow () { snmpwalk - l auth - v 3 - u $ snmpuser - a MD5 - A $ snmppwd $2 ifDescr | grep - vi VLAN / tmp / snmp / $1 _port snmpwalk - l auth - v 3 - u $ snmpuser - a MD5 - A $ snmppwd $2 IF - MIB :: ifHCInOctets / tmp / snmp / $1 _in snmpwalk - l auth - v 3 - u $ snmpuser - a MD5 - A $ snmppwd $2 IF - MIB :: ifHCOutOctets / tmp / snmp / $1 _out result = while read snport do port_name = $ ( echo $ snport | awk {print $NF} ) port_id = $ ( echo $ snport | awk {print $1} | grep - Po \\d+ ) net_in = $ ( awk /IF-MIB::ifHCInOctets.$port_id = / {print $NF*8} / tmp / snmp / $1 _in ) net_out = $ ( awk /IF-MIB::ifHCOutOctets.$port_id = / {print $NF*8} / tmp / snmp / $1 _out ) # echo $ port_name ,$ port_id ,$ net_in ,$ net_out net_all = {\\ metric \\ : \\ switch . if . In \\ , \\ endpoint \\ : \\ $1 \\ , \\ timestamp \\ : $ts,\\ step \\ : 60,\\ value \\ : $net_in, \\ counterType\\ : \\ COUNTER\\ ,\\ tags\\ : \\ ifName=$port_name\\ },{\\ metric\\ : \\ switch.if.Out\\ , \\ endpoint\\ : \\ $1\\ , \\ timestamp\\ : $ ts ,\\ step\\ : 60 ,\\ value\\ : $ net_out ,\\ counterType\\ : \\ COUNTER\\ ,\\ tags\\ : \\ ifName=$port_name\\ } curl - s - X POST - d [$net_all] $a pi / dev / null # echo $ net_all # result = $ result $ net_all done / tmp / snmp / $1 _port # echo $ result | sed s/,$//g # curl - s - X POST - d [$(echo $result | sed s / ,$ // g )] $a pi / dev / null } while read line do getflow $ line # getflow $ line done sw - host . txt","title":"snmpwalk"},{"location":"command/#iptables","text":"iptables - t  - A  lt ;-i/o  gt; -p  lt;-s IP/ gt; --sport  lt;-d IP/ gt; --dport  -j  - A ：； - D ：； - I ：； - L ：； ： raw ：，：。 mangle ：（ QOS ），。 nat ：，。 filter ：，。 ： INPUT ：。 OUTPUT ：。 PORWARD ：。 PREROUTING ：（ DNAT ）。 POSTOUTING ：（ SNAT ）。 ： ACCEPT ：。 REJECT ：。 DROP ：。 REDIRECT ：、、。 SNAT ：。 DNAT ：。 MASQUERADE ： IP （ NAT ）， ADSL 。 LOG ：。  iptables  iptables - F iptables - X iptables - Z  chain  iptables - P INPUT DROP iptables - P FORWARD ACCEPT iptables - P OUTPUT ACCEPT  iptables - A INPUT - m state -- state ESTABLISHED , RELATED - j ACCEPT  ( ， ) iptables - A INPUT - s 127 . 0 . 0 . 1 - d 127 . 0 . 0 . 1 - j ACCEPT  (  ) iptables - A OUTPUT - j ACCEPT  iptables - A INPUT - p tcp -- dport 22 - j ACCEPT -- dport 8000 : 10000   22  iptables - A INPUT - j reject  iptables - A FORWARD - j REJECT   IP iptables - I INPUT - s 123 . 45 . 6 . 7 - j DROP  IP  iptables - I INPUT - s 123 . 0 . 0 . 0 / 8 - j DROP  123 . 0 . 0 . 1  123 . 255 . 255 . 254   iptables  iptables - L - n - v  iptables - nL -- line - number  iptables - D FORWARD 2  FORWARD  2 ，。 nat ， - t nat iptables - D INPUT - j REJECT -- reject - with icmp - host - prohibited ，， iptables : No chain / target / match by that name .  iptables - A INPUT - m state – state INVALID - j DROP iptables - A OUTPUT - m state – state INVALID - j DROP iptables - A FORWARD - m state – state INVALID - j DROP 2 . 1   ip_forward ,: # echo 1 gt ; /proc/sys/net/ipv4/ip_forward //  # vi / ect / sysctl . conf //  # sysctl - p  # iptables - t nat - A PREROUTING - p tcp - m tcp -- dport 80 - j REDIRECT -- to - ports 8080  iptables  ， INPUT ，（）， 8080 ， 80 ： # iptables - A INPUT - s 172 . 29 . 88 . 0 / 24 - p tcp - m state -- state NEW - m tcp -- dport 8080 - j ACCEPT  http  80  8080 （），， curl  firfox  http : // localhost : 80  http : // doman . com : 80 （），， OUTPUT ： iptables - t nat - A OUTPUT - p tcp -- dport 80 - j REDIRECT -- to - ports 8080 ： iptables - t nat - A PREROUTING - p tcp - i eth0 - d $ YOUR_HOST_IP -- dport 80 - j DNAT -- to $ YOUR_HOST_IP : 8080 iptables - t nat - A OUTPUT - p tcp - d $ YOUR_HOST_IP -- dport 80 - j DNAT -- to 127 . 0 . 0 . 1 : 8080 iptables - t nat - A OUTPUT - p tcp - d 127 . 0 . 0 . 1 -- dport 80 - j DNAT -- to 127 . 0 . 0 . 1 : 8080  ，， IP (  PC )  iptables 。（， linux  ）  192 . 168 . 10 . 100 : 8000 ， 172 . 29 . 88 . 56 : 80 ， 192 . 168 . 10 . 100 : iptables - t nat - A PREROUTING - i eth0 - p tcp - d 192 . 168 . 10 . 100 -- dport 8000 - j DNAT -- to - destination 172 . 29 . 88 . 56 : 80 iptables - t nat - A POSTROUTING - o eth0 - j SNAT -- to - source 192 . 168 . 10 . 100  iptables - t nat - A PREROUTING - d 192 . 168 . 10 . 100 - p tcp -- dport 8000 - j DNAT -- to 172 . 29 . 88 . 56 : 80 iptables - t nat - A POSTROUTING - d 172 . 29 . 88 . 56 - p tcp -- dport 80 - j SNAT -- to - source 192 . 168 . 10 . 100 ， FORWARD  DROP ， FORWARD ： iptables - A FORWARD - d 172 . 29 . 88 . 56 - p tcp -- dport 80 - j ACCEPT iptables - A FORWARD - s 172 . 29 . 88 . 56 - p tcp - j ACCEPT 2 . 2   22  INPUT ， input  1 ， / var / log / message ， -- limit ： iptables - R INPUT 1 - p tcp -- dport 22 - m limit -- limit 3 / minute -- limit - burst 8 - j LOG vi / etc / rsyslog . conf ， kern . = notice / var / log / iptables . log ，。 service rsyslog restart # 2 . 3  DoS  SYN  SYN  DoS ， DoS ： ipt - tcp . sh ： iptables - N syn - flood ( “ : syn - flood - [ 0 : 0 ] ”， ) iptables - A INPUT - p tcp -- syn - j syn - flood iptables - I syn - flood - p tcp - m limit -- limit 2 / s -- limit - burst 5 - j RETURN iptables - A syn - flood - j REJECT #  DOS , IP  15 , #  iptables v1 . 4 . 19 ： iptables - V iptables - A INPUT - p tcp -- syn - i eth0 -- dport 80 - m connlimit -- connlimit - above 20 -- connlimit - mask 24 - j DROP # Iptables  DDOS (  ) iptables - A INPUT - p tcp -- syn - m limit -- limit 5 / s -- limit - burst 10 - j ACCEPT iptables - A FORWARD - p tcp -- syn - m limit -- limit 1 / s - j ACCEPT iptables - A FORWARD - p icmp - m limit -- limit 2 / s -- limit - burst 10 - j ACCEPT iptables - A INPUT - p icmp -- icmp - type 0 - s ! 172 . 29 . 73 . 0 / 24 - j DROP  iptables - save gt ; iptales.bak cat iptables . bak | iptables - restore / etc / init . d / iptables save (  ) centos 7 yum install - y iptables iptables - services / usr / libexec / iptables / iptables . init save","title":"iptables"},{"location":"command/#logrotate","text":"1 . (  rotate . conf ，。 ) / usr / sbin / logrotate - v / etc / logrotate . conf 2 . (  rotate . conf ，,， debug  ) / usr / sbin / logrotate - d / etc / logrotate . conf 3 . (  log  ) vi / var / lib / logrotate . status 4 . (  rpm  logrotate  ) ls / etc / logrotate . d /  vim / etc / logrotate . d / tomcat / usr / local / tomcat_pingtai / logs / catalina . out { copytruncate daily dateext rotate 30 missingok } logtotate - d / etc / logrotate . d / tomcat    compress  gzip  nocompress ， copytruncate ， nocopytruncate  create mode owner group ， nocreate  delaycompress  compress ， nodelaycompress  delaycompress ，。 errors address  Email  ifempty ， logrotate 。 notifempty ， mail address  E - mail  nomail  olddir directory ， noolddir  prerotate / endscript ， postrotate / endscript ， daily  weekly  monthly  rotate count ， 0 ， 5  5  tabootext [ + ] list  logrotate ，：. rpm - orig , . rpmsave , v ,  ~ size size ， Size  bytes (  )  K ( sizek )  M ( sizem ) . ： 1 . log does not need rotating logrotate ： configure  1 。 logrotate  rotate 。， logrotate  status  rotate ，  status ，。， rotate ，。 ：， 3 ，，。 - s  status ,。 2 .  log  rotate  rpm ， conf  / etc / logrotate . d / ， cron . daily 。 ： / etc / logrotate . d /  3 . compress 、 copytruncate 、 delaycompress 、 dateext ：  ( name - 20090713 ) ，， ， log  rotate ，。 name - 20090714 ， (  rotate n  ) ,。","title":"logrotate"},{"location":"disk/","text":"fdisk fdisk - l  fdisk / dev / sda p  n  w  d  t   partprode   hdparm - Tt  swap 1 、 fdisk  swap mkswap / xx / xx 2 、 dd if =/ dev / zero of =/ tmp / swap bs =  count =   / etc / fstab swapon / xx / xx  swap swapoff  swap swapon - s  fsck （） parted  2 T   Parted  LVM  ， Parted  1 ， parted  www . 2 cto . com # parted / dev / sda GNU Parted 2 . 1  / dev / sda Welcome to GNU Parted ! Type help to view a list of commands . ( parted ) help  ( parted ) mktable ？ gpt GPT  GRUB ， MBR ， 2 T  ( parted ) p  4398 GB  Model : DELL MD32xx ( scsi ) Disk / dev / sda : 4398 GB Sector size ( logical / physical ) : 512 B / 512 B Partition Table : gpt Number Start End Size File system Name  ( parted ) mkpart # ？ []? # ？ [ ext2 ]? # ？ 0 G # ？ 4398 G # ( parted ) p Model : DELL MD32xx ( scsi ) Disk / dev / sda : 4398 GB Sector size ( logical / physical ) : 512 B / 512 B Partition Table : gpt Number Start End Size File system Name  1 1049 kB 4398 GB 4398 GB ( parted ) toggle 1 lvm # lvm ( parted ) p Model : DELL MD32xx ( scsi ) Disk / dev / sda : 4398 GB Sector size ( logical / physical ) : 512 B / 512 B Partition Table : gpt Number Start End Size File system Name  1 1049 kB 4398 GB 4398 GB lvm ( parted ) quit : You may need to update / etc / fstab . 2 ， sdb , sdc , sdd  ， LVM ，， PV , VG , LVM 1 ， PV # pvcreate / dev / sda1 / dev / sdb1 / dev / sdc1 / dev / sdd1 Writing physical volume data to disk /dev/sda1 Physical volume /dev/sda1 successfully created Writing physical volume data to disk /dev/sdb1 Physical volume /dev/sdb1 successfully created Writing physical volume data to disk /dev/sdc1 Physical volume /dev/sdc1 successfully created Writing physical volume data to disk /dev/sdd1 Physical volume /dev/sdd1 successfully created 2 , VG # vgcreate md3200 / dev / sda1 / dev / sdb1 / dev / sdc1 / dev / sdd1 Volume group md3200 successfully created # lvcreate - n md3200lv1 - L 8 T md3200 Logical volume md3200lv1 created You have new mail in / var / spool / mail / root 3 , LVM # lvcreate - n md3200lv1 - L 8 T md3200 Logical volume md3200lv1 created # lvcreate - n md3200lv2 - L 8 T md3200 Logical volume md3200lv2 created ， # mkfs . ext4 / dev / md3200 / md3200lv1 mke2fs 1 . 41 . 12 ( 17 - May - 2010 )  = : Linux  = 4096 ( log = 2 )  = 4096 ( log = 2 ) Stride = 0 blocks , Stripe width = 0 blocks 536870912 inodes , 2147483648 blocks 107374182 blocks ( 5 . 00 % ) reserved for the super user  = 0 Maximum filesystem blocks = 4294967296 65536 block groups 32768 blocks per group , 32768 fragments per group 8192 inodes per group Superblock backups stored on blocks : 32768 , 98304 , 163840 , 229376 , 294912 , 819200 , 884736 , 1605632 , 2654208 , 4096000 , 7962624 , 11239424 , 20480000 , 23887872 , 71663616 , 78675968 , 102400000 , 214990848 , 512000000 , 550731776 , 644972544 , 1934917632  inode :  Creating journal ( 32768 blocks ) :  Writing superblocks and filesystem accounting information :  This filesystem will be automatically checked every 33 mounts or 180 days , whichever comes first . Use tune2fs - c or - i to override . ， # mkdir md3200lv1 md3200lv2 # mount / dev / md3200 / md3200lv1 / md3200lv1 / # ls / md3200lv1 / lost + found # tail - n 2 / etc / fstab / dev / md3200 / md3200lv1 / md3200lv1 ext4 defaults 1 2 / dev / md3200 / md3200lv2 / md3200lv2 ext4 defaults 1 2 ， # reboot # df - hl      %%  / dev / mapper / md3200 - md3200lv1 7 . 9 T 175 M 7 . 5 T 1 % / md3200lv1 / dev / mapper / md3200 - md3200lv2 7 . 9 T 175 M 7 . 5 T 1 % / md3200lv2 ， # dd if =/ dev / zero of = . / test bs = 10 M count = 1000  1000 + 0   1000 + 0  10485760000  ( 10 GB ) ， 8 . 83453 ， 1 . 2 GB /  # free - g total used free shared buffers cached Mem : 62 11 51 0 0 9 -/+ buffers / cache : 1 61 Swap : 7 0 7 # dd if = . / test of = . / test1 bs = 10 M count = 1000  1000 + 0   1000 + 0  10485760000  ( 10 GB ) ， 12 . 3038 ， 852 MB /  # dd if = . / test1 of = . / test2 bs = 10 M count = 1000  1000 + 0   1000 + 0  10485760000  ( 10 GB ) ， 19 . 0357 ， 551 MB /  # dd if = . / test2 of = . / test3 bs = 10 M count = 1000  1000 + 0   1000 + 0  10485760000  ( 10 GB ) ， 18 . 641 ， 563 MB /  # free - g total used free shared buffers cached Mem : 62 41 21 0 0 39 -/+ buffers / cache : 2 60 Swap : 7 0 7 # dd if = . / test3 of = . / test4 bs = 10 M count = 1000  1000 + 0   1000 + 0  10485760000  ( 10 GB ) ， 17 . 3797 ， 603 MB /  # dd if = . / test4 of = . / test5 bs = 10 M count = 1000  1000 + 0   1000 + 0  10485760000  ( 10 GB ) ， 22 . 8714 ， 458 MB /  # dd if = . / test5 of = . / test6 bs = 10 M count = 1000  1000 + 0   1000 + 0  10485760000  ( 10 GB ) ， 100 . 246 ， 105 MB /   64 G ，， 105 。 ： http : // www . 2 cto . com / os / 201303 / 195308 . html MegaCli http : // www . avagotech . com / docs - and - downloads / raid - controllers / raid - controllers - common - files / 8 - 07 - 14 _MegaCLI . zip  Linux   raid ： raid ， # cat / proc / mdstat  raid ： raid ，， # dmesg | grep - i raid # cat / proc / scsi / scsi 2 .  raid  raid  ,  MegaCLI   MegaCli ，。 # rpm - ivh MegaCli - 1 . 01 . 24 - 0 . i386 . rpm  / opt ， / opt / MegaCli 。 ： # / opt / MegaRAID / MegaCli / MegaCli64 - CfgForeign - Clear - a0  Foreign  #/ opt / MegaCli - LDInfo - Lall - aALL  raid  #/ opt / MegaCli - AdpAllInfo - aALL  raid  #/ opt / MegaCli - PDList - aALL  #/ opt / MegaCli - AdpBbuCmd - aAll  #/ opt / MegaCli - FwTermLog - Dsply - aALL  raid  #/ opt / MegaCli - adpCount 【】 #/ opt / MegaCli - AdpGetTime – aALL 【】 #/ opt / MegaCli - AdpAllInfo - aAll 【】 #/ opt / MegaCli - LDInfo - LALL - aAll 【】 #/ opt / MegaCli - PDList - aAll 【】 #/ opt / MegaCli - AdpBbuCmd - GetBbuStatus - aALL | grep ‘ Charger Status ’ 【】 #/ opt / MegaCli - AdpBbuCmd - GetBbuStatus - aALL 【 BBU 】 #/ opt / MegaCli - AdpBbuCmd - GetBbuCapacityInfo - aALL 【 BBU 】 #/ opt / MegaCli - AdpBbuCmd - GetBbuDesignInfo - aALL 【 BBU 】 #/ opt / MegaCli - AdpBbuCmd - GetBbuProperties - aALL 【 BBU 】 #/ opt / MegaCli - cfgdsply - aALL 【 Raid ， Raid ， Disk 】 3 . ，，。 Device | Normal | Damage | Rebuild | Normal Virtual Drive | Optimal | Degraded | Degraded | Optimal Physical Drive | Online | Failed – gt ; Unconfigured | Rebuild | Online 4 .  #/ opt / MegaCli - LDGetProp - Cache - L0 - a0 or #/ opt / MegaCli - LDGetProp - Cache - L1 - a0 or #/ opt / MegaCli - LDGetProp - Cache - LALL - a0 ro #/ opt / MegaCli - LDGetProp - Cache - LALL - aALL ro #/ opt / MegaCli - LDGetProp - DskCache - LALL - aALL 5 .  ： WT ( Write through WB ( Write back ) NORA ( No read ahead ) RA ( Read ahead ) ADRA ( Adaptive read ahead ) Cached Direct ： #/ opt / MegaCli - LDSetProp WT | WB | NORA | RA | ADRA - L0 - a0 or #/ opt / MegaCli - LDSetProp - Cached |- Direct - L0 - a0 or enable / disable disk cache #/ opt / MegaCli - LDSetProp - EnDskCache |- DisDskCache - L0 - a0 6 .  raid5 ， 2 , 3 , 4 ， 5 #/ opt / MegaCli - CfgLdAdd - r5 [ 1 : 2 , 1 : 3 , 1 : 4 ] WB Direct - Hsp [ 1 : 5 ] - a0 7 . ， #/ opt / MegaCli - CfgLdAdd - r5 [ 1 : 2 , 1 : 3 , 1 : 4 ] WB Direct - a0 8 .  #/ opt / MegaCli - CfgLdDel - L1 - a0 9 .  #/ opt / MegaCli - LDRecon - Start - r5 - Add - PhysDrv [ 1 : 4 ] - L1 - a0 10 . ，，。 #/ opt / MegaCli - LDInit - ShowProg - LALL - aALL  #/ opt / MegaCli - LDInit - ProgDsply - LALL - aALL 11 .  #/ opt / MegaCli - LDBI - ShowProg - LALL - aALL  #/ opt / MegaCli - LDBI - ProgDsply - LALL - aALL 12 .  5  #/ opt / MegaCli - PDHSP - Set [ - EnclAffinity ] [ - nonRevertible ] - PhysDrv [ 1 : 5 ] - a0 13 .  #/ opt / MegaCli - PDHSP - Set [ - Dedicated [ - Array1 ]] [ - EnclAffinity ] [ - nonRevertible ] - PhysDrv [ 1 : 5 ] - a0 14 .  #/ opt / MegaCli - PDHSP - Rmv - PhysDrv [ 1 : 5 ] - a0 15 .  /  MegaCli64 - PDList - aALL  [ Enclosure Device ID : Slot Number ] [ 1 : 4 ] #/ opt / MegaCli - PDOffline - PhysDrv [ 1 : 4 ] - a0 #/ opt / MegaCli - PDOnline - PhysDrv [ 1 : 4 ] - a0 16 .  #/ opt / MegaCli - PDRbld - ShowProg - PhysDrv [ 1 : 5 ] - a0  #/ opt / MegaCli - PDRbld - ProgDsply - PhysDrv [ 1 : 5 ] - a0  owncloud https : // owncloud . org / seafile https : // www . seafile . com / home / lvm lvm  pv ， vg  ： pvcreate / dev / xxx vgcreate vg0 / dev / xx lvcreate - L 512 M - n lv0 vg0 mkfs . ext3 / dev / vg1 / lv0 mount / dev / vg1 / lv0 / data / vim / etc / fatab / dev / mapper / vg1 - lvdata / data ext3 defaults 1 2  pvdisplay or pvscan vgdisplay or vgscan lvdisplay or lvscan lvm  ： fdisk / dev / hda n p # ，，，（： P - P - P - P  P - P - P - E ） 1 # ， / dev / hda6 t 8 e #  8 e  LVM  w #  partprobe #  partx / dev / hda #   PV ， VG ， LV pvcreate / dev / hda1 vgdisplay #  VG ， VG ： VolGroup00  vgextend VolGroup00 / dev / hda1 #  VolGroup00 lvdisplay #  LV ， LV ： LogVol01  lvextend – L 1 G / dev / VolGroup00 / LogVol01 #  LV - l + 100 % FREE  ext3 ext4  resize2fs / dev / VolGroup00 / LogVol01 # ， LogVol01  xfs  xfs_growfs / dev / centos / root # ， LogVol01  df – h # ， samba yum install samba samba - client samba - common samba - swat    wab systemctl restart smb vim / etc / samba / smb . conf security = share / user user ，  ： passdb backend = tdbsam username map =/ etc / samba / smbusers vim / etc / samba / smbusers  = samba1 [  ] samba2 smbpasswd - a  / etc / samba / smb . conf [ homes ]  comment = xxxx  path =/ tmp / samba chmod o + w / tmp / samba public = yes  guesk ok = yes browseable = yes  ， yes writable = yes  write list =  ，  read only = yes  read list =  ，   ，  valid users =  ，  invalid users =  ，   ：  ，  [ work ] comment = All path = / data #public = no browseable = yes #guest ok = yes writable = yes read only = no write list = ftp , work valid users = ftp , work  smbclient - L ip  smbclient // ip /  - U  mount - t cifs // ip /  / mnt / abc - O username = test , passwd = windows \\\\ ip nfs 、 NFS  　　 NFS  Network File System ，。， Sun ， 1984 。 、，，  Unix 。 　　 NFS “ RPC ”，， 。 　　 NFS  RPC 。 RPC ， ( Remote Procedure Call )  。 NFS ， NFS ， NFS  。 RPC 。 NFS  RPC 。 NFS  RPC SERVER 。 NFS   RPC ， NFS SERVER  NFS CLIENT 。 SERVER  CLIENT  RPC  PROGRAM PORT 。 RPC  NFS  ： NFS ， RPC 。 、 ： CentOS release 5 . 6 ( Final ) NFS Server IP ： 192 . 168 . 1 . 108  / iptables : Firewall is not running . SELINUX = disabled 、 NFS  NFS ，，，。 nfs - utils -* ： NFS  portmap -* ： NFS RPC ， rpcbind  NFS  nfs - utils portmap 。 、 NFS  nfsd ： NFS ，； mountd ： RPC ， NFS 。 nfsd  NFS ， NFS ， 。 NFS  / etc / exports 。 portmap ：。 RPC （ NFS ）， portmap  ，。 、 NFS  NFS ，， NFS 。 NFS  / etc / exports NFS  / usr / sbin / exportfs NFS  / usr / sbin / showmount  / var / lib / nfs / etab  NFS  / var / lib / nfs / xtab  NFS  / etc / exports ， NFS ，，， vim ，。 / etc / exports ：  [  1 （ ,  , ） ] [  2 （ ,  , ） ] a . ：  NFS ； b . ：  NFS    ip ： 192 . 168 . 0 . 200 ： 192 . 168 . 0 . 0 / 24 192 . 168 . 0 . 0 / 255 . 255 . 255 . 0 ： david . bsmart . cn ： * . bsmart . cn ： * c . ： 、。 NFS  3 ：  ： ro ： rw  all_squash ：（ nfsnobody ）； no_all_squash ： all_squash （）； root_squash ： root （）； no_root_squash ： rootsquash ； anonuid = xxx ：，（ UID = xxx ）； anongid = xxx ：，（ GID = xxx ）；  secure ： 1024  tcp / ip  nfs （）； insecure ： 1024  tcp / ip ； sync ：，，； async ：，； wdelay ：，，（）； no_wdelay ：， sync ； subtree ：， nfs  (  ) ； no_subtree ：， nfs ，； 、 NFS   exports ， NFS 。 1 、 NFS   NFS ， portmap  nfs ， portmap  nfs 。 # service portmap start # service nfs start 2 、 NFS  # service portmap status # service nfs status 3 、 NFS   NFS ， nfs  portmap ， (  NIS ) ， portmap  # service nfs stop # service portmap stop 4 、 NFS  ， LINUX  nfs ， portmap  nfs 。 # chkconfig --list portmap # chkconfig --list nfs  portmap  nfs  3  5 。 # chkconfig --level 35 portmap on # chkconfig --level 35 nfs on 、 1 、 NFS Server  / home / david /  192 . 168 . 1 . 0 / 24 ，。 # vi / etc / exports / home / david 192 . 168 . 1 . 0 / 24 ( rw ) 2 、 portmap  nfs  # service portmap restart # service nfs restart # exportfs 3 、 showmount  NFS  # showmount - e 　　　　 // ， DNS ， # showmount - a 　　　　 //  4 、 showmount  NFS  # showmount - e NFS  IP 5 、 NFS   # mount NFS  IP :   # mount 192 . 168 . 1 . 108 : / home / david / / tmp / david / # mount | grep nfs 。 。 6 、 NFS   / tmp / david / ， # touch 20130103  Permission denied ， NFS ，。 # chmod 777 - R / home / david /  / tmp / david /   root ， nfsnobody 。 NFS ， / var / lib / nfs / etab  / home / david / 。 # cat / var / lib / nfs / etab  sync ， wdelay ， hide ， no_root_squash  root ， root_squash  root  nobody ， no_all_squash  。， root  nfsnobody 。 、。 # su - david $ cd / tmp / david / $ touch 2013 david ，。 　　 　　 1 . ， 　　　　 a . ，； 　　　　 b .  NFS server ， NFS server ； 　　　　 c . ，，  nfsnobody ； 　　 2 . ， root  　　　　 a .  no_root_squash ， root  NFS server  root ； 　　　　 b .  all_squash 、 anonuid 、 anongid ， root ； 　　　　 c . ， root  nfsnobody ； 　　　　 d .  no_root_squash  all_squash  nfsnobody ， anonuid 、 anongid  ； 7 、 NFS  # umount / tmp / david / 、 nfs  ： server : / remote / export / local / directory nfs options 0 0 # vi / etc / fstab ，。  / home / david 。 。 、 1 、 exportfs  NFS  / etc / exports ， nfs ？ exportfs ， ： 　　 # exportfs [ - aruv ] 　　 - a  / etc / exports  　　 - r  / etc / exports  ， / etc / exports 、 / var / lib / nfs / xtab 　　 - u （ - a  / etc / exports ） 　　 - v  export ，。 ： 　　 # exportfs - au  　　 # exportfs - rv  2 、 nfsstat  NFS ， NFS 。 3 、 rpcinfo  rpc ， rpc ， rpcinfo - p  RPC 。 4 、 showmount 　　 - a  　　 - e IP  hostname  IP  5 、 netstat  nfs ， nfs  2049 ， portmap  111 ， rpc 。 ，， root ， sudo 。 NFS server  NFS ，！ showmount - a ， kill killall pkill ，（ - 9 ） iozone http : // www . iozone . org wget http : // www . iozone . org / src / current / iozone3_465 . tar tar - xf iozone3_465 . tar cd iozone3_465 / src / current / make linux ，（）， linux 。 。  . / iozone - s 5 g - i0 - i1 - i2 - Rb ioperf . xls - I ， - I direct io  . / iozone - Rab ioperf . xls - s 64 G - i 0 - i 1 - i 2 - y 4 k - q 16 k  : - a auto mode  16 K - 512 M , 4 K - 16 M ； - e  fflush ， fsync ； - f  ； - R  excel （, excel ） - b  excel  - s   - k - m - g ； - r ； - g - n  auto ， / ； - q - y  auto ， / ； - i ： ( 0 = write / rewrite , 1 = read / re - read , 2 = random - read / write 3 = Read - backwards , 4 = Re - write - record , 5 = stride - read , 6 = fwrite / re - fwrite , 7 = fread / Re - fread , 8 = random mix , 9 = pwrite / Re - pwrite , 10 = pread / Re - pread , 11 = pwritev / Re - pwritev , 12 = preadv / Repreadv ） - I  direct io ； - p  cpu cache ； - t  - O  IOPS ； - R  excel ； - W ；  ioperf1 . xls  read ， write ，， write ，（ Kbytes ) , ，。，“ 19918 ”， 64 K ， 4 K ，  19918 Kbytes / s 。 - i ： 0 = write / rewrite 1 = read / re - read 2 = random - read / write 3 = Read - backwards 4 = Re - write - record 5 = stride - read 6 = fwrite / re - fwrite 7 = fread / Re - fread 8 = random mix 9 = pwrite / Re - pwrite 10 = pread / Re - pread 11 = pwritev / Re - pwritev 12 = preadv / Re - preadv Write :。，， 。“”。，。 ， Write  Re - write 。 Re - write :。，，。 Re - write   Write 。 Read : 。 Re - Read :。 Re - Read ，。。 Random Read :。，：，， 。 Random Write :。，，：，， 。 Random Mix :。，，：，， 。。 / 。 /  roundrobin 。  / 。 Backwards Read :。，，。 MSCNastran  。（ G  T ）。， 。 Record Rewrite :。。（ CPU ）， 。 CPU  TLB ，。，， 。，。 Strided Read :。： 0  4 Kbytes ， 200 Kbytes , 4 Kbytes ， 200 Kbytes ，。  4 Kbytes ， 200 Kbytes 。， 。 。，。 ，。 Fwrite : fwrite () 。。。 ， fwrite ()  I / O 。 ，。 Frewrite : fwrite () 。。。 ， fwrite ()  I / O 。 ，，。 Fread : fread () 。。。 ， fwrite ()  I / O 。 Freread :  fread  fio   ：  ，   ！！！ FIO wget http : // brick . kernel . dk / snaps / fio - 2.2.5 . tar . gz yum install libaio - devel tar - zxvf fio - 2.2.5 . tar . gz cd fio - 2.2.5 make make install  、 FIO ：  ： (  ， 2G ， 10  ， 1 ，  ) fio - filename =/ tmp / test_randread - direct = 1 - iodepth 1 - thread - rw = randread - ioengine = psync - bs = 16 k - size = 2 G - numjobs = 10 - runtime = 60 - group_reporting - name = mytest  ： filename =/ dev / sdb1  ， data 。 direct = 1 buffer 。  。 rw = randwrite I / O rw = randrw I / O bs = 16 k io16k bsrange = 512 - 2048  ，  size = 5 g 5g ， 4kio 。 numjobs = 30 30 . runtime = 1000 1000 ， 5g4k 。 ioengine = psync iopync rwmixwrite = 30  ， 30 % group_reporting  ，  。  lockmem = 1 g 1g 。 zero_buffers 0buffer 。 nrfiles = 8  。 read  write  rw , readwrite  randwrite  randread  randrw  io bw ：  KB / s iops ： IO runt ：  lat ( msec ) ：  (  ) msec ：  usec ：   ： fio - filename =/ dev / sdb1 - direct = 1 - iodepth 1 - thread - rw = read - ioengine = psync - bs = 16 k - size = 2 G - numjobs = 10 - runtime = 60 - group_reporting - name = mytest  ： fio - filename =/ dev / sdb1 - direct = 1 - iodepth 1 - thread - rw = randwrite - ioengine = psync - bs = 16 k - size = 2 G - numjobs = 10 - runtime = 60 - group_reporting - name = mytest  ： fio - filename =/ dev / sdb1 - direct = 1 - iodepth 1 - thread - rw = write - ioengine = psync - bs = 16 k - size = 2 G - numjobs = 10 - runtime = 60 - group_reporting - name = mytest  ： fio - filename =/ dev / sdb1 - direct = 1 - iodepth 1 - thread - rw = randrw - rwmixread = 70 - ioengine = psync - bs = 16 k - size = 2 G - numjobs = 10 - runtime = 60 - group_reporting - name = mytest - ioscheduler = noop  ，  ： [ root@localhost ~ ] # fio - filename =/ dev / sdb1 - direct = 1 - iodepth 1 - thread - rw = randrw - rwmixread = 70 - ioengine = psync - bs = 16 k - size = 200 G - numjobs = 30 - runtime = 100 - group_reporting - name = mytest1 mytest1 : ( g = 0 ) : rw = randrw , bs = 16 K - 16 K / 16 K - 16 K , ioengine = psync , iodepth = 1 … mytest1 : ( g = 0 ) : rw = randrw , bs = 16 K - 16 K / 16 K - 16 K , ioengine = psync , iodepth = 1 fio 2.0.7 Starting 30 threads Jobs : 1 ( f = 1 ) : [ ________________m_____________ ] [ 3.5% done ] [ 6935K/3116K /s ] [ 423 /190 iops ] [ eta 48m:20s ] s ] mytest1 : ( groupid = 0 , jobs = 30 ) : err = 0 : pid = 23802 read : io = 1853.4 MB , bw = 18967 KB / s , iops = 1185 , runt = 100058 msec clat ( usec ) : min = 60 , max = 871116 , avg = 25227.91 , stdev = 31653.46 lat ( usec ) : min = 60 , max = 871117 , avg = 25228.08 , stdev = 31653.46 clat percentiles ( msec ) : | 1.00 th =[ 3 ] , 5.00 th =[ 5 ] , 10.00 th =[ 6 ] , 20.00 th =[ 8 ] , | 30.00 th =[ 10 ] , 40.00 th =[ 12 ] , 50.00 th =[ 15 ] , 60.00 th =[ 19 ] , | 70.00 th =[ 26 ] , 80.00 th =[ 37 ] , 90.00 th =[ 57 ] , 95.00 th =[ 79 ] , | 99.00 th =[ 151 ] , 99.50 th =[ 202 ] , 99.90 th =[ 338 ] , 99.95 th =[ 383 ] , | 99.99 th =[ 523 ] bw ( KB / s ) : min = 26 , max = 1944 , per = 3.36 % , avg = 636.84 , stdev = 189.15 write : io = 803600 KB , bw = 8031.4 KB / s , iops = 501 , runt = 100058 msec clat ( usec ) : min = 52 , max = 9302 , avg = 146.25 , stdev = 299.17 lat ( usec ) : min = 52 , max = 9303 , avg = 147.19 , stdev = 299.17 clat percentiles ( usec ) : | 1.00 th =[ 62 ] , 5.00 th =[ 65 ] , 10.00 th =[ 68 ] , 20.00 th =[ 74 ] , | 30.00 th =[ 84 ] , 40.00 th =[ 87 ] , 50.00 th =[ 89 ] , 60.00 th =[ 90 ] , | 70.00 th =[ 92 ] , 80.00 th =[ 97 ] , 90.00 th =[ 120 ] , 95.00 th =[ 370 ] , | 99.00 th =[ 1688 ] , 99.50 th =[ 2128 ] , 99.90 th =[ 3088 ] , 99.95 th =[ 3696 ] , | 99.99 th =[ 5216 ] bw ( KB / s ) : min = 20 , max = 1117 , per = 3.37 % , avg = 270.27 , stdev = 133.27 lat ( usec ) : 100 = 24.32 % , 250 = 3.83 % , 500 = 0.33 % , 750 = 0.28 % , 1000 = 0.27 % lat ( msec ) : 2 = 0.64 % , 4 = 3.08 % , 10 = 20.67 % , 20 = 19.90 % , 50 = 17.91 % lat ( msec ) : 100 = 6.87 % , 250 = 1.70 % , 500 = 0.19 % , 750 = 0.01 % , 1000 = 0.01 % cpu : usr = 1.70 % , sys = 2.41 % , ctx = 5237835 , majf = 0 , minf = 6344162 IO depths : 1 = 100.0 % , 2 = 0.0 % , 4 = 0.0 % , 8 = 0.0 % , 16 = 0.0 % , 32 = 0.0 % , = 64 = 0.0 % submit : 0 = 0.0 % , 4 = 100.0 % , 8 = 0.0 % , 16 = 0.0 % , 32 = 0.0 % , 64 = 0.0 % , = 64 = 0.0 % complete : 0 = 0.0 % , 4 = 100.0 % , 8 = 0.0 % , 16 = 0.0 % , 32 = 0.0 % , 64 = 0.0 % , = 64 = 0.0 % issued : total = r = 118612 / w = 50225 / d = 0 , short = r = 0 / w = 0 / d = 0 Run status group 0 ( all jobs ) : READ : io = 1853.4 MB , aggrb = 18966 KB / s , minb = 18966 KB / s , maxb = 18966 KB / s , mint = 100058 msec , maxt = 100058 msec WRITE : io = 803600 KB , aggrb = 8031 KB / s , minb = 8031 KB / s , maxb = 8031 KB / s , mint = 100058 msec , maxt = 100058 msec Disk stats ( read / write ) : sdb : ios = 118610 / 50224 , merge = 0 / 0 , ticks = 2991317 / 6860 , in_queue = 2998169 , util = 99.77 % iop vsftp 777 ，  ，   ，  FlashFXP #connect_from_port_20 = YES  pasv_enable = YES pasv_promiscuous = YES pasv_min_port = 3000 pasv_max_port = 3500 2 .3.5  ， vsftpd ，  ，  allow_writeable_chroot = YES   chmod a - w / home / user chroot_local_user = YES  chroot_list_enable = YES # ( default follows ) #chroot_list_file =/ etc / vsftpd / chroot_list  “  ”，  yum install vsftpd curlftpfs ftp ，  / etc / vsftpd /  ，  ： ftpusers ftp 。 user_list ftp . vsftpd . conf vsftpd . ftpusersuser_list 。 ftpusers ，  ，  ！  db_load - T - t hash - f / etc / vsftpd / vftpuser . txt / etc / vsftpd / vu_list . db / etc / init . d / vsftpd restart vsftpd . conf ： 1 、  ， NO anon_upload_enable = NO anon_mkdir_write_enable = NO  ，  ，  。 anonymous_enable = NO 2 、  port_enable = YES ，  ， FTP PORT connect_from_port_20 = YES ，  ， FTP PORT20 ( ftp - data ) 。 YES ， NO 。 ftp_data_port = port number ， ftp ( ftp - data )  。 20 。 PORT FTP 。 3 、  ascii 。 NO ， binary 。 ascii_upload_enable = YES ascii_download_enable = YES   / var / ftp  anon_root =/ data / 3 mang_apps （ 777 ，  ） vim / etc / vsftpd / vsftpd . conf anonymous_enable = YES  local_enable = YES  anon_world_readable_only = YES   anon_other_write_enable = YES  anon_upload_enable = YES  anon_mkdir_write_enable = YES  local_max_rate = 1000000 --------------1M   xferlog_enable = YES xferlog_std_format = YES xferlog_file =/ var / log / xferlog dual_log_enable = YES vsftpd_log_file =/ var / log / vsftpd . log  curlftpfs ftp : // $ IP / mnt /   ” anonymous_enable = YES “  “ anonymous_enable = NO ” chroot_list_enable = YES chroot_list_file =/ etc / vsftpd / chroot_list useradd ftpadmin - s / sbin / nologin - d / home / ftpadmin 755 ， 777  (  ， 777 ) passwd ftpadmin  / etc / vsftpd / chroot_list ftpadmin user_list 。  ftp / var / ftp ，  / mnt / soft ，  / var / ftp / a ，   / var / ftp [ root@localhost ~ ] # mkdir / var / ftp / a mount [ root@localhost ~ ] # mount --bind /mnt/soft /var/ftp/a OK。 [ root@localhost etc ] # vi / etc / fstab  / mnt / soft / home / public auto bind 0 0  / etc / fstab  vim / etc / vsftpd / vftpuser . txt user passwd user2 passwd2 db_load - T - t hash - f / etc / vsftpd / vftpuser . txt / etc / vsftpd / vu_list . db chmod 600 / etc / vsftpd / vu_list . db vi / etc / pam . d / vsftp . vu PAM auth required / usr / lib64 / security / pam_userdb . so db =/ etc / vsftpd / vu_list account required / usr / lib64 / security / pam_userdb . so db =/ etc / vsftpd / vu_list # pam_userdb . so find / - name pam_userdb . so ，  useradd - d / home / ftpsite virtual_user  chmod 700 / home / ftpsite  / etc / vsftpd / vsftpd . conf ，  （  ）： anonymous_enable = NO local_enable = YES local_umask = 022 xferlog_enable = YES connect_from_port_20 = YES xferlog_std_format = YES listen = YES write_enable = YES anon_upload_enable = YES anon_mkdir_write_enable = YES anon_other_write_enable = YES anon_umask = 022 one_process_model = NO chroot_local_user = YES allow_writeable_chroot = YES ftpd_banner = Welcom to my FTP server . anon_world_readable_only = NO guest_enable = YES guest_username = virtual_user pam_service_name = vsftp . vu  ， guest_enable = YES ； guest_username = virtual_user ， virtual_user ； pam_service_name = vsftp . vu PAM vsftp . vu FTP ，  。  / etc / vsftpd . conf ： user_config_dir =/ etc / vsftpd / vsftpd_user_conf   ， gou ： #vi / etc / vsftpd / vsftpd_user_conf / gou write_enable = YES local_root =  virtual_user 9. FTP 1. vftpuser . txt 2.  ,  db_load - T - t hash - f / etc / vsftpd / vftpuser . txt / etc / vsftpd / vu_list . db 3 etc / vsftpd / vsftpd_user_conf ,  local_root =  4 ftp systemctl restart vsftpd  、 FTP  FTPTCP ，  ：  ，  。 21 （  ） 20 （  ）。 FTP ： N （ N 1024 ） FTP ， 21 。 N + 1 ， FTP “ port N + 1 ” FTP 。  （ 20 ）  （ N + 1 ）。  ， PASV ，  。 FTP ，  .  FTP ，  （ N 1024 N + 1 ）。 21 ， FTP ， PORT ，  PASV 。  （ P 1024 ）， PORT P 。 N + 1 P 。  ，  ， TCP 。  ，  。（  ，  ）  、 FTP Linux ，  ， FTP 。 FTP ，  ： 1. 1024FTP21 。（  ） 2. FTP211024 。 （  ） 3. FTP201024 。（  ） 4. 1024FTP20 （ ACK ） FTP ，  : 1. 102421 （  ） 2. 211024 （  ） 3. 10241024 （  ） 4. 10241024 （ ACK ）  ： vi / etc / vsftpd / vsftpd . confpasv ： pasv_enable = YES  （  ）： pasv_min_port = 10020 pasv_max_port = 11020 vsftpd 。 vi / etc / sysconfig / iptables ，  ： - A INPUT - m state --state RELATED,ESTABLISHED -j ACCEPT - A INPUT - p icmp - j ACCEPT - A INPUT - i lo - j ACCEPT - A INPUT - p tcp - m state --state NEW -m tcp --dport 10020:11020 -j ACCEPT - A INPUT - p tcp - m state --state NEW -m tcp --dport 20 -j ACCEPT - A INPUT - p tcp - m state --state NEW -m tcp --dport 21 -j ACCEPT iptables 。 FTP ，  ，  / etc / vsftpd / vsftpd . conf ，  ： pasv_address = 111.111.111.111 （  ） pasv_addr_resolve = yes pasv_promiscuous = yes  ： 200 PORT command successful . Consider using PASV .  ，  PASV ，  。 VLAN ，  ，  ， PASV ， PASV ，  。 vsftpd-mysql 、 1 、 mysql  ; # yum -y install mysql-server mysql-devel # yum -y groupinstall Development Tools Development Libraries 2.  pam_mysql - 0.7 RC1 # tar zxvf pam_mysql-0.7RC1.tar.gz # cd pam_mysql-0.7RC1 # ./configure --with-mysql=/usr --with-openssl # make # make install 3.  vsftpd # yum -y install vsftpd 、 1.   mysql 。，， vsftpd 。 mysql create database vsftpd ; mysql grant select on vsftpd . * to vsftpd @ localhost identified by www . magedu . com ; mysql grant select on vsftpd . * to vsftpd @127.0.0.1 identified by www . magedu . com ; mysql flush privileges ; mysql use vsftpd ; mysql create table users ( - id int AUTO_INCREMENT NOT NULL , - name char ( 20 ) binary NOT NULL , - password char ( 48 ) binary NOT NULL , - primary key ( id ) - ); 2 、 ，，， pam_mysql  password ()  MySQL  password ()  。 mysql insert into users ( name , password ) values ( tom , magedu ); mysql insert into users ( name , password ) values ( jerry , magedu ); 、 vsftpd 1.  pam  #vi /etc/pam.d/vsftpd.mysql  auth required / lib / security / pam_mysql . so user = vsftpd passwd = www . magedu . com host = localhost db = vsftpd table = users  usercolumn = name passwdcolumn = password crypt = 0 account required / lib / security / pam_mysql . so user = vsftpd passwd = www . magedu . com host = localhost db = vsftpd table = users  usercolumn = name passwdcolumn = password crypt = 0 2.  vsftpd ， mysql   #useradd -s /sbin/nologin -d /var/ftproot vuser #chmod go+rx /var/ftproot  / etc / vsftpd . conf  anonymous_enable = YES local_enable = YES write_enable = YES anon_upload_enable = NO anon_mkdir_write_enable = NO chroot_local_user = YES  guest_enable = YES guest_username = vuser  pam_service_name  pam_service_name = vsftpd . mysql 、 vsftpd  # service vsftpd start # chkconfig vsftpd on  # netstat -tnlp |grep :21 tcp 0 0 0.0.0.0 : 21 0.0.0.0 :* LISTEN 23286 / vsftpd  , ，， Win Box  IE  FTP  # ftp localhost 、 vsftpd  ftp ，。 ， vsftpd . conf 。 1 、 vsftpd  # vim vsftpd.conf  user_config_dir =/ etc / vsftpd / vusers_dir 2 、， # mkdir /etc/vsftpd/vusers_dir/ # cd /etc/vsftpd/vusers_dir/ # touch tom jerry 3 、  vsftpd 。， tom ， / etc / vsftpd / vusers / tom ，。 anon_upload_enable = YES lsyncd 1.1 inotify + rsync ， inotify + rsync ， 100 W + ， 20 M ， ， 10  M ， 20 M ，； ， inotifywait  5 s  10 ， 10  rsync ， 2 - 3 M ，  200 M 。，，，， 。  Linux  inotify + rsync  。 1.2 sersync  sersync ，，。 sersync  ， c ++ ，，，， crontab 。 ，： ，， 2011 （ googlecode ，）， 10  xml ，， ， 。，。，， ，，，（，  refreshCDN plugin ）。  c ++ ， FileSynchronize ， rsync  273 ，，  -- exclude =  -- eclude - from 。。 ， Sersync   ， rsync + inotify 。 ，， rsync ， module ， rsync ， ，，。 sersync ， rsync ——， rsync 。（） ，。，。  sersync2 ，，。。 1.3 lsyncd ，。 lsyncd ，， googlecode ，  github ： https : //github.com/axkibe/lsyncd 。 Lysncd  lua  inotify  rsync ， Linux （ 2.6.13 ） inotify ，  rsync ，。， inotify + rsync   —— 。，， lua ， 。 lsyncd ， cp ， rsync ， rsyncssh 。 （），。 2.  lsyncd  ， source  target ， source ，。 2.1  lsyncd  lsyncd ， ubuntu ， apt - get install lsyncd 。  Redhat （ CentOS 6.2 x86_64 ）， lsyncd - 2.1.5 - 6.f c21 . x86_64 . rpm ， yum install lua lua - devel 。， epel - release ： # rpm -ivh http: //dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm# yum install lsyncd   lsyncd ，： yum install lua lua - devel asciidoc cmake 。  googlecode lsyncd  lsyncd - 2.1.5 . tar . gz ， . / configure 、 make make install 。  github  lsyncd - master . zip  2.1.5  cmake ， . / configure ： # uzip lsyncd-master.zip# cd lsyncd-master# cmake -DCMAKE_INSTALL_PREFIX=/usr/local/lsyncd-2.1.5# make make install  bug ， INSTALL  build  make ，： [ 100 % ] Generating doc / lsyncd .1 Updating the manpage a2x : failed : source file not found : doc / lsyncd .1 . txt make [ 2 ] : *** [ doc / lsyncd .1 ] Error 1 make [ 1 ] : *** [ CMakeFiles / manpage . dir / all ] Error 2 make : *** [ all ] Error 2  cmake ， mkdir build ， CMakeList . txt  doc ，$ { PROJECT_SOURCE_DIR } 。 2.2 lsyncd . conf 。 echo 8192000 / proc / sys / fs / inotify / max_user_watches  rc . local 2.2.1 lsyncd  # cd /usr/local/lsyncd-2.1.5# mkdir etc var# vi etc/lsyncd.confsettings { logfile = /usr/local/lsyncd-2.1.5/var/lsyncd.log , statusFile = /usr/local/lsyncd-2.1.5/var/lsyncd.status , inotifyMode = CloseWrite , maxProcesses = 7 , -- nodaemon = true , } sync { default . rsync , source = /tmp/src , target = /tmp/dest , -- excludeFrom = /etc/rsyncd.d/rsync_exclude.lst , rsync = { binary = /usr/bin/rsync , archive = true , compress = true , verbose = true } }  lsycnd ，，。 2.2.2 lsyncd . conf  settings ， -- ，： logfile  stausFile  nodaemon = true ， statusInterval  lsyncd  statusFile ， 10  inotifyMode  inotify ， CloseWrite ， Modify  CloseWrite or Modify maxProcesses 。 20 ， maxProcesses = 8 ， 8  rysnc  maxDelays ， delay  sync ， maxDelays  settings 。 lsyncd ： rsync 、 rsyncssh 、 direct ： default . rsync ：， rsync ， ssh  rsync ， daemon  rsyncd ； default . direct ：， cp 、 rm ； default . rsyncssh ：， rsync  ssh ， key  source ，。 target  . ： / tmp / dest ：， direct  rsync  172.29.88.223 :/ tmp / dest ：， rsync  rsyncssh ， / usr / bin / rsync - ltsd -- delete -- include - from =- -- exclude =* SOURCE TARGET ， rsync ， username ， 172.29.88.223 :: module ：， rsync  。 init ， init = false ，，。 true delay ， rsync ， 15 （ 1000 ）。 15 s ， rsync ，。（， 15 s ，） excludeFrom ，， excludeFrom = /etc/lsyncd.exclude ，， exclude = LIST 。  rsync ，： ，， / bin / foo / bar  foo  / ，  / ， ? ， / *  0 ， / **  0 ， / delete  target  souce  ,  false ， Lsyncd  delete = true 。 false ， startup 、 running ， Lsyncd 2.1 . x ‖ Layer 4 Config ‖ Default Behavior 。 rsync （， delete  exclude  rsync ， sync ， rsync ） bwlimit ， kb / s ， rsync （） compress  true 。 cpu ， false perms 。  rsync   rsyncssh ， host 、 targetdir 、 rsync_path 、 password_file ，。 rsyncOps = { -avz , --delete }  2.1 . * 。 lsyncd . conf  sync ， source ， target ，，。 2.3  lsyncd ，，。 lsyncd - log Exec / usr / local / lsyncd - 2.1.5 / etc / lsyncd . conf 2.4 lsyncd . conf  ，： settings { logfile = /usr/local/lsyncd-2.1.5/var/lsyncd.log , statusFile = /usr/local/lsyncd-2.1.5/var/lsyncd.status , inotifyMode = CloseWrite , maxProcesses = 8 , } -- I . ， direct ： cp / rm / mv 。 ： 500 + ， sync { default . direct , source = /tmp/src , target = /tmp/dest , delay = 1 maxProcesses = 1 } -- II . ， rsync ： rsync sync { default . rsync , source = /tmp/src , target = /tmp/dest1 , excludeFrom = /etc/rsyncd.d/rsync_exclude.lst , rsync = { binary = /usr/bin/rsync , archive = true , compress = true , bwlimit = 2000 } } -- III . ， rsync  + rsyncd daemon sync { default . rsync , source = /tmp/src , target = syncuser@172.29.88.223::module1 , delete = running , exclude = { .* , .tmp }, delay = 30 , init = false , rsync = { binary = /usr/bin/rsync , archive = true , compress = true , verbose = true , password_file = /etc/rsyncd.d/rsync.pwd , _extra = { --bwlimit=200 } } } -- IV . ， rsync  + ssh shell sync { default . rsync , source = /tmp/src , target = 172.29.88.223:/tmp/dest , -- target = root@172.29.88.223:/remote/dest , --  target ，， maxDelays = 5 , delay = 30 , -- init = true , rsync = { binary = /usr/bin/rsync , archive = true , compress = true , bwlimit = 2000 -- rsh = /usr/bin/ssh -p 22 -o StrictHostKeyChecking=no -- ， rsh } } -- V . ， rsync  + rsyncssh ， sync { default . rsyncssh , source = /tmp/src2 , host = 172.29.88.223 , targetdir = /remote/dir , excludeFrom = /etc/rsyncd.d/rsync_exclude.lst , -- maxDelays = 5 , delay = 0 , -- init = false , rsync = { binary = /usr/bin/rsync , archive = true , compress = true , verbose = true , _extra = { --bwlimit=2000 }, }, ssh = { port = 1234 } } ， III  rsync  rsyncd ，。 IV 、 V  ssh ， ， ssh ，：  ssh ，： user $ ssh - keygen - t rsa  ... user $ cd ~/ . ssh user $ cat id_rsa . pub authorized_keys  id_rsa  lsyncd  user $ chmod 600 ~/ . ssh / id_rsa  user $ ssh user @172.29.88.223 3. lsyncd  lsyncd ， Lsyncd 2.1 . x ‖ Layer 2 Config ‖ Advanced onAction ， ，， example ， jpg 、 gif 、 png ， pdf ， 。， java ，， lsyncd  。， lua （ example ）。 ， maxDelays  delay ，，， rsync 。 TO - DO ： ： csync2 ， clsync ， btsync ， drdb 。 lsyncd ： GlusterFS inotify_sync  web  (  html , jpg   ) ，，，，。 ，， inotifywait ， rsync 。，  inotify + rsync 。 。 inotifywait  1 / usr / local / bin / inotifywait - mrq -- format % Xe % w % f - e modify , create , delete , attrib / data / ， inotifywait  / data / ， modify , create , delete , attrib ， % Xe % w % f 。  / data /  touch  1 touch / data / { 1..5 }  inotify  ATTRIB / data / 1 --  ATTRIB   / data / 1 ATTRIB / data / 2 ATTRIB / data / 3 ATTRIB / data / 4 ATTRIB / data / 5  ， rsync  inotifywait ， rsync 。  inotify + rsync  ，。 ( ，， ) #!/bin/bash / usr / bin / inotifywait - mrq -- format % w % f - e create , close_write , delete / backup | while read file #file ，？$file rsync do cd / backup rsync - az -- delete / backup / rsync_backup @192.168.24.101 :: backup /-- password - file =/ etc / rsync . password done # rsync ()， filersync ，10，10 rsync  (  ) ， rsync 。 # 。rsync，。  rsync 。 #，。CPU，。  ， rsync ， inotify 。 rsync ， 。  #!/bin/bash src =/ data / #  des = data #  rsync -- daemon ， rsync -- daemon ， ，。 rsync_passwd_file =/ etc / rsyncd . passwd # rsync  ip1 = 192.168.0.18 #  1 ip2 = 192.168.0.19 #  2 user = root # rsync -- daemon  cd $ { src } # ， rsync ， cd ， inotify  . /  rsync ， / usr / local / bin / inotifywait - mrq -- format % Xe % w % f - e modify , create , delete , attrib . / | while read file #    do INO_EVENT = $ ( echo $ file | awk { print $ 1 } ) #  inotify   INO_EVENT INO_FILE = $ ( echo $ file | awk { print $ 2 } ) #  inotify   INO_FILE echo ------------------------------------ echo $ file #、 #、，，，，。 if [[ $ INO_EVENT =~ CREATE ]] || [[ $ INO_EVENT =~ MODIFY ]] #  then echo CREATE or MODIFY rsync - avzR -- password - file =/ etc / rsync - client . pass $ { INO_FILE } $ { user }@ $ { ip1 } :: $ { des } # INO_FILE  rsync - avzR -- password - file =/ etc / rsync - client . pass $ { INO_FILE } $ { user }@ $ { ip2 } :: $ { des } # rsync ${INO_FILE}  -R   fi # if [[ $ INO_EVENT =~ DELETE ]] then echo DELETE rsync - avzR -- delete -- password - file =/ etc / rsync - client . pass $ ( dirname $ { INO_FILE }) $ { user }@ $ { ip1 } :: $ { des } rsync - avzR -- delete -- password - file =/ etc / rsync - client . pass $ ( dirname $ { INO_FILE }) $ { user }@ $ { ip2 } :: $ { des } #rsync ${INO_FILE}no such or directory ，  -- delete ，， ，， 。，。 fi #  touch chgrp chmod chown if [[ $ INO_EVENT =~ ATTRIB ]] then echo ATTRIB if [ ! - d $INO_FILE ] #  ，，， rsync  。 then rsync - avzR -- password - file =/ etc / rsync - client . pass $ { INO_FILE } $ { user }@ $ { ip1 } :: $ { des } rsync - avzR -- password - file =/ etc / rsync - client . pass $ { INO_FILE } $ { user }@ $ { ip2 } :: $ { des } fi fi done  1   inotify ，，， 2  1 ， ，。 1 2 crontab - e * */ 2 * * * rsync - avz -- password - file =/ etc / rsync - client . pass / data / root @192.168.0.18 :: data rsync - avz -- password - file =/ etc / rsync - client . pass / data / root @192.168.0.19 :: data 。  inotify  inotify  -- 、、， * #### * _0_ * #### *  2.6.13 ， Inotify  、、，，。 inotifywait    - m , – monitor  - r , – recursive  - q , – quiet  – excludei ， - t , – timeout  – timefmt  – format  - e , – event 、、 inotifywait events    access  modify  attrib  close_write  close_nowrite close open  moved_to  moved_from  move  create  delete  delete_self unmount   Inotify # /proc/sys/fs/inotify，inotify [ root @ web ~ ] # ll / proc / sys / fs / inotify /  0 - rw - r -- r -- 1 root root 09  923 : 36 max_queued_events - rw - r -- r -- 1 root root 09  923 : 36 max_user_instances - rw - r -- r -- 1 root root 09  923 : 36 max_user_watches ----------------------------- max_user_watches # inotifywait  inotifywatch  (  ) max_user_instances # inotifywait  inotifywatch  max_queued_events # inotify  ( event )  ---------------------------- [ root @ web ~ ] # echo 50000000 / proc / sys / fs / inotify / max_user_watches --  / etc / rc . local  [ root @ web ~ ] # echo 50000000 / proc / sys / fs / inotify / max_queued_events","title":"disk"},{"location":"disk/#fdisk","text":"fdisk - l  fdisk / dev / sda p  n  w  d  t   partprode   hdparm - Tt  swap 1 、 fdisk  swap mkswap / xx / xx 2 、 dd if =/ dev / zero of =/ tmp / swap bs =  count =   / etc / fstab swapon / xx / xx  swap swapoff  swap swapon - s  fsck （）","title":"fdisk"},{"location":"disk/#parted","text":" 2 T   Parted  LVM  ， Parted  1 ， parted  www . 2 cto . com # parted / dev / sda GNU Parted 2 . 1  / dev / sda Welcome to GNU Parted ! Type help to view a list of commands . ( parted ) help  ( parted ) mktable ？ gpt GPT  GRUB ， MBR ， 2 T  ( parted ) p  4398 GB  Model : DELL MD32xx ( scsi ) Disk / dev / sda : 4398 GB Sector size ( logical / physical ) : 512 B / 512 B Partition Table : gpt Number Start End Size File system Name  ( parted ) mkpart # ？ []? # ？ [ ext2 ]? # ？ 0 G # ？ 4398 G # ( parted ) p Model : DELL MD32xx ( scsi ) Disk / dev / sda : 4398 GB Sector size ( logical / physical ) : 512 B / 512 B Partition Table : gpt Number Start End Size File system Name  1 1049 kB 4398 GB 4398 GB ( parted ) toggle 1 lvm # lvm ( parted ) p Model : DELL MD32xx ( scsi ) Disk / dev / sda : 4398 GB Sector size ( logical / physical ) : 512 B / 512 B Partition Table : gpt Number Start End Size File system Name  1 1049 kB 4398 GB 4398 GB lvm ( parted ) quit : You may need to update / etc / fstab . 2 ， sdb , sdc , sdd  ， LVM ，， PV , VG , LVM 1 ， PV # pvcreate / dev / sda1 / dev / sdb1 / dev / sdc1 / dev / sdd1 Writing physical volume data to disk /dev/sda1 Physical volume /dev/sda1 successfully created Writing physical volume data to disk /dev/sdb1 Physical volume /dev/sdb1 successfully created Writing physical volume data to disk /dev/sdc1 Physical volume /dev/sdc1 successfully created Writing physical volume data to disk /dev/sdd1 Physical volume /dev/sdd1 successfully created 2 , VG # vgcreate md3200 / dev / sda1 / dev / sdb1 / dev / sdc1 / dev / sdd1 Volume group md3200 successfully created # lvcreate - n md3200lv1 - L 8 T md3200 Logical volume md3200lv1 created You have new mail in / var / spool / mail / root 3 , LVM # lvcreate - n md3200lv1 - L 8 T md3200 Logical volume md3200lv1 created # lvcreate - n md3200lv2 - L 8 T md3200 Logical volume md3200lv2 created ， # mkfs . ext4 / dev / md3200 / md3200lv1 mke2fs 1 . 41 . 12 ( 17 - May - 2010 )  = : Linux  = 4096 ( log = 2 )  = 4096 ( log = 2 ) Stride = 0 blocks , Stripe width = 0 blocks 536870912 inodes , 2147483648 blocks 107374182 blocks ( 5 . 00 % ) reserved for the super user  = 0 Maximum filesystem blocks = 4294967296 65536 block groups 32768 blocks per group , 32768 fragments per group 8192 inodes per group Superblock backups stored on blocks : 32768 , 98304 , 163840 , 229376 , 294912 , 819200 , 884736 , 1605632 , 2654208 , 4096000 , 7962624 , 11239424 , 20480000 , 23887872 , 71663616 , 78675968 , 102400000 , 214990848 , 512000000 , 550731776 , 644972544 , 1934917632  inode :  Creating journal ( 32768 blocks ) :  Writing superblocks and filesystem accounting information :  This filesystem will be automatically checked every 33 mounts or 180 days , whichever comes first . Use tune2fs - c or - i to override . ， # mkdir md3200lv1 md3200lv2 # mount / dev / md3200 / md3200lv1 / md3200lv1 / # ls / md3200lv1 / lost + found # tail - n 2 / etc / fstab / dev / md3200 / md3200lv1 / md3200lv1 ext4 defaults 1 2 / dev / md3200 / md3200lv2 / md3200lv2 ext4 defaults 1 2 ， # reboot # df - hl      %%  / dev / mapper / md3200 - md3200lv1 7 . 9 T 175 M 7 . 5 T 1 % / md3200lv1 / dev / mapper / md3200 - md3200lv2 7 . 9 T 175 M 7 . 5 T 1 % / md3200lv2 ， # dd if =/ dev / zero of = . / test bs = 10 M count = 1000  1000 + 0   1000 + 0  10485760000  ( 10 GB ) ， 8 . 83453 ， 1 . 2 GB /  # free - g total used free shared buffers cached Mem : 62 11 51 0 0 9 -/+ buffers / cache : 1 61 Swap : 7 0 7 # dd if = . / test of = . / test1 bs = 10 M count = 1000  1000 + 0   1000 + 0  10485760000  ( 10 GB ) ， 12 . 3038 ， 852 MB /  # dd if = . / test1 of = . / test2 bs = 10 M count = 1000  1000 + 0   1000 + 0  10485760000  ( 10 GB ) ， 19 . 0357 ， 551 MB /  # dd if = . / test2 of = . / test3 bs = 10 M count = 1000  1000 + 0   1000 + 0  10485760000  ( 10 GB ) ， 18 . 641 ， 563 MB /  # free - g total used free shared buffers cached Mem : 62 41 21 0 0 39 -/+ buffers / cache : 2 60 Swap : 7 0 7 # dd if = . / test3 of = . / test4 bs = 10 M count = 1000  1000 + 0   1000 + 0  10485760000  ( 10 GB ) ， 17 . 3797 ， 603 MB /  # dd if = . / test4 of = . / test5 bs = 10 M count = 1000  1000 + 0   1000 + 0  10485760000  ( 10 GB ) ， 22 . 8714 ， 458 MB /  # dd if = . / test5 of = . / test6 bs = 10 M count = 1000  1000 + 0   1000 + 0  10485760000  ( 10 GB ) ， 100 . 246 ， 105 MB /   64 G ，， 105 。 ： http : // www . 2 cto . com / os / 201303 / 195308 . html","title":"parted"},{"location":"disk/#megacli","text":"http : // www . avagotech . com / docs - and - downloads / raid - controllers / raid - controllers - common - files / 8 - 07 - 14 _MegaCLI . zip  Linux   raid ： raid ， # cat / proc / mdstat  raid ： raid ，， # dmesg | grep - i raid # cat / proc / scsi / scsi 2 .  raid  raid  ,  MegaCLI   MegaCli ，。 # rpm - ivh MegaCli - 1 . 01 . 24 - 0 . i386 . rpm  / opt ， / opt / MegaCli 。 ： # / opt / MegaRAID / MegaCli / MegaCli64 - CfgForeign - Clear - a0  Foreign  #/ opt / MegaCli - LDInfo - Lall - aALL  raid  #/ opt / MegaCli - AdpAllInfo - aALL  raid  #/ opt / MegaCli - PDList - aALL  #/ opt / MegaCli - AdpBbuCmd - aAll  #/ opt / MegaCli - FwTermLog - Dsply - aALL  raid  #/ opt / MegaCli - adpCount 【】 #/ opt / MegaCli - AdpGetTime – aALL 【】 #/ opt / MegaCli - AdpAllInfo - aAll 【】 #/ opt / MegaCli - LDInfo - LALL - aAll 【】 #/ opt / MegaCli - PDList - aAll 【】 #/ opt / MegaCli - AdpBbuCmd - GetBbuStatus - aALL | grep ‘ Charger Status ’ 【】 #/ opt / MegaCli - AdpBbuCmd - GetBbuStatus - aALL 【 BBU 】 #/ opt / MegaCli - AdpBbuCmd - GetBbuCapacityInfo - aALL 【 BBU 】 #/ opt / MegaCli - AdpBbuCmd - GetBbuDesignInfo - aALL 【 BBU 】 #/ opt / MegaCli - AdpBbuCmd - GetBbuProperties - aALL 【 BBU 】 #/ opt / MegaCli - cfgdsply - aALL 【 Raid ， Raid ， Disk 】 3 . ，，。 Device | Normal | Damage | Rebuild | Normal Virtual Drive | Optimal | Degraded | Degraded | Optimal Physical Drive | Online | Failed – gt ; Unconfigured | Rebuild | Online 4 .  #/ opt / MegaCli - LDGetProp - Cache - L0 - a0 or #/ opt / MegaCli - LDGetProp - Cache - L1 - a0 or #/ opt / MegaCli - LDGetProp - Cache - LALL - a0 ro #/ opt / MegaCli - LDGetProp - Cache - LALL - aALL ro #/ opt / MegaCli - LDGetProp - DskCache - LALL - aALL 5 .  ： WT ( Write through WB ( Write back ) NORA ( No read ahead ) RA ( Read ahead ) ADRA ( Adaptive read ahead ) Cached Direct ： #/ opt / MegaCli - LDSetProp WT | WB | NORA | RA | ADRA - L0 - a0 or #/ opt / MegaCli - LDSetProp - Cached |- Direct - L0 - a0 or enable / disable disk cache #/ opt / MegaCli - LDSetProp - EnDskCache |- DisDskCache - L0 - a0 6 .  raid5 ， 2 , 3 , 4 ， 5 #/ opt / MegaCli - CfgLdAdd - r5 [ 1 : 2 , 1 : 3 , 1 : 4 ] WB Direct - Hsp [ 1 : 5 ] - a0 7 . ， #/ opt / MegaCli - CfgLdAdd - r5 [ 1 : 2 , 1 : 3 , 1 : 4 ] WB Direct - a0 8 .  #/ opt / MegaCli - CfgLdDel - L1 - a0 9 .  #/ opt / MegaCli - LDRecon - Start - r5 - Add - PhysDrv [ 1 : 4 ] - L1 - a0 10 . ，，。 #/ opt / MegaCli - LDInit - ShowProg - LALL - aALL  #/ opt / MegaCli - LDInit - ProgDsply - LALL - aALL 11 .  #/ opt / MegaCli - LDBI - ShowProg - LALL - aALL  #/ opt / MegaCli - LDBI - ProgDsply - LALL - aALL 12 .  5  #/ opt / MegaCli - PDHSP - Set [ - EnclAffinity ] [ - nonRevertible ] - PhysDrv [ 1 : 5 ] - a0 13 .  #/ opt / MegaCli - PDHSP - Set [ - Dedicated [ - Array1 ]] [ - EnclAffinity ] [ - nonRevertible ] - PhysDrv [ 1 : 5 ] - a0 14 .  #/ opt / MegaCli - PDHSP - Rmv - PhysDrv [ 1 : 5 ] - a0 15 .  /  MegaCli64 - PDList - aALL  [ Enclosure Device ID : Slot Number ] [ 1 : 4 ] #/ opt / MegaCli - PDOffline - PhysDrv [ 1 : 4 ] - a0 #/ opt / MegaCli - PDOnline - PhysDrv [ 1 : 4 ] - a0 16 .  #/ opt / MegaCli - PDRbld - ShowProg - PhysDrv [ 1 : 5 ] - a0  #/ opt / MegaCli - PDRbld - ProgDsply - PhysDrv [ 1 : 5 ] - a0","title":"MegaCli"},{"location":"disk/#_1","text":"owncloud https : // owncloud . org / seafile https : // www . seafile . com / home /","title":""},{"location":"disk/#lvm","text":"lvm  pv ， vg  ： pvcreate / dev / xxx vgcreate vg0 / dev / xx lvcreate - L 512 M - n lv0 vg0 mkfs . ext3 / dev / vg1 / lv0 mount / dev / vg1 / lv0 / data / vim / etc / fatab / dev / mapper / vg1 - lvdata / data ext3 defaults 1 2  pvdisplay or pvscan vgdisplay or vgscan lvdisplay or lvscan lvm  ： fdisk / dev / hda n p # ，，，（： P - P - P - P  P - P - P - E ） 1 # ， / dev / hda6 t 8 e #  8 e  LVM  w #  partprobe #  partx / dev / hda #   PV ， VG ， LV pvcreate / dev / hda1 vgdisplay #  VG ， VG ： VolGroup00  vgextend VolGroup00 / dev / hda1 #  VolGroup00 lvdisplay #  LV ， LV ： LogVol01  lvextend – L 1 G / dev / VolGroup00 / LogVol01 #  LV - l + 100 % FREE  ext3 ext4  resize2fs / dev / VolGroup00 / LogVol01 # ， LogVol01  xfs  xfs_growfs / dev / centos / root # ， LogVol01  df – h # ，","title":"lvm"},{"location":"disk/#samba","text":"yum install samba samba - client samba - common samba - swat    wab systemctl restart smb vim / etc / samba / smb . conf security = share / user user ，  ： passdb backend = tdbsam username map =/ etc / samba / smbusers vim / etc / samba / smbusers  = samba1 [  ] samba2 smbpasswd - a  / etc / samba / smb . conf [ homes ]  comment = xxxx  path =/ tmp / samba chmod o + w / tmp / samba public = yes  guesk ok = yes browseable = yes  ， yes writable = yes  write list =  ，  read only = yes  read list =  ，   ，  valid users =  ，  invalid users =  ，   ：  ，  [ work ] comment = All path = / data #public = no browseable = yes #guest ok = yes writable = yes read only = no write list = ftp , work valid users = ftp , work  smbclient - L ip  smbclient // ip /  - U  mount - t cifs // ip /  / mnt / abc - O username = test , passwd = windows \\\\ ip","title":"samba"},{"location":"disk/#nfs","text":"、 NFS  　　 NFS  Network File System ，。， Sun ， 1984 。 、，，  Unix 。 　　 NFS “ RPC ”，， 。 　　 NFS  RPC 。 RPC ， ( Remote Procedure Call )  。 NFS ， NFS ， NFS  。 RPC 。 NFS  RPC 。 NFS  RPC SERVER 。 NFS   RPC ， NFS SERVER  NFS CLIENT 。 SERVER  CLIENT  RPC  PROGRAM PORT 。 RPC  NFS  ： NFS ， RPC 。 、 ： CentOS release 5 . 6 ( Final ) NFS Server IP ： 192 . 168 . 1 . 108  / iptables : Firewall is not running . SELINUX = disabled 、 NFS  NFS ，，，。 nfs - utils -* ： NFS  portmap -* ： NFS RPC ， rpcbind  NFS  nfs - utils portmap 。 、 NFS  nfsd ： NFS ，； mountd ： RPC ， NFS 。 nfsd  NFS ， NFS ， 。 NFS  / etc / exports 。 portmap ：。 RPC （ NFS ）， portmap  ，。 、 NFS  NFS ，， NFS 。 NFS  / etc / exports NFS  / usr / sbin / exportfs NFS  / usr / sbin / showmount  / var / lib / nfs / etab  NFS  / var / lib / nfs / xtab  NFS  / etc / exports ， NFS ，，， vim ，。 / etc / exports ：  [  1 （ ,  , ） ] [  2 （ ,  , ） ] a . ：  NFS ； b . ：  NFS    ip ： 192 . 168 . 0 . 200 ： 192 . 168 . 0 . 0 / 24 192 . 168 . 0 . 0 / 255 . 255 . 255 . 0 ： david . bsmart . cn ： * . bsmart . cn ： * c . ： 、。 NFS  3 ：  ： ro ： rw  all_squash ：（ nfsnobody ）； no_all_squash ： all_squash （）； root_squash ： root （）； no_root_squash ： rootsquash ； anonuid = xxx ：，（ UID = xxx ）； anongid = xxx ：，（ GID = xxx ）；  secure ： 1024  tcp / ip  nfs （）； insecure ： 1024  tcp / ip ； sync ：，，； async ：，； wdelay ：，，（）； no_wdelay ：， sync ； subtree ：， nfs  (  ) ； no_subtree ：， nfs ，； 、 NFS   exports ， NFS 。 1 、 NFS   NFS ， portmap  nfs ， portmap  nfs 。 # service portmap start # service nfs start 2 、 NFS  # service portmap status # service nfs status 3 、 NFS   NFS ， nfs  portmap ， (  NIS ) ， portmap  # service nfs stop # service portmap stop 4 、 NFS  ， LINUX  nfs ， portmap  nfs 。 # chkconfig --list portmap # chkconfig --list nfs  portmap  nfs  3  5 。 # chkconfig --level 35 portmap on # chkconfig --level 35 nfs on 、 1 、 NFS Server  / home / david /  192 . 168 . 1 . 0 / 24 ，。 # vi / etc / exports / home / david 192 . 168 . 1 . 0 / 24 ( rw ) 2 、 portmap  nfs  # service portmap restart # service nfs restart # exportfs 3 、 showmount  NFS  # showmount - e 　　　　 // ， DNS ， # showmount - a 　　　　 //  4 、 showmount  NFS  # showmount - e NFS  IP 5 、 NFS   # mount NFS  IP :   # mount 192 . 168 . 1 . 108 : / home / david / / tmp / david / # mount | grep nfs 。 。 6 、 NFS   / tmp / david / ， # touch 20130103  Permission denied ， NFS ，。 # chmod 777 - R / home / david /  / tmp / david /   root ， nfsnobody 。 NFS ， / var / lib / nfs / etab  / home / david / 。 # cat / var / lib / nfs / etab  sync ， wdelay ， hide ， no_root_squash  root ， root_squash  root  nobody ， no_all_squash  。， root  nfsnobody 。 、。 # su - david $ cd / tmp / david / $ touch 2013 david ，。 　　 　　 1 . ， 　　　　 a . ，； 　　　　 b .  NFS server ， NFS server ； 　　　　 c . ，，  nfsnobody ； 　　 2 . ， root  　　　　 a .  no_root_squash ， root  NFS server  root ； 　　　　 b .  all_squash 、 anonuid 、 anongid ， root ； 　　　　 c . ， root  nfsnobody ； 　　　　 d .  no_root_squash  all_squash  nfsnobody ， anonuid 、 anongid  ； 7 、 NFS  # umount / tmp / david / 、 nfs  ： server : / remote / export / local / directory nfs options 0 0 # vi / etc / fstab ，。  / home / david 。 。 、 1 、 exportfs  NFS  / etc / exports ， nfs ？ exportfs ， ： 　　 # exportfs [ - aruv ] 　　 - a  / etc / exports  　　 - r  / etc / exports  ， / etc / exports 、 / var / lib / nfs / xtab 　　 - u （ - a  / etc / exports ） 　　 - v  export ，。 ： 　　 # exportfs - au  　　 # exportfs - rv  2 、 nfsstat  NFS ， NFS 。 3 、 rpcinfo  rpc ， rpc ， rpcinfo - p  RPC 。 4 、 showmount 　　 - a  　　 - e IP  hostname  IP  5 、 netstat  nfs ， nfs  2049 ， portmap  111 ， rpc 。 ，， root ， sudo 。 NFS server  NFS ，！ showmount - a ， kill killall pkill ，（ - 9 ）","title":"nfs"},{"location":"disk/#iozone","text":"http : // www . iozone . org wget http : // www . iozone . org / src / current / iozone3_465 . tar tar - xf iozone3_465 . tar cd iozone3_465 / src / current / make linux ，（）， linux 。 。  . / iozone - s 5 g - i0 - i1 - i2 - Rb ioperf . xls - I ， - I direct io  . / iozone - Rab ioperf . xls - s 64 G - i 0 - i 1 - i 2 - y 4 k - q 16 k  : - a auto mode  16 K - 512 M , 4 K - 16 M ； - e  fflush ， fsync ； - f  ； - R  excel （, excel ） - b  excel  - s   - k - m - g ； - r ； - g - n  auto ， / ； - q - y  auto ， / ； - i ： ( 0 = write / rewrite , 1 = read / re - read , 2 = random - read / write 3 = Read - backwards , 4 = Re - write - record , 5 = stride - read , 6 = fwrite / re - fwrite , 7 = fread / Re - fread , 8 = random mix , 9 = pwrite / Re - pwrite , 10 = pread / Re - pread , 11 = pwritev / Re - pwritev , 12 = preadv / Repreadv ） - I  direct io ； - p  cpu cache ； - t  - O  IOPS ； - R  excel ； - W ；  ioperf1 . xls  read ， write ，， write ，（ Kbytes ) , ，。，“ 19918 ”， 64 K ， 4 K ，  19918 Kbytes / s 。 - i ： 0 = write / rewrite 1 = read / re - read 2 = random - read / write 3 = Read - backwards 4 = Re - write - record 5 = stride - read 6 = fwrite / re - fwrite 7 = fread / Re - fread 8 = random mix 9 = pwrite / Re - pwrite 10 = pread / Re - pread 11 = pwritev / Re - pwritev 12 = preadv / Re - preadv Write :。，， 。“”。，。 ， Write  Re - write 。 Re - write :。，，。 Re - write   Write 。 Read : 。 Re - Read :。 Re - Read ，。。 Random Read :。，：，， 。 Random Write :。，，：，， 。 Random Mix :。，，：，， 。。 / 。 /  roundrobin 。  / 。 Backwards Read :。，，。 MSCNastran  。（ G  T ）。， 。 Record Rewrite :。。（ CPU ）， 。 CPU  TLB ，。，， 。，。 Strided Read :。： 0  4 Kbytes ， 200 Kbytes , 4 Kbytes ， 200 Kbytes ，。  4 Kbytes ， 200 Kbytes 。， 。 。，。 ，。 Fwrite : fwrite () 。。。 ， fwrite ()  I / O 。 ，。 Frewrite : fwrite () 。。。 ， fwrite ()  I / O 。 ，，。 Fread : fread () 。。。 ， fwrite ()  I / O 。 Freread :  fread ","title":"iozone"},{"location":"disk/#fio","text":"  ：  ，   ！！！ FIO wget http : // brick . kernel . dk / snaps / fio - 2.2.5 . tar . gz yum install libaio - devel tar - zxvf fio - 2.2.5 . tar . gz cd fio - 2.2.5 make make install  、 FIO ：  ： (  ， 2G ， 10  ， 1 ，  ) fio - filename =/ tmp / test_randread - direct = 1 - iodepth 1 - thread - rw = randread - ioengine = psync - bs = 16 k - size = 2 G - numjobs = 10 - runtime = 60 - group_reporting - name = mytest  ： filename =/ dev / sdb1  ， data 。 direct = 1 buffer 。  。 rw = randwrite I / O rw = randrw I / O bs = 16 k io16k bsrange = 512 - 2048  ，  size = 5 g 5g ， 4kio 。 numjobs = 30 30 . runtime = 1000 1000 ， 5g4k 。 ioengine = psync iopync rwmixwrite = 30  ， 30 % group_reporting  ，  。  lockmem = 1 g 1g 。 zero_buffers 0buffer 。 nrfiles = 8  。 read  write  rw , readwrite  randwrite  randread  randrw  io bw ：  KB / s iops ： IO runt ：  lat ( msec ) ：  (  ) msec ：  usec ：   ： fio - filename =/ dev / sdb1 - direct = 1 - iodepth 1 - thread - rw = read - ioengine = psync - bs = 16 k - size = 2 G - numjobs = 10 - runtime = 60 - group_reporting - name = mytest  ： fio - filename =/ dev / sdb1 - direct = 1 - iodepth 1 - thread - rw = randwrite - ioengine = psync - bs = 16 k - size = 2 G - numjobs = 10 - runtime = 60 - group_reporting - name = mytest  ： fio - filename =/ dev / sdb1 - direct = 1 - iodepth 1 - thread - rw = write - ioengine = psync - bs = 16 k - size = 2 G - numjobs = 10 - runtime = 60 - group_reporting - name = mytest  ： fio - filename =/ dev / sdb1 - direct = 1 - iodepth 1 - thread - rw = randrw - rwmixread = 70 - ioengine = psync - bs = 16 k - size = 2 G - numjobs = 10 - runtime = 60 - group_reporting - name = mytest - ioscheduler = noop  ，  ： [ root@localhost ~ ] # fio - filename =/ dev / sdb1 - direct = 1 - iodepth 1 - thread - rw = randrw - rwmixread = 70 - ioengine = psync - bs = 16 k - size = 200 G - numjobs = 30 - runtime = 100 - group_reporting - name = mytest1 mytest1 : ( g = 0 ) : rw = randrw , bs = 16 K - 16 K / 16 K - 16 K , ioengine = psync , iodepth = 1 … mytest1 : ( g = 0 ) : rw = randrw , bs = 16 K - 16 K / 16 K - 16 K , ioengine = psync , iodepth = 1 fio 2.0.7 Starting 30 threads Jobs : 1 ( f = 1 ) : [ ________________m_____________ ] [ 3.5% done ] [ 6935K/3116K /s ] [ 423 /190 iops ] [ eta 48m:20s ] s ] mytest1 : ( groupid = 0 , jobs = 30 ) : err = 0 : pid = 23802 read : io = 1853.4 MB , bw = 18967 KB / s , iops = 1185 , runt = 100058 msec clat ( usec ) : min = 60 , max = 871116 , avg = 25227.91 , stdev = 31653.46 lat ( usec ) : min = 60 , max = 871117 , avg = 25228.08 , stdev = 31653.46 clat percentiles ( msec ) : | 1.00 th =[ 3 ] , 5.00 th =[ 5 ] , 10.00 th =[ 6 ] , 20.00 th =[ 8 ] , | 30.00 th =[ 10 ] , 40.00 th =[ 12 ] , 50.00 th =[ 15 ] , 60.00 th =[ 19 ] , | 70.00 th =[ 26 ] , 80.00 th =[ 37 ] , 90.00 th =[ 57 ] , 95.00 th =[ 79 ] , | 99.00 th =[ 151 ] , 99.50 th =[ 202 ] , 99.90 th =[ 338 ] , 99.95 th =[ 383 ] , | 99.99 th =[ 523 ] bw ( KB / s ) : min = 26 , max = 1944 , per = 3.36 % , avg = 636.84 , stdev = 189.15 write : io = 803600 KB , bw = 8031.4 KB / s , iops = 501 , runt = 100058 msec clat ( usec ) : min = 52 , max = 9302 , avg = 146.25 , stdev = 299.17 lat ( usec ) : min = 52 , max = 9303 , avg = 147.19 , stdev = 299.17 clat percentiles ( usec ) : | 1.00 th =[ 62 ] , 5.00 th =[ 65 ] , 10.00 th =[ 68 ] , 20.00 th =[ 74 ] , | 30.00 th =[ 84 ] , 40.00 th =[ 87 ] , 50.00 th =[ 89 ] , 60.00 th =[ 90 ] , | 70.00 th =[ 92 ] , 80.00 th =[ 97 ] , 90.00 th =[ 120 ] , 95.00 th =[ 370 ] , | 99.00 th =[ 1688 ] , 99.50 th =[ 2128 ] , 99.90 th =[ 3088 ] , 99.95 th =[ 3696 ] , | 99.99 th =[ 5216 ] bw ( KB / s ) : min = 20 , max = 1117 , per = 3.37 % , avg = 270.27 , stdev = 133.27 lat ( usec ) : 100 = 24.32 % , 250 = 3.83 % , 500 = 0.33 % , 750 = 0.28 % , 1000 = 0.27 % lat ( msec ) : 2 = 0.64 % , 4 = 3.08 % , 10 = 20.67 % , 20 = 19.90 % , 50 = 17.91 % lat ( msec ) : 100 = 6.87 % , 250 = 1.70 % , 500 = 0.19 % , 750 = 0.01 % , 1000 = 0.01 % cpu : usr = 1.70 % , sys = 2.41 % , ctx = 5237835 , majf = 0 , minf = 6344162 IO depths : 1 = 100.0 % , 2 = 0.0 % , 4 = 0.0 % , 8 = 0.0 % , 16 = 0.0 % , 32 = 0.0 % , = 64 = 0.0 % submit : 0 = 0.0 % , 4 = 100.0 % , 8 = 0.0 % , 16 = 0.0 % , 32 = 0.0 % , 64 = 0.0 % , = 64 = 0.0 % complete : 0 = 0.0 % , 4 = 100.0 % , 8 = 0.0 % , 16 = 0.0 % , 32 = 0.0 % , 64 = 0.0 % , = 64 = 0.0 % issued : total = r = 118612 / w = 50225 / d = 0 , short = r = 0 / w = 0 / d = 0 Run status group 0 ( all jobs ) : READ : io = 1853.4 MB , aggrb = 18966 KB / s , minb = 18966 KB / s , maxb = 18966 KB / s , mint = 100058 msec , maxt = 100058 msec WRITE : io = 803600 KB , aggrb = 8031 KB / s , minb = 8031 KB / s , maxb = 8031 KB / s , mint = 100058 msec , maxt = 100058 msec Disk stats ( read / write ) : sdb : ios = 118610 / 50224 , merge = 0 / 0 , ticks = 2991317 / 6860 , in_queue = 2998169 , util = 99.77 % iop","title":"fio"},{"location":"disk/#vsftp","text":"777 ，  ，   ，  FlashFXP #connect_from_port_20 = YES  pasv_enable = YES pasv_promiscuous = YES pasv_min_port = 3000 pasv_max_port = 3500 2 .3.5  ， vsftpd ，  ，  allow_writeable_chroot = YES   chmod a - w / home / user chroot_local_user = YES  chroot_list_enable = YES # ( default follows ) #chroot_list_file =/ etc / vsftpd / chroot_list  “  ”，  yum install vsftpd curlftpfs ftp ，  / etc / vsftpd /  ，  ： ftpusers ftp 。 user_list ftp . vsftpd . conf vsftpd . ftpusersuser_list 。 ftpusers ，  ，  ！  db_load - T - t hash - f / etc / vsftpd / vftpuser . txt / etc / vsftpd / vu_list . db / etc / init . d / vsftpd restart vsftpd . conf ： 1 、  ， NO anon_upload_enable = NO anon_mkdir_write_enable = NO  ，  ，  。 anonymous_enable = NO 2 、  port_enable = YES ，  ， FTP PORT connect_from_port_20 = YES ，  ， FTP PORT20 ( ftp - data ) 。 YES ， NO 。 ftp_data_port = port number ， ftp ( ftp - data )  。 20 。 PORT FTP 。 3 、  ascii 。 NO ， binary 。 ascii_upload_enable = YES ascii_download_enable = YES   / var / ftp  anon_root =/ data / 3 mang_apps （ 777 ，  ） vim / etc / vsftpd / vsftpd . conf anonymous_enable = YES  local_enable = YES  anon_world_readable_only = YES   anon_other_write_enable = YES  anon_upload_enable = YES  anon_mkdir_write_enable = YES  local_max_rate = 1000000 --------------1M   xferlog_enable = YES xferlog_std_format = YES xferlog_file =/ var / log / xferlog dual_log_enable = YES vsftpd_log_file =/ var / log / vsftpd . log  curlftpfs ftp : // $ IP / mnt /   ” anonymous_enable = YES “  “ anonymous_enable = NO ” chroot_list_enable = YES chroot_list_file =/ etc / vsftpd / chroot_list useradd ftpadmin - s / sbin / nologin - d / home / ftpadmin 755 ， 777  (  ， 777 ) passwd ftpadmin  / etc / vsftpd / chroot_list ftpadmin user_list 。  ftp / var / ftp ，  / mnt / soft ，  / var / ftp / a ，   / var / ftp [ root@localhost ~ ] # mkdir / var / ftp / a mount [ root@localhost ~ ] # mount --bind /mnt/soft /var/ftp/a OK。 [ root@localhost etc ] # vi / etc / fstab  / mnt / soft / home / public auto bind 0 0  / etc / fstab  vim / etc / vsftpd / vftpuser . txt user passwd user2 passwd2 db_load - T - t hash - f / etc / vsftpd / vftpuser . txt / etc / vsftpd / vu_list . db chmod 600 / etc / vsftpd / vu_list . db vi / etc / pam . d / vsftp . vu PAM auth required / usr / lib64 / security / pam_userdb . so db =/ etc / vsftpd / vu_list account required / usr / lib64 / security / pam_userdb . so db =/ etc / vsftpd / vu_list # pam_userdb . so find / - name pam_userdb . so ，  useradd - d / home / ftpsite virtual_user  chmod 700 / home / ftpsite  / etc / vsftpd / vsftpd . conf ，  （  ）： anonymous_enable = NO local_enable = YES local_umask = 022 xferlog_enable = YES connect_from_port_20 = YES xferlog_std_format = YES listen = YES write_enable = YES anon_upload_enable = YES anon_mkdir_write_enable = YES anon_other_write_enable = YES anon_umask = 022 one_process_model = NO chroot_local_user = YES allow_writeable_chroot = YES ftpd_banner = Welcom to my FTP server . anon_world_readable_only = NO guest_enable = YES guest_username = virtual_user pam_service_name = vsftp . vu  ， guest_enable = YES ； guest_username = virtual_user ， virtual_user ； pam_service_name = vsftp . vu PAM vsftp . vu FTP ，  。  / etc / vsftpd . conf ： user_config_dir =/ etc / vsftpd / vsftpd_user_conf   ， gou ： #vi / etc / vsftpd / vsftpd_user_conf / gou write_enable = YES local_root =  virtual_user 9. FTP 1. vftpuser . txt 2.  ,  db_load - T - t hash - f / etc / vsftpd / vftpuser . txt / etc / vsftpd / vu_list . db 3 etc / vsftpd / vsftpd_user_conf ,  local_root =  4 ftp systemctl restart vsftpd  、 FTP  FTPTCP ，  ：  ，  。 21 （  ） 20 （  ）。 FTP ： N （ N 1024 ） FTP ， 21 。 N + 1 ， FTP “ port N + 1 ” FTP 。  （ 20 ）  （ N + 1 ）。  ， PASV ，  。 FTP ，  .  FTP ，  （ N 1024 N + 1 ）。 21 ， FTP ， PORT ，  PASV 。  （ P 1024 ）， PORT P 。 N + 1 P 。  ，  ， TCP 。  ，  。（  ，  ）  、 FTP Linux ，  ， FTP 。 FTP ，  ： 1. 1024FTP21 。（  ） 2. FTP211024 。 （  ） 3. FTP201024 。（  ） 4. 1024FTP20 （ ACK ） FTP ，  : 1. 102421 （  ） 2. 211024 （  ） 3. 10241024 （  ） 4. 10241024 （ ACK ）  ： vi / etc / vsftpd / vsftpd . confpasv ： pasv_enable = YES  （  ）： pasv_min_port = 10020 pasv_max_port = 11020 vsftpd 。 vi / etc / sysconfig / iptables ，  ： - A INPUT - m state --state RELATED,ESTABLISHED -j ACCEPT - A INPUT - p icmp - j ACCEPT - A INPUT - i lo - j ACCEPT - A INPUT - p tcp - m state --state NEW -m tcp --dport 10020:11020 -j ACCEPT - A INPUT - p tcp - m state --state NEW -m tcp --dport 20 -j ACCEPT - A INPUT - p tcp - m state --state NEW -m tcp --dport 21 -j ACCEPT iptables 。 FTP ，  ，  / etc / vsftpd / vsftpd . conf ，  ： pasv_address = 111.111.111.111 （  ） pasv_addr_resolve = yes pasv_promiscuous = yes  ： 200 PORT command successful . Consider using PASV .  ，  PASV ，  。 VLAN ，  ，  ， PASV ， PASV ，  。","title":"vsftp"},{"location":"disk/#vsftpd-mysql","text":"、 1 、 mysql  ; # yum -y install mysql-server mysql-devel # yum -y groupinstall Development Tools Development Libraries 2.  pam_mysql - 0.7 RC1 # tar zxvf pam_mysql-0.7RC1.tar.gz # cd pam_mysql-0.7RC1 # ./configure --with-mysql=/usr --with-openssl # make # make install 3.  vsftpd # yum -y install vsftpd 、 1.   mysql 。，， vsftpd 。 mysql create database vsftpd ; mysql grant select on vsftpd . * to vsftpd @ localhost identified by www . magedu . com ; mysql grant select on vsftpd . * to vsftpd @127.0.0.1 identified by www . magedu . com ; mysql flush privileges ; mysql use vsftpd ; mysql create table users ( - id int AUTO_INCREMENT NOT NULL , - name char ( 20 ) binary NOT NULL , - password char ( 48 ) binary NOT NULL , - primary key ( id ) - ); 2 、 ，，， pam_mysql  password ()  MySQL  password ()  。 mysql insert into users ( name , password ) values ( tom , magedu ); mysql insert into users ( name , password ) values ( jerry , magedu ); 、 vsftpd 1.  pam  #vi /etc/pam.d/vsftpd.mysql  auth required / lib / security / pam_mysql . so user = vsftpd passwd = www . magedu . com host = localhost db = vsftpd table = users  usercolumn = name passwdcolumn = password crypt = 0 account required / lib / security / pam_mysql . so user = vsftpd passwd = www . magedu . com host = localhost db = vsftpd table = users  usercolumn = name passwdcolumn = password crypt = 0 2.  vsftpd ， mysql   #useradd -s /sbin/nologin -d /var/ftproot vuser #chmod go+rx /var/ftproot  / etc / vsftpd . conf  anonymous_enable = YES local_enable = YES write_enable = YES anon_upload_enable = NO anon_mkdir_write_enable = NO chroot_local_user = YES  guest_enable = YES guest_username = vuser  pam_service_name  pam_service_name = vsftpd . mysql 、 vsftpd  # service vsftpd start # chkconfig vsftpd on  # netstat -tnlp |grep :21 tcp 0 0 0.0.0.0 : 21 0.0.0.0 :* LISTEN 23286 / vsftpd  , ，， Win Box  IE  FTP  # ftp localhost 、 vsftpd  ftp ，。 ， vsftpd . conf 。 1 、 vsftpd  # vim vsftpd.conf  user_config_dir =/ etc / vsftpd / vusers_dir 2 、， # mkdir /etc/vsftpd/vusers_dir/ # cd /etc/vsftpd/vusers_dir/ # touch tom jerry 3 、  vsftpd 。， tom ， / etc / vsftpd / vusers / tom ，。 anon_upload_enable = YES","title":"vsftpd-mysql"},{"location":"disk/#lsyncd","text":"1.1 inotify + rsync ， inotify + rsync ， 100 W + ， 20 M ， ， 10  M ， 20 M ，； ， inotifywait  5 s  10 ， 10  rsync ， 2 - 3 M ，  200 M 。，，，， 。  Linux  inotify + rsync  。 1.2 sersync  sersync ，，。 sersync  ， c ++ ，，，， crontab 。 ，： ，， 2011 （ googlecode ，）， 10  xml ，， ， 。，。，， ，，，（，  refreshCDN plugin ）。  c ++ ， FileSynchronize ， rsync  273 ，，  -- exclude =  -- eclude - from 。。 ， Sersync   ， rsync + inotify 。 ，， rsync ， module ， rsync ， ，，。 sersync ， rsync ——， rsync 。（） ，。，。  sersync2 ，，。。 1.3 lsyncd ，。 lsyncd ，， googlecode ，  github ： https : //github.com/axkibe/lsyncd 。 Lysncd  lua  inotify  rsync ， Linux （ 2.6.13 ） inotify ，  rsync ，。， inotify + rsync   —— 。，， lua ， 。 lsyncd ， cp ， rsync ， rsyncssh 。 （），。 2.  lsyncd  ， source  target ， source ，。 2.1  lsyncd  lsyncd ， ubuntu ， apt - get install lsyncd 。  Redhat （ CentOS 6.2 x86_64 ）， lsyncd - 2.1.5 - 6.f c21 . x86_64 . rpm ， yum install lua lua - devel 。， epel - release ： # rpm -ivh http: //dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm# yum install lsyncd   lsyncd ，： yum install lua lua - devel asciidoc cmake 。  googlecode lsyncd  lsyncd - 2.1.5 . tar . gz ， . / configure 、 make make install 。  github  lsyncd - master . zip  2.1.5  cmake ， . / configure ： # uzip lsyncd-master.zip# cd lsyncd-master# cmake -DCMAKE_INSTALL_PREFIX=/usr/local/lsyncd-2.1.5# make make install  bug ， INSTALL  build  make ，： [ 100 % ] Generating doc / lsyncd .1 Updating the manpage a2x : failed : source file not found : doc / lsyncd .1 . txt make [ 2 ] : *** [ doc / lsyncd .1 ] Error 1 make [ 1 ] : *** [ CMakeFiles / manpage . dir / all ] Error 2 make : *** [ all ] Error 2  cmake ， mkdir build ， CMakeList . txt  doc ，$ { PROJECT_SOURCE_DIR } 。 2.2 lsyncd . conf 。 echo 8192000 / proc / sys / fs / inotify / max_user_watches  rc . local 2.2.1 lsyncd  # cd /usr/local/lsyncd-2.1.5# mkdir etc var# vi etc/lsyncd.confsettings { logfile = /usr/local/lsyncd-2.1.5/var/lsyncd.log , statusFile = /usr/local/lsyncd-2.1.5/var/lsyncd.status , inotifyMode = CloseWrite , maxProcesses = 7 , -- nodaemon = true , } sync { default . rsync , source = /tmp/src , target = /tmp/dest , -- excludeFrom = /etc/rsyncd.d/rsync_exclude.lst , rsync = { binary = /usr/bin/rsync , archive = true , compress = true , verbose = true } }  lsycnd ，，。 2.2.2 lsyncd . conf  settings ， -- ，： logfile  stausFile  nodaemon = true ， statusInterval  lsyncd  statusFile ， 10  inotifyMode  inotify ， CloseWrite ， Modify  CloseWrite or Modify maxProcesses 。 20 ， maxProcesses = 8 ， 8  rysnc  maxDelays ， delay  sync ， maxDelays  settings 。 lsyncd ： rsync 、 rsyncssh 、 direct ： default . rsync ：， rsync ， ssh  rsync ， daemon  rsyncd ； default . direct ：， cp 、 rm ； default . rsyncssh ：， rsync  ssh ， key  source ，。 target  . ： / tmp / dest ：， direct  rsync  172.29.88.223 :/ tmp / dest ：， rsync  rsyncssh ， / usr / bin / rsync - ltsd -- delete -- include - from =- -- exclude =* SOURCE TARGET ， rsync ， username ， 172.29.88.223 :: module ：， rsync  。 init ， init = false ，，。 true delay ， rsync ， 15 （ 1000 ）。 15 s ， rsync ，。（， 15 s ，） excludeFrom ，， excludeFrom = /etc/lsyncd.exclude ，， exclude = LIST 。  rsync ，： ，， / bin / foo / bar  foo  / ，  / ， ? ， / *  0 ， / **  0 ， / delete  target  souce  ,  false ， Lsyncd  delete = true 。 false ， startup 、 running ， Lsyncd 2.1 . x ‖ Layer 4 Config ‖ Default Behavior 。 rsync （， delete  exclude  rsync ， sync ， rsync ） bwlimit ， kb / s ， rsync （） compress  true 。 cpu ， false perms 。  rsync   rsyncssh ， host 、 targetdir 、 rsync_path 、 password_file ，。 rsyncOps = { -avz , --delete }  2.1 . * 。 lsyncd . conf  sync ， source ， target ，，。 2.3  lsyncd ，，。 lsyncd - log Exec / usr / local / lsyncd - 2.1.5 / etc / lsyncd . conf 2.4 lsyncd . conf  ，： settings { logfile = /usr/local/lsyncd-2.1.5/var/lsyncd.log , statusFile = /usr/local/lsyncd-2.1.5/var/lsyncd.status , inotifyMode = CloseWrite , maxProcesses = 8 , } -- I . ， direct ： cp / rm / mv 。 ： 500 + ， sync { default . direct , source = /tmp/src , target = /tmp/dest , delay = 1 maxProcesses = 1 } -- II . ， rsync ： rsync sync { default . rsync , source = /tmp/src , target = /tmp/dest1 , excludeFrom = /etc/rsyncd.d/rsync_exclude.lst , rsync = { binary = /usr/bin/rsync , archive = true , compress = true , bwlimit = 2000 } } -- III . ， rsync  + rsyncd daemon sync { default . rsync , source = /tmp/src , target = syncuser@172.29.88.223::module1 , delete = running , exclude = { .* , .tmp }, delay = 30 , init = false , rsync = { binary = /usr/bin/rsync , archive = true , compress = true , verbose = true , password_file = /etc/rsyncd.d/rsync.pwd , _extra = { --bwlimit=200 } } } -- IV . ， rsync  + ssh shell sync { default . rsync , source = /tmp/src , target = 172.29.88.223:/tmp/dest , -- target = root@172.29.88.223:/remote/dest , --  target ，， maxDelays = 5 , delay = 30 , -- init = true , rsync = { binary = /usr/bin/rsync , archive = true , compress = true , bwlimit = 2000 -- rsh = /usr/bin/ssh -p 22 -o StrictHostKeyChecking=no -- ， rsh } } -- V . ， rsync  + rsyncssh ， sync { default . rsyncssh , source = /tmp/src2 , host = 172.29.88.223 , targetdir = /remote/dir , excludeFrom = /etc/rsyncd.d/rsync_exclude.lst , -- maxDelays = 5 , delay = 0 , -- init = false , rsync = { binary = /usr/bin/rsync , archive = true , compress = true , verbose = true , _extra = { --bwlimit=2000 }, }, ssh = { port = 1234 } } ， III  rsync  rsyncd ，。 IV 、 V  ssh ， ， ssh ，：  ssh ，： user $ ssh - keygen - t rsa  ... user $ cd ~/ . ssh user $ cat id_rsa . pub authorized_keys  id_rsa  lsyncd  user $ chmod 600 ~/ . ssh / id_rsa  user $ ssh user @172.29.88.223 3. lsyncd  lsyncd ， Lsyncd 2.1 . x ‖ Layer 2 Config ‖ Advanced onAction ， ，， example ， jpg 、 gif 、 png ， pdf ， 。， java ，， lsyncd  。， lua （ example ）。 ， maxDelays  delay ，，， rsync 。 TO - DO ： ： csync2 ， clsync ， btsync ， drdb 。 lsyncd ： GlusterFS","title":"lsyncd"},{"location":"disk/#inotify_sync","text":" web  (  html , jpg   ) ，，，，。 ，， inotifywait ， rsync 。，  inotify + rsync 。 。 inotifywait  1 / usr / local / bin / inotifywait - mrq -- format % Xe % w % f - e modify , create , delete , attrib / data / ， inotifywait  / data / ， modify , create , delete , attrib ， % Xe % w % f 。  / data /  touch  1 touch / data / { 1..5 }  inotify  ATTRIB / data / 1 --  ATTRIB   / data / 1 ATTRIB / data / 2 ATTRIB / data / 3 ATTRIB / data / 4 ATTRIB / data / 5  ， rsync  inotifywait ， rsync 。  inotify + rsync  ，。 ( ，， ) #!/bin/bash / usr / bin / inotifywait - mrq -- format % w % f - e create , close_write , delete / backup | while read file #file ，？$file rsync do cd / backup rsync - az -- delete / backup / rsync_backup @192.168.24.101 :: backup /-- password - file =/ etc / rsync . password done # rsync ()， filersync ，10，10 rsync  (  ) ， rsync 。 # 。rsync，。  rsync 。 #，。CPU，。  ， rsync ， inotify 。 rsync ， 。  #!/bin/bash src =/ data / #  des = data #  rsync -- daemon ， rsync -- daemon ， ，。 rsync_passwd_file =/ etc / rsyncd . passwd # rsync  ip1 = 192.168.0.18 #  1 ip2 = 192.168.0.19 #  2 user = root # rsync -- daemon  cd $ { src } # ， rsync ， cd ， inotify  . /  rsync ， / usr / local / bin / inotifywait - mrq -- format % Xe % w % f - e modify , create , delete , attrib . / | while read file #    do INO_EVENT = $ ( echo $ file | awk { print $ 1 } ) #  inotify   INO_EVENT INO_FILE = $ ( echo $ file | awk { print $ 2 } ) #  inotify   INO_FILE echo ------------------------------------ echo $ file #、 #、，，，，。 if [[ $ INO_EVENT =~ CREATE ]] || [[ $ INO_EVENT =~ MODIFY ]] #  then echo CREATE or MODIFY rsync - avzR -- password - file =/ etc / rsync - client . pass $ { INO_FILE } $ { user }@ $ { ip1 } :: $ { des } # INO_FILE  rsync - avzR -- password - file =/ etc / rsync - client . pass $ { INO_FILE } $ { user }@ $ { ip2 } :: $ { des } # rsync ${INO_FILE}  -R   fi # if [[ $ INO_EVENT =~ DELETE ]] then echo DELETE rsync - avzR -- delete -- password - file =/ etc / rsync - client . pass $ ( dirname $ { INO_FILE }) $ { user }@ $ { ip1 } :: $ { des } rsync - avzR -- delete -- password - file =/ etc / rsync - client . pass $ ( dirname $ { INO_FILE }) $ { user }@ $ { ip2 } :: $ { des } #rsync ${INO_FILE}no such or directory ，  -- delete ，， ，， 。，。 fi #  touch chgrp chmod chown if [[ $ INO_EVENT =~ ATTRIB ]] then echo ATTRIB if [ ! - d $INO_FILE ] #  ，，， rsync  。 then rsync - avzR -- password - file =/ etc / rsync - client . pass $ { INO_FILE } $ { user }@ $ { ip1 } :: $ { des } rsync - avzR -- password - file =/ etc / rsync - client . pass $ { INO_FILE } $ { user }@ $ { ip2 } :: $ { des } fi fi done  1   inotify ，，， 2  1 ， ，。 1 2 crontab - e * */ 2 * * * rsync - avz -- password - file =/ etc / rsync - client . pass / data / root @192.168.0.18 :: data rsync - avz -- password - file =/ etc / rsync - client . pass / data / root @192.168.0.19 :: data 。  inotify  inotify  -- 、、， * #### * _0_ * #### *  2.6.13 ， Inotify  、、，，。 inotifywait    - m , – monitor  - r , – recursive  - q , – quiet  – excludei ， - t , – timeout  – timefmt  – format  - e , – event 、、 inotifywait events    access  modify  attrib  close_write  close_nowrite close open  moved_to  moved_from  move  create  delete  delete_self unmount   Inotify # /proc/sys/fs/inotify，inotify [ root @ web ~ ] # ll / proc / sys / fs / inotify /  0 - rw - r -- r -- 1 root root 09  923 : 36 max_queued_events - rw - r -- r -- 1 root root 09  923 : 36 max_user_instances - rw - r -- r -- 1 root root 09  923 : 36 max_user_watches ----------------------------- max_user_watches # inotifywait  inotifywatch  (  ) max_user_instances # inotifywait  inotifywatch  max_queued_events # inotify  ( event )  ---------------------------- [ root @ web ~ ] # echo 50000000 / proc / sys / fs / inotify / max_user_watches --  / etc / rc . local  [ root @ web ~ ] # echo 50000000 / proc / sys / fs / inotify / max_queued_events","title":"inotify_sync"},{"location":"docker/","text":" docker run - d - v / etc / localtime : / etc / localtime : ro - v / etc / sysconfig / clock : / etc / sysconfig / clock : ro  ， docker   yum install docker systemctl start docker docker run - d --hostname wwwtest --name wwwtest -p 28080:8080 --add-host=mlivetest.dachuizichan.com:127.0.0.1 --add-host=db.dachuizichan.com:192.168.1.18 --add-host=atlastest.dachuizichan.com:192.168.1.16 --add-host=hprpt2livetest.eucp.b2m.cn:127.0.0.1 --add-host=smtplivetest.exmail.qq.com:183.232.93.197 --add-host=redis.dachuizichan.com:172.17.0.168 -v /dachui:/dachui - v / tomcat / war / wwwtest : / usr / local / tomcat / webapps / DaChui - v / tomcat / log / wwwtest : / usr / local / tomcat / log - v / etc / localtime : / etc / localtime : ro - v / etc / sysconfig / clock : / etc / sysconfig / clock : ro tomcat : v6 / usr / bin / supervisord  docker pull centos6 . 6  docker images  docker save - o ubuntu_14 . 04 . tar ubuntu : 14 . 04  docker load --input ubuntu_14.04.tar  docker commit 0 b2616b0e5a8 ouruser  docker rmi training / sinatra   docker run - t - i - p 8000 : 80 centos6 . 6 / bin / bash ， docker ps  docekr status id  docker stop id  docker restart id  docker rm - f id  docker export 7691 a814370e ubuntu . tar  cat ubuntu . tar | sudo docker import - test / ubuntu : v1 . 0  docker logs - f --tail=10 wwwtest  # ENTRYPOINT [ /usr/local/tomcat/bin/catalina.sh , run ]   Delete all containers docker rm $ ( docker ps - a - q ) Delete all images docker rmi $ ( docker images - q ) docker-regisrty yum install - y python - devel libevent - devel python - pip gcc xz - devel swig openssl - devel pip install docker - registry cd / usr / lib / python2 . 6 / site - packages / config cp config_sample . yml config . yml  / tmp / registry ： gunicorn - b 0 . 0 . 0 . 0 : 5000 docker_registry . wsgi : application or gunicorn -- access - logfile - -- error - logfile - - k gevent - b 0 . 0 . 0 . 0 : 5000 - w 4 -- max - requests 100 docker_registry . wsgi : application docker tag a4e2366f858c 192 . 168 . 10 . 49 : 5000 / pingtai - 0508 a4e2366f858c  imageid   https ： / etc / sysconfig / docker ： DOCKER_OPTS = --insecure-registry 192.168.10.49:5000  $e xec - d $ other_args $ logfile  $e xec - d $D OCKER_OPTS $ logfile  docker ， push  OK  service docker restart dockerfile FROM ubuntu : trusty ENV DEBIAN_FRONTEND noninteractive ENV PATH $ PATH : / usr / local / nginx / sbin EXPOSE 1935 EXPOSE 80 # create directories RUN mkdir / src / config / logs / data / static # update and upgrade packages RUN apt - get update \\ apt - get upgrade - y \\ apt - get clean \\ apt - get install - y --no-install-recommends build-essential \\ wget software - properties - common \\ # ffmpeg add - apt - repository ppa : mc3man / trusty - media \\ apt - get update \\ apt - get install - y --no-install-recommends ffmpeg \\ # nginx dependencies apt - get install - y --no-install-recommends libpcre3-dev \\ zlib1g - dev libssl - dev wget \\ rm - rf / var / lib / apt / lists /* # get nginx source WORKDIR /src RUN wget http://nginx.org/download/nginx-1.6.2.tar.gz \\ tar zxf nginx-1.6.2.tar.gz \\ rm nginx-1.6.2.tar.gz \\ # get nginx-rtmp module wget https://github.com/arut/nginx-rtmp-module/archive/v1.1.6.tar.gz \\ tar zxf v1.1.6.tar.gz \\ rm v1.1.6.tar.gz # compile nginx WORKDIR /src/nginx-1.6.2 RUN ./configure --add-module=/src/nginx-rtmp-module-1.1.6 \\ --conf-path=/config/nginx.conf \\ --error-log-path=/logs/error.log \\ --http-log-path=/logs/access.log \\ make \\ make install ADD nginx.conf /config/nginx.conf ADD static /static WORKDIR / CMD nginx  docker pull daocloud . io / centos : 6 docker pull daocloud . io / centos : 7 docker run - ti daocloud . io / centos : 6 / bin / bash  images  https : // dashboard . daocloud . io / packages centos6 CentOS 6 . 5 ( 64  )   CentOS 6 . 5 ， = 2 . 6 . 32 - 431 ， Docker 。 $ uname - r 2 . 6 . 32 - 431 . 17 . 1 . el6 . x86_64 Device Mapper Docker  AUFS ， AUFS  Linux 。 CentOS   Device Mapper ，  2 . 6 . 9 。 : $ ls - l / sys / class / misc / device - mapper lrwxrwxrwx 1 root root 0 May 1 20 : 55 / sys / class / misc / device - mapper - .. / .. / devices / virtual / misc / device - mapper  Device Mapper ， device - mapper  : $ sudo yum install - y device - mapper  dm_mod  : $ sudo modprobe dm_mod  epel  ， CentOS6 . 5 ， docker 。 Docker RPM   docker - io ， docker 。 $ sudo yum - y remove docker  Install Docker - IO  docker - io  RPM 。 $ sudo yum - y install docker - io harbor DockerDocker Registry ， Docker Registry  ，  ， Registry ， Harbor 。 Harbor HarborDockerRegistry ，   ，  、  ， Docker Distribution 。 Registry ， Harbor  。 Registry 。 HarborRegistry  ， Registry ，  。  ， Harbor  ，  ，  。 Harbor ： http : // vmware . github . io / harbor / Harbor HarborVmwareDocker Registry ，  Docker Registry ， Docker Registry 、  、  。 # cd / usr / local / # git clone https : // github . com / vmware / harbor  harborDeploy # cd harbor / Deploy / # ls config db docker - compose . yml #docker compose docker - compose . yml . photon harbor . cfg #harbor （  ） HarborDocker ， Docker Compose 。  docker - compose . yml ， Harbor6 ： harbor_ui ： harbor 。 harbor_log ： rsyslog ，  。 harbor_mysql ： mysql nginx ： Nginx registry ： Docker registry harbor_jobservice ： Harbor 。 Harborhttps Harborhttp ，  ，  SSL 。 1.  SSL ，  。  SSL 。 https : // buy . wosign . com / free / #ssl [ root@mysql-yxpopoDeploy ] # cd config / nginx / cert 。 xxx . xxx . com . crt （  ） xxx . xxx . com . key （  ） 2. Nginx http : // www . wosign . com / Docdownload / Nginx % 20 SSL % E8 % AF % 81 % E4 % B9 % A6 % E9 % 83 % A8 % E7 % BD % B2 % E6 % 8 C % 87 % E5 % 8 D % 97. pdf # cp nginx . https . conf nginx . conf server { listen443 ssl ; server_name registry . unixhot . com ; # SSL ssl_certificate / etc / nginx / cert / 1 _registry . unixhot . com_bundle . crt ; ssl_certificate_key / etc / nginx / cert / 2 _registry . unixhot . com . key ; ssl_protocols TLSv1 .1 TLSv1 .2 ; ssl_ciphersAESGCM : ALL :! DH : ! EXPORT : ! RC4 : + HIGH : ! MEDIUM : ! LOW : ! aNULL : ! eNULL ; ssl_prefer_server_ciphers on ; ssl_session_cache shared : SSL : 10 m ; #80 ， 443 server { listen80 ; server_name registry . unixhot . com ; rewrite ^/ (. * ) https : // $ server_name : 443 / $ 1 permanent ; } #ACL ，  （  ， IP ） allow127 .0.0.1 ; allow192 .168.0.0 / 16 ; deny all ; Harbor Harbor ， harbor . cfg 。 [ root@mysql-yxpopo Deploy ] # vim harbor . cfg hostname = registry . unixhot . com ui_url_protocol = https harbor_admin_password = unixhot . com Harbor [ root@mysql-yxpopo Deploy ] # . / prepare Generated configuration file : . / config / ui / env Generated configuration file : . / config / ui / app . conf Generated configuration file : . / config / registry / config . yml Generated configuration file : . / config / db / env Generated configuration file : . / config / jobservice / env Clearing the configuration file : . / config / ui / private_key . pem Clearing the configuration file : . / config / registry / root . crt Generated configuration file : . / config / ui / private_key . pem Generated configuration file : . / config / registry / root . crt The configuration files are ready , please usedocker - compose to start the service . DockerCompose [ root@mysql-yxpopo Deploy ] # docker - compose up - d https : // xxx . xxx . com ， Harbor 。 admin /   ，  。  。  ，  。 library ，  ，  ，  。  ， Harbor 。 # docker login registry . unixhot . com Username : admin Password : Email : admin @unixhot . com WARNING : login credentials saved in / root / . docker / config . json Login Succeeded kubernetes kubernetes rc replication controller pod pause proxy service labels master node etcd  kube - apiserver kube - scheduler kube - controller - manager kubelet kube - proxy docker yum - y install kubernetes - 1 . 2 . 0 docker - 1 . 8 . 2 docker - selinux - 1 . 8 . 2 lvs fullnat nginx docker logs fluentd glusterfs hostPath emptyDir cAdvisor heapster + influxdb + grafana flannel host - gw calico  fluentd  nginx ， Python  rolling - update ， nginx  heapster  calico  kubernetes : 1 . 2 . 0 docker : 1 . 8 . 2 centos : 7 . 2 . 1503 calico : 0 . 20 . 0 Master  yum - y install kubernetes - 1 . 2 . 0 wget https : // github . com / projectcalico / calico - containers / releases / download / v0 . 20 . 0 / calicoctl chmod + x calicoctl mv calicoctl / usr / bin docker pull calico / node : v0 . 20 . 0 cat / etc / network - environment EOF # This host s IPv4 address (the source IP address used to reach other nodes # in the Kubernetes cluster ) . DEFAULT_IPV4 = KUBERNETES_MASTER # IP and port of etcd instance used by Calico ETCD_AUTHORITY = KUBERNETES_MASTER : 6666 EOF wget - N - P / etc / systemd https : // raw . githubusercontent . com / projectcalico / calico - cni / k8s - 1 . 1 - docs / samples / kub ernetes / common / calico - node . service systemctl enable / etc / systemd / calico - node . service systemctl start calico - node . service Node  wget https : // github . com / projectcalico / calico - containers / releases / download / v0 . 20 . 0 / calicoctl chmod + x calicoctl mv calicoctl / usr / bin docker pull calico / node : v0 . 20 . 0 cat / etc / network - environment EOF # This host s IPv4 address (the source IP address used to reach other nodes # in the Kubernetes cluster ) . DEFAULT_IPV4 = KUBERNETES_MASTER # IP and port of etcd instance used by Calico ETCD_AUTHORITY = KUBERNETES_MASTER : 6666 EOF wget - N - P / etc / systemd https : // raw . githubusercontent . com / projectcalico / calico - cni / k8s - 1 . 1 - docs / samples / kubernetes / co mmon / calico - node . service systemctl enable / etc / systemd / calico - node . service systemctl start calico - node . service mkdir - p / opt / cni / bin / wget - N - P / opt / cni / bin / https : // github . com / projectcalico / calico - cni / releases / download / v1 . 0 . 0 / calico wget - N - P / opt / cni / bin / https : // github . com / projectcalico / calico - cni / releases / download / v1 . 0 . 0 / calico - ipam chmod + x / opt / cni / bin / calico / opt / cni / bin / calico - ipam # Make the directory structure . mkdir - p / etc / cni / net . d # Make the network configuration file cat / etc / cni / net . d / 10 - calico . conf EOF { name : calico-k8s-network , type : calico , etcd_authority : KUBERNETES_MASTER :6666 , log_level : info , ipam : { type : calico-ipam } } EOF  kubelet vim / etc / kubernetes / kubelet # Add your own ! KUBELET_ARGS = --network-plugin=cni --network-plugin-dir=/etc/cni/net.d calico  [ root @ vm - docker - c7 - 80 ~ ]# calicoctl pool show +----------------+---------+ | IPv4 CIDR | Options | +----------------+---------+ | 192 . 168 . 0 . 0 / 16 | | +----------------+---------+ +--------------------------+---------+ | IPv6 CIDR | Options | +--------------------------+---------+ | fd80 : 24 e2 : f998 : 72 d6 :: / 64 | | +--------------------------+---------+ [ root @ vm - docker - c7 - 80 ~ ]# calicoctl pool add 192 . 168 . 0 . 0 / 16 -- nat - outgoing [ root @ vm - docker - c7 - 80 ~ ]# calicoctl pool show +----------------+--------------+ | IPv4 CIDR | Options | +----------------+--------------+ | 192 . 168 . 0 . 0 / 16 | nat - outgoing | +----------------+--------------+ +--------------------------+---------+ | IPv6 CIDR | Options | +--------------------------+---------+ | fd80 : 24 e2 : f998 : 72 d6 :: / 64 | | +--------------------------+---------+ [ root @ vm - docker - c7 - 80 ~ ]# kubectl get pods NAME READY STATUS RESTARTSAGE test1 1 / 1 Running 0 3 h test2 1 / 1 Running 0 3 h [ root @ vm - docker - c7 - 80 ~ ]# kubectl exec - it test1 ping www . baidu . com PING www . baidu . com ( 61 . 135 . 169 . 125 ) : 56 data bytes 64 bytes from 61 . 135 . 169 . 125 : seq = 0 ttl = 54 time = 2 . 535 ms 64 bytes from 61 . 135 . 169 . 125 : seq = 1 ttl = 54 time = 2 . 309 ms ^ C --- www . baidu . com ping statistics --- 2 packets transmitted , 2 packets received , 0 % packet loss round - trip min / avg / max = 2 . 309 / 2 . 422 / 2 . 535 ms flannel ： kubernetes v1 . 2 . 0 flannel 0 . 5 . 3 centos 7 . 1 kernel 4 . 2 . 3 docker 1 . 8 . 2 ： yum - y install flanneld etcd kubernetes vim / etc / etcd / etcd . conf ETCD_LISTEN_CLIENT_URLS = http://0.0.0.0:2379 ETCD_ADVERTISE_CLIENT_URLS = http://0.0.0.0:2379 vim / etc / sysconfig / flanneld FLANNEL_ETCD = http://127.0.0.1:2379 FLANNEL_ETCD_KEY = /flannel/network FLANNEL_OPTIONS = -iface=br1  flannel ， etcd ： etcdctl set / flanneld / network / config { Network : 10.0.0.0/22 , Backend : { Type : “host-gw”}}’ bashrc_docker wget - P ~ https : // github . com / yeasy / docker_practice / raw / master / _local / . bashrc_docker ; $ echo [ -f ~/.bashrc_docker ] . ~/.bashrc_docker ~/ . bashrc ; source ~/.bashrc  Docker ， docker - pid   PID ； docker - enter 。 cd / root / vim . bashrc_docker # Some useful commands to use docker . # Author : yeasy @ github # Created : 2014 - 09 - 25 alias docker - pid = sudo docker inspect --format {{.State.Pid}} alias docker - ip = sudo docker inspect --format {{ .NetworkSettings.IPAddress }} # the implementation refs from https : // github . com / jpetazzo / nsenter / blob / master / docker - enter function docker - enter () { # if [ - e $ ( dirname $0 ) / nsenter ] ; then # Change for centos bash running if [ - e $ ( dirname $0 ) / nsenter ] ; then # with boot2docker , nsenter is not in the PATH but it is in the same folder NSENTER = $ ( dirname $0 ) / nsenter else # if nsenter has already been installed with path notified , here will be clarified NSENTER = $ ( which nsenter ) # NSENTER = nsenter fi [ - z $NSENTER ] echo WARN Cannot find nsenter return if [ - z $1 ] ; then echo Usage: `basename $0 ` CONTAINER [COMMAND [ARG]...] echo echo Enters the Docker CONTAINER and executes the specified COMMAND. echo If COMMAND is not specified, runs an interactive shell in CONTAINER. else PID = $ ( sudo docker inspect -- format {{.State.Pid}} $1 ) if [ - z $PID ] ; then echo WARN Cannot find the given container return fi shift OPTS = --target $PID --mount --uts --ipc --net --pid if [ - z $1 ] ; then # No command given . # Use su to clear all host environment variables except for TERM , # initialize the environment variables HOME , SHELL , USER , LOGNAME , PATH , # and start a login shell . # sudo $ NSENTER $OPTS su - root sudo $ NSENTER -- target $ PID -- mount -- uts -- ipc -- net -- pid su - root else # Use env to clear all host environment variables . sudo $ NSENTER -- target $ PID -- mount -- uts -- ipc -- net -- pid env - i $@ fi fi } -------------------------------------------- #  echo [ -f ~/.bashrc_docker ] . ~/.bashrc_docker ~/ . bashrc ; source ~/.bashrc # docker ps # docker - enter id # docker - pid id mesos_marathon Mesos：MesosLinux Kernel，。Mesos KernelAPI （，Hadoop、Spark、Kafaka、ElasticSearch）。 ZooKeeper：ZooKeeper，，GoogleChubby，Hadoop HBase。，：、、、。 Marathon：MarathonMesos，，Web。Init.d， Linux，Tomcat、Play。PaSS，，REST API， SSL、，HAProxy。 ，。 1.png 。： index.png Zookeeper mesos，zookeeper，mesoszookeeper。 [root@linux-node1 ~]# cd /usr/local/src [root@linux-node1 src]# wget http://mirrors.cnnic.cn/apache ... ar.gz [root@linux-node1 src]# tar zxf zookeeper-3.4.6.tar.gz [root@linux-node1 src]# mv zookeeper-3.4.6 /usr/local/zookeeper [root@linux-node1 src]# ln -s /usr/local/zookeeper-3.4.6/ /usr/local/zookeeper [root@linux-node1 ~]# cd /usr/local/zookeeper/conf/ [root@linux-node1 conf]# mv zoo_sample.cfg zoo.cfg zookeeper zoo.cfg。zookeeper。 [root@linux-node1 ~]# cat/usr/local/zookeeper/conf/zoo.cfg dataDir： dataLogDir： clientPort： tickTime：Zookeeper ， tickTime 。 initLimit：ZookeeperLeader （Follower）。 5（tickTime） Zookeeper ，。  5*2000=10  syncLimit： Leader  Follower ，tickTime ，  2*2000=4 。 server.A=B：C：D： A ，； B  ip ； C  Leader ； D  Leader ，， Leader， 。 Zookeeper ， B ， Zookeeper ，。 [root@linux-node1 conf]# grep ^[a-z] zoo.cfg tickTime=2000 initLimit=10 syncLimit=5 dataDir=/data/zk1 clientPort=2181 server.1=192.168.56.11:3181:4181 server.2=192.168.56.11:3182:4182 server.3=192.168.56.11:3183:4183 zookeeper [root@linux-node1 ~]# mkdir -p /data/zk1 /data/zk2/data/zk3 [root@linux-node1 ~]# echo 1 /data/zk1/myid [root@linux-node1 ~]# echo 2 /data/zk2/myid [root@linux-node1 ~]# echo 3 /data/zk3/myid zookeeper [root@linux-node1 conf]# cp zoo.cfg zk1.cfg [root@linux-node1 conf]# cp zoo.cfg zk2.cfg [root@linux-node1 conf]# cp zoo.cfg zk3.cfg zk2zk3，。 [root@linux-node1 conf]# sed -i s/zk1/zk2/g zk2.cfg [root@linux-node1 conf]# sed -i s/2181/2182/g zk2.cfg [root@linux-node1 conf]# sed -i s/zk1/zk3/g zk3.cfg [root@linux-node1 conf]# sed -i s/2181/2183/g zk3.cfg Zookeeper /usr/local/zookeeper/bin/zkServer.sh start /usr/local/zookeeper/conf/zk1.cfg /usr/local/zookeeper/bin/zkServer.sh start /usr/local/zookeeper/conf/zk2.cfg /usr/local/zookeeper/bin/zkServer.sh start /usr/local/zookeeper/conf/zk3.cfg Zookeeper [root@linux-node1 ~]#/usr/local/zookeeper/bin/zkServer.sh status /usr/local/zookeeper/conf/zk1.cfg JMX enabled by default Using config: /usr/local/zookeeper/conf/zk1.cfg Mode: follower [root@linux-node1 ~]#/usr/local/zookeeper/bin/zkServer.sh status /usr/local/zookeeper/conf/zk2.cfg JMX enabled by default Using config: /usr/local/zookeeper/conf/zk2.cfg Mode: follower [root@linux-node1 ~]#/usr/local/zookeeper/bin/zkServer.sh status /usr/local/zookeeper/conf/zk3.cfg JMX enabled by default Using config: /usr/local/zookeeper/conf/zk3.cfg Mode: leader Zookeeper [root@linux-node1 ~]# /usr/local/zookeeper/bin/zkCli.sh -server192.168.56.11:2181 ，zk3leader,follower。，。 Mesos  MesosMesosMasterMesos Slave。 mesosphere Mesos MasterMesosSlave： # rpm -Uvh http://repos.mesosphere.com/el ... h.rpm Mesos Master [root@linux-node1 ~]# yum -y install mesos marathon ，zookeeper [root@linux-node1 ~]# vim /etc/mesos/zk zk://192.168.56.11:2181,192.168.56.11:2182,192.168.56.11:2183/mesos [root@linux-node1 ~]# systemctl start mesos-master mesos-slave [root@linux-node1 ~]# systemctl start marathon Mesos Slave [root@linux-node2 ~]# yum -y install mesos marathon [root@linux-node2 ~]# systemctl start mesos-slave MesosWeb Mesos，Mesos MasterWeb，5050。 http:// ${ HOST_IP } :5050 ‘Tasks’。 2.png mesos，MesosWeb，Active Tasks。 [root@linux-node1~]# MASTER=$(mesos-resolve `cat /etc/mesos/zk`) [root@linux-node1~]# mesos-execute --master= $MASTER --name= cluster-test --command= sleep 60 3.png MarathonMesos Docker MesosDocker [root@linux-node1 ~]# yum install -y docker [root@linux-node1 ~]# systemctl start docker ，Docker。 [root@linux-node1 ~]# docker pull nginx mesos-slave， linux-node1: [root@linux-node1 ~]# echo docker,mesos | tee/etc/mesos-slave/containerizers docker,mesos [root@linux-node1 ~]# systemctl restart mesos-slave linux-node2: [root@linux-node2 ~]# echo docker,mesos | tee/etc/mesos-slave/containerizers docker,mesos [root@linux-node2 ~]# systemctl restart mesos-slave ，marathonnginxDocker，Mesos。 mesos-master， marathon。8080，http://{HOST}:8080/marathon。： 4.png ，marathon，Mesos？zookeeper,marathon /etc/mesos/zk，ZookeeperMesos Master。marathonREST API，API nginxdocker： nginx.json： [root@linux-node1 ~]# cat nginx.json { id : nginx , cpus :0.2, mem :20.0, instances : 1, constraints : [[ hostname , UNIQUE , ]], container : { type : DOCKER , docker : { image : nginx , network : BRIDGE , portMappings : [ { containerPort : 80, hostPort : 0, servicePort : 0, protocol : tcp } ] } } }  # curl -X POST http://192.168.56.11:8080/v2/apps-d @nginx.json \\ -H Content-type: application/json 4.png 31984nginx。，mesos-slave： [root@linux-node1 ~]# docker ps -a ，Scale Application。，marathonWeb 、。 5.png ： https://www.unixhot.com/article/32  1 、 Docker Volume Docker （）。， Docker 、 。，， ，。 Docker ，， 。 Docker ， Union File System （）。 docker run - t - i - v / data centos : 6 . 6 / bin / bash  docker ps docker inspect ” CONTAINER ID “ 2 、  docker ps docker commit ” CONTAINER ID “ centos : 6 . 6 - 1 docker run - t - i - v / data centos : 6 . 6 - 1 / bin / bash piddocker ，top: 5400 nobody 20 0 73260 30620 2284 S 8.3 0.4 0:20.63 nginx ，docker (ecs10 docker)？  $ pstree -p | grep -n5 5400 pid: ... 114- | |-my_init(5248)-+-nginx(5398)-+-nginx(5399) 115: | | | |-nginx(5400) 116- | | | |-nginx(5401) ... pid=5248, init: $ docker ps | awk {print $1} | grep -v CONTAINER | xargs docker inspect -f {{ .State.Pid }} {{ .Config.Hostname }} | grep 5248 5248 bd939dc98684 container id, $ docker ps | grep bd939dc98684 。","title":"docker"},{"location":"docker/#_1","text":"docker run - d - v / etc / localtime : / etc / localtime : ro - v / etc / sysconfig / clock : / etc / sysconfig / clock : ro  ， docker ","title":""},{"location":"docker/#_2","text":"yum install docker systemctl start docker docker run - d --hostname wwwtest --name wwwtest -p 28080:8080 --add-host=mlivetest.dachuizichan.com:127.0.0.1 --add-host=db.dachuizichan.com:192.168.1.18 --add-host=atlastest.dachuizichan.com:192.168.1.16 --add-host=hprpt2livetest.eucp.b2m.cn:127.0.0.1 --add-host=smtplivetest.exmail.qq.com:183.232.93.197 --add-host=redis.dachuizichan.com:172.17.0.168 -v /dachui:/dachui - v / tomcat / war / wwwtest : / usr / local / tomcat / webapps / DaChui - v / tomcat / log / wwwtest : / usr / local / tomcat / log - v / etc / localtime : / etc / localtime : ro - v / etc / sysconfig / clock : / etc / sysconfig / clock : ro tomcat : v6 / usr / bin / supervisord  docker pull centos6 . 6  docker images  docker save - o ubuntu_14 . 04 . tar ubuntu : 14 . 04  docker load --input ubuntu_14.04.tar  docker commit 0 b2616b0e5a8 ouruser  docker rmi training / sinatra   docker run - t - i - p 8000 : 80 centos6 . 6 / bin / bash ， docker ps  docekr status id  docker stop id  docker restart id  docker rm - f id  docker export 7691 a814370e ubuntu . tar  cat ubuntu . tar | sudo docker import - test / ubuntu : v1 . 0  docker logs - f --tail=10 wwwtest  # ENTRYPOINT [ /usr/local/tomcat/bin/catalina.sh , run ]   Delete all containers docker rm $ ( docker ps - a - q ) Delete all images docker rmi $ ( docker images - q )","title":""},{"location":"docker/#docker-regisrty","text":"yum install - y python - devel libevent - devel python - pip gcc xz - devel swig openssl - devel pip install docker - registry cd / usr / lib / python2 . 6 / site - packages / config cp config_sample . yml config . yml  / tmp / registry ： gunicorn - b 0 . 0 . 0 . 0 : 5000 docker_registry . wsgi : application or gunicorn -- access - logfile - -- error - logfile - - k gevent - b 0 . 0 . 0 . 0 : 5000 - w 4 -- max - requests 100 docker_registry . wsgi : application docker tag a4e2366f858c 192 . 168 . 10 . 49 : 5000 / pingtai - 0508 a4e2366f858c  imageid   https ： / etc / sysconfig / docker ： DOCKER_OPTS = --insecure-registry 192.168.10.49:5000  $e xec - d $ other_args $ logfile  $e xec - d $D OCKER_OPTS $ logfile  docker ， push  OK  service docker restart","title":"docker-regisrty"},{"location":"docker/#dockerfile","text":"FROM ubuntu : trusty ENV DEBIAN_FRONTEND noninteractive ENV PATH $ PATH : / usr / local / nginx / sbin EXPOSE 1935 EXPOSE 80 # create directories RUN mkdir / src / config / logs / data / static # update and upgrade packages RUN apt - get update \\ apt - get upgrade - y \\ apt - get clean \\ apt - get install - y --no-install-recommends build-essential \\ wget software - properties - common \\ # ffmpeg add - apt - repository ppa : mc3man / trusty - media \\ apt - get update \\ apt - get install - y --no-install-recommends ffmpeg \\ # nginx dependencies apt - get install - y --no-install-recommends libpcre3-dev \\ zlib1g - dev libssl - dev wget \\ rm - rf / var / lib / apt / lists /* # get nginx source WORKDIR /src RUN wget http://nginx.org/download/nginx-1.6.2.tar.gz \\ tar zxf nginx-1.6.2.tar.gz \\ rm nginx-1.6.2.tar.gz \\ # get nginx-rtmp module wget https://github.com/arut/nginx-rtmp-module/archive/v1.1.6.tar.gz \\ tar zxf v1.1.6.tar.gz \\ rm v1.1.6.tar.gz # compile nginx WORKDIR /src/nginx-1.6.2 RUN ./configure --add-module=/src/nginx-rtmp-module-1.1.6 \\ --conf-path=/config/nginx.conf \\ --error-log-path=/logs/error.log \\ --http-log-path=/logs/access.log \\ make \\ make install ADD nginx.conf /config/nginx.conf ADD static /static WORKDIR / CMD nginx","title":"dockerfile"},{"location":"docker/#_3","text":"docker pull daocloud . io / centos : 6 docker pull daocloud . io / centos : 7 docker run - ti daocloud . io / centos : 6 / bin / bash  images  https : // dashboard . daocloud . io / packages","title":""},{"location":"docker/#centos6","text":"CentOS 6 . 5 ( 64  )   CentOS 6 . 5 ， = 2 . 6 . 32 - 431 ， Docker 。 $ uname - r 2 . 6 . 32 - 431 . 17 . 1 . el6 . x86_64 Device Mapper Docker  AUFS ， AUFS  Linux 。 CentOS   Device Mapper ，  2 . 6 . 9 。 : $ ls - l / sys / class / misc / device - mapper lrwxrwxrwx 1 root root 0 May 1 20 : 55 / sys / class / misc / device - mapper - .. / .. / devices / virtual / misc / device - mapper  Device Mapper ， device - mapper  : $ sudo yum install - y device - mapper  dm_mod  : $ sudo modprobe dm_mod  epel  ， CentOS6 . 5 ， docker 。 Docker RPM   docker - io ， docker 。 $ sudo yum - y remove docker  Install Docker - IO  docker - io  RPM 。 $ sudo yum - y install docker - io","title":"centos6"},{"location":"docker/#harbor","text":"DockerDocker Registry ， Docker Registry  ，  ， Registry ， Harbor 。 Harbor HarborDockerRegistry ，   ，  、  ， Docker Distribution 。 Registry ， Harbor  。 Registry 。 HarborRegistry  ， Registry ，  。  ， Harbor  ，  ，  。 Harbor ： http : // vmware . github . io / harbor / Harbor HarborVmwareDocker Registry ，  Docker Registry ， Docker Registry 、  、  。 # cd / usr / local / # git clone https : // github . com / vmware / harbor  harborDeploy # cd harbor / Deploy / # ls config db docker - compose . yml #docker compose docker - compose . yml . photon harbor . cfg #harbor （  ） HarborDocker ， Docker Compose 。  docker - compose . yml ， Harbor6 ： harbor_ui ： harbor 。 harbor_log ： rsyslog ，  。 harbor_mysql ： mysql nginx ： Nginx registry ： Docker registry harbor_jobservice ： Harbor 。 Harborhttps Harborhttp ，  ，  SSL 。 1.  SSL ，  。  SSL 。 https : // buy . wosign . com / free / #ssl [ root@mysql-yxpopoDeploy ] # cd config / nginx / cert 。 xxx . xxx . com . crt （  ） xxx . xxx . com . key （  ） 2. Nginx http : // www . wosign . com / Docdownload / Nginx % 20 SSL % E8 % AF % 81 % E4 % B9 % A6 % E9 % 83 % A8 % E7 % BD % B2 % E6 % 8 C % 87 % E5 % 8 D % 97. pdf # cp nginx . https . conf nginx . conf server { listen443 ssl ; server_name registry . unixhot . com ; # SSL ssl_certificate / etc / nginx / cert / 1 _registry . unixhot . com_bundle . crt ; ssl_certificate_key / etc / nginx / cert / 2 _registry . unixhot . com . key ; ssl_protocols TLSv1 .1 TLSv1 .2 ; ssl_ciphersAESGCM : ALL :! DH : ! EXPORT : ! RC4 : + HIGH : ! MEDIUM : ! LOW : ! aNULL : ! eNULL ; ssl_prefer_server_ciphers on ; ssl_session_cache shared : SSL : 10 m ; #80 ， 443 server { listen80 ; server_name registry . unixhot . com ; rewrite ^/ (. * ) https : // $ server_name : 443 / $ 1 permanent ; } #ACL ，  （  ， IP ） allow127 .0.0.1 ; allow192 .168.0.0 / 16 ; deny all ; Harbor Harbor ， harbor . cfg 。 [ root@mysql-yxpopo Deploy ] # vim harbor . cfg hostname = registry . unixhot . com ui_url_protocol = https harbor_admin_password = unixhot . com Harbor [ root@mysql-yxpopo Deploy ] # . / prepare Generated configuration file : . / config / ui / env Generated configuration file : . / config / ui / app . conf Generated configuration file : . / config / registry / config . yml Generated configuration file : . / config / db / env Generated configuration file : . / config / jobservice / env Clearing the configuration file : . / config / ui / private_key . pem Clearing the configuration file : . / config / registry / root . crt Generated configuration file : . / config / ui / private_key . pem Generated configuration file : . / config / registry / root . crt The configuration files are ready , please usedocker - compose to start the service . DockerCompose [ root@mysql-yxpopo Deploy ] # docker - compose up - d https : // xxx . xxx . com ， Harbor 。 admin /   ，  。  。  ，  。 library ，  ，  ，  。  ， Harbor 。 # docker login registry . unixhot . com Username : admin Password : Email : admin @unixhot . com WARNING : login credentials saved in / root / . docker / config . json Login Succeeded","title":"harbor"},{"location":"docker/#kubernetes","text":"kubernetes rc replication controller pod pause proxy service labels master node etcd  kube - apiserver kube - scheduler kube - controller - manager kubelet kube - proxy docker yum - y install kubernetes - 1 . 2 . 0 docker - 1 . 8 . 2 docker - selinux - 1 . 8 . 2 lvs fullnat nginx docker logs fluentd glusterfs hostPath emptyDir cAdvisor heapster + influxdb + grafana flannel host - gw calico  fluentd  nginx ， Python  rolling - update ， nginx  heapster  calico  kubernetes : 1 . 2 . 0 docker : 1 . 8 . 2 centos : 7 . 2 . 1503 calico : 0 . 20 . 0 Master  yum - y install kubernetes - 1 . 2 . 0 wget https : // github . com / projectcalico / calico - containers / releases / download / v0 . 20 . 0 / calicoctl chmod + x calicoctl mv calicoctl / usr / bin docker pull calico / node : v0 . 20 . 0 cat / etc / network - environment EOF # This host s IPv4 address (the source IP address used to reach other nodes # in the Kubernetes cluster ) . DEFAULT_IPV4 = KUBERNETES_MASTER # IP and port of etcd instance used by Calico ETCD_AUTHORITY = KUBERNETES_MASTER : 6666 EOF wget - N - P / etc / systemd https : // raw . githubusercontent . com / projectcalico / calico - cni / k8s - 1 . 1 - docs / samples / kub ernetes / common / calico - node . service systemctl enable / etc / systemd / calico - node . service systemctl start calico - node . service Node  wget https : // github . com / projectcalico / calico - containers / releases / download / v0 . 20 . 0 / calicoctl chmod + x calicoctl mv calicoctl / usr / bin docker pull calico / node : v0 . 20 . 0 cat / etc / network - environment EOF # This host s IPv4 address (the source IP address used to reach other nodes # in the Kubernetes cluster ) . DEFAULT_IPV4 = KUBERNETES_MASTER # IP and port of etcd instance used by Calico ETCD_AUTHORITY = KUBERNETES_MASTER : 6666 EOF wget - N - P / etc / systemd https : // raw . githubusercontent . com / projectcalico / calico - cni / k8s - 1 . 1 - docs / samples / kubernetes / co mmon / calico - node . service systemctl enable / etc / systemd / calico - node . service systemctl start calico - node . service mkdir - p / opt / cni / bin / wget - N - P / opt / cni / bin / https : // github . com / projectcalico / calico - cni / releases / download / v1 . 0 . 0 / calico wget - N - P / opt / cni / bin / https : // github . com / projectcalico / calico - cni / releases / download / v1 . 0 . 0 / calico - ipam chmod + x / opt / cni / bin / calico / opt / cni / bin / calico - ipam # Make the directory structure . mkdir - p / etc / cni / net . d # Make the network configuration file cat / etc / cni / net . d / 10 - calico . conf EOF { name : calico-k8s-network , type : calico , etcd_authority : KUBERNETES_MASTER :6666 , log_level : info , ipam : { type : calico-ipam } } EOF  kubelet vim / etc / kubernetes / kubelet # Add your own ! KUBELET_ARGS = --network-plugin=cni --network-plugin-dir=/etc/cni/net.d calico  [ root @ vm - docker - c7 - 80 ~ ]# calicoctl pool show +----------------+---------+ | IPv4 CIDR | Options | +----------------+---------+ | 192 . 168 . 0 . 0 / 16 | | +----------------+---------+ +--------------------------+---------+ | IPv6 CIDR | Options | +--------------------------+---------+ | fd80 : 24 e2 : f998 : 72 d6 :: / 64 | | +--------------------------+---------+ [ root @ vm - docker - c7 - 80 ~ ]# calicoctl pool add 192 . 168 . 0 . 0 / 16 -- nat - outgoing [ root @ vm - docker - c7 - 80 ~ ]# calicoctl pool show +----------------+--------------+ | IPv4 CIDR | Options | +----------------+--------------+ | 192 . 168 . 0 . 0 / 16 | nat - outgoing | +----------------+--------------+ +--------------------------+---------+ | IPv6 CIDR | Options | +--------------------------+---------+ | fd80 : 24 e2 : f998 : 72 d6 :: / 64 | | +--------------------------+---------+ [ root @ vm - docker - c7 - 80 ~ ]# kubectl get pods NAME READY STATUS RESTARTSAGE test1 1 / 1 Running 0 3 h test2 1 / 1 Running 0 3 h [ root @ vm - docker - c7 - 80 ~ ]# kubectl exec - it test1 ping www . baidu . com PING www . baidu . com ( 61 . 135 . 169 . 125 ) : 56 data bytes 64 bytes from 61 . 135 . 169 . 125 : seq = 0 ttl = 54 time = 2 . 535 ms 64 bytes from 61 . 135 . 169 . 125 : seq = 1 ttl = 54 time = 2 . 309 ms ^ C --- www . baidu . com ping statistics --- 2 packets transmitted , 2 packets received , 0 % packet loss round - trip min / avg / max = 2 . 309 / 2 . 422 / 2 . 535 ms flannel ： kubernetes v1 . 2 . 0 flannel 0 . 5 . 3 centos 7 . 1 kernel 4 . 2 . 3 docker 1 . 8 . 2 ： yum - y install flanneld etcd kubernetes vim / etc / etcd / etcd . conf ETCD_LISTEN_CLIENT_URLS = http://0.0.0.0:2379 ETCD_ADVERTISE_CLIENT_URLS = http://0.0.0.0:2379 vim / etc / sysconfig / flanneld FLANNEL_ETCD = http://127.0.0.1:2379 FLANNEL_ETCD_KEY = /flannel/network FLANNEL_OPTIONS = -iface=br1  flannel ， etcd ： etcdctl set / flanneld / network / config { Network : 10.0.0.0/22 , Backend : { Type : “host-gw”}}’","title":"kubernetes"},{"location":"docker/#bashrc_docker","text":"wget - P ~ https : // github . com / yeasy / docker_practice / raw / master / _local / . bashrc_docker ; $ echo [ -f ~/.bashrc_docker ] . ~/.bashrc_docker ~/ . bashrc ; source ~/.bashrc  Docker ， docker - pid   PID ； docker - enter 。 cd / root / vim . bashrc_docker # Some useful commands to use docker . # Author : yeasy @ github # Created : 2014 - 09 - 25 alias docker - pid = sudo docker inspect --format {{.State.Pid}} alias docker - ip = sudo docker inspect --format {{ .NetworkSettings.IPAddress }} # the implementation refs from https : // github . com / jpetazzo / nsenter / blob / master / docker - enter function docker - enter () { # if [ - e $ ( dirname $0 ) / nsenter ] ; then # Change for centos bash running if [ - e $ ( dirname $0 ) / nsenter ] ; then # with boot2docker , nsenter is not in the PATH but it is in the same folder NSENTER = $ ( dirname $0 ) / nsenter else # if nsenter has already been installed with path notified , here will be clarified NSENTER = $ ( which nsenter ) # NSENTER = nsenter fi [ - z $NSENTER ] echo WARN Cannot find nsenter return if [ - z $1 ] ; then echo Usage: `basename $0 ` CONTAINER [COMMAND [ARG]...] echo echo Enters the Docker CONTAINER and executes the specified COMMAND. echo If COMMAND is not specified, runs an interactive shell in CONTAINER. else PID = $ ( sudo docker inspect -- format {{.State.Pid}} $1 ) if [ - z $PID ] ; then echo WARN Cannot find the given container return fi shift OPTS = --target $PID --mount --uts --ipc --net --pid if [ - z $1 ] ; then # No command given . # Use su to clear all host environment variables except for TERM , # initialize the environment variables HOME , SHELL , USER , LOGNAME , PATH , # and start a login shell . # sudo $ NSENTER $OPTS su - root sudo $ NSENTER -- target $ PID -- mount -- uts -- ipc -- net -- pid su - root else # Use env to clear all host environment variables . sudo $ NSENTER -- target $ PID -- mount -- uts -- ipc -- net -- pid env - i $@ fi fi } -------------------------------------------- #  echo [ -f ~/.bashrc_docker ] . ~/.bashrc_docker ~/ . bashrc ; source ~/.bashrc # docker ps # docker - enter id # docker - pid id","title":"bashrc_docker"},{"location":"docker/#mesos_marathon","text":"Mesos：MesosLinux Kernel，。Mesos KernelAPI （，Hadoop、Spark、Kafaka、ElasticSearch）。 ZooKeeper：ZooKeeper，，GoogleChubby，Hadoop HBase。，：、、、。 Marathon：MarathonMesos，，Web。Init.d， Linux，Tomcat、Play。PaSS，，REST API， SSL、，HAProxy。 ，。 1.png 。： index.png Zookeeper mesos，zookeeper，mesoszookeeper。 [root@linux-node1 ~]# cd /usr/local/src [root@linux-node1 src]# wget http://mirrors.cnnic.cn/apache ... ar.gz [root@linux-node1 src]# tar zxf zookeeper-3.4.6.tar.gz [root@linux-node1 src]# mv zookeeper-3.4.6 /usr/local/zookeeper [root@linux-node1 src]# ln -s /usr/local/zookeeper-3.4.6/ /usr/local/zookeeper [root@linux-node1 ~]# cd /usr/local/zookeeper/conf/ [root@linux-node1 conf]# mv zoo_sample.cfg zoo.cfg zookeeper zoo.cfg。zookeeper。 [root@linux-node1 ~]# cat/usr/local/zookeeper/conf/zoo.cfg dataDir： dataLogDir： clientPort： tickTime：Zookeeper ， tickTime 。 initLimit：ZookeeperLeader （Follower）。 5（tickTime） Zookeeper ，。  5*2000=10  syncLimit： Leader  Follower ，tickTime ，  2*2000=4 。 server.A=B：C：D： A ，； B  ip ； C  Leader ； D  Leader ，， Leader， 。 Zookeeper ， B ， Zookeeper ，。 [root@linux-node1 conf]# grep ^[a-z] zoo.cfg tickTime=2000 initLimit=10 syncLimit=5 dataDir=/data/zk1 clientPort=2181 server.1=192.168.56.11:3181:4181 server.2=192.168.56.11:3182:4182 server.3=192.168.56.11:3183:4183 zookeeper [root@linux-node1 ~]# mkdir -p /data/zk1 /data/zk2/data/zk3 [root@linux-node1 ~]# echo 1 /data/zk1/myid [root@linux-node1 ~]# echo 2 /data/zk2/myid [root@linux-node1 ~]# echo 3 /data/zk3/myid zookeeper [root@linux-node1 conf]# cp zoo.cfg zk1.cfg [root@linux-node1 conf]# cp zoo.cfg zk2.cfg [root@linux-node1 conf]# cp zoo.cfg zk3.cfg zk2zk3，。 [root@linux-node1 conf]# sed -i s/zk1/zk2/g zk2.cfg [root@linux-node1 conf]# sed -i s/2181/2182/g zk2.cfg [root@linux-node1 conf]# sed -i s/zk1/zk3/g zk3.cfg [root@linux-node1 conf]# sed -i s/2181/2183/g zk3.cfg Zookeeper /usr/local/zookeeper/bin/zkServer.sh start /usr/local/zookeeper/conf/zk1.cfg /usr/local/zookeeper/bin/zkServer.sh start /usr/local/zookeeper/conf/zk2.cfg /usr/local/zookeeper/bin/zkServer.sh start /usr/local/zookeeper/conf/zk3.cfg Zookeeper [root@linux-node1 ~]#/usr/local/zookeeper/bin/zkServer.sh status /usr/local/zookeeper/conf/zk1.cfg JMX enabled by default Using config: /usr/local/zookeeper/conf/zk1.cfg Mode: follower [root@linux-node1 ~]#/usr/local/zookeeper/bin/zkServer.sh status /usr/local/zookeeper/conf/zk2.cfg JMX enabled by default Using config: /usr/local/zookeeper/conf/zk2.cfg Mode: follower [root@linux-node1 ~]#/usr/local/zookeeper/bin/zkServer.sh status /usr/local/zookeeper/conf/zk3.cfg JMX enabled by default Using config: /usr/local/zookeeper/conf/zk3.cfg Mode: leader Zookeeper [root@linux-node1 ~]# /usr/local/zookeeper/bin/zkCli.sh -server192.168.56.11:2181 ，zk3leader,follower。，。 Mesos  MesosMesosMasterMesos Slave。 mesosphere Mesos MasterMesosSlave： # rpm -Uvh http://repos.mesosphere.com/el ... h.rpm Mesos Master [root@linux-node1 ~]# yum -y install mesos marathon ，zookeeper [root@linux-node1 ~]# vim /etc/mesos/zk zk://192.168.56.11:2181,192.168.56.11:2182,192.168.56.11:2183/mesos [root@linux-node1 ~]# systemctl start mesos-master mesos-slave [root@linux-node1 ~]# systemctl start marathon Mesos Slave [root@linux-node2 ~]# yum -y install mesos marathon [root@linux-node2 ~]# systemctl start mesos-slave MesosWeb Mesos，Mesos MasterWeb，5050。 http:// ${ HOST_IP } :5050 ‘Tasks’。 2.png mesos，MesosWeb，Active Tasks。 [root@linux-node1~]# MASTER=$(mesos-resolve `cat /etc/mesos/zk`) [root@linux-node1~]# mesos-execute --master= $MASTER --name= cluster-test --command= sleep 60 3.png MarathonMesos Docker MesosDocker [root@linux-node1 ~]# yum install -y docker [root@linux-node1 ~]# systemctl start docker ，Docker。 [root@linux-node1 ~]# docker pull nginx mesos-slave， linux-node1: [root@linux-node1 ~]# echo docker,mesos | tee/etc/mesos-slave/containerizers docker,mesos [root@linux-node1 ~]# systemctl restart mesos-slave linux-node2: [root@linux-node2 ~]# echo docker,mesos | tee/etc/mesos-slave/containerizers docker,mesos [root@linux-node2 ~]# systemctl restart mesos-slave ，marathonnginxDocker，Mesos。 mesos-master， marathon。8080，http://{HOST}:8080/marathon。： 4.png ，marathon，Mesos？zookeeper,marathon /etc/mesos/zk，ZookeeperMesos Master。marathonREST API，API nginxdocker： nginx.json： [root@linux-node1 ~]# cat nginx.json { id : nginx , cpus :0.2, mem :20.0, instances : 1, constraints : [[ hostname , UNIQUE , ]], container : { type : DOCKER , docker : { image : nginx , network : BRIDGE , portMappings : [ { containerPort : 80, hostPort : 0, servicePort : 0, protocol : tcp } ] } } }  # curl -X POST http://192.168.56.11:8080/v2/apps-d @nginx.json \\ -H Content-type: application/json 4.png 31984nginx。，mesos-slave： [root@linux-node1 ~]# docker ps -a ，Scale Application。，marathonWeb 、。 5.png ： https://www.unixhot.com/article/32","title":"mesos_marathon"},{"location":"docker/#_4","text":"1 、 Docker Volume Docker （）。， Docker 、 。，， ，。 Docker ，， 。 Docker ， Union File System （）。 docker run - t - i - v / data centos : 6 . 6 / bin / bash  docker ps docker inspect ” CONTAINER ID “ 2 、  docker ps docker commit ” CONTAINER ID “ centos : 6 . 6 - 1 docker run - t - i - v / data centos : 6 . 6 - 1 / bin / bash","title":""},{"location":"docker/#piddocker","text":"，top: 5400 nobody 20 0 73260 30620 2284 S 8.3 0.4 0:20.63 nginx ，docker (ecs10 docker)？  $ pstree -p | grep -n5 5400 pid: ... 114- | |-my_init(5248)-+-nginx(5398)-+-nginx(5399) 115: | | | |-nginx(5400) 116- | | | |-nginx(5401) ... pid=5248, init: $ docker ps | awk {print $1} | grep -v CONTAINER | xargs docker inspect -f {{ .State.Pid }} {{ .Config.Hostname }} | grep 5248 5248 bd939dc98684 container id, $ docker ps | grep bd939dc98684 。","title":"piddocker"},{"location":"filesystem/","text":"GlusterFs 1 、，，， https : // docs . gluster . org / en / latest / Quick - Start - Guide / Quickstart / ， hosts  ip   mkfs . xfs - i size = 512 / dev / sdb mkdir - p / data / brick1 echo /dev/sdb /data/brick1 xfs defaults 1 2 / etc / fstab mount - a mount mkdir / bricks / brick1 / gv0 yum install centos - release - gluster - y yum install glusterfs - server - y systemctl enable glusterd systemctl start glusterd systemctl status glusterd server1  gluster peer probe server2 server2  gluster peer probe server1 ， gluster volume create gv0 replica 2 server1 : / bricks / brick1 / gv0 server2 : / bricks / brick1 / gv0 gluster volume start gv0 gluster volume info  Status : Started ， raid5 gluster volume create gv0 disperse 3 redundancy 1 cnd01tfilel0 { 1 , 2 , 3 }: / bricks / brick1 / gv5 ： 20 s ，（ 10 M - 40 M ） ，， disperse ： Dispersed Set  bricks ，， volume  bricks  Dispersed Set ； redundancy ：， brick  interrupting ，， redundancy ， 1 ； glusterfs volume  disperse - data ，，： disperse - data = disperse - redundancy ， IO  2 ， 4 k 、 64 k 、 1 M ， volume ， disperse - data  2 ， IO ， RMW ，。  http : // gluster . readthedocs . io / en / latest / Administrator % 20 Guide / Setting % 20 Up % 20 Clients / # mount - t glusterfs - o backupvolfile - server = volfile_server2 , use - readdirp = no , volfile - max - fetch - attempts = 2 , log - level = WARNING , log - file =/ var / log / gluster . log server1 : / test - volume / mnt / glusterfs  backupvolfile - server  fuse ， volfile ， backupvolfile - serveroption   volfile 。  volfile - max - fetch - attempts = X ，。  IP  DNS ，。  use - readdirp  ON ， fuse  readdirp  yum install centos - release - gluster - y yum install glusterfs - client fio - y mount - t glusterfs server1 : / gv0 / mnt  for i in ` seq - w 1 100 ` ; do cp -rp /var/log/messages /mnt/copy-test-$i; done ls - lA / mnt | wc - l fio -- direct = 1 -- rw = rw -- bs = 1 m -- size = 1 g -- numjobs = 4 -- group_reporting -- name = test - rw  ls - lA / bricks / brick1 / gv0 2 、, volume  2 ， 2  server1  gluster peer probe server3 gluster peer probe server4 gluster volume add - brick gv0 server3 : / bricks / brick1 / gv0 server4 : / bricks / brick1 / gv0  gluster volume rebalance gv0 start  gluster volume rebalance gv0 status 3 、 https : // docs . gluster . org / en / latest / Administrator % 20 Guide / Managing % 20 Volumes / # replace - brick http : // blog . 51 cto . com / cmdschool / 1908647  brick  2 . 9 . 1  brick  gluster volume status Gluster process TCP Port RDMA Port Online Pid Brick cnd01tfilel01 : / bricks / brick1 / gv0 49153 0 Y 1838 Brick cnd01tfilel02 : / bricks / brick1 / gv0 49153 0 Y 1719 Brick cnd01tfilel03 : / bricks / brick1 / gv0 N / A N / A N N / A Brick cnd01tfilel04 : / bricks / brick1 / gv0 49152 0 Y 4489 Self - heal Daemon on localhost N / A N / A Y 3718 Self - heal Daemon on cnd01tfilel03 N / A N / A Y 1315 Self - heal Daemon on cnd01tfilel04 N / A N / A Y 5633 Self - heal Daemon on cnd01tfilel02 N / A N / A Y 2913 ： Online “ N ” GH01  PID （ N / A ）。 kill - 15 pid 2 . 9 . 2  mkfs . xfs - i size = 512 / dev / sdb - f  fstab vim / etc / fstab ： / dev / sdb / bricks / brick1 xfs defaults 1 2 mount - a （） mkdir - p / bricks / brick1 / gv2 2 . 9 . 3  ( gh02 )   getfattr - d - m . - e hex / bricks / brick1 / gv0 getfattr : Removing leading / from absolute path names # file : bricks / brick1 / gv0 trusted . gfid = 0 x00000000000000000000000000000001 trusted . glusterfs . dht = 0 x0000000100000000000000007ffffffe trusted . glusterfs . volume - id = 0 xbe45c8bbf3a64dd9a1d735a9b9073268 2 . 9 . 4  1 ） mnt  mount - t glusterfs cnd01tfilel01 : / gv0 / mnt 2 ） mkdir / mnt / testDir001 rmdir / mnt / testDir001 3 ） setfattr - n trusted . non - existent - key - v abc / mnt setfattr - x trusted . non - existent - key / mnt 2 ） In GlusterH01 : gluster volume heal gv0 info ： Brick cnd01tfilel03 : / bricks / brick1 / gv0 Status : Transport endpoint is not connected Number of entries : - ：（ 2 ） 2 . 9 . 6  gluster volume replace - brick gv0 cnd01tfilel03 : / bricks / brick1 / gv0 cnd01tfilel03 : / bricks / brick1 / gv2 commit force volume replace - brick : success : replace - brick commit force operation successful brick  gluster volume status  gluster volume heal gv0 info ：，（）： gluster peer probe GH05 gluster volume replace - brick gv0 GH01 : / data / brick1 / gv0 GH05 : / data / brick1 / gv0 commit 4 、， ，，， IP ， gluster ， ， gluster peer status ， uuid ， / etc / hosts ,  [ root @ mystorage2 ~ ]# gluster peer status Number of Peers : 3 Hostname : mystorage3 Uuid : 36 e4c45c - 466 f - 47 b0 - b829 - dcd4a69ca2e7 State : Peer in Cluster ( Connected ) Hostname : mystorage4 Uuid : c607f6c2 - bdcb - 4768 - bc82 - 4 bc2243b1b7a State : Peer in Cluster ( Connected ) Hostname : mystorage1 Uuid : 6 e6a84af - ac7a - 44 eb - 85 c9 - 50 f1f46acef1 State : Peer in Cluster ( Disconnected )  / var / lib / glusterd / glusterd . info   [ root @ mystorage1 ~ ]# cat / var / lib / glusterd / glusterd . info UUID = 6 e6a84af - ac7a - 44 eb - 85 c9 - 50 f1f46acef1 operating - version = 40100  systemctl start glusterd gluster peer status  Peer in Cluster ( Connected ) , gluster peer probe gfserver03  ，。  gluster volume heal gv2 full  gluster volume heal gv2 info 5 、  gluster volume stop img gluster volume delete img  gluster peer detach 172 . 28 . 26 . 102  172 . 28 . 0 . 0  glusterfs gluster volume set img auth . allow 172 . 28 . 26 . *  (  2 , 2 （ 4 、 6 、 8 ..） ) gluster peer probe 172 . 28 . 26 . 105 gluster peer probe 172 . 28 . 26 . 106 gluster volume add - brick img 172 . 28 . 26 . 105 : / data / gluster 172 . 28 . 26 . 106 : / data / gluster  #  gluster  gluster volume remove - brick img 172 . 28 . 26 . 101 : / data / gluster / img 172 . 28 . 26 . 102 : / data / gluster / img start #  gluster volume remove - brick img 172 . 28 . 26 . 101 : / data / gluster / img 172 . 28 . 26 . 102 : / data / gluster / img status #  gluster volume remove - brick img 172 . 28 . 26 . 101 : / data / gluster / img 172 . 28 . 26 . 102 : / data / gluster / img commit  #  172 . 28 . 26 . 101 , 172 . 28 . 26 . 107  gluster peer probe 172 . 28 . 26 . 107 gluster volume replace - brick img 172 . 28 . 26 . 101 : / data / gluster / img 172 . 28 . 26 . 107 : / data / gluster / img start #  gluster volume replace - brick img 172 . 28 . 26 . 101 : / data / gluster / img 172 . 28 . 26 . 107 : / data / gluster / img status # gluster volume replace - brick img 172 . 28 . 26 . 101 : / data / gluster / img 172 . 28 . 26 . 107 : / data / gluster / img commit #  172 . 28 . 26 . 101 , gluster  gluster volume replace - brick img 172 . 28 . 26 . 101 : / data / gluster / img 172 . 28 . 26 . 102 : / data / gluster / img commit - force gluster volume heal imgs full ceph http : // docs . ceph . com / docs / master / ceph ,  !! # ceph - deploy purge node1 node2 ... # ceph - deploy purgedata node1 node2 ... cat / etc / yum . repos . d / ceph . repo [ Ceph ] name = Ceph packages for $ba search baseurl = http : // mirrors . aliyun . com / ceph / rpm - mimic / el7 / $ba search enabled = 1 gpgcheck = 1 type = rpm - md gpgkey = https : // mirrors . aliyun . com / ceph / keys / release . asc priority = 1 [ Ceph - noarch ] name = Ceph noarch packages baseurl = http : // mirrors . aliyun . com / ceph / rpm - mimic / el7 / noarch enabled = 1 gpgcheck = 1 type = rpm - md gpgkey = https : // mirrors . aliyun . com / ceph / keys / release . asc priority = 1 [ ceph - source ] name = Ceph source packages baseurl = http : // mirrors . aliyun . com / ceph / rpm - mimic / el7 / SRPMS enabled = 1 gpgcheck = 1 type = rpm - md gpgkey = https : // mirrors . aliyun . com / ceph / keys / release . asc priority = 1  yum install ceph - deploy - y ssh - keygen ssh - copy - id hostname  yum - y install ceph ceph - radosgw  ceph - deploy new ceph - node1 ceph - node2 ceph - node3 ceph - deploy install ceph - node1 ceph - node2 ceph - node3 ceph - deploy mon create - initial ，： ceph . client . admin . keyring ceph . bootstrap - osd . keyring ceph . bootstrap - mds . keyring ceph - deploy admin ceph - node1 ceph - node2 ceph - node3 ceph - deploy mgr create node1  luminous12 . x  ceph - deploy osd create -- data / dev / vdb node1 ceph - deploy osd create -- data / dev / vdb node2 ceph - deploy osd create -- data / dev / vdb node3  ceph health detail ceph - s  metadata  ceph - deploy mds create ceph - node1  metadata   metadata ，。 http : // docs . ceph . org . cn / cephfs / createfs / pg_num = 100 $ ceph osd pool create cephfs_data pg_num $ ceph osd pool create cephfs_metadata pg_num $ ceph fs new cephfs cephfs_metadata cephfs_data / etc / ceph / ceph . client . admin . keyring  yum install ceph - fuse mount - t ceph 192 . 168 . 41 . 31 : 6789 : / / mnt - o name = admin , secret = passwd   ceph - fuse - m { ip - address - of - monitor }: 6789 / mnt / ceph  MooseFS https : // moosefs . com 1 、 Add the key : # curl https://ppa.moosefs.com/RPM-GPG-KEY-MooseFS / etc / pki / rpm - gpg / RPM - GPG - KEY - MooseFS Add an appropriate repository entry : # curl http://ppa.moosefs.com/MooseFS-3-el7.repo / etc / yum . repos . d / MooseFS . repo then install appropriate MooseFS components : For Master Servers : # yum install moosefs - master moosefs - cgi moosefs - cgiserv moosefs - cli systemctl start moosefs - master For Metaloggers : # yum install moosefs - metalogger vim / etc / mfs / mfsmetalogger . cfg MASTER_HOST = 192 . 168 . 41 . 31 systemctl start moosefs - metalogger For Chunkservers : # yum install moosefs - chunkserver vim / etc / mfs / mfschunkserver . cfg MASTER_HOST = 192 . 168 . 41 . 31 vim / etc / mfs / mfshdd . cfg / bricks / brick1 / chown mfs . mfs / bricks / brick1 / systemctl start moosefs - chunkserver For Clients : # yum install moosefs - client mkdir / mfsdata mfsmount / mfsdata - H 192 . 168 . 41 . 31","title":"filesystem"},{"location":"filesystem/#glusterfs","text":"1 、，，， https : // docs . gluster . org / en / latest / Quick - Start - Guide / Quickstart / ， hosts  ip   mkfs . xfs - i size = 512 / dev / sdb mkdir - p / data / brick1 echo /dev/sdb /data/brick1 xfs defaults 1 2 / etc / fstab mount - a mount mkdir / bricks / brick1 / gv0 yum install centos - release - gluster - y yum install glusterfs - server - y systemctl enable glusterd systemctl start glusterd systemctl status glusterd server1  gluster peer probe server2 server2  gluster peer probe server1 ， gluster volume create gv0 replica 2 server1 : / bricks / brick1 / gv0 server2 : / bricks / brick1 / gv0 gluster volume start gv0 gluster volume info  Status : Started ， raid5 gluster volume create gv0 disperse 3 redundancy 1 cnd01tfilel0 { 1 , 2 , 3 }: / bricks / brick1 / gv5 ： 20 s ，（ 10 M - 40 M ） ，， disperse ： Dispersed Set  bricks ，， volume  bricks  Dispersed Set ； redundancy ：， brick  interrupting ，， redundancy ， 1 ； glusterfs volume  disperse - data ，，： disperse - data = disperse - redundancy ， IO  2 ， 4 k 、 64 k 、 1 M ， volume ， disperse - data  2 ， IO ， RMW ，。  http : // gluster . readthedocs . io / en / latest / Administrator % 20 Guide / Setting % 20 Up % 20 Clients / # mount - t glusterfs - o backupvolfile - server = volfile_server2 , use - readdirp = no , volfile - max - fetch - attempts = 2 , log - level = WARNING , log - file =/ var / log / gluster . log server1 : / test - volume / mnt / glusterfs  backupvolfile - server  fuse ， volfile ， backupvolfile - serveroption   volfile 。  volfile - max - fetch - attempts = X ，。  IP  DNS ，。  use - readdirp  ON ， fuse  readdirp  yum install centos - release - gluster - y yum install glusterfs - client fio - y mount - t glusterfs server1 : / gv0 / mnt  for i in ` seq - w 1 100 ` ; do cp -rp /var/log/messages /mnt/copy-test-$i; done ls - lA / mnt | wc - l fio -- direct = 1 -- rw = rw -- bs = 1 m -- size = 1 g -- numjobs = 4 -- group_reporting -- name = test - rw  ls - lA / bricks / brick1 / gv0 2 、, volume  2 ， 2  server1  gluster peer probe server3 gluster peer probe server4 gluster volume add - brick gv0 server3 : / bricks / brick1 / gv0 server4 : / bricks / brick1 / gv0  gluster volume rebalance gv0 start  gluster volume rebalance gv0 status 3 、 https : // docs . gluster . org / en / latest / Administrator % 20 Guide / Managing % 20 Volumes / # replace - brick http : // blog . 51 cto . com / cmdschool / 1908647  brick  2 . 9 . 1  brick  gluster volume status Gluster process TCP Port RDMA Port Online Pid Brick cnd01tfilel01 : / bricks / brick1 / gv0 49153 0 Y 1838 Brick cnd01tfilel02 : / bricks / brick1 / gv0 49153 0 Y 1719 Brick cnd01tfilel03 : / bricks / brick1 / gv0 N / A N / A N N / A Brick cnd01tfilel04 : / bricks / brick1 / gv0 49152 0 Y 4489 Self - heal Daemon on localhost N / A N / A Y 3718 Self - heal Daemon on cnd01tfilel03 N / A N / A Y 1315 Self - heal Daemon on cnd01tfilel04 N / A N / A Y 5633 Self - heal Daemon on cnd01tfilel02 N / A N / A Y 2913 ： Online “ N ” GH01  PID （ N / A ）。 kill - 15 pid 2 . 9 . 2  mkfs . xfs - i size = 512 / dev / sdb - f  fstab vim / etc / fstab ： / dev / sdb / bricks / brick1 xfs defaults 1 2 mount - a （） mkdir - p / bricks / brick1 / gv2 2 . 9 . 3  ( gh02 )   getfattr - d - m . - e hex / bricks / brick1 / gv0 getfattr : Removing leading / from absolute path names # file : bricks / brick1 / gv0 trusted . gfid = 0 x00000000000000000000000000000001 trusted . glusterfs . dht = 0 x0000000100000000000000007ffffffe trusted . glusterfs . volume - id = 0 xbe45c8bbf3a64dd9a1d735a9b9073268 2 . 9 . 4  1 ） mnt  mount - t glusterfs cnd01tfilel01 : / gv0 / mnt 2 ） mkdir / mnt / testDir001 rmdir / mnt / testDir001 3 ） setfattr - n trusted . non - existent - key - v abc / mnt setfattr - x trusted . non - existent - key / mnt 2 ） In GlusterH01 : gluster volume heal gv0 info ： Brick cnd01tfilel03 : / bricks / brick1 / gv0 Status : Transport endpoint is not connected Number of entries : - ：（ 2 ） 2 . 9 . 6  gluster volume replace - brick gv0 cnd01tfilel03 : / bricks / brick1 / gv0 cnd01tfilel03 : / bricks / brick1 / gv2 commit force volume replace - brick : success : replace - brick commit force operation successful brick  gluster volume status  gluster volume heal gv0 info ：，（）： gluster peer probe GH05 gluster volume replace - brick gv0 GH01 : / data / brick1 / gv0 GH05 : / data / brick1 / gv0 commit 4 、， ，，， IP ， gluster ， ， gluster peer status ， uuid ， / etc / hosts ,  [ root @ mystorage2 ~ ]# gluster peer status Number of Peers : 3 Hostname : mystorage3 Uuid : 36 e4c45c - 466 f - 47 b0 - b829 - dcd4a69ca2e7 State : Peer in Cluster ( Connected ) Hostname : mystorage4 Uuid : c607f6c2 - bdcb - 4768 - bc82 - 4 bc2243b1b7a State : Peer in Cluster ( Connected ) Hostname : mystorage1 Uuid : 6 e6a84af - ac7a - 44 eb - 85 c9 - 50 f1f46acef1 State : Peer in Cluster ( Disconnected )  / var / lib / glusterd / glusterd . info   [ root @ mystorage1 ~ ]# cat / var / lib / glusterd / glusterd . info UUID = 6 e6a84af - ac7a - 44 eb - 85 c9 - 50 f1f46acef1 operating - version = 40100  systemctl start glusterd gluster peer status  Peer in Cluster ( Connected ) , gluster peer probe gfserver03  ，。  gluster volume heal gv2 full  gluster volume heal gv2 info 5 、  gluster volume stop img gluster volume delete img  gluster peer detach 172 . 28 . 26 . 102  172 . 28 . 0 . 0  glusterfs gluster volume set img auth . allow 172 . 28 . 26 . *  (  2 , 2 （ 4 、 6 、 8 ..） ) gluster peer probe 172 . 28 . 26 . 105 gluster peer probe 172 . 28 . 26 . 106 gluster volume add - brick img 172 . 28 . 26 . 105 : / data / gluster 172 . 28 . 26 . 106 : / data / gluster  #  gluster  gluster volume remove - brick img 172 . 28 . 26 . 101 : / data / gluster / img 172 . 28 . 26 . 102 : / data / gluster / img start #  gluster volume remove - brick img 172 . 28 . 26 . 101 : / data / gluster / img 172 . 28 . 26 . 102 : / data / gluster / img status #  gluster volume remove - brick img 172 . 28 . 26 . 101 : / data / gluster / img 172 . 28 . 26 . 102 : / data / gluster / img commit  #  172 . 28 . 26 . 101 , 172 . 28 . 26 . 107  gluster peer probe 172 . 28 . 26 . 107 gluster volume replace - brick img 172 . 28 . 26 . 101 : / data / gluster / img 172 . 28 . 26 . 107 : / data / gluster / img start #  gluster volume replace - brick img 172 . 28 . 26 . 101 : / data / gluster / img 172 . 28 . 26 . 107 : / data / gluster / img status # gluster volume replace - brick img 172 . 28 . 26 . 101 : / data / gluster / img 172 . 28 . 26 . 107 : / data / gluster / img commit #  172 . 28 . 26 . 101 , gluster  gluster volume replace - brick img 172 . 28 . 26 . 101 : / data / gluster / img 172 . 28 . 26 . 102 : / data / gluster / img commit - force gluster volume heal imgs full","title":"GlusterFs"},{"location":"filesystem/#ceph","text":"http : // docs . ceph . com / docs / master / ceph ,  !! # ceph - deploy purge node1 node2 ... # ceph - deploy purgedata node1 node2 ... cat / etc / yum . repos . d / ceph . repo [ Ceph ] name = Ceph packages for $ba search baseurl = http : // mirrors . aliyun . com / ceph / rpm - mimic / el7 / $ba search enabled = 1 gpgcheck = 1 type = rpm - md gpgkey = https : // mirrors . aliyun . com / ceph / keys / release . asc priority = 1 [ Ceph - noarch ] name = Ceph noarch packages baseurl = http : // mirrors . aliyun . com / ceph / rpm - mimic / el7 / noarch enabled = 1 gpgcheck = 1 type = rpm - md gpgkey = https : // mirrors . aliyun . com / ceph / keys / release . asc priority = 1 [ ceph - source ] name = Ceph source packages baseurl = http : // mirrors . aliyun . com / ceph / rpm - mimic / el7 / SRPMS enabled = 1 gpgcheck = 1 type = rpm - md gpgkey = https : // mirrors . aliyun . com / ceph / keys / release . asc priority = 1  yum install ceph - deploy - y ssh - keygen ssh - copy - id hostname  yum - y install ceph ceph - radosgw  ceph - deploy new ceph - node1 ceph - node2 ceph - node3 ceph - deploy install ceph - node1 ceph - node2 ceph - node3 ceph - deploy mon create - initial ，： ceph . client . admin . keyring ceph . bootstrap - osd . keyring ceph . bootstrap - mds . keyring ceph - deploy admin ceph - node1 ceph - node2 ceph - node3 ceph - deploy mgr create node1  luminous12 . x  ceph - deploy osd create -- data / dev / vdb node1 ceph - deploy osd create -- data / dev / vdb node2 ceph - deploy osd create -- data / dev / vdb node3  ceph health detail ceph - s  metadata  ceph - deploy mds create ceph - node1  metadata   metadata ，。 http : // docs . ceph . org . cn / cephfs / createfs / pg_num = 100 $ ceph osd pool create cephfs_data pg_num $ ceph osd pool create cephfs_metadata pg_num $ ceph fs new cephfs cephfs_metadata cephfs_data / etc / ceph / ceph . client . admin . keyring  yum install ceph - fuse mount - t ceph 192 . 168 . 41 . 31 : 6789 : / / mnt - o name = admin , secret = passwd   ceph - fuse - m { ip - address - of - monitor }: 6789 / mnt / ceph ","title":"ceph"},{"location":"filesystem/#moosefs","text":"https : // moosefs . com 1 、 Add the key : # curl https://ppa.moosefs.com/RPM-GPG-KEY-MooseFS / etc / pki / rpm - gpg / RPM - GPG - KEY - MooseFS Add an appropriate repository entry : # curl http://ppa.moosefs.com/MooseFS-3-el7.repo / etc / yum . repos . d / MooseFS . repo then install appropriate MooseFS components : For Master Servers : # yum install moosefs - master moosefs - cgi moosefs - cgiserv moosefs - cli systemctl start moosefs - master For Metaloggers : # yum install moosefs - metalogger vim / etc / mfs / mfsmetalogger . cfg MASTER_HOST = 192 . 168 . 41 . 31 systemctl start moosefs - metalogger For Chunkservers : # yum install moosefs - chunkserver vim / etc / mfs / mfschunkserver . cfg MASTER_HOST = 192 . 168 . 41 . 31 vim / etc / mfs / mfshdd . cfg / bricks / brick1 / chown mfs . mfs / bricks / brick1 / systemctl start moosefs - chunkserver For Clients : # yum install moosefs - client mkdir / mfsdata mfsmount / mfsdata - H 192 . 168 . 41 . 31","title":"MooseFS"},{"location":"git-svn/","text":"ant ?xml version= 1.0 encoding= UTF-8 ? !-- ，warFile。 -- project name= Visit default= warFile basedir= . !-- ，war。 -- property name= warFileName value= CuiShou.war /property !-- ，javajar。 -- path id= project.lib fileset dir= ${ basedir } /WebRoot/WEB-INF/lib include name= **/*.jar / /fileset fileset dir= /usr/local/tomcat_pingtai/lib include name= **/*.jar / /fileset /path !-- ，：class，build。 -- target name= clean delete dir= ${ basedir } /build / mkdir dir= ${ basedir } /build / /target !-- ，srcjava，class。 -- target name= compile depends= clean javac srcdir= ${ basedir } /src destdir= ${ basedir } /build includeantruntime= false compilerarg line= -encoding UTF-8 / classpath refid= project.lib /classpath compilerarg value= -XDignore.symbol.file / /javac copy todir = ${basedir}/build fileset dir= ${ basedir } /src excludes= **/*.java /fileset ， fileset dir= ${ basedir } /resources include name= **/**.* / /fileset /copy /target !-- ，classjar。 -- target name= warFile depends= compile !-- war。 -- delete dir= ${ basedir } / ${ warFileName } / !-- war。 -- war destfile= ${ basedir } / ${ warFileName } webxml= ${ basedir } /WebRoot/WEB-INF/web.xml !-- jarclasswar。 -- fileset dir= ${ basedir } /WebRoot include name= **/**.* / exclude name= **/*.jar / exclude name= **/*.class / /fileset !-- jarclasswar。 -- lib dir= ${ basedir } /WebRoot/WEB-INF/lib / classes dir= ${ basedir } /build / /war /target /project gitlab gitlab https : // about . gitlab . com / downloads / # centos6 yum install curl openssh - server postfix cronie service postfix start chkconfig postfix on lokkit - s http - s ssh wget https : // mirrors . tuna . tsinghua . edu . cn / gitlab - ce / yum / el6 / gitlab - ce - 8 . 9 . 8 - ce . 0 . el6 . x86_64 . rpm rpm - i gitlab - ce - XXX . rpm gitlab - ctl reconfigure  Username : root Password : 5 iveL ! fe gitlab + ldap  / etc / gitlab / gitlab . rb  ldap  # For omnibus packages gitlab_rails [ ldap_enabled ] = true gitlab_rails [ ldap_servers ] = YAML . load - EOS # remember to close this block with EOS below main : # main is the GitLab provider ID of this LDAP server label : LDAP host : ldap_server_IP port : 389 uid : uid method : plain # tls or ssl or plain allow_username_or_email_login : true bind_dn : cn=xxx,dc=xxx,dc=com password : PASSWPRD active_directory : false base : ou=xxx,dc=xxx,dc=com user_filter : EOS  # gitlab - ctl reconfigure  gitlab  ldap  ldap  / var / log / gitlab / gitlab - rails / production . log gitlab  gitlab - ctl start | stop | restart  / etc / gitlab / gitlab . rb   # gitlab - ctl reconfigure ps  chef  / etc / gitlab / gitlab . rb  / var / opt / gitlab / gitlab - rails / etc / gitlab . yml --------------------------- Gitlab  ，，。， （）。 ： sudo cat / opt / gitlab / embedded / service / gitlab - rails / VERSION  VERSION ， 8 . 6 。 ，。， issue 。 ， clone 。 # GitLab . com  git clone https : // gitlab . com / larryli / gitlab . git #  Coding . net  git clone https : // git . coding . net / larryli / gitlab . git ， Coding . net ， clone  checkout ， patch  diff 。 # 8 . 1  git diff origin / 8 - 6 - stable .. 8 - 6 - zh .. / 8 . 6 . diff  8 . 6 . diff 。 #  gitlab sudo gitlab - ctl stop sudo patch - d / opt / gitlab / embedded / service / gitlab - rails - p1 8 . 6 . diff  . rej ， GitLab 。 sudo gitlab - ctl start ， GitLab （）。 Gitlab   sudo gitlab - ctl start #  gitlab  sudo gitlab - ctl stop #  gitlab  sudo gitlab - ctl restart #  gitlab    GitLab repositories and GitLab metadata  crontab ： 0 2 * * * / usr / bin / gitlab - rake gitlab : backup : create   gitlab ， gitlab_rails [ backup_path ]， / var / opt / gitlab / backups 。  unicorn  sidekiq ，，。 sudo gitlab - ctl stop unicorn # ok : down : unicorn : 0 s , normally up sudo gitlab - ctl stop sidekiq # ok : down : sidekiq : 0 s , normally up ， 1406691018  gitlab - rake gitlab : backup : restore BACKUP = 1406691018  ， gitlab  / var / opt / gitlab / git - data ， ，。  ，： git_data_dir /path/to/git-data ： sudo gitlab - ctl reconfigure 。  ，。 ，： sudo gitlab - ctl stop  rsync ：  / ， / ， repositories  sudo rsync - av / var / opt / gitlab / git - data / repositories / path / to / git - data / ： ，，。 sudo gitlab - ctl reconfigure sudo gitlab - ctl start 。  ， gitlabhq ，， 500 。  root  / home 。 ， root 。  IPv6  IPv6 ， gitlab  IPv6 。  / etc / gitlab / gitlab . rb ： # nginx [ listen_addresses ] = [ * ]  nginx [ listen_addresses ] = [ * , [::] ]  sudo gitlab - ctl reconfigure  IPv6 。 gitlab  SMTP ， 163 。 $ sudo vi / etc / gitlab / gitlab . rb # Change the external_url to the address your users will type in their browserexternal_url http: //xxhost.com #Sending application email via SMTP gitlab_rails [ smtp_enable ] = true gitlab_rails [ smtp_address ] = smtp.163.com gitlab_rails [ smtp_port ] = 25 gitlab_rails [ smtp_user_name ] = xxuser@163.com gitlab_rails [ smtp_password ] = xxpassword gitlab_rails [ smtp_domain ] = 163.com gitlab_rails [ smtp_authentication ] = : login gitlab_rails [ smtp_enable_starttls_auto ] = true ##gitlab gitlab_rails [ gitlab_email_from ] = xxuser@163.com user [ git_user_email ] = xxuser@163.com （ smtp ，，，。） gitlab - ctl reconfigure  gitlab - ctl tail  git http : // www . liaoxuefeng . com / wiki / 0013739516305929606 dd18361248578c67b8067c8c017b000 git config git config --global user.name name git config --global user.email email  git pull https : // github . com / XX - net / XX - Net . git master git add . git commit - m net git push - u origin master (  ) git push (  ) . gitignorecache git rm - r --cached . git add . git commit - m update .gitignore yum install curl - devel expat - devel gettext - devel openssl - devel zlib - devel # yum install git  mkdir learngit cd learngit git init git add readme . txt # git commit - m wrote a readme file # git status # git diff filename #difference ， Unixdiff  git log git reset --hard commit #， git reflog 54 edaa9 HEAD @{ 2 }: commit : 3 967 d2cd HEAD @{ 3 }: commit : m git reset --hard 54edaa9 git checkout ，  ，  “  ”  git branch dev #dev git checkout dev #dev git branch # git checkout - b name  +  git checkout master master git merge dev devmaster git branch - d dev dev Git git useradd git  ， ~/ . ssh / id_rsa . pub ，  / home / git / . ssh / authorized_keys ，  。 cd / srv git init --bare sample.git git init chown - R git : git sample . git  / etc / passwd git : x : 1001 : 1001 : ,,, : / home / git : / usr / bin / git - shell git clone git @server : / srv / sample . git #git git pull #git git clean   1 、 rm - rf . git 2 、 git init git add . git commit - m Initial commit 3 、 git remote add origin github - uri git push - u --force origin master jenkins http : // pkg . jenkins - ci . org / redhat / wget - O / etc / yum . repos . d / jenkins . repo http : // pkg . jenkins - ci . org / redhat / jenkins . repo rpm -- import http : // pkg . jenkins - ci . org / redhat / jenkins - ci . org . key yum install java jenkins jenkins  （） #!/bin/bash [ ! - d ../ package ] mkdir ../ package tar - zcf ../ package / $ JOB_NAME - $ tag . tar . gz . svn . 1.  SVN （ 3 3  ） 【： 3690 】 yum - y install subversion . 2.  mkdir - pv / tmp / svn svnadmin create / tmp / svn #SVN， . 3.  mkdir - pv / tmp / www / { trunk , branches , tags } #、、 echo csn / tmp / www / trunk / a . html . 4.  svn import / tmp / www / file : /// tmp / svn / www - m project D #/tmp/www/tmp/svn/www ，project D . 5.  vim / etc / init . d / svnserve . 6.  service svnserve start . 7. （ # # ， ） vim / tmp / svn / conf / svnserve . conf （  ） # . 8.  vim / tmp / svn / conf / passwd dev = client #： =  . 9.  # cd / var / www / html # svn checkout svn : // 192.168 . 38.1 / www # echo upload_test / var / www / html / www / trunk / b . html svn add / var / www / html / www / trunk / b . html cd / var / www / html / www / #（） svn commit - m ‘ version2 ’ #（），，version2 10.  svn update  Apache . 1.  e Apache  yum - y install mod_dav_svn . 2. （ ， ） vim / etc / httpd / conf . d / subversion . conf Location / DAV svn SVNPath / tmp / svn # # （） / Location . 3.  d httpd  service httpd restart . 4.  N SVN  svnadmin hotcopy / tmp / svn / / tmp / bak N SVN  . 1.  cp / tmp / svn / hooks / post - commit . tmpl / tmp / svn / hooks / post - commit . 2. ，  ，， vim / tmp / svn / hooks / post - commit ssh root @192.168.38.2 - C “ cd / var / www / html / www / svn update ”  echo “$ REPOS = “$ 1 ” ; $ REV =“$2””| mutt -s update code abc @163.com ; ssh 192.168 . 38.2 “ cd / var / www / html / www / svn update ” . 3.  chmod + x / tmp / svn / hooks / post - commit # #  x selinux  sestatus svn http https://docs.bitnami.com/virtual-machine/components/subversion/ yum install mod_dav_svn # svnadmin create stuff # chown -R apache.apache stuff/ /etc/httpd/conf.d/subversion.conf Location /repos DAV svn SVNParentPath /var/www/svn AuthType Basic # ，、 AuthName Authorization Realm #  AuthUserFile /etc/svn/svnusers.conf #  Require valid-user #  /Location # mkdir -p /etc/svn/ # htpasswd -c /etc/svn/svnusers.conf admin /etc/init.d/httpd restart svn  svn  svnadmin recover / path / to / repos  =================== svnlook youngest sinacuishou /  svnadmin dump sinacuishou / sinacuishou_svn . dumpfile  svnadmin load sinacuishou / sinacuishou_svn . dumpfile  svnadmin dump myrepos – r 23 rev - 23 . dumpfile //  version23  svnadmin dump myrepos – r 100 : 200 rev - 100 - 200 . dumpfile //  version100 ~ 200  ， - r ","title":"git-svn"},{"location":"git-svn/#ant","text":"?xml version= 1.0 encoding= UTF-8 ? !-- ，warFile。 -- project name= Visit default= warFile basedir= . !-- ，war。 -- property name= warFileName value= CuiShou.war /property !-- ，javajar。 -- path id= project.lib fileset dir= ${ basedir } /WebRoot/WEB-INF/lib include name= **/*.jar / /fileset fileset dir= /usr/local/tomcat_pingtai/lib include name= **/*.jar / /fileset /path !-- ，：class，build。 -- target name= clean delete dir= ${ basedir } /build / mkdir dir= ${ basedir } /build / /target !-- ，srcjava，class。 -- target name= compile depends= clean javac srcdir= ${ basedir } /src destdir= ${ basedir } /build includeantruntime= false compilerarg line= -encoding UTF-8 / classpath refid= project.lib /classpath compilerarg value= -XDignore.symbol.file / /javac copy todir = ${basedir}/build fileset dir= ${ basedir } /src excludes= **/*.java /fileset ， fileset dir= ${ basedir } /resources include name= **/**.* / /fileset /copy /target !-- ，classjar。 -- target name= warFile depends= compile !-- war。 -- delete dir= ${ basedir } / ${ warFileName } / !-- war。 -- war destfile= ${ basedir } / ${ warFileName } webxml= ${ basedir } /WebRoot/WEB-INF/web.xml !-- jarclasswar。 -- fileset dir= ${ basedir } /WebRoot include name= **/**.* / exclude name= **/*.jar / exclude name= **/*.class / /fileset !-- jarclasswar。 -- lib dir= ${ basedir } /WebRoot/WEB-INF/lib / classes dir= ${ basedir } /build / /war /target /project","title":"ant"},{"location":"git-svn/#gitlab","text":"gitlab https : // about . gitlab . com / downloads / # centos6 yum install curl openssh - server postfix cronie service postfix start chkconfig postfix on lokkit - s http - s ssh wget https : // mirrors . tuna . tsinghua . edu . cn / gitlab - ce / yum / el6 / gitlab - ce - 8 . 9 . 8 - ce . 0 . el6 . x86_64 . rpm rpm - i gitlab - ce - XXX . rpm gitlab - ctl reconfigure  Username : root Password : 5 iveL ! fe gitlab + ldap  / etc / gitlab / gitlab . rb  ldap  # For omnibus packages gitlab_rails [ ldap_enabled ] = true gitlab_rails [ ldap_servers ] = YAML . load - EOS # remember to close this block with EOS below main : # main is the GitLab provider ID of this LDAP server label : LDAP host : ldap_server_IP port : 389 uid : uid method : plain # tls or ssl or plain allow_username_or_email_login : true bind_dn : cn=xxx,dc=xxx,dc=com password : PASSWPRD active_directory : false base : ou=xxx,dc=xxx,dc=com user_filter : EOS  # gitlab - ctl reconfigure  gitlab  ldap  ldap  / var / log / gitlab / gitlab - rails / production . log gitlab  gitlab - ctl start | stop | restart  / etc / gitlab / gitlab . rb   # gitlab - ctl reconfigure ps  chef  / etc / gitlab / gitlab . rb  / var / opt / gitlab / gitlab - rails / etc / gitlab . yml --------------------------- Gitlab  ，，。， （）。 ： sudo cat / opt / gitlab / embedded / service / gitlab - rails / VERSION  VERSION ， 8 . 6 。 ，。， issue 。 ， clone 。 # GitLab . com  git clone https : // gitlab . com / larryli / gitlab . git #  Coding . net  git clone https : // git . coding . net / larryli / gitlab . git ， Coding . net ， clone  checkout ， patch  diff 。 # 8 . 1  git diff origin / 8 - 6 - stable .. 8 - 6 - zh .. / 8 . 6 . diff  8 . 6 . diff 。 #  gitlab sudo gitlab - ctl stop sudo patch - d / opt / gitlab / embedded / service / gitlab - rails - p1 8 . 6 . diff  . rej ， GitLab 。 sudo gitlab - ctl start ， GitLab （）。 Gitlab   sudo gitlab - ctl start #  gitlab  sudo gitlab - ctl stop #  gitlab  sudo gitlab - ctl restart #  gitlab    GitLab repositories and GitLab metadata  crontab ： 0 2 * * * / usr / bin / gitlab - rake gitlab : backup : create   gitlab ， gitlab_rails [ backup_path ]， / var / opt / gitlab / backups 。  unicorn  sidekiq ，，。 sudo gitlab - ctl stop unicorn # ok : down : unicorn : 0 s , normally up sudo gitlab - ctl stop sidekiq # ok : down : sidekiq : 0 s , normally up ， 1406691018  gitlab - rake gitlab : backup : restore BACKUP = 1406691018  ， gitlab  / var / opt / gitlab / git - data ， ，。  ，： git_data_dir /path/to/git-data ： sudo gitlab - ctl reconfigure 。  ，。 ，： sudo gitlab - ctl stop  rsync ：  / ， / ， repositories  sudo rsync - av / var / opt / gitlab / git - data / repositories / path / to / git - data / ： ，，。 sudo gitlab - ctl reconfigure sudo gitlab - ctl start 。  ， gitlabhq ，， 500 。  root  / home 。 ， root 。  IPv6  IPv6 ， gitlab  IPv6 。  / etc / gitlab / gitlab . rb ： # nginx [ listen_addresses ] = [ * ]  nginx [ listen_addresses ] = [ * , [::] ]  sudo gitlab - ctl reconfigure  IPv6 。","title":"gitlab"},{"location":"git-svn/#gitlab_1","text":" SMTP ， 163 。 $ sudo vi / etc / gitlab / gitlab . rb # Change the external_url to the address your users will type in their browserexternal_url http: //xxhost.com #Sending application email via SMTP gitlab_rails [ smtp_enable ] = true gitlab_rails [ smtp_address ] = smtp.163.com gitlab_rails [ smtp_port ] = 25 gitlab_rails [ smtp_user_name ] = xxuser@163.com gitlab_rails [ smtp_password ] = xxpassword gitlab_rails [ smtp_domain ] = 163.com gitlab_rails [ smtp_authentication ] = : login gitlab_rails [ smtp_enable_starttls_auto ] = true ##gitlab gitlab_rails [ gitlab_email_from ] = xxuser@163.com user [ git_user_email ] = xxuser@163.com （ smtp ，，，。） gitlab - ctl reconfigure  gitlab - ctl tail ","title":"gitlab"},{"location":"git-svn/#git","text":"http : // www . liaoxuefeng . com / wiki / 0013739516305929606 dd18361248578c67b8067c8c017b000 git config git config --global user.name name git config --global user.email email  git pull https : // github . com / XX - net / XX - Net . git master git add . git commit - m net git push - u origin master (  ) git push (  ) . gitignorecache git rm - r --cached . git add . git commit - m update .gitignore yum install curl - devel expat - devel gettext - devel openssl - devel zlib - devel # yum install git  mkdir learngit cd learngit git init git add readme . txt # git commit - m wrote a readme file # git status # git diff filename #difference ， Unixdiff  git log git reset --hard commit #， git reflog 54 edaa9 HEAD @{ 2 }: commit : 3 967 d2cd HEAD @{ 3 }: commit : m git reset --hard 54edaa9 git checkout ，  ，  “  ”  git branch dev #dev git checkout dev #dev git branch # git checkout - b name  +  git checkout master master git merge dev devmaster git branch - d dev dev Git git useradd git  ， ~/ . ssh / id_rsa . pub ，  / home / git / . ssh / authorized_keys ，  。 cd / srv git init --bare sample.git git init chown - R git : git sample . git  / etc / passwd git : x : 1001 : 1001 : ,,, : / home / git : / usr / bin / git - shell git clone git @server : / srv / sample . git #git git pull #git","title":"git"},{"location":"git-svn/#git-clean","text":"  1 、 rm - rf . git 2 、 git init git add . git commit - m Initial commit 3 、 git remote add origin github - uri git push - u --force origin master","title":"git clean"},{"location":"git-svn/#jenkins","text":"http : // pkg . jenkins - ci . org / redhat / wget - O / etc / yum . repos . d / jenkins . repo http : // pkg . jenkins - ci . org / redhat / jenkins . repo rpm -- import http : // pkg . jenkins - ci . org / redhat / jenkins - ci . org . key yum install java jenkins jenkins  （） #!/bin/bash [ ! - d ../ package ] mkdir ../ package tar - zcf ../ package / $ JOB_NAME - $ tag . tar . gz .","title":"jenkins"},{"location":"git-svn/#svn","text":". 1.  SVN （ 3 3  ） 【： 3690 】 yum - y install subversion . 2.  mkdir - pv / tmp / svn svnadmin create / tmp / svn #SVN， . 3.  mkdir - pv / tmp / www / { trunk , branches , tags } #、、 echo csn / tmp / www / trunk / a . html . 4.  svn import / tmp / www / file : /// tmp / svn / www - m project D #/tmp/www/tmp/svn/www ，project D . 5.  vim / etc / init . d / svnserve . 6.  service svnserve start . 7. （ # # ， ） vim / tmp / svn / conf / svnserve . conf （  ） # . 8.  vim / tmp / svn / conf / passwd dev = client #： =  . 9.  # cd / var / www / html # svn checkout svn : // 192.168 . 38.1 / www # echo upload_test / var / www / html / www / trunk / b . html svn add / var / www / html / www / trunk / b . html cd / var / www / html / www / #（） svn commit - m ‘ version2 ’ #（），，version2 10.  svn update  Apache . 1.  e Apache  yum - y install mod_dav_svn . 2. （ ， ） vim / etc / httpd / conf . d / subversion . conf Location / DAV svn SVNPath / tmp / svn # # （） / Location . 3.  d httpd  service httpd restart . 4.  N SVN  svnadmin hotcopy / tmp / svn / / tmp / bak N SVN  . 1.  cp / tmp / svn / hooks / post - commit . tmpl / tmp / svn / hooks / post - commit . 2. ，  ，， vim / tmp / svn / hooks / post - commit ssh root @192.168.38.2 - C “ cd / var / www / html / www / svn update ”  echo “$ REPOS = “$ 1 ” ; $ REV =“$2””| mutt -s update code abc @163.com ; ssh 192.168 . 38.2 “ cd / var / www / html / www / svn update ” . 3.  chmod + x / tmp / svn / hooks / post - commit # #  x selinux  sestatus","title":"svn"},{"location":"git-svn/#svn-http","text":"https://docs.bitnami.com/virtual-machine/components/subversion/ yum install mod_dav_svn # svnadmin create stuff # chown -R apache.apache stuff/ /etc/httpd/conf.d/subversion.conf Location /repos DAV svn SVNParentPath /var/www/svn AuthType Basic # ，、 AuthName Authorization Realm #  AuthUserFile /etc/svn/svnusers.conf #  Require valid-user #  /Location # mkdir -p /etc/svn/ # htpasswd -c /etc/svn/svnusers.conf admin /etc/init.d/httpd restart","title":"svn http"},{"location":"git-svn/#svn_1","text":" svn  svnadmin recover / path / to / repos  =================== svnlook youngest sinacuishou /  svnadmin dump sinacuishou / sinacuishou_svn . dumpfile  svnadmin load sinacuishou / sinacuishou_svn . dumpfile  svnadmin dump myrepos – r 23 rev - 23 . dumpfile //  version23  svnadmin dump myrepos – r 100 : 200 rev - 100 - 200 . dumpfile //  version100 ~ 200  ， - r ","title":"svn"},{"location":"hadoop/","text":"hadoop  hdfs  hadoop jar share / hadoop / mapreduce / hadoop - mapreduce - client - jobclient - 2 . 7 . 0 - tests . jar TestDFSIO - write - nrFiles 10 - fileSize 1000  hdfs  hadoop jar share / hadoop / mapreduce / hadoop - mapreduce - client - jobclient - 2 . 7 . 0 - tests . jar TestDFSIO - read - nrFiles 10 - fileSize 1000  hadoop jar share / hadoop / mapreduce / hadoop - mapreduce - client - jobclient - 2 . 7 . 0 - tests . jar TestDFSIO - clean Total MBytes processed ：  100 MB Throughput mb / sec ： / （ map （ Test exec time sec ））＝＝》 100 / ( map1  + map2  + ... ) Average IO rate mb / sec ：（ map  /  map ） /  ＝＝》 ( 20 / map1 ＋ 20 / map2  + ... ) / 1000 ，。 IO rate std deviation ： Test exec time sec ： job  mapreduces  hadoop jar share / hadoop / mapreduce / hadoop - mapreduce - client - jobclient - 2 . 7 . 0 - tests . jar mrbench - baseDir / tmp / mrbench - maps 100 - reduces 100 - numRuns 1 spark spark - 2 . 0 . 1 / conf / spark - env . sh SPARK_WORKER_MEMORY = 6 g SPARK_WORKER_CORES = 8 SPARK_SSH_OPTS = -p 27005 export JAVA_HOME = /usr/java/jre1.8.0_121/ namenode ha http : // blog . csdn . net / carl810224 / article / details / 52160418 http : // blog . leanote . com / post / lh1649896772@ 163. com / Hadoop %E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%EF%BC%88%E6%B5%8B%E8%AF%95%EF%BC%89 Hadoop0 JDK / Zookeeper / Hadoop namenode / zkfc / journalnode / resourcemanager / QuoqumPeerMain Hadoop1 JDK / Zookeeper / Hadoop namenode / zkfc / journalnode / resourcemanager / QuoqumPeerMain Hadoop2 JDK / Zookeeper / Hadoop datanode // journalnode / nodemanager / QuoqumPeerMain wget http : // mirrors . aliyun . com / apache / zookeeper / zookeeper - 3.4.6 / zookeeper - 3.4.6 . tar . gz cd zookeeper - 3.4.6 / cp conf / zoo_sample . cfg conf / zoo . cfg vim conf / zoo . cfg tickTime = 2000 //（） initLimit = 10 // syncLimit = 5 // dataDir=/usr / local / zookeeper - 3.4.6 / data // dataLogDir=/usr / local / zookeeper - 3.4.6 / data / log // clientPort = 2181 // maxClientCnxns = 2000 //zookeeper server .1 = hadoop0: 2888 : 3888 //zookeeper server .2 = hadoop1: 2888 : 3888 server .3 = hadoop2: 2888 : 3888 mkdir - p data / log echo 1 data / myid 23，  . / bin / zkServer . sh start hadoop cd hadoop - 2.7.0 / etc / hadoop / vim hadoop - env . sh （）: export JAVA_HOME =/home / hadoop / apache / jdk1 .8.0 _ 101 //jdk export HADOOP_SSH_OPTS = -p 27005 ssh export HADOOP_HEAPSIZE = 1024 //Hadoop export HADOOP_NAMENODE_OPTS = -Xmx1024m -Dhadoop.security.logger=${HADOOP_SECURITY_LOGGER:-INFO,RFAS} -Dhdfs.audit.logger=${HDFS_AUDIT_LOGGER:-INFO,NullAppender} $HADOOP_NAMENODE_OPTS //Namenode， export HADOOP_DATANODE_OPTS = -Xmx1024m -Dhadoop.security.logger=ERROR,RFAS $HADOOP_DATANODE_OPTS //Datanode export HADOOP_PORTMAP_OPTS= - Xmx1024m $ HADOOP_PORTMAP_OPTS //1024m slaves vi etc / hadoop / slaves hadoop1 hadoop2 core - site . xml : vim core - site . xml configuration ! -- hdfsnameservicesmycluster，hdfs - site . xmlHA  -- property name fs . defaultFS /name value hdfs : // mycluster /value /property ! -- zookeeper -- property name ha . zookeeper . quorum /name value hadoop0: 2181 , hadoop1: 2181 , hadoop2: 2181 /value /property （，：） property name hadoop . tmp . dir /name value / usr / local / hadoop - 2.7.0 / tmp /value /property property name io . file . buffer . size /name value 131072 /value /property ! -- hdfs（：），0， -- property name fs . trash . interval /name value 10080 /value /property /configuration hdfs - site . xml : vim hdfs - site . xml configuration ! --  -- property name dfs . replication /name value 1 /value /property ! --  -- property name dfs . permissions . enabled /name value false /value /property ! -- WebHDFS（REST） -- property name dfs . webhdfs . enabled /name value true /value /property ! -- //////////////HDFS HA ////////////// -- ! -- hdfsnameservicesmycluster -- property name dfs . nameservices /name value mycluster /value /property ! -- myclusternamenodenn1 , nn2 -- property name dfs . ha . namenodes . mycluster /name value nn1 , nn2 /value /property ! -- nn1 , nn2rpc -- property name dfs . namenode . rpc - address . mycluster . nn1 /name value hadoop0: 8020 /value /property property name dfs . namenode . rpc - address . mycluster . nn2 /name value hadoop1: 8020 /value /property ! -- nn1 , nn2http -- property name dfs . namenode . http - address . mycluster . nn1 /name value hadoop0: 50070 /value /property property name dfs . namenode . http - address . mycluster . nn2 /name value hadoop1: 50070 /value /property ! -- namenodejournalnode , 3journalnode -- property name dfs . namenode . shared . edits . dir /name value qjournal : // hadoop0: 8485 ; hadoop1: 8485 ; hadoop2: 8485 / mycluster /value /property ! -- HDFSactive namenodejava -- property name dfs . client . failover . proxy . provider . mycluster /name value org . apache . hadoop . hdfs . server . namenode . ha . ConfiguredFailoverProxyProvider /value /property ! -- ssh -- property name dfs . ha . fencing . methods /name value sshfence ( spark : 27005 ) /value ssh /property ! --  -- property name dfs . ha . fencing . ssh . private - key - files /name value /root/.ssh / id_dsa /value /property ! -- journalnode -- property name dfs . journalnode . edits . dir /name value /usr / local / hadoop - 2.7.0 / tmp / journal /value /property ! --  -- property name dfs . ha . automatic - failover . enabled /name value true /value /property /configuration mapred - site . xml : cp mapred - site . xml . template mapred - site . xml vim mapred - site . xml configuration ! -- MapReduceYARN -- property name mapreduce . framework . name /name value yarn /value /property ! -- jobhistory serverrpc -- property name mapreduce . jobhistory . address /name value hadoop0: 10020 /value /property ! -- jobhistory serverhttp -- property name mapreduce . jobhistory . webapp . address /name value hadoop0: 19888 /value /property ! -- uber（） -- property name mapreduce . job . ubertask . enable /name value true /value /property ! -- ubermap -- property name mapreduce . job . ubertask . maxmaps /name value 3 /value /property ! -- uberreduce -- property name mapreduce . job . ubertask . maxreduces /name value 1 /value /property /configuration yarn - site . xml: vim yarn - site . xml configuration NodeManager ，mapreduce_shuffleMapReduce property name yarn . nodemanager . aux - services /name value mapreduce_shuffle /value /property ! -- Web Application Proxy （yarn） -- property name yarn . web - proxy . address /name value hadoop1: 8888 /value /property ! --  -- property name yarn . log - aggregation - enable /name value true /value /property ! -- nodemanager -- property name yarn . nodemanager . resource . memory - mb /name value 4096 /value /property ! -- nodemanagerCPU -- property name yarn . nodemanager . resource . cpu - vcores /name value 4 /value /property ! -- //////////////YARN HA ////////////// -- ! -- YARN HA -- property name yarn . resourcemanager . ha . enabled /name value true /value /property ! --  -- property name yarn . resourcemanager . ha . automatic - failover . enabled /name value true /value /property ! -- YARN HA -- property name yarn . resourcemanager . cluster - id /name value yarncluster /value /property ! -- resourcemanager -- property name yarn . resourcemanager . ha . rm - ids /name value rm1 , rm2 /value /property ! -- rm1，rm2 -- property name yarn . resourcemanager . hostname . rm1 /name value hadoop0 /value /property property name yarn . resourcemanager . hostname . rm2 /name value hadoop1 /value /property ! -- YARNhttp -- property name yarn . resourcemanager . webapp . address . rm1 /name value hadoop0: 8088 /value /property property name yarn . resourcemanager . webapp . address . rm2 /name value hadoop1: 8088 /value /property ! -- zookeeper -- property name yarn . resourcemanager . zk - address /name value hadoop0: 2181 /value /property ! -- zookeeper -- property name yarn . resourcemanager . zk - state - store . parent - path /name value /rmstore /value /property ! -- yarn resourcemanager restart -- property name yarn . resourcemanager . recovery . enabled /name value true /value /property ! -- resourcemanagerzookeeper -- property name yarn . resourcemanager . store . class /name value org . apache . hadoop . yarn . server . resourcemanager . recovery . ZKRMStateStore /value /property ! -- yarn nodemanager restart -- property name yarn . nodemanager . recovery . enabled /name value true /value /property ! -- nodemanager IPC -- property name yarn . nodemanager . address /name value 0.0.0.0 : 45454 /value /property /configuration Hadoop zookeeper echo 1 / usr / local / zookeeper - 3.4.6 / data / myid echo 2 / usr / local / zookeeper - 3.4.6 / data / myid echo 3 / usr / local / zookeeper - 3.4.6 / data / myid zookeeper：cd / usr / local / zookeeper - 3.4.6 / . / bin / zkServer . sh start zookeeper: . / bin / zkServer . sh status hadoop0zkfc： . / bin / hdfs zkfc - formatZK journalnode： . / sbin / hadoop - daemon . sh start journalnode Hadoop0 hdfs . / bin / hdfs namenode - format hadoop0nameodehadoop1 scp - r tmp / dfs hadoop1:/usr / local / hadoop - 2.7.0 / tmp / hadoop ssh，key hadoop0dfs： . / sbin / start - dfs . sh ： namenode ( hadoop0 , hadoop1 ) journalnode ( hadoop0 , hadoop1 , hadoop2 ) DFSZKFailoverController ( hadoop0 , hadoop1 ) datanode ( hadoop1 , hadoop2 ) slave hadoop1YARN . / sbin / start - yarn . sh hadoop1ResourceManager ( hadoop1 , hadoop2 ) NodeManager hadoop0ResourceManager . / sbin / yarn - daemon . sh start resourcemanager hadoop1YARN yarn - daemon . sh start proxyserver ：proxyserver， hadoop0YARN . / sbin / mr - jobhistory - daemon . sh start historyserver namenode http : // hadoop0: 50070 http : // hadoop1: 50070   wordcount vi a . txt hello you hello me cd / usr / local / hadoop - 2 . 7 . 0 / . / bin / hdfs dfs - put a . txt / . / bin / hdfs dfs - rm - r / out /  . / bin / hadoop jar share / hadoop / mapreduce / hadoop - mapreduce - examples - 2 . 7 . 0 . jar wordcount / a . txt / out . / bin / hdfs dfs - text / out / part - r - 00000  hadoop  hadoop  ssh  ssh - keygen - t rsa ssh - copy - id - i . ssh / id_rsa . pub - p 27005 root @192.168.3.129  hadoop ， dockerfile 。  ssh ，。（） ： root  root #http: //mirrors.aliyun.com/apache/hadoop/core/hadoop-2.7.0/hadoop-2.7.0.tar.gz FROM daocloud . io / centos : 6 EXPOSE 22 ENV JAVA_HOME / usr / lib / jvm / jre - 1.8.0 - openjdk . x86_64 / ADD epel - 6. repo / etc / yum . repos . d / epel . repo RUN yum install supervisor java - 1.8.0 - openjdk openssh - server openssh - clients rsync - y RUN sed - i s / UsePAM yes / UsePAM no / g / etc / ssh / sshd_config RUN ssh - keygen - t dsa - f / etc / ssh / ssh_host_dsa_key RUN ssh - keygen - t rsa - f / etc / ssh / ssh_host_rsa_key RUN ssh - keygen - t dsa - P - f ~/ . ssh / id_dsa RUN cat ~/ . ssh / id_dsa . pub ~/ . ssh / authorized_keys RUN echo root:root | chpasswd COPY supervisord . conf / etc / supervisord . conf ADD hadoop - 2.7.0 . tar . gz / usr / local / CMD [ /usr/bin/supervisord ] supervisord . conf  [ supervisord ] nodaemon = true  [ program : sshd ] command =/ usr / sbin / sshd – D ， ： hadoop0 ip ： 192.168.2.10  1 ： hadoop1 ip ： 192.168.2.11  2 ： hadoop2 ip ： 192.168.2.12 vi / etc / hosts 172.17.0.119 hadoop0 172.17.0.120 hadoop1 172.17.0.121 hadoop2  hadoop   etc / hadoop   slaves vi etc / hadoop / slaves hadoop1 hadoop2  core - site . xml 、 hdfs - site . xml 、 yarn - site . xml 、 mapred - site . xml ( 1 ) hadoop - env . sh export JAVA_HOME =/ usr / lib / jvm / jre - 1.8.0 - openjdk . x86_64 / ( 2 ) core - site . xml configuration property name fs . defaultFS / name value hdfs : //hadoop0:9000 /value / property property name hadoop . tmp . dir / name value / usr / local / hadoop / tmp / value / property property name fs . trash . interval / name value 1440 / value / property / configuration ( 3 ) hdfs - site . xml configuration property name dfs . replication / name value 1 / value / property property name dfs . permissions / name value false / value / property / configuration ( 4 ) yarn - site . xml configuration property name yarn . nodemanager . aux - services / name value mapreduce_shuffle / value / property property name yarn . log - aggregation - enable / name value true / value / property / configuration ( 5 ) ： cp mapred - site . xml . template mapred - site . xml vi mapred - site . xml configuration property name mapreduce . framework . name / name value yarn / value / property / configuration ( 6 )  resourcemanager ， yarn - site . xml property description The hostname of the RM . / description name yarn . resourcemanager . hostname / name value hadoop0 / value / property ( 7 )   / usr / local / hadoop  1 、 bin / hdfs namenode – format  hdfs ， ：， which ，  yum install - y which 。， - force 。 ( 8 )  hadoop ： sbin / start - all . sh  yes 。  jps ，？ hadoop0 4643 Jps 4073 NameNode 4216 SecondaryNameNode 4381 ResourceManager hadoop1 456 NodeManager 589 Jps 388 DataNode ( 9 )  hadoop ： sbin / stop - all . sh docker run - d -- name hadoop0 -- hostname hadoop0 - p 50070 : 50070 - p 8088 : 8088 hadoop : v3 / usr / bin / supervisord docker run - d -- name hadoop1 -- hostname hadoop1 hadoop : v3 / usr / bin / supervisord docker run - d -- name hadoop2 -- hostname hadoop2 hadoop : v3 / usr / bin / supervisord nativecodeloader WARN util . NativeCodeLoader : Unable to load native - hadoop library for your platform .  log4j 。 // usr / local / hadoop - 2 . 5 . 2 / etc / hadoop / log4j . properties  log4j . logger . org . apache . hadoop . util . NativeCodeLoader = ERROR ambrai Ambari  Apache Software Foundation 。 Ambari 、、 Hadoop 。  Hadoop （ Hive ， Hbase ， Sqoop ， Zookeeper ）。 Hadoop ， ， Ambari 。  http : // ambari . apache . org /  Ambari ， Ambari  Spark ， Storm ， Kafka 、 YARN 。 Ambari ，： Ambari Server  Ambari Agent 。 Ambari Server  Ambari Agent ； Ambari Agent  Web 。 Ambari Agent  Ambari Server ， Web ， 。  ，。 Ambari Server  SSH 。  ssh - keygen - t rsa  Key [ root @ linux - node1 ~ ]# ssh - keygen - t rsa Generating public / private rsa key pair . Enter file in which to save the key ( / root / . ssh / id_rsa ) : Enter passphrase ( empty for no passphrase ) : Enter same passphrase again : Your identification has been saved in / root / . ssh / id_rsa . Your public key has been saved in / root / . ssh / id_rsa . pub .  Server ， ssh - keygen ，。  Ambari Server  scp  [ root @ linux - node1 ~ ]# scp . ssh / id_rsa . pub 192 . 168 . 56 . 12 : / root / . ssh / authorized_keys  [ root @ linux - node2 ~ ]# chmod 600 ~/ . ssh / authorized_keys  [ root @ linux - node1 ~ ]# ssh 192 . 168 . 56 . 12 Last login : Sat Apr 2 16 : 42 : 46 2016 from 192 . 168 . 56 . 1 [ root @ linux - node2 ~ ]# ， ambari - server 。  jdk  ambari  jdk ， yum  openjdk [ root @ linux - node1 ~ ]# yum install - y java - 1 . 8 . 0  ambari - server ambari - server ，。  ambari - server [ root @ test - node3 ~ ]# cd / etc / yum . repos . d / # wget http : // public - repo - 1 . hortonwor ... . repo # yum install - y ambari - server ：， ambari - server  354 M ，。  ambari - server ， ambari - server setup ，，。 [ root @ linux - node1 ~ ]# ambari - server setup Using python / usr / bin / python2 Setup ambari - server Checking SELinux ... SELinux status is disabled Customize user account for ambari - server daemon [ y / n ] ( n ) ? Adjusting ambari - server permissions and ownership ... Checking firewall status ... Redirecting to / bin / systemctl status iptables . service Checking JDK ...[ 1 ] Oracle JDK 1 . 8 + Java Cryptography Extension ( JCE ) Policy Files 8 [ 2 ] Oracle JDK 1 . 7 + Java Cryptography Extension ( JCE ) Policy Files 7 [ 3 ] Custom JDK =========================================================================== Enter choice ( 1 ) : 3 WARNING : JDK must be installed on all hosts and JAVA_HOME must be valid on all hosts . WARNING : JCE Policy files are required for configuring Kerberos security . If you plan to use Kerberos , please make sure JCE Unlimited Strength Jurisdiction Policy Files are valid on all hosts . Path to JAVA_HOME : / usr / lib / jvm / java - 1 . 8 . 0 - openjdk - 1 . 8 . 0 . 77 - 0 . b03 . el7_2 . x86_64 / jre / Validating JDK on Ambari Server ... done . Completing setup ... Configuring database ... Enter advanced database configuration [ y / n ] ( n ) ? Configuring database ... Default properties detected . Using built - in database . Configuring ambari database ... Checking PostgreSQL ... Running initdb : This may take upto a minute . Initializing database ... OK About to start PostgreSQL Configuring local database ... Connecting to local database ... done . Configuring PostgreSQL ... Restarting PostgreSQL Extracting system views ... ambari - admin - 2 . 2 . 0 . 0 . 1310 . jar ...... Adjusting ambari - server permissions and ownership ... Ambari Server setup completed successfully . 1 )  SELinux2 ) ， - （。） 3 )  iptables  JDK ，  Oracle JDK 1 . 8 。 jdk ， jdk 。 yum  openjdk ， / usr / lib / jvm / java - 1 . 8 . 0 - openjdk - xxx . x86_64 / jre / 4 ) 。 5 ) ， -   ambari - server [ root @ linux - node1 ~ ]# ambari - server start  [ root @ linux - node1 ~ ]# netstat - ntlp | grep 8080 tcp6 0 0 ::: 8080 ::: * LISTEN 24168 / java  ambari server  ambari server 。 8080 。 http : // 192 . 168 . 56 . 11 : 8080 /  admin  Hadoop   Ambari ，“ Launch Install Wizard ”，。","title":"hadoop"},{"location":"hadoop/#hadoop","text":" hdfs  hadoop jar share / hadoop / mapreduce / hadoop - mapreduce - client - jobclient - 2 . 7 . 0 - tests . jar TestDFSIO - write - nrFiles 10 - fileSize 1000  hdfs  hadoop jar share / hadoop / mapreduce / hadoop - mapreduce - client - jobclient - 2 . 7 . 0 - tests . jar TestDFSIO - read - nrFiles 10 - fileSize 1000  hadoop jar share / hadoop / mapreduce / hadoop - mapreduce - client - jobclient - 2 . 7 . 0 - tests . jar TestDFSIO - clean Total MBytes processed ：  100 MB Throughput mb / sec ： / （ map （ Test exec time sec ））＝＝》 100 / ( map1  + map2  + ... ) Average IO rate mb / sec ：（ map  /  map ） /  ＝＝》 ( 20 / map1 ＋ 20 / map2  + ... ) / 1000 ，。 IO rate std deviation ： Test exec time sec ： job  mapreduces  hadoop jar share / hadoop / mapreduce / hadoop - mapreduce - client - jobclient - 2 . 7 . 0 - tests . jar mrbench - baseDir / tmp / mrbench - maps 100 - reduces 100 - numRuns 1","title":"hadoop"},{"location":"hadoop/#spark","text":"spark - 2 . 0 . 1 / conf / spark - env . sh SPARK_WORKER_MEMORY = 6 g SPARK_WORKER_CORES = 8 SPARK_SSH_OPTS = -p 27005 export JAVA_HOME = /usr/java/jre1.8.0_121/","title":"spark"},{"location":"hadoop/#namenode-ha","text":"http : // blog . csdn . net / carl810224 / article / details / 52160418 http : // blog . leanote . com / post / lh1649896772@ 163. com / Hadoop %E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%EF%BC%88%E6%B5%8B%E8%AF%95%EF%BC%89 Hadoop0 JDK / Zookeeper / Hadoop namenode / zkfc / journalnode / resourcemanager / QuoqumPeerMain Hadoop1 JDK / Zookeeper / Hadoop namenode / zkfc / journalnode / resourcemanager / QuoqumPeerMain Hadoop2 JDK / Zookeeper / Hadoop datanode // journalnode / nodemanager / QuoqumPeerMain wget http : // mirrors . aliyun . com / apache / zookeeper / zookeeper - 3.4.6 / zookeeper - 3.4.6 . tar . gz cd zookeeper - 3.4.6 / cp conf / zoo_sample . cfg conf / zoo . cfg vim conf / zoo . cfg tickTime = 2000 //（） initLimit = 10 // syncLimit = 5 // dataDir=/usr / local / zookeeper - 3.4.6 / data // dataLogDir=/usr / local / zookeeper - 3.4.6 / data / log // clientPort = 2181 // maxClientCnxns = 2000 //zookeeper server .1 = hadoop0: 2888 : 3888 //zookeeper server .2 = hadoop1: 2888 : 3888 server .3 = hadoop2: 2888 : 3888 mkdir - p data / log echo 1 data / myid 23，  . / bin / zkServer . sh start hadoop cd hadoop - 2.7.0 / etc / hadoop / vim hadoop - env . sh （）: export JAVA_HOME =/home / hadoop / apache / jdk1 .8.0 _ 101 //jdk export HADOOP_SSH_OPTS = -p 27005 ssh export HADOOP_HEAPSIZE = 1024 //Hadoop export HADOOP_NAMENODE_OPTS = -Xmx1024m -Dhadoop.security.logger=${HADOOP_SECURITY_LOGGER:-INFO,RFAS} -Dhdfs.audit.logger=${HDFS_AUDIT_LOGGER:-INFO,NullAppender} $HADOOP_NAMENODE_OPTS //Namenode， export HADOOP_DATANODE_OPTS = -Xmx1024m -Dhadoop.security.logger=ERROR,RFAS $HADOOP_DATANODE_OPTS //Datanode export HADOOP_PORTMAP_OPTS= - Xmx1024m $ HADOOP_PORTMAP_OPTS //1024m slaves vi etc / hadoop / slaves hadoop1 hadoop2 core - site . xml : vim core - site . xml configuration ! -- hdfsnameservicesmycluster，hdfs - site . xmlHA  -- property name fs . defaultFS /name value hdfs : // mycluster /value /property ! -- zookeeper -- property name ha . zookeeper . quorum /name value hadoop0: 2181 , hadoop1: 2181 , hadoop2: 2181 /value /property （，：） property name hadoop . tmp . dir /name value / usr / local / hadoop - 2.7.0 / tmp /value /property property name io . file . buffer . size /name value 131072 /value /property ! -- hdfs（：），0， -- property name fs . trash . interval /name value 10080 /value /property /configuration hdfs - site . xml : vim hdfs - site . xml configuration ! --  -- property name dfs . replication /name value 1 /value /property ! --  -- property name dfs . permissions . enabled /name value false /value /property ! -- WebHDFS（REST） -- property name dfs . webhdfs . enabled /name value true /value /property ! -- //////////////HDFS HA ////////////// -- ! -- hdfsnameservicesmycluster -- property name dfs . nameservices /name value mycluster /value /property ! -- myclusternamenodenn1 , nn2 -- property name dfs . ha . namenodes . mycluster /name value nn1 , nn2 /value /property ! -- nn1 , nn2rpc -- property name dfs . namenode . rpc - address . mycluster . nn1 /name value hadoop0: 8020 /value /property property name dfs . namenode . rpc - address . mycluster . nn2 /name value hadoop1: 8020 /value /property ! -- nn1 , nn2http -- property name dfs . namenode . http - address . mycluster . nn1 /name value hadoop0: 50070 /value /property property name dfs . namenode . http - address . mycluster . nn2 /name value hadoop1: 50070 /value /property ! -- namenodejournalnode , 3journalnode -- property name dfs . namenode . shared . edits . dir /name value qjournal : // hadoop0: 8485 ; hadoop1: 8485 ; hadoop2: 8485 / mycluster /value /property ! -- HDFSactive namenodejava -- property name dfs . client . failover . proxy . provider . mycluster /name value org . apache . hadoop . hdfs . server . namenode . ha . ConfiguredFailoverProxyProvider /value /property ! -- ssh -- property name dfs . ha . fencing . methods /name value sshfence ( spark : 27005 ) /value ssh /property ! --  -- property name dfs . ha . fencing . ssh . private - key - files /name value /root/.ssh / id_dsa /value /property ! -- journalnode -- property name dfs . journalnode . edits . dir /name value /usr / local / hadoop - 2.7.0 / tmp / journal /value /property ! --  -- property name dfs . ha . automatic - failover . enabled /name value true /value /property /configuration mapred - site . xml : cp mapred - site . xml . template mapred - site . xml vim mapred - site . xml configuration ! -- MapReduceYARN -- property name mapreduce . framework . name /name value yarn /value /property ! -- jobhistory serverrpc -- property name mapreduce . jobhistory . address /name value hadoop0: 10020 /value /property ! -- jobhistory serverhttp -- property name mapreduce . jobhistory . webapp . address /name value hadoop0: 19888 /value /property ! -- uber（） -- property name mapreduce . job . ubertask . enable /name value true /value /property ! -- ubermap -- property name mapreduce . job . ubertask . maxmaps /name value 3 /value /property ! -- uberreduce -- property name mapreduce . job . ubertask . maxreduces /name value 1 /value /property /configuration yarn - site . xml: vim yarn - site . xml configuration NodeManager ，mapreduce_shuffleMapReduce property name yarn . nodemanager . aux - services /name value mapreduce_shuffle /value /property ! -- Web Application Proxy （yarn） -- property name yarn . web - proxy . address /name value hadoop1: 8888 /value /property ! --  -- property name yarn . log - aggregation - enable /name value true /value /property ! -- nodemanager -- property name yarn . nodemanager . resource . memory - mb /name value 4096 /value /property ! -- nodemanagerCPU -- property name yarn . nodemanager . resource . cpu - vcores /name value 4 /value /property ! -- //////////////YARN HA ////////////// -- ! -- YARN HA -- property name yarn . resourcemanager . ha . enabled /name value true /value /property ! --  -- property name yarn . resourcemanager . ha . automatic - failover . enabled /name value true /value /property ! -- YARN HA -- property name yarn . resourcemanager . cluster - id /name value yarncluster /value /property ! -- resourcemanager -- property name yarn . resourcemanager . ha . rm - ids /name value rm1 , rm2 /value /property ! -- rm1，rm2 -- property name yarn . resourcemanager . hostname . rm1 /name value hadoop0 /value /property property name yarn . resourcemanager . hostname . rm2 /name value hadoop1 /value /property ! -- YARNhttp -- property name yarn . resourcemanager . webapp . address . rm1 /name value hadoop0: 8088 /value /property property name yarn . resourcemanager . webapp . address . rm2 /name value hadoop1: 8088 /value /property ! -- zookeeper -- property name yarn . resourcemanager . zk - address /name value hadoop0: 2181 /value /property ! -- zookeeper -- property name yarn . resourcemanager . zk - state - store . parent - path /name value /rmstore /value /property ! -- yarn resourcemanager restart -- property name yarn . resourcemanager . recovery . enabled /name value true /value /property ! -- resourcemanagerzookeeper -- property name yarn . resourcemanager . store . class /name value org . apache . hadoop . yarn . server . resourcemanager . recovery . ZKRMStateStore /value /property ! -- yarn nodemanager restart -- property name yarn . nodemanager . recovery . enabled /name value true /value /property ! -- nodemanager IPC -- property name yarn . nodemanager . address /name value 0.0.0.0 : 45454 /value /property /configuration Hadoop zookeeper echo 1 / usr / local / zookeeper - 3.4.6 / data / myid echo 2 / usr / local / zookeeper - 3.4.6 / data / myid echo 3 / usr / local / zookeeper - 3.4.6 / data / myid zookeeper：cd / usr / local / zookeeper - 3.4.6 / . / bin / zkServer . sh start zookeeper: . / bin / zkServer . sh status hadoop0zkfc： . / bin / hdfs zkfc - formatZK journalnode： . / sbin / hadoop - daemon . sh start journalnode Hadoop0 hdfs . / bin / hdfs namenode - format hadoop0nameodehadoop1 scp - r tmp / dfs hadoop1:/usr / local / hadoop - 2.7.0 / tmp / hadoop ssh，key hadoop0dfs： . / sbin / start - dfs . sh ： namenode ( hadoop0 , hadoop1 ) journalnode ( hadoop0 , hadoop1 , hadoop2 ) DFSZKFailoverController ( hadoop0 , hadoop1 ) datanode ( hadoop1 , hadoop2 ) slave hadoop1YARN . / sbin / start - yarn . sh hadoop1ResourceManager ( hadoop1 , hadoop2 ) NodeManager hadoop0ResourceManager . / sbin / yarn - daemon . sh start resourcemanager hadoop1YARN yarn - daemon . sh start proxyserver ：proxyserver， hadoop0YARN . / sbin / mr - jobhistory - daemon . sh start historyserver namenode http : // hadoop0: 50070 http : // hadoop1: 50070","title":"namenode ha"},{"location":"hadoop/#_1","text":" wordcount vi a . txt hello you hello me cd / usr / local / hadoop - 2 . 7 . 0 / . / bin / hdfs dfs - put a . txt / . / bin / hdfs dfs - rm - r / out /  . / bin / hadoop jar share / hadoop / mapreduce / hadoop - mapreduce - examples - 2 . 7 . 0 . jar wordcount / a . txt / out . / bin / hdfs dfs - text / out / part - r - 00000 ","title":""},{"location":"hadoop/#hadoop_1","text":" hadoop  ssh  ssh - keygen - t rsa ssh - copy - id - i . ssh / id_rsa . pub - p 27005 root @192.168.3.129  hadoop ， dockerfile 。  ssh ，。（） ： root  root #http: //mirrors.aliyun.com/apache/hadoop/core/hadoop-2.7.0/hadoop-2.7.0.tar.gz FROM daocloud . io / centos : 6 EXPOSE 22 ENV JAVA_HOME / usr / lib / jvm / jre - 1.8.0 - openjdk . x86_64 / ADD epel - 6. repo / etc / yum . repos . d / epel . repo RUN yum install supervisor java - 1.8.0 - openjdk openssh - server openssh - clients rsync - y RUN sed - i s / UsePAM yes / UsePAM no / g / etc / ssh / sshd_config RUN ssh - keygen - t dsa - f / etc / ssh / ssh_host_dsa_key RUN ssh - keygen - t rsa - f / etc / ssh / ssh_host_rsa_key RUN ssh - keygen - t dsa - P - f ~/ . ssh / id_dsa RUN cat ~/ . ssh / id_dsa . pub ~/ . ssh / authorized_keys RUN echo root:root | chpasswd COPY supervisord . conf / etc / supervisord . conf ADD hadoop - 2.7.0 . tar . gz / usr / local / CMD [ /usr/bin/supervisord ] supervisord . conf  [ supervisord ] nodaemon = true  [ program : sshd ] command =/ usr / sbin / sshd – D ， ： hadoop0 ip ： 192.168.2.10  1 ： hadoop1 ip ： 192.168.2.11  2 ： hadoop2 ip ： 192.168.2.12 vi / etc / hosts 172.17.0.119 hadoop0 172.17.0.120 hadoop1 172.17.0.121 hadoop2  hadoop   etc / hadoop   slaves vi etc / hadoop / slaves hadoop1 hadoop2  core - site . xml 、 hdfs - site . xml 、 yarn - site . xml 、 mapred - site . xml ( 1 ) hadoop - env . sh export JAVA_HOME =/ usr / lib / jvm / jre - 1.8.0 - openjdk . x86_64 / ( 2 ) core - site . xml configuration property name fs . defaultFS / name value hdfs : //hadoop0:9000 /value / property property name hadoop . tmp . dir / name value / usr / local / hadoop / tmp / value / property property name fs . trash . interval / name value 1440 / value / property / configuration ( 3 ) hdfs - site . xml configuration property name dfs . replication / name value 1 / value / property property name dfs . permissions / name value false / value / property / configuration ( 4 ) yarn - site . xml configuration property name yarn . nodemanager . aux - services / name value mapreduce_shuffle / value / property property name yarn . log - aggregation - enable / name value true / value / property / configuration ( 5 ) ： cp mapred - site . xml . template mapred - site . xml vi mapred - site . xml configuration property name mapreduce . framework . name / name value yarn / value / property / configuration ( 6 )  resourcemanager ， yarn - site . xml property description The hostname of the RM . / description name yarn . resourcemanager . hostname / name value hadoop0 / value / property ( 7 )   / usr / local / hadoop  1 、 bin / hdfs namenode – format  hdfs ， ：， which ，  yum install - y which 。， - force 。 ( 8 )  hadoop ： sbin / start - all . sh  yes 。  jps ，？ hadoop0 4643 Jps 4073 NameNode 4216 SecondaryNameNode 4381 ResourceManager hadoop1 456 NodeManager 589 Jps 388 DataNode ( 9 )  hadoop ： sbin / stop - all . sh docker run - d -- name hadoop0 -- hostname hadoop0 - p 50070 : 50070 - p 8088 : 8088 hadoop : v3 / usr / bin / supervisord docker run - d -- name hadoop1 -- hostname hadoop1 hadoop : v3 / usr / bin / supervisord docker run - d -- name hadoop2 -- hostname hadoop2 hadoop : v3 / usr / bin / supervisord","title":"hadoop"},{"location":"hadoop/#nativecodeloader","text":"WARN util . NativeCodeLoader : Unable to load native - hadoop library for your platform .  log4j 。 // usr / local / hadoop - 2 . 5 . 2 / etc / hadoop / log4j . properties  log4j . logger . org . apache . hadoop . util . NativeCodeLoader = ERROR","title":"nativecodeloader"},{"location":"hadoop/#ambrai","text":"Ambari  Apache Software Foundation 。 Ambari 、、 Hadoop 。  Hadoop （ Hive ， Hbase ， Sqoop ， Zookeeper ）。 Hadoop ， ， Ambari 。  http : // ambari . apache . org /  Ambari ， Ambari  Spark ， Storm ， Kafka 、 YARN 。 Ambari ，： Ambari Server  Ambari Agent 。 Ambari Server  Ambari Agent ； Ambari Agent  Web 。 Ambari Agent  Ambari Server ， Web ， 。  ，。 Ambari Server  SSH 。  ssh - keygen - t rsa  Key [ root @ linux - node1 ~ ]# ssh - keygen - t rsa Generating public / private rsa key pair . Enter file in which to save the key ( / root / . ssh / id_rsa ) : Enter passphrase ( empty for no passphrase ) : Enter same passphrase again : Your identification has been saved in / root / . ssh / id_rsa . Your public key has been saved in / root / . ssh / id_rsa . pub .  Server ， ssh - keygen ，。  Ambari Server  scp  [ root @ linux - node1 ~ ]# scp . ssh / id_rsa . pub 192 . 168 . 56 . 12 : / root / . ssh / authorized_keys  [ root @ linux - node2 ~ ]# chmod 600 ~/ . ssh / authorized_keys  [ root @ linux - node1 ~ ]# ssh 192 . 168 . 56 . 12 Last login : Sat Apr 2 16 : 42 : 46 2016 from 192 . 168 . 56 . 1 [ root @ linux - node2 ~ ]# ， ambari - server 。  jdk  ambari  jdk ， yum  openjdk [ root @ linux - node1 ~ ]# yum install - y java - 1 . 8 . 0  ambari - server ambari - server ，。  ambari - server [ root @ test - node3 ~ ]# cd / etc / yum . repos . d / # wget http : // public - repo - 1 . hortonwor ... . repo # yum install - y ambari - server ：， ambari - server  354 M ，。  ambari - server ， ambari - server setup ，，。 [ root @ linux - node1 ~ ]# ambari - server setup Using python / usr / bin / python2 Setup ambari - server Checking SELinux ... SELinux status is disabled Customize user account for ambari - server daemon [ y / n ] ( n ) ? Adjusting ambari - server permissions and ownership ... Checking firewall status ... Redirecting to / bin / systemctl status iptables . service Checking JDK ...[ 1 ] Oracle JDK 1 . 8 + Java Cryptography Extension ( JCE ) Policy Files 8 [ 2 ] Oracle JDK 1 . 7 + Java Cryptography Extension ( JCE ) Policy Files 7 [ 3 ] Custom JDK =========================================================================== Enter choice ( 1 ) : 3 WARNING : JDK must be installed on all hosts and JAVA_HOME must be valid on all hosts . WARNING : JCE Policy files are required for configuring Kerberos security . If you plan to use Kerberos , please make sure JCE Unlimited Strength Jurisdiction Policy Files are valid on all hosts . Path to JAVA_HOME : / usr / lib / jvm / java - 1 . 8 . 0 - openjdk - 1 . 8 . 0 . 77 - 0 . b03 . el7_2 . x86_64 / jre / Validating JDK on Ambari Server ... done . Completing setup ... Configuring database ... Enter advanced database configuration [ y / n ] ( n ) ? Configuring database ... Default properties detected . Using built - in database . Configuring ambari database ... Checking PostgreSQL ... Running initdb : This may take upto a minute . Initializing database ... OK About to start PostgreSQL Configuring local database ... Connecting to local database ... done . Configuring PostgreSQL ... Restarting PostgreSQL Extracting system views ... ambari - admin - 2 . 2 . 0 . 0 . 1310 . jar ...... Adjusting ambari - server permissions and ownership ... Ambari Server setup completed successfully . 1 )  SELinux2 ) ， - （。） 3 )  iptables  JDK ，  Oracle JDK 1 . 8 。 jdk ， jdk 。 yum  openjdk ， / usr / lib / jvm / java - 1 . 8 . 0 - openjdk - xxx . x86_64 / jre / 4 ) 。 5 ) ， -   ambari - server [ root @ linux - node1 ~ ]# ambari - server start  [ root @ linux - node1 ~ ]# netstat - ntlp | grep 8080 tcp6 0 0 ::: 8080 ::: * LISTEN 24168 / java  ambari server  ambari server 。 8080 。 http : // 192 . 168 . 56 . 11 : 8080 /  admin  Hadoop   Ambari ，“ Launch Install Wizard ”，。","title":"ambrai"},{"location":"haproxy/","text":"haproxy 、 HAProxy  HAProxy 、 TCP  HTTP ，，、。 HAProxy  web ，。 HAProxy ， 。，  web  。 HAProxy 、，。 、 ，。 ( User - Space ) ， 。，，。  CPU  ( Cycle ) 。 ———— HAProxy 、 TCP  HTTP 、，  7  web 。 HAProxy ： 1.4 ——： 1.2 ，，。  ( client - side keep - alive ) TCP  ( TCP speedups )  ( response buffering ) RDP   ( source - based stickiness )  ( a much better stats interfaces )  ( more verbose health checks )  ( traffic - based health )  HTTP   ( server management from the CLI )  ACL  ( ACL - based persistence )  1.3 ——： 1.2 ，。  ( content switching ) ：； ACL ：；  ( load - balancing algorithms ) ：；  ( content inspection ) ：；  ( transparent proxy ) ： Linux  IP ；  TCP  ( kernel TCP splicing ) ： copy  G ；  ( layered design ) ：、 TCP 、 HTTP 、； 、 ( fast and fair scheduler ) ： QoS ；  ( session rate limiting ) ：；  OS ： x86 、 x86_64 、 Alpha 、 SPARC 、 MIPS  PARISC  Linux 2.4 ； x86 、 x86_64 、 ARM ( ixp425 )  PPC64  Linux2 .6 ； UltraSPARC 2  3  Sloaris 8 / 9 ； Opteron  UltraSPARC  Solaris 10 ； x86  FreeBSD 4.1 - 8 ； i386 , amd64 , macppc , alpha , sparc64  VAX  OpenBSD 3.1 - current ； ， Linux 2.6  epoll  Linux 2.4  haproxy 1.2.5 。 haproxy 1.1 l  polling  select () ，。 1.2  1.3  poll () ， ， Solaris 。 HAProxy 1.3  Linux 2.6  epoll  Linux 2.4  epoll ，  FreeBSD  kqueue ，。  Linux 2.6 ( = 2.6.27.19 ) ， HAProxy  splice () ， 10 Gbps 。 ， x86  x86_64 ，，。 Linux 2.6.32  HAProxy 1.4 ；  epoll  Linux 2.4  HAProxy 1.4 ； FreeBSD  HAProxy 1.4 ； Solaris 10  HAProxy 1.4 ；  HAProxy  OS 。 、。 O ( 1 )  ( event checker ) 。 ， ( single buffering ) ， CPU ；  Linux 2.6 ( = 2.6.27.19 )  splice () ， HAProxy  ( Zero - copy forwarding ) ，  Linux 3.5  OS  ( zero - starting ) ； MRU ，； ：， O ( log ( N )) 、 ；  HTTP ： HTTP ； ，，、；  CPU ，， 5 %  95 % ， HAProxy  20 。， OS  。， CPU  10 % ， 7 。， HAProxy  7 。 ， 7  HAProxy 。“” ， ( request across multiple packets ) ，，。 ， TCP ，，。 ：    、 HAProxy 2.1  HAProxy  3 ： ——， ——“ global ”，； —— proxy ，“ defaults ”、“ listen ”、“ frontend ”“ backend ”； 2.2  ，。，。 us :  ( microseconds ) ， 1 / 1000000 ； ms :  ( milliseconds ) ， 1 / 1000 ； s :  ( seconds ) ； m :  ( minutes ) ； h ： ( hours ) ； d :  ( days ) ； 2.3   80  HTTP proxy ， 127.0.0.1 : 8000  server 。 global daemon maxconn 25600 defaults mode http timeout connect 5000 ms timeout client 50000 ms timeout server 50000 ms frontend http - in bind *: 80 default_backend servers backend servers server server1 127.0.0.1 : 8080 maxconn 32 2.4  “ global ”， OS 。 *  - chroot jail dir ： haproxy  chroot () ， haproxy ， ； - daemon ： haproxy ，“ - D ”，，“ - db ”； - gid number ： GID  haproxy ， haproxy  GID ，； - group group name ： gid ，； - log address facility [ max level [ min level ]] ： syslog ，； - log - send - hostname [ string ] ： syslog ，“ string ”，； - nbproc number ： haproxy ， haproxy ；，， ； - pidfile ： - uid ： UID  haproxy ； - ulimit - n ：，，； - user ： uid ，； - stats ： - node ：， HA  haproxy  IP ； - description ：； *  - maxconn number ： haproxy ，“ - n ”；“ ulimit - n ” ； - maxpipes number ： haproxy  pipe  tcp ， pipe ； pipe  ，，“ ulimit - n ”； maxconn / 4 ，； - noepoll ： Linux  epoll ； - nokqueue ： BSE  kqueue ； - nopoll ： poll ； - nosepoll ： Linux  epoll ； - nosplice ： Linux  tcp ， recv / send ；， Linux 2.6.25 - 28 ， tcp  bug ； - spread - checks 0..50 , in percent ： haproxy ， ；； - tune . bufsize number ： buffer ，， haproxy ，  cookie ； 16384 ，，； - tune . chksize number ：，；， ；； - tune . maxaccept number ： haproxy ，，  100 ， 8 ， - 1 ；； - tune . maxpollevents number ：， OS ； 200 ， ， 200 ，； - tune . maxrewrite number ：， 1024 ；， haproxy ； - tune . rcvbuf . client number ： - tune . rcvbuf . server number ：，；； - tune . sndbuf . client ： - tune . sndbuf . server ： * Debug  - debug - quiet 2.5  。 - defaults name - frontend name - backend name - listen name “ defaults ”，“ defaults ”。 “ frontend ”，。 “ backend ”“”，。 “ listen ”“”“”， TCP 。 、、、 - (  ) 、 _ (  ) 、 .(  )  : (  ) 。， ACL 。 、 3.1 balance balance algorithm [ arguments ] balance url_param param [ check_post [ max_wait ]] ，“ defaults ”、“ listen ”“ backend ”。 algorithm  server ， 。： roundrobin ：，，、。， ，，， 4128 ； static - rr ：， roundrobin ，，；， ； leastconn ：；， LDAP 、 SQL ， ， HTTP ；，； source ： hash ，； IP  ；，，， ； cookie  TCP ；， hash - type ； uri ： URI  ( “” )  URI  hash ，；  URI ，； ；， HTTP ；， hash - type ； url_param ： argument  URL  HTTP GET ；“ = ” ， hash ；  ID ，；， ；， hash - type ； hdr ( name ) ： HTTP ， name  HTTP ；， ；“ use_domain_only ”， Host  (  www . magedu . com ， magedu  hash  )  hash ；， hash - type ； rdp - cookie rdp - cookie ( name ) ： 3.2 bind bind [ address ] : port_range [, ...] bind [ address ] : port_range [, ...] interface interface  frontend  listen ，。 address ：，、 IPv4 、 IPv6  * ；、 *  0.0.0.0 ， IPv4 ； port_range ： TCP ， (  5005 - 5010 ) ，；，  address : port ， 1024 ， uid  ； interface ：， Linux ；，， ； 3.3 mode mode { tcp | http | health } 。， (  HTTP  ) ，。 tcp ： TCP ，， 7 ；， SSL 、 SSH 、 SMTP ； http ： HTTP ，， RFC ； health ： health ，“ OK ”，； ；，， tcp  http  monitor ； 3.4 hash - type hash - type method  hash ； frontend ； map - based  consistent ， map - based 。 map - based ： hash 。 hash ，，， ，。，，， ，，，。 consistent ： hash ； hash  hash ，。 ，，。，，，  cache 。，，，， 。 3.5 log log global log address facility [ level [ minlevel ]] ，。 log ，，“ log global ” global   log ， log 。 global ： global ，；“ log global ”，； address ：， IPv4_address : PORT ， port  UDP ， 514 ； Unix  ， chroot ； facility ： syslog  facility ； level ：，，；，； 3.6 maxconn maxconn conns ，， backend 。， haproxy ， 。，“ global ”。，， haproxy ，  8 KB ，， 17 KB  RAM 。， 1 GB  RAM  40000 - 50000  。  conns ，，，；， 。 2000 。 3.7 default_backend default_backend backend  use_backend ，， backend 。 frontend  backend  ， use-backend ；。 backend ：； ： use_backend dynamic if url_dyn use_backend static if url_css url_img extension_img default_backend dynamic 3.8 server server name address [ : port ] [ param * ]  server ，， defaults  frontend 。 name ：，； http-send-server-name ， ； address ： IPv4 ，， IPv4 ； [ : port ] ：，；，； [ param * ] ：；，，； ： backup ：， server  server ； check ： server ，，： inter delay ：，， 2000 ； fastinter  downinter  ； rise count ：， server ； fall count ： server ； cookie value ： server  cookie ，， server ， ； maxconn maxconn ：；，， ； maxqueue maxqueue ：； observe mode ：，，“ layer4 ”“ layer7 ”，“ layer7 ” http  ； redir prefix ：， GET  HEAD  302 ；， prefix  / ， ，；： server srv1 172.16.100.6 : 80 redir http : //imageserver.magedu.com check weight weight ：， 1 ， 256 ， 0 ； ： option httpchk option httpchk uri option httpchk method uri option httpchk method uri version ： frontend ，： backend https_relay mode tcp option httpchk OPTIONS * HTTP / 1.1 \\ r \\ nHost : \\ www . magedu . com server apache1 192.168.1.1 : 443 check port 80 ： server first 172.16.100.7 : 1080 cookie first check inter 1000 server second 172.16.100.8 : 1080 cookie second check inter 1000 3.9 capture request header capture request header name len length ，“ frontend ”“ listen ”。 {} 。 ，，“ | ”。， “ Host ”、“ Content - length ”、“ User - agent ”， “ X - Forward - For ”。 name ：，，，。， ，。 length ：，。 ， 64 。 frontend ， frontend 。 3.10 capture response header capture response header name len length ，。 3.11 stats enable ，“ frontend ”。，： - stats uri : / haproxy ? stats - stats realm : HAProxy Statistics - stats auth : no authentication - stats scope : no restriction “ stats enable ”，，。。 backend public_www server websrv1 172.16.100.11 : 80 stats enable stats hide - version stats scope . stats uri / haproxyadmin ? stats stats realm Haproxy \\ Statistics stats auth statsadmin : password stats auth statsmaster : password 3.12 stats hide - version stats hide - version  HAProxy ，“ frontend ”。，， HAProxy ，，  HAProxy ，。“ stats hide - version ” ，，。“ stats enable ”。 3.13 stats realm stats realm realm ，“ frontend ”。 haproxy  realm ，， 。“ stats auth ”。 realm ： HTTP ，。 “ stats realm ”，，。 “ stats enable ”。 3.14 stats scope stats scope { name | . } ，“ frontend ”。，， 。，。，， 。 name ：“ listen ”、“ frontend ”“ backend ”，“ . ” stats scope 。 “ stats scope ”，，。。 backend private_monitoring stats enable stats uri / haproxyadmin ? stats stats refresh 10 s 3.15 stats auth stats auth user : passwd ，“ frontend ”。 user ：； passwd ：，； ，，。“ stats realm ” 。，“ 401 Forbidden ”。 HTTP Basic ， ，，。 “ stats auth ”，，。 3.16 stats admin stats admin { if | unless } cond ， web ，，， 。， HAProxy ，。 ， POST ，，，，。， 。，， 。 backend stats_localhost stats enable stats admin if LOCALHOST backend stats_auth stats enable stats auth haproxyadmin : password stats admin if TRUE 3.17 option httplog option httplog [ clf ]  HTTP 、。 clf ： CLF  HAProxy  HTTP ， CLF 。 ，，、，“ option httplog ”，  HTTP 、、、、 cookie 、“ frontend ”、“ backend ”， 。 3.18 option logasap no option logasap option logasap no option logasap  HTTP ，“ backend ”。 ， HTTP ，，， 。“ option logasap ” complete ，，。， “ Content - Length ”。。 listen http_proxy 0.0.0.0 : 80 mode http option httplog option logasap log 172.16.100.9 local2 3.19 option forwardfor option forwardfor [ except network ] [ header name ] [ if - none ] “ X - Forwarded - For ”。 network ：，，。 name ：，，“ X - Client ”“ X - Forwarded - For ”。 web 。 if - none ：。 HAProxy ， IP  HAProxy ， ，“ X - Forwarded - For ”。 HAProxy ， IP  value 。 ， HAProxy ，，，。 ，“ option httpclose ”、“ option forceclose ”“ option http - server - close ” option 。 。 frontend www mode http option forwardfor except 127.0.0.1 3.20 errorfile errorfile code file ， haproxy ；。 code ： HTTP ； 200 、 400 、 403 、 408 、 500 、 502 、 503  504 ； file ：； ： errorfile 400 / etc / haproxy / errorpages / 400 badreq . http errorfile 403 / etc / haproxy / errorpages / 403f orbid . http errorfile 503 / etc / haproxy / errorpages / 503 sorry . http 3.21 errorloc  errorloc302 errorloc code url errorloc302 code url ， HTTP  URL ；。 code ： HTTP ； 200 、 400 、 403 、 408 、 500 、 502 、 503  504 ； url ： Location ，，；，  URI ，； ， 302 ， HTTP  URL ， GET  (  POST )  ， URL  GET 。， errorloc303  303 。 3.22 errorloc303 errorloc303 code url ， HTTP  URL ；。 code ： HTTP ； 400 、 403 、 408 、 500 、 502 、 503  504 ； url ： Location ，，；，  URI ，； ： backend webserver server 172.16.100.6 172.16.100.6 : 80 check maxconn 3000 cookie srv01 server 172.16.100.7 172.16.100.7 : 80 check maxconn 3000 cookie srv02 errorloc 403 / etc / haproxy / errorpages / sorry . htm errorloc 503 / etc / haproxy / errorpages / sorry . htm ： #--------------------------------------------------------------------- # Global settings #--------------------------------------------------------------------- global # to have these messages end up in /var/log/haproxy.log you will # need to: # # 1) configure syslog to accept network log events. This is done # by adding the -r option to the SYSLOGD_OPTIONS in # /etc/sysconfig/syslog # # 2) configure local2 events to go to the /var/log/haproxy.log # file. A line like the following can be added to # /etc/sysconfig/syslog # # local2.* /var/log/haproxy.log # log 127.0.0.1 local2 chroot / var / lib / haproxy pidfile / var / run / haproxy . pid maxconn 4000 user haproxy group haproxy daemon defaults mode http log global option httplog option dontlognull option http - server - close option forwardfor except 127.0.0.0 / 8 option redispatch retries 3 timeout http - request 10 s timeout queue 1 m timeout connect 10 s timeout client 1 m timeout server 1 m timeout http - keep - alive 10 s timeout check 10 s maxconn 30000 listen stats mode http bind 0.0.0.0 : 1080 stats enable stats hide - version stats uri / haproxyadmin ? stats stats realm Haproxy \\ Statistics stats auth admin : admin stats admin if TRUE frontend http - in bind *: 80 mode http log global option httpclose option logasap option dontlognull capture request header Host len 20 capture request header Referer len 60 default_backend servers frontend healthcheck bind : 1099 mode http option httpclose option forwardfor default_backend servers backend servers balance roundrobin server websrv1 192.168.10.11 : 80 check maxconn 2000 server websrv2 192.168.10.12 : 80 check maxconn 2000  MySQL  #--------------------------------------------------------------------- # Global settings #--------------------------------------------------------------------- global # to have these messages end up in /var/log/haproxy.log you will # need to: # # 1) configure syslog to accept network log events. This is done # by adding the -r option to the SYSLOGD_OPTIONS in # /etc/sysconfig/syslog # # 2) configure local2 events to go to the /var/log/haproxy.log # file. A line like the following can be added to # /etc/sysconfig/syslog # # local2.* /var/log/haproxy.log # log 127.0.0.1 local2 chroot / var / lib / haproxy pidfile / var / run / haproxy . pid maxconn 4000 user haproxy group haproxy daemon defaults mode tcp log global option httplog option dontlognull retries 3 timeout http - request 10 s timeout queue 1 m timeout connect 10 s timeout client 1 m timeout server 1 m timeout http - keep - alive 10 s timeout check 10 s maxconn 600 listen stats mode http bind 0.0.0.0 : 1080 stats enable stats hide - version stats uri / haproxyadmin ? stats stats realm Haproxy \\ Statistics stats auth admin : admin stats admin if TRUE frontend mysql bind *: 3306 mode tcp log global default_backend mysqlservers backend mysqlservers balance leastconn server dbsrv1 192.168.10.11 : 3306 check port 3306 intval 2 rise 1 fall 2 maxconn 300 server dbsrv2 192.168.10.12 : 3306 check port 3306 intval 2 rise 1 fall 2 maxconn 300 install http://www.haproxy.org/download/1.7/src/haproxy-1.7.10.tar.gz tar -zxf haproxy-1.7.10.tar.gz cd haproxy-1.7.10 grep '- linux' README  TARGET= make TARGET=linux2628 prefix=/usr/local/haproxy make install PREFIX=/usr/local/haproxy # /etc/security/limits.conf  * soft nofile 2097152 * hard nofile 2097152 * soft nproc 65535 * hard nproc 65535 * soft memlock 1048576 * hard memlock 1048576 /etc/sysctl.conf  fs.nr_open = 2097152 fs.file-max = 2097152 log 1 、 vim / etc / haproxy / haproxy . conf global log 127 . 0 . 0 . 1 local3 # local3   / etc / rsyslog . conf ， info  maxconn 1024 user haproxy group haproxy daemon pidfile / var / run / haproxy . pid defaults mode http log global option httplog option dontlognull option http - server - close option forwardfor except 127 . 0 . 0 . 0 / 8 retries 2 option redispatch maxconn 1024 2 、 vim / etc / rsyslog . conf ， / etc / rsyslog . d /*.conf $IncludeConfig /etc/rsyslog.d/*.conf haproxy vim /etc/rsyslog.d/haproxy.conf $ModLoad imudp $UDPServerRun 514 local3.* /var/log/haproxy.log #/var/log/haproxy.log，message ~ 3、rsyslog， vim /etc/sysconfig/rsyslog SYSLOGD_OPTIONS=”-c 2 -r -m 0″ #-c 2 ， -c 5 #-r  #-m 0 。，0， haproxyrsyslog /etc/init.d/rsyslog restart /etc/init.d/haproxy restart check log  global log 127 . 0 . 0 . 1 local3 defaults mode http log - format % { + Q } o \\ % { - Q } ci \\ [ % T ]\\ % r \\ % ST \\ % B \\ % cp \\ % ms \\ % ft \\ % b \\ % s \\ \\ % Tq \\ % Tw \\ % Tc \\ % Tr \\ % Tt \\ % tsc \\ % ac \\ % fc \\ % bc \\ % sc \\ % rc \\ % sq \\ % bq \\ % hrl \\ % hsl option log - health - checks option httpclose option forwardfor  front  backend  log global   backend ， / etc / rsyslog . conf  cat / etc / logrotate . d / haproxy / var / log / haproxy . log { copytruncate daily dateext rotate 7 missingok notifempty } service 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 #!/bin/sh # # chkconfig: - 85 15 # # description: HA-Proxy is a TCP/HTTP reverse proxy which is particularly suited \\ # for high availability environments. # processname: haproxy # config: /usr/local/haproxy/conf/haproxy.cfg # pidfile: /var/run/haproxy.pid # # Version: 20150901 if [ -f /etc/init.d/functions ] ; then . /etc/init.d/functions elif [ -f /etc/rc.d/init.d/functions ] ; then . /etc/rc.d/init.d/functions else exit 0 fi conf = /usr/local/haproxy/conf/haproxy.cfg if [ ! -f $conf ] ; then echo -e \\033[31m config file not exist! \\033[0m exit 1 fi error = $( grep bind $conf | sort | uniq -c | awk $1!=1{print $3} ) if [ ! -z $error ] ; then echo -e \\033[31m vip is duplicate, please check: \\033[0m for vip in $error do echo -e \\033[31m \\t $vip \\033[0m done else echo -e \\033[32m \\t vip is not duplicate \\033[0m fi #BASENAME= haproxy BASENAME = ` basename $0 ` HAproxy_path_conf = /usr/local/haproxy/conf HAproxy_path_sbin = /usr/local/haproxy/sbin if [ -L $0 ] ; then BASENAME = ` find $0 -name $BASENAME -printf %1 ` BASENAME = ` basename $BASENAME ` fi [ -f $HAproxy_path_conf / $BASENAME .cfg ] || exit 1 RETVAL = 0 start () { $HAproxy_path_sbin / $BASENAME -c -q -f $HAproxy_path_conf / $BASENAME .cfg if [ $? -ne 0 ] ; then echo Errors found in configuration file, check it with $BASENAME check return 1 fi echo -n Starting $BASENAME : daemon $HAproxy_path_sbin / $BASENAME -D -f $HAproxy_path_conf / $BASENAME .cfg -p /var/run/ $BASENAME .pid RETVAL = $? echo [ $RETVAL -eq 0 ] touch /var/lock/subsys/ $BASENAME return $RETVAL } stop () { echo -n Shutting down $BASENAME : killproc $BASENAME -USR1 RETVAL = $? echo [ $RETVAL -eq 0 ] rm -f /var/lock/subsys/ $BASENAME [ $RETVAL -eq 0 ] rm -f /var/run/ $BASENAME .pid return $RETVAL } restart () { $HAproxy_path_sbin / $BASENAME -c -q -f $HAproxy_path_conf / $BASENAME .cfg if [ $? -ne 0 ] ; then echo Errors found in configuration file, check it with $BASENAME check return 1 fi stop sleep 1 start } reload () { $HAproxy_path_sbin / $BASENAME -c -q -f $HAproxy_path_conf / $BASENAME .cfg if [ $? -ne 0 ] ; then echo Errors found in configuration file, check it with $BASENAME check . return 1 fi $HAproxy_path_sbin / $BASENAME -D -f $HAproxy_path_conf / $BASENAME .cfg -p /var/run/ $BASENAME .pid -sf $( cat /var/run/ $BASENAME .pid ) echo HAproxy is reloaded... } status () { p_count = $( ps -ef | grep haproxy | grep -v grep | wc -l ) if [ $p_count -ge 1 ] ; then if [ -f /var/run/ $BASENAME .pid ] ; then echo haproxy is running... else echo haproxy is stopping... fi else echo haproxy is stopping... fi } check () { $HAproxy_path_sbin / $BASENAME -c -q -V -f $HAproxy_path_conf / $BASENAME .cfg } case $1 in start ) start ;; stop ) stop ;; restart ) restart ;; status ) status ;; reload ) reload ;; check ) check ;; * ) echo $ Usage: $BASENAME {start|stop|restart|status|reload|check} exit 1 esac exit $? keepalived keepalived . conf ! Configuration File for keepalived vrrp_script chk_http_port { script /etc/keepalived/check_haproxy.sh interval 2 weight 2 } global_defs { notification_email { test } router_id test_haproxy } vrrp_instance VI_1 { state BACKUP interface eth1 virtual_router_id 27 priority 100 nopreempt advert_int 1 garp_master_delay 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 10 . 141 . 10 . 111 dev eth1 scope global # test VIP } track_script { chk_http_port } } cat check_haproxy . sh # !/ bin / bash SendMailProgram =/ usr / local / bin / sendEmail A = ` ps - C haproxy -- no - header | wc - l ` if [ $A - eq 0 ] ;then # / usr / local / haproxy / sbin / haproxy - f / usr / local / haproxy / conf / haproxy . cfg / etc / init . d / haproxy restart sleep 2 if [ ` ps - C haproxy -- no - header | wc - l ` - eq 0 ] ;then / etc / init . d / keepalived restart / usr / local / bin / sendEmail - f ${ MailFrom [@]} - t ${ MailTo [@]} - s $ MailServer - u ERROR: [$(hostname)] keepalived haproxy switch - xu $ MailUser - xp $ MailPass - m [$(hostname)] keepalived haproxy switch. Please check!!!!! fi fi","title":"haproxy"},{"location":"haproxy/#haproxy","text":"、 HAProxy  HAProxy 、 TCP  HTTP ，，、。 HAProxy  web ，。 HAProxy ， 。，  web  。 HAProxy 、，。 、 ，。 ( User - Space ) ， 。，，。  CPU  ( Cycle ) 。 ———— HAProxy 、 TCP  HTTP 、，  7  web 。 HAProxy ： 1.4 ——： 1.2 ，，。  ( client - side keep - alive ) TCP  ( TCP speedups )  ( response buffering ) RDP   ( source - based stickiness )  ( a much better stats interfaces )  ( more verbose health checks )  ( traffic - based health )  HTTP   ( server management from the CLI )  ACL  ( ACL - based persistence )  1.3 ——： 1.2 ，。  ( content switching ) ：； ACL ：；  ( load - balancing algorithms ) ：；  ( content inspection ) ：；  ( transparent proxy ) ： Linux  IP ；  TCP  ( kernel TCP splicing ) ： copy  G ；  ( layered design ) ：、 TCP 、 HTTP 、； 、 ( fast and fair scheduler ) ： QoS ；  ( session rate limiting ) ：；  OS ： x86 、 x86_64 、 Alpha 、 SPARC 、 MIPS  PARISC  Linux 2.4 ； x86 、 x86_64 、 ARM ( ixp425 )  PPC64  Linux2 .6 ； UltraSPARC 2  3  Sloaris 8 / 9 ； Opteron  UltraSPARC  Solaris 10 ； x86  FreeBSD 4.1 - 8 ； i386 , amd64 , macppc , alpha , sparc64  VAX  OpenBSD 3.1 - current ； ， Linux 2.6  epoll  Linux 2.4  haproxy 1.2.5 。 haproxy 1.1 l  polling  select () ，。 1.2  1.3  poll () ， ， Solaris 。 HAProxy 1.3  Linux 2.6  epoll  Linux 2.4  epoll ，  FreeBSD  kqueue ，。  Linux 2.6 ( = 2.6.27.19 ) ， HAProxy  splice () ， 10 Gbps 。 ， x86  x86_64 ，，。 Linux 2.6.32  HAProxy 1.4 ；  epoll  Linux 2.4  HAProxy 1.4 ； FreeBSD  HAProxy 1.4 ； Solaris 10  HAProxy 1.4 ；  HAProxy  OS 。 、。 O ( 1 )  ( event checker ) 。 ， ( single buffering ) ， CPU ；  Linux 2.6 ( = 2.6.27.19 )  splice () ， HAProxy  ( Zero - copy forwarding ) ，  Linux 3.5  OS  ( zero - starting ) ； MRU ，； ：， O ( log ( N )) 、 ；  HTTP ： HTTP ； ，，、；  CPU ，， 5 %  95 % ， HAProxy  20 。， OS  。， CPU  10 % ， 7 。， HAProxy  7 。 ， 7  HAProxy 。“” ， ( request across multiple packets ) ，，。 ， TCP ，，。 ：    、 HAProxy 2.1  HAProxy  3 ： ——， ——“ global ”，； —— proxy ，“ defaults ”、“ listen ”、“ frontend ”“ backend ”； 2.2  ，。，。 us :  ( microseconds ) ， 1 / 1000000 ； ms :  ( milliseconds ) ， 1 / 1000 ； s :  ( seconds ) ； m :  ( minutes ) ； h ： ( hours ) ； d :  ( days ) ； 2.3   80  HTTP proxy ， 127.0.0.1 : 8000  server 。 global daemon maxconn 25600 defaults mode http timeout connect 5000 ms timeout client 50000 ms timeout server 50000 ms frontend http - in bind *: 80 default_backend servers backend servers server server1 127.0.0.1 : 8080 maxconn 32 2.4  “ global ”， OS 。 *  - chroot jail dir ： haproxy  chroot () ， haproxy ， ； - daemon ： haproxy ，“ - D ”，，“ - db ”； - gid number ： GID  haproxy ， haproxy  GID ，； - group group name ： gid ，； - log address facility [ max level [ min level ]] ： syslog ，； - log - send - hostname [ string ] ： syslog ，“ string ”，； - nbproc number ： haproxy ， haproxy ；，， ； - pidfile ： - uid ： UID  haproxy ； - ulimit - n ：，，； - user ： uid ，； - stats ： - node ：， HA  haproxy  IP ； - description ：； *  - maxconn number ： haproxy ，“ - n ”；“ ulimit - n ” ； - maxpipes number ： haproxy  pipe  tcp ， pipe ； pipe  ，，“ ulimit - n ”； maxconn / 4 ，； - noepoll ： Linux  epoll ； - nokqueue ： BSE  kqueue ； - nopoll ： poll ； - nosepoll ： Linux  epoll ； - nosplice ： Linux  tcp ， recv / send ；， Linux 2.6.25 - 28 ， tcp  bug ； - spread - checks 0..50 , in percent ： haproxy ， ；； - tune . bufsize number ： buffer ，， haproxy ，  cookie ； 16384 ，，； - tune . chksize number ：，；， ；； - tune . maxaccept number ： haproxy ，，  100 ， 8 ， - 1 ；； - tune . maxpollevents number ：， OS ； 200 ， ， 200 ，； - tune . maxrewrite number ：， 1024 ；， haproxy ； - tune . rcvbuf . client number ： - tune . rcvbuf . server number ：，；； - tune . sndbuf . client ： - tune . sndbuf . server ： * Debug  - debug - quiet 2.5  。 - defaults name - frontend name - backend name - listen name “ defaults ”，“ defaults ”。 “ frontend ”，。 “ backend ”“”，。 “ listen ”“”“”， TCP 。 、、、 - (  ) 、 _ (  ) 、 .(  )  : (  ) 。， ACL 。 、 3.1 balance balance algorithm [ arguments ] balance url_param param [ check_post [ max_wait ]] ，“ defaults ”、“ listen ”“ backend ”。 algorithm  server ， 。： roundrobin ：，，、。， ，，， 4128 ； static - rr ：， roundrobin ，，；， ； leastconn ：；， LDAP 、 SQL ， ， HTTP ；，； source ： hash ，； IP  ；，，， ； cookie  TCP ；， hash - type ； uri ： URI  ( “” )  URI  hash ，；  URI ，； ；， HTTP ；， hash - type ； url_param ： argument  URL  HTTP GET ；“ = ” ， hash ；  ID ，；， ；， hash - type ； hdr ( name ) ： HTTP ， name  HTTP ；， ；“ use_domain_only ”， Host  (  www . magedu . com ， magedu  hash  )  hash ；， hash - type ； rdp - cookie rdp - cookie ( name ) ： 3.2 bind bind [ address ] : port_range [, ...] bind [ address ] : port_range [, ...] interface interface  frontend  listen ，。 address ：，、 IPv4 、 IPv6  * ；、 *  0.0.0.0 ， IPv4 ； port_range ： TCP ， (  5005 - 5010 ) ，；，  address : port ， 1024 ， uid  ； interface ：， Linux ；，， ； 3.3 mode mode { tcp | http | health } 。， (  HTTP  ) ，。 tcp ： TCP ，， 7 ；， SSL 、 SSH 、 SMTP ； http ： HTTP ，， RFC ； health ： health ，“ OK ”，； ；，， tcp  http  monitor ； 3.4 hash - type hash - type method  hash ； frontend ； map - based  consistent ， map - based 。 map - based ： hash 。 hash ，，， ，。，，， ，，，。 consistent ： hash ； hash  hash ，。 ，，。，，，  cache 。，，，， 。 3.5 log log global log address facility [ level [ minlevel ]] ，。 log ，，“ log global ” global   log ， log 。 global ： global ，；“ log global ”，； address ：， IPv4_address : PORT ， port  UDP ， 514 ； Unix  ， chroot ； facility ： syslog  facility ； level ：，，；，； 3.6 maxconn maxconn conns ，， backend 。， haproxy ， 。，“ global ”。，， haproxy ，  8 KB ，， 17 KB  RAM 。， 1 GB  RAM  40000 - 50000  。  conns ，，，；， 。 2000 。 3.7 default_backend default_backend backend  use_backend ，， backend 。 frontend  backend  ， use-backend ；。 backend ：； ： use_backend dynamic if url_dyn use_backend static if url_css url_img extension_img default_backend dynamic 3.8 server server name address [ : port ] [ param * ]  server ，， defaults  frontend 。 name ：，； http-send-server-name ， ； address ： IPv4 ，， IPv4 ； [ : port ] ：，；，； [ param * ] ：；，，； ： backup ：， server  server ； check ： server ，，： inter delay ：，， 2000 ； fastinter  downinter  ； rise count ：， server ； fall count ： server ； cookie value ： server  cookie ，， server ， ； maxconn maxconn ：；，， ； maxqueue maxqueue ：； observe mode ：，，“ layer4 ”“ layer7 ”，“ layer7 ” http  ； redir prefix ：， GET  HEAD  302 ；， prefix  / ， ，；： server srv1 172.16.100.6 : 80 redir http : //imageserver.magedu.com check weight weight ：， 1 ， 256 ， 0 ； ： option httpchk option httpchk uri option httpchk method uri option httpchk method uri version ： frontend ，： backend https_relay mode tcp option httpchk OPTIONS * HTTP / 1.1 \\ r \\ nHost : \\ www . magedu . com server apache1 192.168.1.1 : 443 check port 80 ： server first 172.16.100.7 : 1080 cookie first check inter 1000 server second 172.16.100.8 : 1080 cookie second check inter 1000 3.9 capture request header capture request header name len length ，“ frontend ”“ listen ”。 {} 。 ，，“ | ”。， “ Host ”、“ Content - length ”、“ User - agent ”， “ X - Forward - For ”。 name ：，，，。， ，。 length ：，。 ， 64 。 frontend ， frontend 。 3.10 capture response header capture response header name len length ，。 3.11 stats enable ，“ frontend ”。，： - stats uri : / haproxy ? stats - stats realm : HAProxy Statistics - stats auth : no authentication - stats scope : no restriction “ stats enable ”，，。。 backend public_www server websrv1 172.16.100.11 : 80 stats enable stats hide - version stats scope . stats uri / haproxyadmin ? stats stats realm Haproxy \\ Statistics stats auth statsadmin : password stats auth statsmaster : password 3.12 stats hide - version stats hide - version  HAProxy ，“ frontend ”。，， HAProxy ，，  HAProxy ，。“ stats hide - version ” ，，。“ stats enable ”。 3.13 stats realm stats realm realm ，“ frontend ”。 haproxy  realm ，， 。“ stats auth ”。 realm ： HTTP ，。 “ stats realm ”，，。 “ stats enable ”。 3.14 stats scope stats scope { name | . } ，“ frontend ”。，， 。，。，， 。 name ：“ listen ”、“ frontend ”“ backend ”，“ . ” stats scope 。 “ stats scope ”，，。。 backend private_monitoring stats enable stats uri / haproxyadmin ? stats stats refresh 10 s 3.15 stats auth stats auth user : passwd ，“ frontend ”。 user ：； passwd ：，； ，，。“ stats realm ” 。，“ 401 Forbidden ”。 HTTP Basic ， ，，。 “ stats auth ”，，。 3.16 stats admin stats admin { if | unless } cond ， web ，，， 。， HAProxy ，。 ， POST ，，，，。， 。，， 。 backend stats_localhost stats enable stats admin if LOCALHOST backend stats_auth stats enable stats auth haproxyadmin : password stats admin if TRUE 3.17 option httplog option httplog [ clf ]  HTTP 、。 clf ： CLF  HAProxy  HTTP ， CLF 。 ，，、，“ option httplog ”，  HTTP 、、、、 cookie 、“ frontend ”、“ backend ”， 。 3.18 option logasap no option logasap option logasap no option logasap  HTTP ，“ backend ”。 ， HTTP ，，， 。“ option logasap ” complete ，，。， “ Content - Length ”。。 listen http_proxy 0.0.0.0 : 80 mode http option httplog option logasap log 172.16.100.9 local2 3.19 option forwardfor option forwardfor [ except network ] [ header name ] [ if - none ] “ X - Forwarded - For ”。 network ：，，。 name ：，，“ X - Client ”“ X - Forwarded - For ”。 web 。 if - none ：。 HAProxy ， IP  HAProxy ， ，“ X - Forwarded - For ”。 HAProxy ， IP  value 。 ， HAProxy ，，，。 ，“ option httpclose ”、“ option forceclose ”“ option http - server - close ” option 。 。 frontend www mode http option forwardfor except 127.0.0.1 3.20 errorfile errorfile code file ， haproxy ；。 code ： HTTP ； 200 、 400 、 403 、 408 、 500 、 502 、 503  504 ； file ：； ： errorfile 400 / etc / haproxy / errorpages / 400 badreq . http errorfile 403 / etc / haproxy / errorpages / 403f orbid . http errorfile 503 / etc / haproxy / errorpages / 503 sorry . http 3.21 errorloc  errorloc302 errorloc code url errorloc302 code url ， HTTP  URL ；。 code ： HTTP ； 200 、 400 、 403 、 408 、 500 、 502 、 503  504 ； url ： Location ，，；，  URI ，； ， 302 ， HTTP  URL ， GET  (  POST )  ， URL  GET 。， errorloc303  303 。 3.22 errorloc303 errorloc303 code url ， HTTP  URL ；。 code ： HTTP ； 400 、 403 、 408 、 500 、 502 、 503  504 ； url ： Location ，，；，  URI ，； ： backend webserver server 172.16.100.6 172.16.100.6 : 80 check maxconn 3000 cookie srv01 server 172.16.100.7 172.16.100.7 : 80 check maxconn 3000 cookie srv02 errorloc 403 / etc / haproxy / errorpages / sorry . htm errorloc 503 / etc / haproxy / errorpages / sorry . htm ： #--------------------------------------------------------------------- # Global settings #--------------------------------------------------------------------- global # to have these messages end up in /var/log/haproxy.log you will # need to: # # 1) configure syslog to accept network log events. This is done # by adding the -r option to the SYSLOGD_OPTIONS in # /etc/sysconfig/syslog # # 2) configure local2 events to go to the /var/log/haproxy.log # file. A line like the following can be added to # /etc/sysconfig/syslog # # local2.* /var/log/haproxy.log # log 127.0.0.1 local2 chroot / var / lib / haproxy pidfile / var / run / haproxy . pid maxconn 4000 user haproxy group haproxy daemon defaults mode http log global option httplog option dontlognull option http - server - close option forwardfor except 127.0.0.0 / 8 option redispatch retries 3 timeout http - request 10 s timeout queue 1 m timeout connect 10 s timeout client 1 m timeout server 1 m timeout http - keep - alive 10 s timeout check 10 s maxconn 30000 listen stats mode http bind 0.0.0.0 : 1080 stats enable stats hide - version stats uri / haproxyadmin ? stats stats realm Haproxy \\ Statistics stats auth admin : admin stats admin if TRUE frontend http - in bind *: 80 mode http log global option httpclose option logasap option dontlognull capture request header Host len 20 capture request header Referer len 60 default_backend servers frontend healthcheck bind : 1099 mode http option httpclose option forwardfor default_backend servers backend servers balance roundrobin server websrv1 192.168.10.11 : 80 check maxconn 2000 server websrv2 192.168.10.12 : 80 check maxconn 2000  MySQL  #--------------------------------------------------------------------- # Global settings #--------------------------------------------------------------------- global # to have these messages end up in /var/log/haproxy.log you will # need to: # # 1) configure syslog to accept network log events. This is done # by adding the -r option to the SYSLOGD_OPTIONS in # /etc/sysconfig/syslog # # 2) configure local2 events to go to the /var/log/haproxy.log # file. A line like the following can be added to # /etc/sysconfig/syslog # # local2.* /var/log/haproxy.log # log 127.0.0.1 local2 chroot / var / lib / haproxy pidfile / var / run / haproxy . pid maxconn 4000 user haproxy group haproxy daemon defaults mode tcp log global option httplog option dontlognull retries 3 timeout http - request 10 s timeout queue 1 m timeout connect 10 s timeout client 1 m timeout server 1 m timeout http - keep - alive 10 s timeout check 10 s maxconn 600 listen stats mode http bind 0.0.0.0 : 1080 stats enable stats hide - version stats uri / haproxyadmin ? stats stats realm Haproxy \\ Statistics stats auth admin : admin stats admin if TRUE frontend mysql bind *: 3306 mode tcp log global default_backend mysqlservers backend mysqlservers balance leastconn server dbsrv1 192.168.10.11 : 3306 check port 3306 intval 2 rise 1 fall 2 maxconn 300 server dbsrv2 192.168.10.12 : 3306 check port 3306 intval 2 rise 1 fall 2 maxconn 300","title":"haproxy"},{"location":"haproxy/#install","text":"http://www.haproxy.org/download/1.7/src/haproxy-1.7.10.tar.gz tar -zxf haproxy-1.7.10.tar.gz cd haproxy-1.7.10 grep '- linux' README  TARGET= make TARGET=linux2628 prefix=/usr/local/haproxy make install PREFIX=/usr/local/haproxy # /etc/security/limits.conf  * soft nofile 2097152 * hard nofile 2097152 * soft nproc 65535 * hard nproc 65535 * soft memlock 1048576 * hard memlock 1048576 /etc/sysctl.conf  fs.nr_open = 2097152 fs.file-max = 2097152","title":"install"},{"location":"haproxy/#log","text":"1 、 vim / etc / haproxy / haproxy . conf global log 127 . 0 . 0 . 1 local3 # local3   / etc / rsyslog . conf ， info  maxconn 1024 user haproxy group haproxy daemon pidfile / var / run / haproxy . pid defaults mode http log global option httplog option dontlognull option http - server - close option forwardfor except 127 . 0 . 0 . 0 / 8 retries 2 option redispatch maxconn 1024 2 、 vim / etc / rsyslog . conf ， / etc / rsyslog . d /*.conf $IncludeConfig /etc/rsyslog.d/*.conf haproxy vim /etc/rsyslog.d/haproxy.conf $ModLoad imudp $UDPServerRun 514 local3.* /var/log/haproxy.log #/var/log/haproxy.log，message ~ 3、rsyslog， vim /etc/sysconfig/rsyslog SYSLOGD_OPTIONS=”-c 2 -r -m 0″ #-c 2 ， -c 5 #-r  #-m 0 。，0， haproxyrsyslog /etc/init.d/rsyslog restart /etc/init.d/haproxy restart","title":"log"},{"location":"haproxy/#check-log","text":" global log 127 . 0 . 0 . 1 local3 defaults mode http log - format % { + Q } o \\ % { - Q } ci \\ [ % T ]\\ % r \\ % ST \\ % B \\ % cp \\ % ms \\ % ft \\ % b \\ % s \\ \\ % Tq \\ % Tw \\ % Tc \\ % Tr \\ % Tt \\ % tsc \\ % ac \\ % fc \\ % bc \\ % sc \\ % rc \\ % sq \\ % bq \\ % hrl \\ % hsl option log - health - checks option httpclose option forwardfor  front  backend  log global   backend ， / etc / rsyslog . conf  cat / etc / logrotate . d / haproxy / var / log / haproxy . log { copytruncate daily dateext rotate 7 missingok notifempty }","title":"check log"},{"location":"haproxy/#service","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 #!/bin/sh # # chkconfig: - 85 15 # # description: HA-Proxy is a TCP/HTTP reverse proxy which is particularly suited \\ # for high availability environments. # processname: haproxy # config: /usr/local/haproxy/conf/haproxy.cfg # pidfile: /var/run/haproxy.pid # # Version: 20150901 if [ -f /etc/init.d/functions ] ; then . /etc/init.d/functions elif [ -f /etc/rc.d/init.d/functions ] ; then . /etc/rc.d/init.d/functions else exit 0 fi conf = /usr/local/haproxy/conf/haproxy.cfg if [ ! -f $conf ] ; then echo -e \\033[31m config file not exist! \\033[0m exit 1 fi error = $( grep bind $conf | sort | uniq -c | awk $1!=1{print $3} ) if [ ! -z $error ] ; then echo -e \\033[31m vip is duplicate, please check: \\033[0m for vip in $error do echo -e \\033[31m \\t $vip \\033[0m done else echo -e \\033[32m \\t vip is not duplicate \\033[0m fi #BASENAME= haproxy BASENAME = ` basename $0 ` HAproxy_path_conf = /usr/local/haproxy/conf HAproxy_path_sbin = /usr/local/haproxy/sbin if [ -L $0 ] ; then BASENAME = ` find $0 -name $BASENAME -printf %1 ` BASENAME = ` basename $BASENAME ` fi [ -f $HAproxy_path_conf / $BASENAME .cfg ] || exit 1 RETVAL = 0 start () { $HAproxy_path_sbin / $BASENAME -c -q -f $HAproxy_path_conf / $BASENAME .cfg if [ $? -ne 0 ] ; then echo Errors found in configuration file, check it with $BASENAME check return 1 fi echo -n Starting $BASENAME : daemon $HAproxy_path_sbin / $BASENAME -D -f $HAproxy_path_conf / $BASENAME .cfg -p /var/run/ $BASENAME .pid RETVAL = $? echo [ $RETVAL -eq 0 ] touch /var/lock/subsys/ $BASENAME return $RETVAL } stop () { echo -n Shutting down $BASENAME : killproc $BASENAME -USR1 RETVAL = $? echo [ $RETVAL -eq 0 ] rm -f /var/lock/subsys/ $BASENAME [ $RETVAL -eq 0 ] rm -f /var/run/ $BASENAME .pid return $RETVAL } restart () { $HAproxy_path_sbin / $BASENAME -c -q -f $HAproxy_path_conf / $BASENAME .cfg if [ $? -ne 0 ] ; then echo Errors found in configuration file, check it with $BASENAME check return 1 fi stop sleep 1 start } reload () { $HAproxy_path_sbin / $BASENAME -c -q -f $HAproxy_path_conf / $BASENAME .cfg if [ $? -ne 0 ] ; then echo Errors found in configuration file, check it with $BASENAME check . return 1 fi $HAproxy_path_sbin / $BASENAME -D -f $HAproxy_path_conf / $BASENAME .cfg -p /var/run/ $BASENAME .pid -sf $( cat /var/run/ $BASENAME .pid ) echo HAproxy is reloaded... } status () { p_count = $( ps -ef | grep haproxy | grep -v grep | wc -l ) if [ $p_count -ge 1 ] ; then if [ -f /var/run/ $BASENAME .pid ] ; then echo haproxy is running... else echo haproxy is stopping... fi else echo haproxy is stopping... fi } check () { $HAproxy_path_sbin / $BASENAME -c -q -V -f $HAproxy_path_conf / $BASENAME .cfg } case $1 in start ) start ;; stop ) stop ;; restart ) restart ;; status ) status ;; reload ) reload ;; check ) check ;; * ) echo $ Usage: $BASENAME {start|stop|restart|status|reload|check} exit 1 esac exit $?","title":"service"},{"location":"haproxy/#keepalived","text":"keepalived . conf ! Configuration File for keepalived vrrp_script chk_http_port { script /etc/keepalived/check_haproxy.sh interval 2 weight 2 } global_defs { notification_email { test } router_id test_haproxy } vrrp_instance VI_1 { state BACKUP interface eth1 virtual_router_id 27 priority 100 nopreempt advert_int 1 garp_master_delay 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 10 . 141 . 10 . 111 dev eth1 scope global # test VIP } track_script { chk_http_port } } cat check_haproxy . sh # !/ bin / bash SendMailProgram =/ usr / local / bin / sendEmail A = ` ps - C haproxy -- no - header | wc - l ` if [ $A - eq 0 ] ;then # / usr / local / haproxy / sbin / haproxy - f / usr / local / haproxy / conf / haproxy . cfg / etc / init . d / haproxy restart sleep 2 if [ ` ps - C haproxy -- no - header | wc - l ` - eq 0 ] ;then / etc / init . d / keepalived restart / usr / local / bin / sendEmail - f ${ MailFrom [@]} - t ${ MailTo [@]} - s $ MailServer - u ERROR: [$(hostname)] keepalived haproxy switch - xu $ MailUser - xp $ MailPass - m [$(hostname)] keepalived haproxy switch. Please check!!!!! fi fi","title":"keepalived"},{"location":"linux-base/","text":"glibc-2.14 http : // ftp . gnu . org / gnu / glibc / glibc - 2 . 14 . tar . gz tar - xzf glibc - 2 . 14 . tar . gz mkdir build //  glibc - 2 . 14  build  cd build //  build  .. / configure --prefix=/opt/glibc-2.14 // glibcglibc-2.14 make make install //  glibc - 2 . 14  cp / etc / ld . so . conf / usr / local / glibc - 2 . 14 / etc / （ ld . so . conf not found ）  export LD_LIBRARY_PATH =/ usr / local / glibc - 2 . 14 / lib / : $ LD_LIBRARY_PATH （） rm - rf / lib64 / libc . so . 6 //  libc . so . 6  ln - s / opt / glibc - 2 . 14 / lib / libc - 2 . 14 . so / lib64 / libc . so . 6 phantomjs yum - y install bitmap - fonts bitmap - fonts - cjk mkfontscale fontconfig cjkuni - fonts *  http : // phantomjs . org / wget https : // bitbucket . org / ariya / phantomjs / downloads / phantomjs - 2 . 1 . 1 - linux - x86_64 . tar . bz2 rander . js ： var page = require ( webpage ) . create () , system = require ( system ) , address , output , size ; if ( system . args . length 3 || system . args . length 5 ) { console . log ( Usage: rasterize.js URL filename ) ; phantom . exit ( 1 ) ; } else { address = system . args [ 1 ] ; output = system . args [ 2 ] ; page . viewportSize = { width : 1280 , height : 1580 } ;  page . open ( address , function ( status ) { //  var bb = page . evaluate ( function () { return document . getElementsByTagName ( html ) [ 0 ]. getBoundingClientRect () ; } ) ; // ， page . clipRect = { top : bb . top , left : bb . left , width : bb . width , height : bb . height } ; //  window . setTimeout ( function () { page . render ( output ) ; page . close () ; console . log ( render ok ) ; phantom . exit () ; }, 1000 ) ; } ) ; }  ： / usr / local / src / phantomjs - 2 . 1 . 1 - linux - x86_64 / bin / phantomjs rander . js http : // 192 . 168 . 1 . 5 : 9380 / DaChuibus / manage / statistics / allstatistics / quanjutongji . do 1 . png doxygen yum install doxygen graphviz  cd cuishouv1 / doxygen - g  doxygen - s - g   Doxyfile PROJECT_NAME = cuishou  PROJECT_NUMBER = 1.0.0  OUTPUT_DIRECTORY = doc /  INPUT = src / java ， FILE_PATTERNS = * . java  INPUT  RECURSIVE = YES  INPUT  INCLUDE_FILE_PATTERNS = * . java  GENERATE_LATEX = NO  LaTeX  HAVE_DOT = YES  dot   doxygen Doxyfile dell omsa dell  http : // en . community . dell . com / techcenter / systems - management / w / wiki / 1760 . openma nage - server - administrator - omsa # Download_OMSA http : // www . dell . com / support / home / us / en / 19 / Drivers / DriversDetails ? driverId = K37MM  mv OM - SrvAdmin - Dell - Web - LX - 8 . 5 . 0 - 2372 . RHEL6 . x86_64_A00 . tar . gz omsa / tar - zxf OM - SrvAdmin - Dell - Web - LX - 8 . 5 . 0 - 2372 . RHEL6 . x86_64_A00 . tar . gz vim linux / supportscripts / srvadmin - install . sh centos ， rhel  grep - c Santiago / etc / redhat - release  grep - c CentOS / etc / redhat - release ： yum install - y libcmpi CppImpl0 openwsman - server sblim - sfcb sblim - sfcc libwsman1 net - snmp - utils openwsman - client libcmpiCppImpl0 . / setup . sh   https : // ip : 1311  root  iptables - I INPUT - p tcp - s 192 . 168 . 1 . 0 / 24 --dport 1311 -j ACCEPT boot  / boot /  boot  / boot / grub / grub . conf  root  uuid ,   uuid  blkid  / etc / fstab  uuid ， uuid  / boot / grub / menu . lst ，， menu . lst - . / grub . conf yum install kernel （） grub - install / dev / sda （ boot ，） http head Requests  Header   Accept  Accept : text / plain , text / html Accept - Charset 。 Accept - Charset : iso - 8859 - 5 Accept - Encoding  web 。 Accept - Encoding : compress , gzip Accept - Language  Accept - Language : en , zh Accept - Ranges  Accept - Ranges : bytes Authorization HTTP  Authorization : Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ == Cache - Control  Cache - Control : no - cache Connection 。（ HTTP 1 . 1 ） Connection : close Cookie HTTP ， cookie  web 。 Cookie : $ Version = 1 ; Skin=new; Content - Length  Content - Length : 348 Content - Type  MIME  Content - Type : application / x - www - form - urlencoded Date  Date : Tue , 15 Nov 2010 08 : 12 : 31 GMT Expect  Expect : 100 - continue From  Email From : user @ email . com Host  Host : www . zcmhi . com If - Match  If - Match : “ 737060 cd8c284d8af7ad3082f209582d ” If - Modified - Since ， 304  If - None - Match  304 ， Etag ， Etag  If - Range ，，。 Etag If - Unmodified - Since  If - Unmodified - Since : Sat , 29 Oct 2010 19 : 43 : 31 GMT Max - Forwards  Max - Forwards : 10 Pragma  Pragma : no - cache Proxy - Authorization  Proxy - Authorization : Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ == Range ， Range : bytes = 500 - 999 Referer ，, Referer : http : // www . zcmhi . com / archives / 71 . html TE ， TE : trailers , deflate ;q=0.5 Upgrade （） Upgrade : HTTP / 2 . 0 , SHTTP / 1 . 3 , IRC / 6 . 9 , RTA / x11 User - Agent User - Agent  User - Agent : Mozilla / 5 . 0 ( Linux ; X11) Via ， Via : 1 . 0 fred , 1 . 1 nowhere . com ( Apache / 1 . 1 ) Warning  Warn : 199 Miscellaneous warning Responses  Header   Accept - Ranges  Accept - Ranges : bytes Age （，） Age : 12 Allow ， 405 Allow : GET , HEAD Cache - Control  Cache - Control : no - cache Content - Encoding web 。 Content - Encoding : gzip Content - Language  Content - Language : en , zh Content - Length  Content - Length : 348 Content - Location  Content - Location : / index . htm Content - MD5  MD5  Content - MD5 : Q2hlY2sgSW50ZWdyaXR5IQ == Content - Range  Content - Range : bytes 21010 - 47021 / 47022 Content - Type  MIME  Content - Type : text / html ; charset=utf-8 Date  Date : Tue , 15 Nov 2010 08 : 12 : 31 GMT ETag  ETag : “ 737060 cd8c284d8af7ad3082f209582d ” Expires  Expires : Thu , 01 Dec 2010 16 : 00 : 00 GMT Last - Modified  Last - Modified : Tue , 15 Nov 2010 12 : 45 : 26 GMT Location  URL  Location : http : // www . zcmhi . com / archives / 94 . html Pragma ， Pragma : no - cache Proxy - Authenticate  URL  Proxy - Authenticate : Basic refresh ， 5 （，） Refresh : 5 ; url= http : // www . zcmhi . com / archives / 94 . html Retry - After ， Retry - After : 120 Server web  Server : Apache / 1 . 3 . 27 ( Unix ) ( Red - Hat / Linux ) Set - Cookie  Http Cookie Set - Cookie : UserID = JohnDoe ; Max-Age=3600; Version=1 Trailer  Trailer : Max - Forwards Transfer - Encoding  Transfer - Encoding : chunked Vary  Vary : * Via  Via : 1 . 0 fred , 1 . 1 nowhere . com ( Apache / 1 . 1 ) Warning  Warning : 199 Miscellaneous warning WWW - Authenticate  WWW - Authenticate : Basic  1 、 vim / etc / bashrc export HISTORY_FILE =/ var / log / `whoami` _ `date +%y-%m-%d ` . log readonly PROMPT_COMMAND = { date +%y-%m-%d %T ### $(who am i |awk {print $1 $2 $5} ) ### $(history 1 | { read x cmd; echo $cmd ; }) ; } $HISTORY_FILE  export HISTORY_FILE =/ var / log / `whoami` _ `date +%y-%m-%d ` . log readonly PROMPT_COMMAND = { msg=$(history 1 | { read x y; echo $y; }); echo $(who am i):[`pwd`] $msg ; } $HISTORY_FILE 2 、 vim / etc / profile export HISTTIMEFORMAT = %F %T `whoami` 1  2   awk - F : $3==0 {print $1} / etc / passwd （） awk - F : length($2)==0 {print $1} / etc / shadow （） lsof - p pid （） top ps ， cat / etc / crontab ls / etc / cron . * cat / etc / rc . d / rc . local yum install rkhunter - y rkhunter - c  1 . MD5  ,  . 2 .  rootkits  . 3 .  . 4 .  . 5 .  -  rootkit hunter  . 6 .  . 7 .  / etc / rc . d /  ,  ,  .  ,  / dev / . udev  / etc / . pwd . lock  ,  . 8 .  .  : Apache Web Server , Procmail  .  ,  :  ,  MD5  . rkhunter  rootkit  rootkits  ,  ,   : # rkhunter --update  cron job  ,  root  crontab  : 59 23 1 * * echo “ Rkhunter update check in progress ” ; / usr / local / bin / rkhunter --update core dump  Linux  core  ： $ uname - a Linux dev 2.4.21 - 9.30 AXsmp # 1 SMP Wed May 26 23 : 37 : 09 EDT 2004 i686 i686 i386 GNU / Linux ， core file size  0 ， core 。 $ ulimit - a core file size ( blocks , - c ) 0 data seg size ( kbytes , - d ) unlimited file size ( blocks , - f ) unlimited max locked memory ( kbytes , - l ) 4 max memory size ( kbytes , - m ) unlimited open files ( - n ) 2048 pipe size ( 512 bytes , - p ) 8 stack size ( kbytes , - s ) 10240 cpu time ( seconds , - t ) unlimited max user processes ( - u ) 7168 virtual memory ( kbytes , - v ) unlimited ， core 。 $ more foo . c #include static void sub(void); int main ( void ) { sub (); return 0 ; } static void sub ( void ) { int * p = NULL ; /* derefernce a null pointer, expect core dump. */ printf ( %d , * p ); } $ gcc - Wall - g foo . c $ . / a . out Segmentation fault $ ls - l core . * ls : core . *: No such file or directory  core ， ulimit ，。 1024  $ ulimit - c 655355 $ ulimit - a core file size ( blocks , - c ) 1024 data seg size ( kbytes , - d ) unlimited file size ( blocks , - f ) unlimited max locked memory ( kbytes , - l ) 4 max memory size ( kbytes , - m ) unlimited open files ( - n ) 2048 pipe size ( 512 bytes , - p ) 8 stack size ( kbytes , - s ) 10240 cpu time ( seconds , - t ) unlimited max user processes ( - u ) 7168 virtual memory ( kbytes , - v ) unlimited $ . / a . out Segmentation fault ( core dumped ) $ ls - l core . * - rw ------- 1 uniware uniware 53248 Jun 30 17 : 10 core .9128 ， ( core dumped ) 。 core ， 9128  PID 。 GDB  core 。 $ gdb -- core = core .9128 GNU gdb Asianux ( 6.0 post - 0.20040223.17.1 AX ) Copyright 2004 Free Software Foundation , Inc . GDB is free software , covered by the GNU General Public License , and you are welcome to change it and / or distribute copies of it under certain conditions . Type show copying to see the conditions . There is absolutely no warranty for GDB . Type show warranty for details . This GDB was configured as i386-asianux-linux-gnu . Core was generated by ` . / a . out . Program terminated with signal 11 , Segmentation fault . #0 0x08048373 in ?? () ( gdb ) bt #0 0x08048373 in ?? () #1 0xbfffd8f8 in ?? () #2 0x0804839e in ?? () #3 0xb74cc6b3 in ?? () #4 0x00000000 in ?? ()  bt  backtrace ，， GDB 。： ( gdb ) file . / a . out Reading symbols from . / a . out ... done . Using host libthread_db library /lib/tls/libthread_db.so.1 . ( gdb ) bt #0 0x08048373 in sub () at foo.c:17 #1 0x08048359 in main () at foo.c:8  backtrace 。 ( gdb ) l 8 sub (); 9 return 0 ; 10 } 11 12 static void sub ( void ) 13 { 14 int * p = NULL ; 15 16 /* derefernce a null pointer, expect core dump. */ 17 printf ( %d , * p ); ( gdb ) ， core （，）。 gdb  core ， 。 1. core  --------------------------------- 1 ） ulimit - c  core 。 0 ，， core 。 2 ） ulimit - c filesize ， core （ filesize  kbyte ）。 ulimit - c unlimited ， core 。，， core 。 core ， gdb 。 2. core  ---------------------------- core  : 。  core ， core 。 core  core 。 1 ） / proc / sys / kernel / core_uses_pid  core  pid 。 1 ， pid ，  core  core . xxxx ； 0  core  core 。 ： echo 1 / proc / sys / kernel / core_uses_pid 2 ） proc / sys / kernel / core_pattern  core 。 ： echo /corefile/core-%e-%p-%t core_pattern ， core  / corefile ， core -  - pid -   : %p - insert pid into filename  pid %u - insert current uid into filename  uid %g - insert current gid into filename  gid %s - insert signal that caused the coredump into the filename  core  %t - insert UNIX time that the coredump occurred into filename  core  unix  %h - insert hostname where the coredump happened into filename  %e - insert coredumping executable name into filename  3. core  ----------------- core  gdb 。 gdb . / a . out core - file core . xxxx  bt 。 ，，。 1 ） gdb - core = core . xxxx file . / a . out bt 2 ） gdb - c core . xxxx file . / a . out bt 4.  core  -----------------------------  linux ， core 。 gdb ，（）、 core  PC  linux 。  PC  core ， gdb ， gdb  solib - absolute - prefix  solib - search - path  gdb 。， gdb ， ： gdb  . gdbinit 。 ： set solib - absolute - prefix YOUR_CROSS_COMPILE_PATH set solib - search - path YOUR_CROSS_COMPILE_PATH set solib - search - path YOUR_DEVELOPER_TOOLS_LIB_PATH handle SIG32 nostop noprint pass idrac wget - q - O - http : // linux . dell . com / repo / hardware / latest / bootstrap . cgi | bash yum - y install srvadmin - idrac7 racadm closessn - a  session racadm racreset  idrac 1 、 RHEL  iDRAC ： Dell EMC OpenManage Linux Remote Access Utilities : http : // www . dell . com / support / home / cn / zh / cndhs1 / drivers / driversdetails ? driverId = 49 T1M ， net - snmp - utils  rpm  / root / linux / rac / RHEL7 / x86_64 ， ： ：， # racadm command  iDRAC  ：， - r IP # racadm - r 192 . 168 . 1 . 1 - u User - p Password command  iDRAC  2 、 iDRAC ： http : // topics - cdn . dell . com / pdf / idrac7 - 8 - lifecycle - controller - v2 . 50 . 50 . 50 _reference - guide_en - us . pdf 3 、 iDRAC  、、 # racadm config - g cfgUserAdmin - o cfgUserAdminUserName - i 10 User01  10  User01 # racadm config - g cfgUserAdmin - o cfgUserAdminPassword - i 10 Password  # racadm set iDRAC . Users . 10 . Password NewPassword  # racadm config - g cfgUserAdmin - i 10 - o cfgUserAdminEnable 1  1 ， 0  # racadm config - g cfgUserAdmin - o cfgUserAdminUserName - i 10  # racadm config - g cfgUserAdmin - o cfgUserAdminPrivilege - i 10 4  User01  、 # racadm serveraction powerup  # racadm serveraction powerdown  # racadm serveraction powercycle  # racadm serveraction powerstatus  iDRAC  # racadm racreset soft  iDRAC # racadm racreset hard  iDRAC # racadm racreset soft - f  iDRAC # racadm racreset hard - f  iDRAC # racadm set iDRAC . IPv4 . Address x . x . x . x  IP  # racadm set iDRAC . IPv4 . Netmask x . x . x . x  # racadm set iDRAC . IPv4 . Gateway x . x . x . x   idrac ， idrac ssh ssh idrac  IP  ssh  / admin1 - racadm config ...  racadm   racadm config - g cfgLanNetworking - o cfgNicGateway 192 . 168 . 63 . 155 % Get all iDRAC settings in a file racadm get - f config . txt If you like you can change the contents of config . txt and apply it back to iDRAC racadm set - f config . txt % Set password for root user racadm set iDRAC . Users . 2 . Password PASSWORD % List all ssh keys for root user racadm sshpkauth - i 2 - v - k all % Add ssh key to root user racadm sshpkauth - i 2 - k 1 CONTENTS OF PUBLIC KEY % Delete ssh key for root user racadm sshpkauth - i 2 - d - k 1 % Get iDRAC IP config racadm getniccfg racadm get iDRAC . NIC % set iDRAC IP Using config command : racadm config - g cfgLanNetworking - o cfgNicEnable 1 racadm config - g cfgLanNetworking - o cfgNicIpAddress x . x . x . x racadm config - g cfgLanNetworking - o cfgNicNetmask 255 . 255 . 255 . 0 racadm config - g cfgLanNetworking - o cfgNicGateway x . x . x . x racadm config - g cfgLanNetworking - o cfgNicUseDHCP 0 racadm config - g cfgLanNetworking - o cfgDNSServersFromDHCP 0 racadm config - g cfgLanNetworking - o cfgDNSServer1 y . y . y . y racadm config - g cfgLanNetworking - o cfgDNSServer2 y . y . y . y • Using set command : racadm set iDRAC . Nic . Enable 1 racadm set iDRAC . IPv4 . Address x . x . x . x racadm set iDRAC . IPv4 . Netmask 255 . 255 . 255 . 0 racadm set iDRAC . IPv4 . Gateway x . x . x . x racadm set iDRAC . IPv4 . DHCPEnable 0 racadm set iDRAC . IPv4 . DNSFromDHCP 0 racadm set iDRAC . IPv4 . DNS1 y . y . y . y racadm set iDRAC . IPv4 . DNS2 y . y . y . y % Set iDRAC DNS Name racadm set iDRAC . NIC . DNSRacName iDRACNAME % Set iDRAC domain name racadm set iDRAC . NIC . DNSDomainName DOMAIN . NAME % Set iDRAC DNS Server racadm config - g cfgLanNetworking - o cfgDNSServer1 x . x . x . x racadm config - g cfgLanNetworking - o cfgDNSServer2 y . y . y . y % Set Front LCD to hostname racadm set System . LCD . Configuration 16 % Reset iDRAC to factory defaults racadm racresetcfg % Reset / Reboot iDRAC racadm racreset OPTIONS Options : soft , hard , cold or racadm serveraction powercycle % Get Serial number ( service tag ) racadm getsvctag % Get current system information racadm getsysinfo % Configure one - time - boot to PXE racadm set BIOS . OneTimeBoot . OneTimeBootMode OneTimeBootSeq racadm set BIOS . OneTimeBoot . OneTimeBootSeqDev NIC . Integrated . 1 - 1 - 1 % Configure persistent Boot Device racadm config - g cfgServerInfo - o cfgServerBootOnce 0 racadm config - g cfgServerInfo - i cfgServerFirstBootDevice HDD % Check boot order list racadm get BIOS . BiosBootSettings . bootseq % Disable HyperThreading racadm set BIOS . ProcSettings . LogicalProc Disabled % Disable OS to iDRAC pass - thru for iDRAC service module ( automatically create a pseudo NIC in OS ) racadm set iDRAC . OS - BMC . AdminState Disabled % Change SNMP public community string racadm set iDRAC . SNMP . AgentCommunity NEW STRING % Disable ASR racadm config - g cfgRacTuning - o cfgRacTuneAsrEnable 0 % Configure Serial redirection racadm config - g cfgSerial - o cfgSerialConsoleEnable 1 racadm config - g cfgSerial - o cfgSerialBaudRate 115200 racadm config - g cfgSerial - o cfgSerialCom2RedirEnable 1 racadm config - g cfgSerial - o cfgSerialTelnetEnable 0 racadm config - g cfgSerial - o cfgSerialSshEnable 1 to access console via ssh console com2 % Disable Serial On Lan racadm config - g cfgImpiSol - o cfgIpmiSolEnable 0 % Change Power Profile racadm set BIOS . SysProfileSettings PerfPerWattOptimizedOs % Set AC Power Recovery racadm set BIOS . SysSecurity . AcPwdRcvry Last racadm set BIOS . SysSecurity . AcPwdRcvryDelay Immediate % Get RAID physical Disk information racadm raid get pdisks racadm raid get pdisks - o ( all information ) racadm raid get pdisks - o - p state , size ( specific information ) % Get RAID Virtual Disk Information Racadm raid get vdisks dns  cat / etc / resolv . conf nameserver 223 . 5 . 5 . 5 options timeout : 1 attempts : 1 centos  vim / etc / grub . conf quiet  pcie_aspm = off  [ root@localhost ~ ] # dmesg | grep PCIe [ 0.000000 ] PCIe ASPM is disabled tuned systemctl stop tuned systemctl disable tuned  xorg . conf ，  ，  ，  。 vi / etc / X11 / xorg . conf  Section ServerFlags Option BlankTime 0 Option StandbyTime 0 Option SuspendTime 0 Option OffTime 0 EndSection Section Monitor Option DPMS false EndSection CentOS ！ kernel panic  / etc / sysctl . conf ， kernel panic 20  Linux ： # vi / etc / sysctl . conf kernel . panic = 20 src.rpm yum install rpm - build rpm - ivh --xxx--.src.rpm cd / usr / src / redhat / SPECS rpmbuild - bb xxx . spec cd / usr / src / redhat / RPMS / i386 / rpm - ivh xxxx . rpm ab yum install gcc apr - devel apr - util - devel pcre - devel wget https : // mirrors . aliyun . com / apache / httpd / httpd - 2 . 2 . 32 . tar . gz  http ， support / ab . c 1395  } else { 1395 // apr_err ( apr_socket_recv , status ) ; 1396 bad ++ ; 1397 close_connection ( c ) ; 1398 return ; 1399 } 1400 } . / configure -- prefix =/ usr / local / apache make make  ab ： . / support / ab （ make install ） / usr / local / apache / bin / ab - n 10000 - c 1000 http : // www . baidu . com / Server Software : web  Server Hostname :  Server Port :  Document Path :  Document Length :  Concurrency Level :  Time taken for tests :  Complete requests :  Failed requests :  Write errors :  Total transferred : ， http  HTML transferred : html ， Requests per second : ，（） Time per request : ， Time per request :  Transfer rate : （）  Failed requests ： Failed requests : 2303 ( Connect : 0 , Length : 2303 , Exceptions : 0 )  Failed requests ， Connect 、 Length 、 Exceptions 。 Connect 、、。 Length  (  Content - Length  ) 。 Exception 。 bond cat ifcfg - eth0 DEVICE = eth0 BOOTPROTO = none ONBOOT = yes TYPE = Ethernet MASTER = bond1 SLAVE = yes cat ifcfg - eth1 DEVICE = eth1 BOOTPROTO = none ONBOOT = yes TYPE = Ethernet MASTER = bond1 SLAVE = yes cat ifcfg - bond1 DEVICE = bond1 NAME = bond1 BOOTPROTO = none ONBOOT = yes IPADDR = 10 . 21 . 20 . 210 NETMASK = 255 . 255 . 255 . 0 GATEWAY = 10 . 21 . 20 . 1 TYPE = Bond BONDING_MASTER = yes BONDING_OPTS = mode=1 miimon=100  bond ： 1 、 # ls / sys / class / net bond0 bond1 bonding_masters br0 eth0 eth1 lo ： bond0  2 、 # cat bonding_masters bond0 bond1 ： ： # echo - bond0 bonding_masters ： echo  - ， +  snoopy https : // github . com / a2o / snoopy yum install gcc socat wget http : // source . a2o . si / download / snoopy / snoopy - 2.4.6 . tar . gz tar - zxf snoopy - 2.4.6 . tar . gz cd snoopy - 2.4.6 . / configure make make install make enable -- vim / usr / local / etc / snoopy . ini ( # ) [ snoopy ] message_format = %{datetime} %{hostname} %{pid} %{eusername} %{tty_username} %{tty} %{cwd} %{filename} # %{cmdline} filter_chain = exclude_spawns_of:cron output = file : / var / log / . snoopy . log -- / usr / local / sbin / snoopy - disable snoopy / usr / local / sbin / snoopy - enable snoopy  / var / log / . snoopy . log logstash grok SNOOPYLOG % { TIMESTAMP_ISO8601 : datetime } % { USERNAME : hostname } % { INT : pid } % { USER : eusername } % { USER : tty_username } % { NOTSPACE : tty } % { UNIXPATH : pwd } % { UNIXPATH : cmd_name } # % { GREEDYDATA : cmdline }  LVS  Cache ，，。 / var / log / messages  nf_conntrack : table full , dropping packet . ：  # chkconfig iptables off # chkconfig ip6tables off # service iptables stop # service ip6tables stop ， iptables （ iptables - nL ）！，。，，！  # lsmod | grep nf nf_nat 22759 0 nf_conntrack_ipv4 9506 2 nf_nat nf_conntrack 79645 2 nf_nat , nf_conntrack_ipv4 nf_defrag_ipv4 1483 1 nf_conntrack_ipv4 # rmmod nf_nat # rmmod nf_conntrack_ipv4 # rmmod nf_conntrack  centos Centos6 . 6  Centos7 . 2 ：  7.4   7. x ， 7.2  update   Centos6 . 9  7.2   ssh yum ，， ,  vi start . sh #rootstart.sh #!/bin/bash ln - s / usr / lib64 / libsasl2 . so . 3.0 . 0 / usr / lib64 / libsasl2 . so . 2 ln - s / usr / lib64 / libpcre . so . 1.2 . 0 / usr / lib64 / libpcre . so . 0 service sshd restart # chmod + x start . sh chmod + x / etc / rc . d / rc . local cp / etc / rc . d / rc . local / etc / rc . d / rc . local . bak # echo bash /root/start.sh / etc / rc . d / rc . local # step 1 ： cat / etc / yum . repos . d / upgrade . repo [ upgrade ] name = upgrade baseurl = http : // dev . centos . org / centos / 6 / upg / x86_64 / enable = 1 gpgcheck = 0 step 2 ： yum erase openscap yum install http : // dev . centos . org / centos / 6 / upg / x86_64 / Packages / openscap - 1.0 . 8 - 1.0 . 1. el6 . centos . x86_64 . rpm yum install openscap - 1.0 . 8 [ root @localhost ~ ] # yum install preupgrade-assistant-contents redhat-upgrade-tool preupgrade-assistant step 3 : [ root @localhost ~ ] # preupg step 4 ： [ root @localhost ~ ] # rpm --import http://vault.centos.org/centos/7.2.1511/os/x86_64/RPM-GPG-KEY-CentOS-7 [ root @localhost ~ ] # redhat-upgrade-tool --network 7 --instrepo http://vault.centos.org/centos/7.2.1511/os/x86_64/ ( 265 / 266 ): zlib - 1.2 . 7 - 13. el7 . x86_64 . rpm | 89 kB 00 : 00 ( 266 / 266 ): zlib - devel - 1.2 . 7 - 13. el7 . x86_64 . rpm | 49 kB 00 : 00 testing upgrade transaction rpm transaction 100 % [ =========================================== ] rpm install 100 % [ =========================================== ] setting up system for upgrade Finished . Reboot to start upgrade .  el6  rpm  web 1 、 webmin http : // www . webmin . com / rpm . html wget http : // prdownloads . sourceforge . net / webadmin / webmin - 1 . 881 - 1 . noarch . rpm yum - y install perl perl - Net - SSLeay openssl perl - IO - Tty perl - Encode - Detect rpm - U webmin - 1 . 881 - 1 . noarch . rpm https : // ip : 10000 /  2 、 redhat  https : // cockpit - project . org yum install cockpit - ws cockpit - system cockpit - bridge # cockpit - docker docker ， docker systemctl restart cockpit systemctl enable cockpit vim / etc / cockpit / cockpit . conf  [ Log ] Fatal = criticals [ WebService ] AllowUnencrypted = true UrlRoot =/ co / vim / usr / lib / systemd / system / cockpit . socket ListenStream = 127 . 0 . 0 . 1 : 9090  systemctl daemon - reload systemctl restart cockpit . socket nginx  map $ http_upgrade $c onnection_upgrade { default upgrade ; close ; } upstream websocket { server 127 . 0 . 0 . 1 : 9090 ; } server { listen 80 ; server_name cockpit . domain . tld www . cockpit . domain . tld ; return 301 https : // $ server_name $ request_uri ; } server { listen 443 ; server_name www . cockpit . domain . tld cockpit . domain . tld ; ssl on ; ssl_certificate / path / to / certificate ; ssl_certificate_key / path / to / key ; location / co / { #  cockpit . conf  uri proxy_pass http : // websocket ; proxy_http_version 1 . 1 ; proxy_buffering off ; proxy_set_header X - Real - IP $ remote_addr ; proxy_set_header Host $ host ; proxy_set_header X - Forwarded - For $ remote_addr ; # needed for websocket proxy_set_header Upgrade $ http_upgrade ; proxy_set_header Connection $c onnection_upgrade ; # change scheme of Origin to http proxy_set_header Origin http : // $ host ; # Pass ETag header from cockpit to clients . # See : https : // github . com / cockpit - project / cockpit / issues / 5239 # gzip off ; } } crontab ， crontab ，。，。： 1 . crontab   cron ，。 shelll ， 。 3 ： 1 ）； 2 ） java ， source ，： cat start_cbp . sh #!/ bin / sh source / etc / profile export RUN_CONF =/ home / d139 / conf / platform / cbp / cbp_jboss . conf / usr / local / jboss - 4 . 0 . 5 / bin / run . sh - c mev 3 ） OK ， crontab 。， crontab 。： 0 * * * * . / etc / profile ; / bin / sh / var / www / java / audit_no_count / bin / restart_audit . sh 2 .  1 ） cron job ，， 2 。 cron 。 2 ） JOB ，。，，。 JOB  ： / dev / null 2 1 。 Job  , 。 3 ） crontab ， / etc / init . d / crond restart 。 job  /  tail - f / var / log / cron 。 4 ） crontab - r 。 Crontab （ / var / spool / cron ） Crontab 。 crontab 。 5 ） crontab  % ，。 % ， date ‘ +% Y % m % d ’ crontab ，  date ‘ +% Y % m % d ’ ` 。 3 . crontab  crontab ： / dev / null 2 1 ， crontab 。 shell ‘ ’ / dev / null 　　 ，： echo 123 / home / 123 . txt 　 1  stdout ， 1 ， /dev/null  1 /dev/null 2  stderr  　 ， 2 1 ， 2  1 　 ： 1 / dev / null ，，。 2 1 ，，。 centos centos6  cat / etc / modprobe . conf alias em2 bond0 mv ifcfg - em2 ifcfg - bond0  ，  centos7 [ root@localhost ~ ] # vi / usr / lib / udev / rules . d / 60 - net . rules  # #ACTION == add , SUBSYSTEM == net , DRIVERS == ?* , ATTR { type } == 1 , PROGRAM = /lib/udev/rename_device , RESULT == ?* , NAME = $result ACTION == add , SUBSYSTEM == net , DRIVERS == ?* , ATTR { type } == 1 , ATTR { address } == d8:9e:*:10:*11 , NAME = eth0 ip link set dev eth0 name eth1  ，  service tag linux : dmidecode - s system - serial - number windows :  cmd ，： wmic ： bios get serialnumber ","title":"linux-base"},{"location":"linux-base/#glibc-214","text":"http : // ftp . gnu . org / gnu / glibc / glibc - 2 . 14 . tar . gz tar - xzf glibc - 2 . 14 . tar . gz mkdir build //  glibc - 2 . 14  build  cd build //  build  .. / configure --prefix=/opt/glibc-2.14 // glibcglibc-2.14 make make install //  glibc - 2 . 14  cp / etc / ld . so . conf / usr / local / glibc - 2 . 14 / etc / （ ld . so . conf not found ）  export LD_LIBRARY_PATH =/ usr / local / glibc - 2 . 14 / lib / : $ LD_LIBRARY_PATH （） rm - rf / lib64 / libc . so . 6 //  libc . so . 6  ln - s / opt / glibc - 2 . 14 / lib / libc - 2 . 14 . so / lib64 / libc . so . 6","title":"glibc-2.14"},{"location":"linux-base/#phantomjs","text":"yum - y install bitmap - fonts bitmap - fonts - cjk mkfontscale fontconfig cjkuni - fonts *  http : // phantomjs . org / wget https : // bitbucket . org / ariya / phantomjs / downloads / phantomjs - 2 . 1 . 1 - linux - x86_64 . tar . bz2 rander . js ： var page = require ( webpage ) . create () , system = require ( system ) , address , output , size ; if ( system . args . length 3 || system . args . length 5 ) { console . log ( Usage: rasterize.js URL filename ) ; phantom . exit ( 1 ) ; } else { address = system . args [ 1 ] ; output = system . args [ 2 ] ; page . viewportSize = { width : 1280 , height : 1580 } ;  page . open ( address , function ( status ) { //  var bb = page . evaluate ( function () { return document . getElementsByTagName ( html ) [ 0 ]. getBoundingClientRect () ; } ) ; // ， page . clipRect = { top : bb . top , left : bb . left , width : bb . width , height : bb . height } ; //  window . setTimeout ( function () { page . render ( output ) ; page . close () ; console . log ( render ok ) ; phantom . exit () ; }, 1000 ) ; } ) ; }  ： / usr / local / src / phantomjs - 2 . 1 . 1 - linux - x86_64 / bin / phantomjs rander . js http : // 192 . 168 . 1 . 5 : 9380 / DaChuibus / manage / statistics / allstatistics / quanjutongji . do 1 . png","title":"phantomjs"},{"location":"linux-base/#doxygen","text":"yum install doxygen graphviz  cd cuishouv1 / doxygen - g  doxygen - s - g   Doxyfile PROJECT_NAME = cuishou  PROJECT_NUMBER = 1.0.0  OUTPUT_DIRECTORY = doc /  INPUT = src / java ， FILE_PATTERNS = * . java  INPUT  RECURSIVE = YES  INPUT  INCLUDE_FILE_PATTERNS = * . java  GENERATE_LATEX = NO  LaTeX  HAVE_DOT = YES  dot   doxygen Doxyfile","title":"doxygen"},{"location":"linux-base/#dell-omsa","text":"dell  http : // en . community . dell . com / techcenter / systems - management / w / wiki / 1760 . openma nage - server - administrator - omsa # Download_OMSA http : // www . dell . com / support / home / us / en / 19 / Drivers / DriversDetails ? driverId = K37MM  mv OM - SrvAdmin - Dell - Web - LX - 8 . 5 . 0 - 2372 . RHEL6 . x86_64_A00 . tar . gz omsa / tar - zxf OM - SrvAdmin - Dell - Web - LX - 8 . 5 . 0 - 2372 . RHEL6 . x86_64_A00 . tar . gz vim linux / supportscripts / srvadmin - install . sh centos ， rhel  grep - c Santiago / etc / redhat - release  grep - c CentOS / etc / redhat - release ： yum install - y libcmpi CppImpl0 openwsman - server sblim - sfcb sblim - sfcc libwsman1 net - snmp - utils openwsman - client libcmpiCppImpl0 . / setup . sh   https : // ip : 1311  root  iptables - I INPUT - p tcp - s 192 . 168 . 1 . 0 / 24 --dport 1311 -j ACCEPT","title":"dell omsa"},{"location":"linux-base/#boot","text":" / boot /  boot  / boot / grub / grub . conf  root  uuid ,   uuid  blkid  / etc / fstab  uuid ， uuid  / boot / grub / menu . lst ，， menu . lst - . / grub . conf yum install kernel （） grub - install / dev / sda （ boot ，）","title":"boot"},{"location":"linux-base/#http-head","text":"Requests  Header   Accept  Accept : text / plain , text / html Accept - Charset 。 Accept - Charset : iso - 8859 - 5 Accept - Encoding  web 。 Accept - Encoding : compress , gzip Accept - Language  Accept - Language : en , zh Accept - Ranges  Accept - Ranges : bytes Authorization HTTP  Authorization : Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ == Cache - Control  Cache - Control : no - cache Connection 。（ HTTP 1 . 1 ） Connection : close Cookie HTTP ， cookie  web 。 Cookie : $ Version = 1 ; Skin=new; Content - Length  Content - Length : 348 Content - Type  MIME  Content - Type : application / x - www - form - urlencoded Date  Date : Tue , 15 Nov 2010 08 : 12 : 31 GMT Expect  Expect : 100 - continue From  Email From : user @ email . com Host  Host : www . zcmhi . com If - Match  If - Match : “ 737060 cd8c284d8af7ad3082f209582d ” If - Modified - Since ， 304  If - None - Match  304 ， Etag ， Etag  If - Range ，，。 Etag If - Unmodified - Since  If - Unmodified - Since : Sat , 29 Oct 2010 19 : 43 : 31 GMT Max - Forwards  Max - Forwards : 10 Pragma  Pragma : no - cache Proxy - Authorization  Proxy - Authorization : Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ == Range ， Range : bytes = 500 - 999 Referer ，, Referer : http : // www . zcmhi . com / archives / 71 . html TE ， TE : trailers , deflate ;q=0.5 Upgrade （） Upgrade : HTTP / 2 . 0 , SHTTP / 1 . 3 , IRC / 6 . 9 , RTA / x11 User - Agent User - Agent  User - Agent : Mozilla / 5 . 0 ( Linux ; X11) Via ， Via : 1 . 0 fred , 1 . 1 nowhere . com ( Apache / 1 . 1 ) Warning  Warn : 199 Miscellaneous warning Responses  Header   Accept - Ranges  Accept - Ranges : bytes Age （，） Age : 12 Allow ， 405 Allow : GET , HEAD Cache - Control  Cache - Control : no - cache Content - Encoding web 。 Content - Encoding : gzip Content - Language  Content - Language : en , zh Content - Length  Content - Length : 348 Content - Location  Content - Location : / index . htm Content - MD5  MD5  Content - MD5 : Q2hlY2sgSW50ZWdyaXR5IQ == Content - Range  Content - Range : bytes 21010 - 47021 / 47022 Content - Type  MIME  Content - Type : text / html ; charset=utf-8 Date  Date : Tue , 15 Nov 2010 08 : 12 : 31 GMT ETag  ETag : “ 737060 cd8c284d8af7ad3082f209582d ” Expires  Expires : Thu , 01 Dec 2010 16 : 00 : 00 GMT Last - Modified  Last - Modified : Tue , 15 Nov 2010 12 : 45 : 26 GMT Location  URL  Location : http : // www . zcmhi . com / archives / 94 . html Pragma ， Pragma : no - cache Proxy - Authenticate  URL  Proxy - Authenticate : Basic refresh ， 5 （，） Refresh : 5 ; url= http : // www . zcmhi . com / archives / 94 . html Retry - After ， Retry - After : 120 Server web  Server : Apache / 1 . 3 . 27 ( Unix ) ( Red - Hat / Linux ) Set - Cookie  Http Cookie Set - Cookie : UserID = JohnDoe ; Max-Age=3600; Version=1 Trailer  Trailer : Max - Forwards Transfer - Encoding  Transfer - Encoding : chunked Vary  Vary : * Via  Via : 1 . 0 fred , 1 . 1 nowhere . com ( Apache / 1 . 1 ) Warning  Warning : 199 Miscellaneous warning WWW - Authenticate  WWW - Authenticate : Basic","title":"http head"},{"location":"linux-base/#_1","text":"1 、 vim / etc / bashrc export HISTORY_FILE =/ var / log / `whoami` _ `date +%y-%m-%d ` . log readonly PROMPT_COMMAND = { date +%y-%m-%d %T ### $(who am i |awk {print $1 $2 $5} ) ### $(history 1 | { read x cmd; echo $cmd ; }) ; } $HISTORY_FILE  export HISTORY_FILE =/ var / log / `whoami` _ `date +%y-%m-%d ` . log readonly PROMPT_COMMAND = { msg=$(history 1 | { read x y; echo $y; }); echo $(who am i):[`pwd`] $msg ; } $HISTORY_FILE 2 、 vim / etc / profile export HISTTIMEFORMAT = %F %T `whoami` 1  2 ","title":""},{"location":"linux-base/#_2","text":"awk - F : $3==0 {print $1} / etc / passwd （） awk - F : length($2)==0 {print $1} / etc / shadow （） lsof - p pid （） top ps ， cat / etc / crontab ls / etc / cron . * cat / etc / rc . d / rc . local yum install rkhunter - y rkhunter - c  1 . MD5  ,  . 2 .  rootkits  . 3 .  . 4 .  . 5 .  -  rootkit hunter  . 6 .  . 7 .  / etc / rc . d /  ,  ,  .  ,  / dev / . udev  / etc / . pwd . lock  ,  . 8 .  .  : Apache Web Server , Procmail  .  ,  :  ,  MD5  . rkhunter  rootkit  rootkits  ,  ,   : # rkhunter --update  cron job  ,  root  crontab  : 59 23 1 * * echo “ Rkhunter update check in progress ” ; / usr / local / bin / rkhunter --update","title":""},{"location":"linux-base/#core-dump","text":" Linux  core  ： $ uname - a Linux dev 2.4.21 - 9.30 AXsmp # 1 SMP Wed May 26 23 : 37 : 09 EDT 2004 i686 i686 i386 GNU / Linux ， core file size  0 ， core 。 $ ulimit - a core file size ( blocks , - c ) 0 data seg size ( kbytes , - d ) unlimited file size ( blocks , - f ) unlimited max locked memory ( kbytes , - l ) 4 max memory size ( kbytes , - m ) unlimited open files ( - n ) 2048 pipe size ( 512 bytes , - p ) 8 stack size ( kbytes , - s ) 10240 cpu time ( seconds , - t ) unlimited max user processes ( - u ) 7168 virtual memory ( kbytes , - v ) unlimited ， core 。 $ more foo . c #include static void sub(void); int main ( void ) { sub (); return 0 ; } static void sub ( void ) { int * p = NULL ; /* derefernce a null pointer, expect core dump. */ printf ( %d , * p ); } $ gcc - Wall - g foo . c $ . / a . out Segmentation fault $ ls - l core . * ls : core . *: No such file or directory  core ， ulimit ，。 1024  $ ulimit - c 655355 $ ulimit - a core file size ( blocks , - c ) 1024 data seg size ( kbytes , - d ) unlimited file size ( blocks , - f ) unlimited max locked memory ( kbytes , - l ) 4 max memory size ( kbytes , - m ) unlimited open files ( - n ) 2048 pipe size ( 512 bytes , - p ) 8 stack size ( kbytes , - s ) 10240 cpu time ( seconds , - t ) unlimited max user processes ( - u ) 7168 virtual memory ( kbytes , - v ) unlimited $ . / a . out Segmentation fault ( core dumped ) $ ls - l core . * - rw ------- 1 uniware uniware 53248 Jun 30 17 : 10 core .9128 ， ( core dumped ) 。 core ， 9128  PID 。 GDB  core 。 $ gdb -- core = core .9128 GNU gdb Asianux ( 6.0 post - 0.20040223.17.1 AX ) Copyright 2004 Free Software Foundation , Inc . GDB is free software , covered by the GNU General Public License , and you are welcome to change it and / or distribute copies of it under certain conditions . Type show copying to see the conditions . There is absolutely no warranty for GDB . Type show warranty for details . This GDB was configured as i386-asianux-linux-gnu . Core was generated by ` . / a . out . Program terminated with signal 11 , Segmentation fault . #0 0x08048373 in ?? () ( gdb ) bt #0 0x08048373 in ?? () #1 0xbfffd8f8 in ?? () #2 0x0804839e in ?? () #3 0xb74cc6b3 in ?? () #4 0x00000000 in ?? ()  bt  backtrace ，， GDB 。： ( gdb ) file . / a . out Reading symbols from . / a . out ... done . Using host libthread_db library /lib/tls/libthread_db.so.1 . ( gdb ) bt #0 0x08048373 in sub () at foo.c:17 #1 0x08048359 in main () at foo.c:8  backtrace 。 ( gdb ) l 8 sub (); 9 return 0 ; 10 } 11 12 static void sub ( void ) 13 { 14 int * p = NULL ; 15 16 /* derefernce a null pointer, expect core dump. */ 17 printf ( %d , * p ); ( gdb ) ， core （，）。 gdb  core ， 。 1. core  --------------------------------- 1 ） ulimit - c  core 。 0 ，， core 。 2 ） ulimit - c filesize ， core （ filesize  kbyte ）。 ulimit - c unlimited ， core 。，， core 。 core ， gdb 。 2. core  ---------------------------- core  : 。  core ， core 。 core  core 。 1 ） / proc / sys / kernel / core_uses_pid  core  pid 。 1 ， pid ，  core  core . xxxx ； 0  core  core 。 ： echo 1 / proc / sys / kernel / core_uses_pid 2 ） proc / sys / kernel / core_pattern  core 。 ： echo /corefile/core-%e-%p-%t core_pattern ， core  / corefile ， core -  - pid -   : %p - insert pid into filename  pid %u - insert current uid into filename  uid %g - insert current gid into filename  gid %s - insert signal that caused the coredump into the filename  core  %t - insert UNIX time that the coredump occurred into filename  core  unix  %h - insert hostname where the coredump happened into filename  %e - insert coredumping executable name into filename  3. core  ----------------- core  gdb 。 gdb . / a . out core - file core . xxxx  bt 。 ，，。 1 ） gdb - core = core . xxxx file . / a . out bt 2 ） gdb - c core . xxxx file . / a . out bt 4.  core  -----------------------------  linux ， core 。 gdb ，（）、 core  PC  linux 。  PC  core ， gdb ， gdb  solib - absolute - prefix  solib - search - path  gdb 。， gdb ， ： gdb  . gdbinit 。 ： set solib - absolute - prefix YOUR_CROSS_COMPILE_PATH set solib - search - path YOUR_CROSS_COMPILE_PATH set solib - search - path YOUR_DEVELOPER_TOOLS_LIB_PATH handle SIG32 nostop noprint pass","title":"core dump"},{"location":"linux-base/#idrac","text":"wget - q - O - http : // linux . dell . com / repo / hardware / latest / bootstrap . cgi | bash yum - y install srvadmin - idrac7 racadm closessn - a  session racadm racreset  idrac 1 、 RHEL  iDRAC ： Dell EMC OpenManage Linux Remote Access Utilities : http : // www . dell . com / support / home / cn / zh / cndhs1 / drivers / driversdetails ? driverId = 49 T1M ， net - snmp - utils  rpm  / root / linux / rac / RHEL7 / x86_64 ， ： ：， # racadm command  iDRAC  ：， - r IP # racadm - r 192 . 168 . 1 . 1 - u User - p Password command  iDRAC  2 、 iDRAC ： http : // topics - cdn . dell . com / pdf / idrac7 - 8 - lifecycle - controller - v2 . 50 . 50 . 50 _reference - guide_en - us . pdf 3 、 iDRAC  、、 # racadm config - g cfgUserAdmin - o cfgUserAdminUserName - i 10 User01  10  User01 # racadm config - g cfgUserAdmin - o cfgUserAdminPassword - i 10 Password  # racadm set iDRAC . Users . 10 . Password NewPassword  # racadm config - g cfgUserAdmin - i 10 - o cfgUserAdminEnable 1  1 ， 0  # racadm config - g cfgUserAdmin - o cfgUserAdminUserName - i 10  # racadm config - g cfgUserAdmin - o cfgUserAdminPrivilege - i 10 4  User01  、 # racadm serveraction powerup  # racadm serveraction powerdown  # racadm serveraction powercycle  # racadm serveraction powerstatus  iDRAC  # racadm racreset soft  iDRAC # racadm racreset hard  iDRAC # racadm racreset soft - f  iDRAC # racadm racreset hard - f  iDRAC # racadm set iDRAC . IPv4 . Address x . x . x . x  IP  # racadm set iDRAC . IPv4 . Netmask x . x . x . x  # racadm set iDRAC . IPv4 . Gateway x . x . x . x   idrac ，","title":"idrac"},{"location":"linux-base/#idrac-ssh","text":"ssh idrac  IP  ssh  / admin1 - racadm config ...  racadm   racadm config - g cfgLanNetworking - o cfgNicGateway 192 . 168 . 63 . 155 % Get all iDRAC settings in a file racadm get - f config . txt If you like you can change the contents of config . txt and apply it back to iDRAC racadm set - f config . txt % Set password for root user racadm set iDRAC . Users . 2 . Password PASSWORD % List all ssh keys for root user racadm sshpkauth - i 2 - v - k all % Add ssh key to root user racadm sshpkauth - i 2 - k 1 CONTENTS OF PUBLIC KEY % Delete ssh key for root user racadm sshpkauth - i 2 - d - k 1 % Get iDRAC IP config racadm getniccfg racadm get iDRAC . NIC % set iDRAC IP Using config command : racadm config - g cfgLanNetworking - o cfgNicEnable 1 racadm config - g cfgLanNetworking - o cfgNicIpAddress x . x . x . x racadm config - g cfgLanNetworking - o cfgNicNetmask 255 . 255 . 255 . 0 racadm config - g cfgLanNetworking - o cfgNicGateway x . x . x . x racadm config - g cfgLanNetworking - o cfgNicUseDHCP 0 racadm config - g cfgLanNetworking - o cfgDNSServersFromDHCP 0 racadm config - g cfgLanNetworking - o cfgDNSServer1 y . y . y . y racadm config - g cfgLanNetworking - o cfgDNSServer2 y . y . y . y • Using set command : racadm set iDRAC . Nic . Enable 1 racadm set iDRAC . IPv4 . Address x . x . x . x racadm set iDRAC . IPv4 . Netmask 255 . 255 . 255 . 0 racadm set iDRAC . IPv4 . Gateway x . x . x . x racadm set iDRAC . IPv4 . DHCPEnable 0 racadm set iDRAC . IPv4 . DNSFromDHCP 0 racadm set iDRAC . IPv4 . DNS1 y . y . y . y racadm set iDRAC . IPv4 . DNS2 y . y . y . y % Set iDRAC DNS Name racadm set iDRAC . NIC . DNSRacName iDRACNAME % Set iDRAC domain name racadm set iDRAC . NIC . DNSDomainName DOMAIN . NAME % Set iDRAC DNS Server racadm config - g cfgLanNetworking - o cfgDNSServer1 x . x . x . x racadm config - g cfgLanNetworking - o cfgDNSServer2 y . y . y . y % Set Front LCD to hostname racadm set System . LCD . Configuration 16 % Reset iDRAC to factory defaults racadm racresetcfg % Reset / Reboot iDRAC racadm racreset OPTIONS Options : soft , hard , cold or racadm serveraction powercycle % Get Serial number ( service tag ) racadm getsvctag % Get current system information racadm getsysinfo % Configure one - time - boot to PXE racadm set BIOS . OneTimeBoot . OneTimeBootMode OneTimeBootSeq racadm set BIOS . OneTimeBoot . OneTimeBootSeqDev NIC . Integrated . 1 - 1 - 1 % Configure persistent Boot Device racadm config - g cfgServerInfo - o cfgServerBootOnce 0 racadm config - g cfgServerInfo - i cfgServerFirstBootDevice HDD % Check boot order list racadm get BIOS . BiosBootSettings . bootseq % Disable HyperThreading racadm set BIOS . ProcSettings . LogicalProc Disabled % Disable OS to iDRAC pass - thru for iDRAC service module ( automatically create a pseudo NIC in OS ) racadm set iDRAC . OS - BMC . AdminState Disabled % Change SNMP public community string racadm set iDRAC . SNMP . AgentCommunity NEW STRING % Disable ASR racadm config - g cfgRacTuning - o cfgRacTuneAsrEnable 0 % Configure Serial redirection racadm config - g cfgSerial - o cfgSerialConsoleEnable 1 racadm config - g cfgSerial - o cfgSerialBaudRate 115200 racadm config - g cfgSerial - o cfgSerialCom2RedirEnable 1 racadm config - g cfgSerial - o cfgSerialTelnetEnable 0 racadm config - g cfgSerial - o cfgSerialSshEnable 1 to access console via ssh console com2 % Disable Serial On Lan racadm config - g cfgImpiSol - o cfgIpmiSolEnable 0 % Change Power Profile racadm set BIOS . SysProfileSettings PerfPerWattOptimizedOs % Set AC Power Recovery racadm set BIOS . SysSecurity . AcPwdRcvry Last racadm set BIOS . SysSecurity . AcPwdRcvryDelay Immediate % Get RAID physical Disk information racadm raid get pdisks racadm raid get pdisks - o ( all information ) racadm raid get pdisks - o - p state , size ( specific information ) % Get RAID Virtual Disk Information Racadm raid get vdisks","title":"idrac ssh"},{"location":"linux-base/#dns","text":" cat / etc / resolv . conf nameserver 223 . 5 . 5 . 5 options timeout : 1 attempts : 1","title":"dns"},{"location":"linux-base/#centos","text":" vim / etc / grub . conf quiet  pcie_aspm = off  [ root@localhost ~ ] # dmesg | grep PCIe [ 0.000000 ] PCIe ASPM is disabled tuned systemctl stop tuned systemctl disable tuned  xorg . conf ，  ，  ，  。 vi / etc / X11 / xorg . conf  Section ServerFlags Option BlankTime 0 Option StandbyTime 0 Option SuspendTime 0 Option OffTime 0 EndSection Section Monitor Option DPMS false EndSection CentOS ！","title":"centos"},{"location":"linux-base/#kernel-panic","text":" / etc / sysctl . conf ， kernel panic 20  Linux ： # vi / etc / sysctl . conf kernel . panic = 20","title":"kernel panic"},{"location":"linux-base/#srcrpm","text":"yum install rpm - build rpm - ivh --xxx--.src.rpm cd / usr / src / redhat / SPECS rpmbuild - bb xxx . spec cd / usr / src / redhat / RPMS / i386 / rpm - ivh xxxx . rpm","title":"src.rpm"},{"location":"linux-base/#ab","text":"yum install gcc apr - devel apr - util - devel pcre - devel wget https : // mirrors . aliyun . com / apache / httpd / httpd - 2 . 2 . 32 . tar . gz  http ， support / ab . c 1395  } else { 1395 // apr_err ( apr_socket_recv , status ) ; 1396 bad ++ ; 1397 close_connection ( c ) ; 1398 return ; 1399 } 1400 } . / configure -- prefix =/ usr / local / apache make make  ab ： . / support / ab （ make install ） / usr / local / apache / bin / ab - n 10000 - c 1000 http : // www . baidu . com / Server Software : web  Server Hostname :  Server Port :  Document Path :  Document Length :  Concurrency Level :  Time taken for tests :  Complete requests :  Failed requests :  Write errors :  Total transferred : ， http  HTML transferred : html ， Requests per second : ，（） Time per request : ， Time per request :  Transfer rate : （）  Failed requests ： Failed requests : 2303 ( Connect : 0 , Length : 2303 , Exceptions : 0 )  Failed requests ， Connect 、 Length 、 Exceptions 。 Connect 、、。 Length  (  Content - Length  ) 。 Exception 。","title":"ab"},{"location":"linux-base/#bond","text":"cat ifcfg - eth0 DEVICE = eth0 BOOTPROTO = none ONBOOT = yes TYPE = Ethernet MASTER = bond1 SLAVE = yes cat ifcfg - eth1 DEVICE = eth1 BOOTPROTO = none ONBOOT = yes TYPE = Ethernet MASTER = bond1 SLAVE = yes cat ifcfg - bond1 DEVICE = bond1 NAME = bond1 BOOTPROTO = none ONBOOT = yes IPADDR = 10 . 21 . 20 . 210 NETMASK = 255 . 255 . 255 . 0 GATEWAY = 10 . 21 . 20 . 1 TYPE = Bond BONDING_MASTER = yes BONDING_OPTS = mode=1 miimon=100  bond ： 1 、 # ls / sys / class / net bond0 bond1 bonding_masters br0 eth0 eth1 lo ： bond0  2 、 # cat bonding_masters bond0 bond1 ： ： # echo - bond0 bonding_masters ： echo  - ， + ","title":"bond"},{"location":"linux-base/#snoopy","text":"https : // github . com / a2o / snoopy yum install gcc socat wget http : // source . a2o . si / download / snoopy / snoopy - 2.4.6 . tar . gz tar - zxf snoopy - 2.4.6 . tar . gz cd snoopy - 2.4.6 . / configure make make install make enable -- vim / usr / local / etc / snoopy . ini ( # ) [ snoopy ] message_format = %{datetime} %{hostname} %{pid} %{eusername} %{tty_username} %{tty} %{cwd} %{filename} # %{cmdline} filter_chain = exclude_spawns_of:cron output = file : / var / log / . snoopy . log -- / usr / local / sbin / snoopy - disable snoopy / usr / local / sbin / snoopy - enable snoopy  / var / log / . snoopy . log logstash grok SNOOPYLOG % { TIMESTAMP_ISO8601 : datetime } % { USERNAME : hostname } % { INT : pid } % { USER : eusername } % { USER : tty_username } % { NOTSPACE : tty } % { UNIXPATH : pwd } % { UNIXPATH : cmd_name } # % { GREEDYDATA : cmdline }","title":"snoopy"},{"location":"linux-base/#_3","text":"LVS  Cache ，，。 / var / log / messages  nf_conntrack : table full , dropping packet . ：  # chkconfig iptables off # chkconfig ip6tables off # service iptables stop # service ip6tables stop ， iptables （ iptables - nL ）！，。，，！  # lsmod | grep nf nf_nat 22759 0 nf_conntrack_ipv4 9506 2 nf_nat nf_conntrack 79645 2 nf_nat , nf_conntrack_ipv4 nf_defrag_ipv4 1483 1 nf_conntrack_ipv4 # rmmod nf_nat # rmmod nf_conntrack_ipv4 # rmmod nf_conntrack ","title":""},{"location":"linux-base/#centos_1","text":"Centos6 . 6  Centos7 . 2 ：  7.4   7. x ， 7.2  update   Centos6 . 9  7.2   ssh yum ，， ,  vi start . sh #rootstart.sh #!/bin/bash ln - s / usr / lib64 / libsasl2 . so . 3.0 . 0 / usr / lib64 / libsasl2 . so . 2 ln - s / usr / lib64 / libpcre . so . 1.2 . 0 / usr / lib64 / libpcre . so . 0 service sshd restart # chmod + x start . sh chmod + x / etc / rc . d / rc . local cp / etc / rc . d / rc . local / etc / rc . d / rc . local . bak # echo bash /root/start.sh / etc / rc . d / rc . local # step 1 ： cat / etc / yum . repos . d / upgrade . repo [ upgrade ] name = upgrade baseurl = http : // dev . centos . org / centos / 6 / upg / x86_64 / enable = 1 gpgcheck = 0 step 2 ： yum erase openscap yum install http : // dev . centos . org / centos / 6 / upg / x86_64 / Packages / openscap - 1.0 . 8 - 1.0 . 1. el6 . centos . x86_64 . rpm yum install openscap - 1.0 . 8 [ root @localhost ~ ] # yum install preupgrade-assistant-contents redhat-upgrade-tool preupgrade-assistant step 3 : [ root @localhost ~ ] # preupg step 4 ： [ root @localhost ~ ] # rpm --import http://vault.centos.org/centos/7.2.1511/os/x86_64/RPM-GPG-KEY-CentOS-7 [ root @localhost ~ ] # redhat-upgrade-tool --network 7 --instrepo http://vault.centos.org/centos/7.2.1511/os/x86_64/ ( 265 / 266 ): zlib - 1.2 . 7 - 13. el7 . x86_64 . rpm | 89 kB 00 : 00 ( 266 / 266 ): zlib - devel - 1.2 . 7 - 13. el7 . x86_64 . rpm | 49 kB 00 : 00 testing upgrade transaction rpm transaction 100 % [ =========================================== ] rpm install 100 % [ =========================================== ] setting up system for upgrade Finished . Reboot to start upgrade .  el6  rpm ","title":"centos"},{"location":"linux-base/#web","text":"1 、 webmin http : // www . webmin . com / rpm . html wget http : // prdownloads . sourceforge . net / webadmin / webmin - 1 . 881 - 1 . noarch . rpm yum - y install perl perl - Net - SSLeay openssl perl - IO - Tty perl - Encode - Detect rpm - U webmin - 1 . 881 - 1 . noarch . rpm https : // ip : 10000 /  2 、 redhat  https : // cockpit - project . org yum install cockpit - ws cockpit - system cockpit - bridge # cockpit - docker docker ， docker systemctl restart cockpit systemctl enable cockpit vim / etc / cockpit / cockpit . conf  [ Log ] Fatal = criticals [ WebService ] AllowUnencrypted = true UrlRoot =/ co / vim / usr / lib / systemd / system / cockpit . socket ListenStream = 127 . 0 . 0 . 1 : 9090  systemctl daemon - reload systemctl restart cockpit . socket nginx  map $ http_upgrade $c onnection_upgrade { default upgrade ; close ; } upstream websocket { server 127 . 0 . 0 . 1 : 9090 ; } server { listen 80 ; server_name cockpit . domain . tld www . cockpit . domain . tld ; return 301 https : // $ server_name $ request_uri ; } server { listen 443 ; server_name www . cockpit . domain . tld cockpit . domain . tld ; ssl on ; ssl_certificate / path / to / certificate ; ssl_certificate_key / path / to / key ; location / co / { #  cockpit . conf  uri proxy_pass http : // websocket ; proxy_http_version 1 . 1 ; proxy_buffering off ; proxy_set_header X - Real - IP $ remote_addr ; proxy_set_header Host $ host ; proxy_set_header X - Forwarded - For $ remote_addr ; # needed for websocket proxy_set_header Upgrade $ http_upgrade ; proxy_set_header Connection $c onnection_upgrade ; # change scheme of Origin to http proxy_set_header Origin http : // $ host ; # Pass ETag header from cockpit to clients . # See : https : // github . com / cockpit - project / cockpit / issues / 5239 # gzip off ; } }","title":"web"},{"location":"linux-base/#crontab","text":"， crontab ，。，。： 1 . crontab   cron ，。 shelll ， 。 3 ： 1 ）； 2 ） java ， source ，： cat start_cbp . sh #!/ bin / sh source / etc / profile export RUN_CONF =/ home / d139 / conf / platform / cbp / cbp_jboss . conf / usr / local / jboss - 4 . 0 . 5 / bin / run . sh - c mev 3 ） OK ， crontab 。， crontab 。： 0 * * * * . / etc / profile ; / bin / sh / var / www / java / audit_no_count / bin / restart_audit . sh 2 .  1 ） cron job ，， 2 。 cron 。 2 ） JOB ，。，，。 JOB  ： / dev / null 2 1 。 Job  , 。 3 ） crontab ， / etc / init . d / crond restart 。 job  /  tail - f / var / log / cron 。 4 ） crontab - r 。 Crontab （ / var / spool / cron ） Crontab 。 crontab 。 5 ） crontab  % ，。 % ， date ‘ +% Y % m % d ’ crontab ，  date ‘ +% Y % m % d ’ ` 。 3 . crontab  crontab ： / dev / null 2 1 ， crontab 。 shell ‘ ’ / dev / null 　　 ，： echo 123 / home / 123 . txt 　 1  stdout ， 1 ， /dev/null  1 /dev/null 2  stderr  　 ， 2 1 ， 2  1 　 ： 1 / dev / null ，，。 2 1 ，，。","title":"crontab"},{"location":"linux-base/#centos_2","text":"centos6  cat / etc / modprobe . conf alias em2 bond0 mv ifcfg - em2 ifcfg - bond0  ，  centos7 [ root@localhost ~ ] # vi / usr / lib / udev / rules . d / 60 - net . rules  # #ACTION == add , SUBSYSTEM == net , DRIVERS == ?* , ATTR { type } == 1 , PROGRAM = /lib/udev/rename_device , RESULT == ?* , NAME = $result ACTION == add , SUBSYSTEM == net , DRIVERS == ?* , ATTR { type } == 1 , ATTR { address } == d8:9e:*:10:*11 , NAME = eth0 ip link set dev eth0 name eth1  ， ","title":"centos"},{"location":"linux-base/#service-tag","text":"linux : dmidecode - s system - serial - number windows :  cmd ，： wmic ： bios get serialnumber ","title":"service tag"},{"location":"linux-soft/","text":"mkdocs http : // mkdocs . org yum install python - pip pip install mkdocs pip install mkdocs - windmill mkdocs new [ dir - name ] - Create a new project . mkdocs help - Print this help message . mkdocs serve - a 0 . 0 . 0 . 0 : 8080 mkdocs build -- clean mkdocs build  find . - name *.md | awk - F / {print $3} | while read line ; do grep $line mkdocs.yml ; if [ $? -ne 0 ];then echo $line /tmp/diff; fi; done ntopng http : // packages . ntop . org / centos - stable / wget http : // packages . ntop . org / centos - stable / ntop . repo - O / etc / yum . repos . d / ntop . repo yum install pfring n2disk nprobe ntopng ntopng - data cento pfring - drivers - zc - dkms redis systemctl start redis systemctl start ntopng IP : 3000 admin / admin dokuwiki 、 : yum install httpd php php - gd php - ldap 、 1 .  dokuwiki  # wget http : // download . dokuwiki . org / src / dokuwiki / dokuwiki - stable . tgz 2 .  # tar - zvxf dokuwiki - stable . tgz //  # cd dokuwiki - 2016 - 06 - 26 a //  # cp - R dokuwiki - 2016 - 06 - 26 a / home / www / dokuwiki //  # chown - R www : www / home / www //  root  www  (  nginx  ) ： http : //  ip / install . php ： ， zh ，， ，， install . php ， 、 LDAP  1 、 LDAP  2 、 -  phpproxy wget https : // www . php - proxy . com / download / php - proxy . zip  / var / www / chmod 777 / vat / www - R vim / var / www / templates / url_form . php  style div id = top_form style = display:none;  form vim vendor / athlon1600 / php - proxy / src / helpers . php  http  https ，， nginx  yum install php - fpm php - curl php - mbstring youtube - dl root / var / www ; location / { index index . php ; } location ~ \\. php $ { fastcgi_pass 127 . 0 . 0 . 1 : 9000 ; fastcgi_index index . php ; fastcgi_param SCRIPT_FILENAME $d ocument_root $fa stcgi_script_name ; include fastcgi_params ; } apache yum install httpd php php - curl php - mbstring youtube - dl cd / etc / httpd rm conf . d / welcome . conf vim conf / httpd . conf  index . php IfModule dir_module DirectoryIndex index . html index . php / IfModule  php - proxy VirtualHost * : 80 DocumentRoot / var / www / / VirtualHost ServerLimit 10 IfModule mpm_prefork_module StartServers 5 MinSpareServers 5 MaxSpareServers 10 MaxClients 10 MaxRequestsPerChild 0 / IfModule ExtendedStatus On Location / proxy - status SetHandler server - status / Location solr ： ： http : //lucene.apache.org/solr/ ： http : //mirrors.cnnic.cn/apache/lucene/solr/ ：  apache java yum install java httpd java – version  java  openjdk version 1.8.0_65 OpenJDK Runtime Environment ( build 1.8.0 _65 - b17 ) OpenJDK 64 - Bit Server VM ( build 25.65 - b01 , mixed mode ) tar - zxf solr - 5.3.1 . tgz cd solr - 5.3.1 /  . / bin / solr start - e cloud - noprompt  . / bin / post - c gettingstarted  （） . / bin / solr stop - all ; rm - Rf example / cloud /  . / bin / post - c gettingstarted - d delete id SP2514N /id /delete ， */ 1 * * * * / bin / bash / root / add_file_solr . sh / dev / null ： #!/usr/bin/env bash file = ` find / var / www / html / logfile - type f - amin 1 ` for i in $ file do if [ $ i == ]; then / root / solr - 5.3.1 / bin / post - c gettingstarted $ i else exit fi done  http : //localhost:8983/solr  http : //localhost:8983/solr/gettingstarted/browse Documents （ solr command ）  add doc fieldname = url http : //localhost/myBlog/solr-rocks.html /field field name = title Solr Search is Simply Great / field field name = keywords solr , lucene , enterprise , search / field fieldname = creationDate 2007 - 01 - 06 T05 : 04 : 00.000 Z / field field name = rating 10 / field field name = content Solr is a really great open source searchserver . It scales , it s easy to configure and the Solr community is reallysupportive . / field field name = published on / field / doc / add  ID  delete id 0513 8022 / id / delete  delete query id : IW - 02 / query / delete  delete query *:* / query / delete Apache  Vim / etc / httpd / conf / httpd . conf  LoadModule proxy_module modules / mod_proxy . so  LoadModule proxy_http_module modules / mod_proxy_http . so  ： VirtualHost *: 80 ServerAdmin yunwei @3 mang . com ServerName log .3 mang . com ProxyRequests Off Proxy * AuthType Basic allowoverride AuthConfig order allow , deny allow from all AuthName admin AuthUserFile / etc / httpd / . htpassword  require valid - user / Proxy ProxyPass / solr http : //127.0.0.1:8983/solr ProxyPass / solr / admin / cores http : //127.0.0.1:8983/solr/admin/cores ProxyPassReverse / solr http : //127.0.0.1:8983/solr / VirtualHost htpasswd - cm / etc / httpd / . htpassword admin ， htpasswd - m / etc / httpd / . htpassword test  chown apache . apache / etc / httpd / . htpassword chmod 400 / etc / httpd / . htpassword smokeping https : // oss . oetiker . ch / smokeping / doc / smokeping_install . en . html yum - y install gcc httpd - devel libxml2 - devel libpng - devel glib pango pango - devel freetype freetype - devel fontconfig cairo cairo - devel libart_lgpl libart_lgpl - devel popt - devel rrdtool rrdtool - devel rrdtool - perl fping mod_fcgid perl - devel fcgi perl - Sys - Syslog  rrdtool cgilib fping echoping fcgi wget https : // launchpad . net / cgilib / main / 0 . 5 /+ download / cgilib - 0 . 5 . tar . gz tar zxvf cgilib - 0 . 5 . tar . gz cd cgilib - 0 . 5 make cp libcgi . a / usr / local / lib cp cgi . h / usr / include wget https : // fossies . org / linux / misc / old / echoping - 6 . 0 . 2 . tar . gz tar zxvf echoping - 6 . 0 . 2 . tar . gz cd echoping - 6 . 0 . 2 . / configure -- without - libidn make make install yum install perl - core - y wget https : // oss . oetiker . ch / smokeping / pub / smokeping - 2 . 7 . 2 . tar . gz tar zxvf smokeping - 2 . 7 . 2 . tar . gz cd smokeping - 2 . 7 . 2 . / configure -- prefix =/ usr / local / smokeping gmake install gmake install   smokeping cd / usr / local / smokeping / mkdir cache data var chmod 777 cache data var cd / usr / local / smokeping / htdocs / cp smokeping . fcgi . dist smokeping . fcgi cd / usr / local / smokeping / etc / cp config . dist config chmod 400 / usr / local / smokeping / etc / smokeping_secrets . dist ln - s / usr / local / smokeping / cache / usr / local / smokeping / htdocs / cache  vi / etc / rc . local  nohup / usr / local / smokeping / bin / smokeping -- logfile =/ var / log / smokeping . log 2 1  apache  Alias / smokeping / /usr/local/smokeping/htdocs/ Directory /usr/local/smokeping/ AllowOverride None Options All AddHandler cgi - script . fcgi . cgi Order allow , deny Allow from all apache2 . 4  allow order  Require all granted DirectoryIndex smokeping . fcgi / Directory  apache ， nohup / usr / local / smokeping / bin / smokeping -- logfile =/ var / log / smokeping . log 2 1 kill - 9 ` ps aux | grep smokeping | grep - v grep | awk {print $2} ` nohup / usr / local / smokeping / bin / smokeping -- logfile =/ var / log / smokeping . log 2 1  vim / usr / local / smokeping / etc / config  *** Presentation ***  charset = utf - 8 + TEST menu = TEST title = TEST ################ web server ############################ ++ TEST - web - bbs menu = TEST - web - bbs title = TEST  10 . 0 . 100 . 10 host = 61 . 160 . 248 . 10 ++ TEST - web - main menu = TEST  WEB  title = TEST  WEB  10 . 0 . 100 . 21 host = 10 . 0 . 100 . 21 redmine http : // www . redmine . org / projects / redmine / wiki / RedmineInstall Step 1 - Redmine application  redmine http : // www . redmine . org / projects / redmine / wiki / Download  gem ， gem sources -- add http : // gems . ruby - china . org / -- remove http : // rubygems . org /  redmine vim Gemfile  source https://gems.ruby-china.org/  MySQL CREATE DATABASE redmine CHARACTER SET utf8 ; CREATE USER redmine @ localhost IDENTIFIED BY my_password ; GRANT ALL PRIVILEGES ON redmine . * TO redmine @ localhost ; For versions of MySQL prior to 5 . 0 . 2 - skip the create user step and instead : GRANT ALL PRIVILEGES ON redmine . * TO redmine @ localhost IDENTIFIED BY my_password ; PostgreSQL CREATE ROLE redmine LOGIN ENCRYPTED PASSWORD my_password NOINHERIT VALID UNTIL infinity ; CREATE DATABASE redmine WITH ENCODING = UTF8 OWNER = redmine ; SQL Server The database , login and user can be created within SQL Server Management Studio with a few clicks . If you prefer the command line option with SQLCMD , here s some basic example: Show SQL Step 3 - Database connection configuration  Copy config / database . yml . example to config / database . yml and edit this file in order to configure your database settings for production environment . Example for a MySQL database using ruby 1 . 8 or jruby : production : adapter : mysql database : redmine host : localhost username : redmine password : my_password Example for a MySQL database using ruby 1 . 9 ( adapter must be set to mysql2 ) : production : adapter : mysql2 database : redmine host : localhost username : redmine password : my_password If your server is not running on the standard port ( 3306 ) , use this configuration instead : production : adapter : mysql database : redmine host : localhost port : 3307 username : redmine password : my_password Example for a PostgreSQL database ( default port ) : production : adapter : postgresql database : your_database_name host : postgres_host username : postgres_user password : postgres_user_password encoding : utf8 schema_search_path : database_schema ( default - public ) Example for a SQL Server database ( default host localhost , default port 1433 ) : production : adapter : sqlserver database : redmine username : redmine # should match the database user name password : redminepassword # should match the login password Step 4 - Dependencies installation  Redmine uses Bundler to manage gems dependencies . gem install bundler Then you can install all the gems required by Redmine using the following command : bundle install -- without development test Optional dependencies RMagick ( allows the use of ImageMagick to manipulate images for PDF and PNG export ) If ImageMagick is not installed on your system , you should skip the installation of the rmagick gem using : bundle install -- without development test rmagick If you have trouble installing rmagick on Windows , refer to this HowTo . Database adapters Redmine automatically installs the adapter gems required by your database configuration by reading it from the config / database . yml file ( eg . if you configured only a connection using the mysql2 adapter , then only the mysql2 gem will be installed ) . Don t forget to re-run bundle install --without development test ... after adding or removing adapters in the config / database . yml file ! Additional dependencies ( Gemfile . local ) If you need to load gems that are not required by Redmine core ( eg . Puma , fcgi ) , create a file named Gemfile . local at the root of your redmine directory . It will be loaded automatically when running bundle install . Example : # Gemfile . local gem puma Step 5 - Session store secret generation This step generates a random key used by Rails to encode cookies storing session data thus preventing their tampering . Generating a new secret token invalidates all existing sessions after restart . with Redmine 1 . 4 . x : bundle exec rake generate_session_store with Redmine 2 . x : bundle exec rake generate_secret_token Alternatively , you can store this secret in config / secrets . yml : http : // guides . rubyonrails . org / upgrading_ruby_on_rails . html # config - secrets - yml Step 6 - Database schema objects creation  Create the database structure , by running the following command under the application root directory : RAILS_ENV = production bundle exec rake db : migrate Windows syntax : set RAILS_ENV = production bundle exec rake db : migrate It will create tables by running all migrations one by one then create the set of the permissions and the application administrator account , named admin . Ubuntu troubleshooting : If you get this error with Ubuntu : Rake aborted ! no such file to load -- net / https Then you need to install libopenssl - ruby1 . 8 just like this : apt - get install libopenssl - ruby1 . 8 . Step 7 - Database default data set Insert default configuration data in database , by running the following command : RAILS_ENV = production bundle exec rake redmine : load_default_data Redmine will prompt you for the data set language that should be loaded ; you can also define the REDMINE_LANG environment variable before running the command to a value which will be automatically and silently picked up by the task . E . g .: Unices : RAILS_ENV = production REDMINE_LANG = fr bundle exec rake redmine : load_default_data Windows : set RAILS_ENV = production set REDMINE_LANG = fr bundle exec rake redmine : load_default_data Step 8 - File system permissions NB : Windows users can skip this section . The user account running the application must have write permission on the following subdirectories : files ( storage of attachments ) log ( application log file production . log ) tmp and tmp / pdf ( create these ones if not present , used to generate PDF documents among other things ) public / plugin_assets ( assets of plugins ) E . g ., assuming you run the application with a redmine user account : mkdir - p tmp tmp / pdf public / plugin_assets chown - R redmine : redmine files log tmp public / plugin_assets chmod - R 755 files log tmp public / plugin_assets Step 9 - Test the installation Test the installation by running WEBrick web server : with Redmine 1 . 4 . x : bundle exec ruby script / server webrick - e production with Redmine 2 . x : bundle exec ruby script / rails server webrick - e production with Redmine 3 . x : bundle exec rails server webrick - e production Once WEBrick has started , point your browser to http : // localhost : 3000 / . You should now see the application welcome page . Note : Webrick is not suitable for production use , please only use webrick for testing that the installation up to this point is functional . Use one of the many other guides in this wiki to setup redmine to use either Passenger ( aka mod_rails ) , FCGI or a Rack server ( Unicorn , Thin , Puma , hellip ;) to serve up your redmine. Step 10 - Logging into the application Use default administrator account to log in : login : admin password : admin You can go to Administration menu and choose Settings to modify most of the application settings . Configuration Redmine settings are defined in a file named config / configuration . yml . If you need to override default application settings , simply copy config / configuration . yml . example to config / configuration . yml and edit the new file ; the file is well commented by itself, so you should have a look at it . These settings may be defined per Rails environment ( production / development / test ) . Important : don t forget to restart the application after any change. Email / SMTP server settings Email configuration is described in a dedicated page . SCM settings This configuration section allows you to : override default commands names if the SCM binaries present in the PATH variable doesn t use the standard name ( Windows . bat / NaNd names won t work) specify the full path to the binary Examples ( with Subversion ) : Command name override : scm_subversion_command : svn_replacement.exe Absolute path : scm_subversion_command : C:\\Program Files\\Subversion\\bin\\svn.exe Attachment storage settings You can set a path where Redmine attachments will be stored which is different from the default files directory of your Redmine instance using the attachments_storage_path setting . Examples : attachments_storage_path : / var / redmine / files attachments_storage_path : D : / redmine / files Logging configuration Redmine defaults to a log level of : info , writing to the log subdirectory . Depending on site usage , this can be a lot of data so to avoid the contents of the logfile growing without bound , consider rotating them , either through a system utility like logrotate or via theconfig / additional_environment . rb file . To use the latter , copy config / additional_environment . rb . example to config / additional_environment . rb and add the following lines . Note that the new logger defaults to a high log level and hence has to be explicitly set to info . # Logger . new ( PATH , NUM_FILES_TO_ROTATE , FILE_SIZE ) config . logger = Logger . new ( /path/to/logfile.log , 2 , 1000000 ) config . logger . level = Logger :: INFO Backups Redmine backups should include : data ( stored in your redmine database ) attachments ( stored in the files directory of your Redmine install ) Here is a simple shell script that can be used for daily backups ( assuming you re using a mysql database): # Database / usr / bin / mysqldump - u username - p password redmine_database | gzip / path / to / backup / db / redmine_ ` date +% y_ % m_ % d `. gz # Attachments rsync - a / path / to / redmine / files / path / to / backup / files Notes on Linux / Unix installation Be sure to disable security hardenning tools during the installation process if you run into bizarre permission problems . These problems are mostly silent and can be caused by tools like extended ACLs , SELinux , or AppArmor . There tools are mostly used in big companies with a strict security policy , default Linux / Unix distributions settings shouldn t be a problem. Notes on Windows installation There is an prebuilt installer of Ruby MRI available from http : // rubyinstaller . org . After installing it , select Start Command Prompt with Ruby in the start menu . Specifying the RAILS_ENV environment variable : When running command as described in this guide , you have to set the RAILS_ENV environment variable using a separate command . I . e . commands with the following syntaxes : RAILS_ENV = production any commmand any commmand RAILS_ENV = production have to be turned into 2 subsequent commands : set RAILS_ENV = production any commmand MySQL gem installation issue : You may need to manually install the mysql gem using the following command : gem install mysql cobbler http : //blog.chinaunix.net/uid-16728139-id-4174109.html  ipv6 ： cat EOF / etc / modprobe . d / dist . conf alias net - pf - 10 off alias ipv6 off EOF yum install cobbler cobbler - web createrepo yum - utils dhcp httpd tftp cman pykickstart debmirror - y ： 1  cobbler  [ root @ locahost ~ ] # vim / etc / cobbler / settings next_server : 10.3.3.31 server : 10.3.3.31 manage_dhcp : 1 manage_rsync : 1  : [ root @ locahost ~ ] # openssl passwd - 1 - salt cobber 123456 $1$cobber$yV9XfOuaaiVDvImopK7o .1 openssl passwd - 1 - salt   ，， root 。。 [ root @ locahost ~ ] # vim / etc / cobbler / settings default_password_crypted : $1$cobber$yV9XfOuaaiVDvImopK7o.1 2  tfpt  rsync [ root @ locahost ~ ] # vim / etc / xinetd . d / tftp disable = no [ root @ locahost ~ ] # vim / etc / xinetd . d / rsync disable = no  [ root @ locahost ~ ] # / etc / init . d / xinetd restart 3  dhcp  vim / etc / cobbler / dhcp . template subnet 192.168.18.0 netmask 255.255.255.0 { option routers 192.168.18.5 ; option domain - name - servers 192.168.1.1 ; option subnet - mask 255.255.255.0 ; range dynamic - bootp 192.168.18.100 192.168.18.254 ; filename /pxelinux.0 ; default - lease - time 21600 ; max - lease - time 43200 ; next - server $next_server ; } [ root @ locahost ~ ] # vim / etc / debmirror . conf #@dists= sid ; @ sections = main,main/debian-installer,contrib,non-free ; #@arches= i386 ; [ root @ locahost ~ ] # / etc / init . d / cobblerd restart [ root @ locahost ~ ] # / etc / init . d / httpd restart [ root @ locahost ~ ] # / etc / init . d / xinetd restart #[root@locahost ~]# /etc/init.d/dhcpd restart [ root @ locahost ~ ] # cobbler get - loaders downloading http : //cobbler.github.io/loaders/README to /var/lib/cobbler/loaders/README () ......  :  web  htdigest / etc / cobbler / users . digest Cobbler cobbler https : //ip/cobbler_web 1 ： DVD ， [ root @ locahost ~ ] # mkdir - p / mnt / cdrom [ root @ locahost ~ ] # mount / dev / cdrom / mnt / cdrom / [ root @ locahost ~ ] # cobbler import -- path =/ mnt / cdrom / -- name = centos6 .4 -- arch = x86_64 cd / var / lib / cobbler / kickstarts / cp sample_end . ks centos6 . ks cobbler profile profile edit -- name = centos6 .4 -- distro = centos6 .4 -- kickstart =/ var / lib / cobbler / kickstarts / centos6 . ks cobbler report cobbler sync [ root @ locahost ~ ] # / etc / init . d / cobblerd restart [ root @ locahost ~ ] # cobbler sync ，： vim / etc / cobbler / pxe / pxedefault . template DEFAULT menu （）  kickstarts ： cd / var / lib / cobbler / kickstarts # Kickstart  vi / var / lib / cobbler / kickstarts / CentOS - 5.10 - x86_64 . ks # CentOS - 5.10 - x86_64  # Kickstart file automatically generated by anaconda. install url -- url = http : //192.168.21.128/cobbler/ks_mirror/CentOS-5.10-x86_64-x86_64/ lang en_US . UTF - 8 zerombr yes key -- skip keyboard us network -- device eth0 -- bootproto dhcp -- onboot on #network --device eth0 --bootproto static --ip 192.168.21.250 --netmask 255.255.255.0 --gateway 192.168.21.2 -- nameserver 8.8.8.8 -- hostname CentOS5 .10 rootpw -- iscrypted $1$QqobZZ1g$rYnrawi9kYlEeUuq1vcRS / firewall -- enabled -- port = 22 : tcp authconfig -- enableshadow -- enablemd5 selinux -- disabled timezone Asia / Shanghai bootloader -- location = mbr -- driveorder = sda # The following is the partition information you requested # Note that any partitions you deleted are not expressed # here so unless you clear all partitions first, this is # not guaranteed to work #clearpart --linux clearpart -- all -- initlabel part / -- bytes - per - inode = 4096 -- fstype = ext3 -- size = 2048 part / boot -- bytes - per - inode = 4096 -- fstype = ext3 -- size = 128 part swap -- bytes - per - inode = 4096 -- fstype = swap -- size = 500 part / data -- bytes - per - inode = 4096 -- fstype = ext3 -- grow -- size = 1 reboot %packages ntp @ base @ core @ dialup @ editors @ text - internet keyutils trousers fipscheck device - mapper - multipath %post # ntpdate cn . pool . ntp . org hwclock -- systohc echo - e 0 1 * * * root /usr/sbin/ntpdate cn.pool.ntp.org /dev/null / etc / crontab service crond restart #root sed - i s/#PermitRootLogin yes/PermitRootLogin no/g / etc / ssh / sshd_config service sshd restart # for i in ` chkconfig -- list | awk { print $1 } ` ; do if [[ $i = atd || $i = crond || $i = irqbalance || $i = network || $i = sshd || $i = rsyslog || $i = httpd || $i = salt -* || $i = zabbix_ * ]]; then chkconfig -- level 3 $i on else chkconfig $i off fi done grep - v ^# / etc / ssh / sshd_config | grep - v ^$ | grep ^UseDNS no / dev / null if [[ $ ? - ne 0 ]]; then sed - i 122 a \\ UseDNS no / etc / ssh / sshd_config / etc / init . d / sshd restart fi cat / etc / profile EOF if [ $SHELL = /bin/ksh ]; then ulimit - p 16384 ulimit - n 65536 ulimit - c unlimited else ulimit - u 16384 - n 65536 - c unlimited fi EOF source / etc / profile ##set ulimit file cat / etc / security / limits . conf EOF * soft nproc 10000 * hard nproc 16384 * soft nofile 65536 * hard nofile 65536 EOF #Ctrl+Alt+Del sed - i s/ca::ctrlaltdel:\\/sbin\\/shutdown -t3 -r now/#ca::ctrlaltdel:\\/sbin\\/shutdown -t3 -r now/g / etc / inittab # echo - e ulimit -c unlimited / etc / profile echo - e ulimit -s unlimited / etc / profile echo - e ulimit -SHn 65535 / etc / profile source / etc / profile sed - i s/net.ipv4.ip_forward = 0/net.ipv4.ip_forward = 1/g / etc / sysctl . conf echo - e net.core.somaxconn = 262144 / etc / sysctl . conf echo - e net.core.netdev_max_backlog = 262144 / etc / sysctl . conf echo - e net.core.wmem_default = 8388608 / etc / sysctl . conf echo - e net.core.rmem_default = 8388608 / etc / sysctl . conf echo - e net.core.rmem_max = 16777216 / etc / sysctl . conf echo - e net.core.wmem_max = 16777216 / etc / sysctl . conf echo - e net.ipv4.netfilter.ip_conntrack_max = 131072 / etc / sysctl . conf echo - e net.ipv4.netfilter.ip_conntrack_tcp_timeout_established = 180 / etc / sysctl . conf echo - e net.ipv4.route.gc_timeout = 20 / etc / sysctl . conf echo - e net.ipv4.ip_conntrack_max = 819200 / etc / sysctl . conf echo - e net.ipv4.ip_local_port_range = 10024 65535 / etc / sysctl . conf echo - e net.ipv4.tcp_retries2 = 5 / etc / sysctl . conf echo - e net.ipv4.tcp_fin_timeout = 30 / etc / sysctl . conf echo - e net.ipv4.tcp_syn_retries = 1 / etc / sysctl . conf echo - e net.ipv4.tcp_synack_retries = 1 / etc / sysctl . conf echo - e net.ipv4.tcp_timestamps = 0 / etc / sysctl . conf echo - e net.ipv4.tcp_tw_recycle = 1 / etc / sysctl . conf echo - e net.ipv4.tcp_tw_len = 1 / etc / sysctl . conf echo - e net.ipv4.tcp_tw_reuse = 1 / etc / sysctl . conf echo - e net.ipv4.tcp_keepalive_time = 120 / etc / sysctl . conf echo - e net.ipv4.tcp_keepalive_probes = 3 / etc / sysctl . conf echo - e net.ipv4.tcp_keepalive_intvl = 15 / etc / sysctl . conf echo - e net.ipv4.tcp_max_tw_buckets = 36000 / etc / sysctl . conf echo - e net.ipv4.tcp_max_orphans = 3276800 / etc / sysctl . conf echo - e net.ipv4.tcp_max_syn_backlog = 262144 / etc / sysctl . conf echo - e net.ipv4.tcp_wmem = 8192 131072 16777216 / etc / sysctl . conf echo - e net.ipv4.tcp_rmem = 32768 131072 16777216 / etc / sysctl . conf echo - e net.ipv4.tcp_mem = 94500000 915000000 927000000 / etc / sysctl . conf / sbin / sysctl - p # cd / root wget http : //192.168.21.128/cobbler/ks_mirror/config/autoip.sh sh / root / autoip . sh vi / var / www / cobbler / ks_mirror / config / autoip . sh #， Linux  IP 、 DNS 、、 #!/bin/sh ROUTE = $ ( route - n | grep ^0.0.0.0 | awk { print $2 } ) BROADCAST = $ ( / sbin / ifconfig eth0 | grep - i bcast | awk { print $3 } | awk - F : { print $2 } ) HWADDR = $ ( / sbin / ifconfig eth0 | grep - i HWaddr | awk { print $5 } ) IPADDR = $ ( / sbin / ifconfig eth0 | grep inet addr | awk { print $2 } | awk - F : { print $2 } ) NETMASK = $ ( / sbin / ifconfig eth0 | grep inet addr | awk { print $4 } | awk - F : { print $2 } ) cat / etc / sysconfig / network - scripts / ifcfg - eth0 EOF DEVICE = eth0 BOOTPROTO = static BROADCAST = $BROADCAST HWADDR = $HWADDR IPADDR = $IPADDR NETMASK = $NETMASK GATEWAY = $ROUTE ONBOOT = yes EOF IPADDR1 = $ ( echo $IPADDR | awk - F . { print $4 } ) cat / etc / sysconfig / network - scripts / ifcfg - eth1 EOF DEVICE = eth1 BOOTPROTO = static BROADCAST = 10.0.0.255 HWADDR = $ ( / sbin / ifconfig eth1 | grep - i HWaddr | awk { print $5 } ) IPADDR = 10.0.0 . $IPADDR1 NETMASK = 255.255.255.0 ONBOOT = yes EOF HOSTNAME = OsYunWei_HZ_ $ ( echo $IPADDR | awk - F . { print $4 } ) cat / etc / sysconfig / network EOF NETWORKING = yes NETWORKING_IPV6 = no HOSTNAME = $HOSTNAME GATEWAY = $ROUTE EOF echo 127.0.0.1 $HOSTNAME / etc / hosts hostname = $HOSTNAME echo nameserver 8.8.8.8 / etc / resolv . conf echo nameserver 8.8.4.4 / etc / resolv . conf tcpcopy wget https : // github . com / session - replay - tools / intercept / archive / master . zip wget https : // github . com / session - replay - tools / tcpcopy / archive / master . zip tomcat  session ， session  redis ，。  tcpcopy ip 192 . 168 . 1 . 6 . / configure make make install / usr / local / tcpcopy / sbin / tcpcopy - x 8180 - 192 . 168 . 1 . 3 : 8080 - s 192 . 168 . 1 . 3 - c 192 . 168 . 1 . 6 ， iptables - I INPUT - s 192 . 168 . 1 . 3 - p tcp --sport 8080-j DROP # tcpdump ，， tcpdump ， iptables  ip  drop ， ， ip ，， tcpdump ，  8180  192 . 168 . 1 . 3  8080 ， - s intercept  - n 3  3  - c  IP  127 . 0 . 0 . 1  62 . 135 . 200 . x  ==============  intercept ip 192 . 168 . 1 . 3  ip_forward yum install libpcap - devel - y . / configure make make install . / intercept - i eth0 - F tcp and src port 8080 - d tomcat  session  - d  - F  ffmpeng  http : // johnvansickle . com / ffmpeg / wget http : // johnvansickle . com / ffmpeg / builds / ffmpeg - git - 64 bit - static . tar . xz  http : // www . yaosansi . com / post / ffmpeg - on - centos /  epel ， rpmforce   yum - y install glibc gcc gcc - c ++ autoconf automake libtool git make nasm pkgconfig SDL - devel a52dec a52dec - devel alsa - lib - devel faac faac - devel faad2 faad2 - devel freetype - devel giflib gsm gsm - devel imlib2 imlib2 - devel lame lame - devel libICE - devel libSM - devel libX11 - devel libXau - devel libXdmcp - devel libXext - devel libXrandr - devel libXrender - devel libXt - devel libogg libvorbis vorbis - tools mesa - libGL - devel mesa - libGLU - devel xorg - x11 - proto - devel zlib - devel libtheora theora - tools ncurses - devel libdc1394 libdc1394 - devel amrnb - devel amrwb - devel opencore - amr - devel cd / opt wget http : // downloads . xvid . org / downloads / xvidcore - 1 . 3 . 2 . tar . gz tar xzvf xvidcore - 1 . 3 . 2 . tar . gz rm - f xvidcore - 1 . 3 . 2 . tar . gz cd xvidcore / build / generic . / configure -- prefix = $HOME/ffmpeg_build make make install cd / opt wget http : // downloads . xiph . org / releases / ogg / libogg - 1 . 3 . 1 . tar . gz tar xzvf libogg - 1 . 3 . 1 . tar . gz rm - f libogg - 1 . 3 . 1 . tar . gz cd libogg - 1 . 3 . 1 . / configure -- prefix = $HOME/ffmpeg_build -- disable - shared make make install cd / opt wget http : // downloads . xiph . org / releases / vorbis / libvorbis - 1 . 3 . 4 . tar . gz tar xzvf libvorbis - 1 . 3 . 4 . tar . gz rm - f libvorbis - 1 . 3 . 4 . tar . gz cd libvorbis - 1 . 3 . 4 . / configure -- prefix = $HOME/ffmpeg_build -- with - ogg = $HOME/ffmpeg_build -- disable - shared make make install cd / opt wget http : // downloads . xiph . org / releases / theora / libtheora - 1 . 1 . 1 . tar . gz tar xzvf libtheora - 1 . 1 . 1 . tar . gz rm - f libtheora - 1 . 1 . 1 . tar . gz cd libtheora - 1 . 1 . 1 . / configure -- prefix = $HOME/ffmpeg_build -- with - ogg = $HOME/ffmpeg_build -- disable - examples -- disable - shared -- disable - sdltest -- disable - vorbistest make make install cd / opt wget http : // downloads . sourceforge . net / opencore - amr / vo - aacenc - 0 . 1 . 2 . tar . gz tar xzvf vo - aacenc - 0 . 1 . 2 . tar . gz rm - f vo - aacenc - 0 . 1 . 2 . tar . gz cd vo - aacenc - 0 . 1 . 2 . / configure -- prefix = $HOME/ffmpeg_build -- disable - shared make install yum - y remove yasm cd / opt wget http : // www . tortall . net / projects / yasm / releases / yasm - 1 . 2 . 0 . tar . gz tar xzfv yasm - 1 . 2 . 0 . tar . gz rm - f yasm - 1 . 2 . 0 . tar . gz cd yasm - 1 . 2 . 0 . / configure -- prefix = $HOME/ffmpeg_build -- bindir = $HOME/bin make install export PATH=$PATH:$HOME/bin cd / opt git clone http : // git . chromium . org / webm / libvpx . git cd libvpx git checkout tags / v1 . 3 . 0 . / configure -- prefix = $HOME/ffmpeg_build -- disable - examples make make install cd / opt git clone git : // git . videolan . org / x264 . git cd x264 . / configure -- prefix = $HOME/ffmpeg_build -- bindir = $HOME/bin -- enable - static make install export LD_LIBRARY_PATH =/ usr / local / lib / :$ HOME / ffmpeg_build / lib / echo / usr / local / lib / etc / ld . so . conf . d / custom - libs . conf echo $ HOME / ffmpeg_build / lib / / etc / ld . so . conf . d / custom - libs . conf ldconfig cd / opt git clone git : // source . ffmpeg . org / ffmpeg . git cd ffmpeg git checkout release / 2 . 2 PKG_CONFIG_PATH = $HOME/ffmpeg_build/lib/pkgconfig export PKG_CONFIG_PATH . / configure -- prefix = $HOME/ffmpeg_build -- extra - cflags = -I$HOME/ffmpeg_build/include -- extra - ldflags = -L$HOME/ffmpeg_build/lib -- bindir = $HOME/bin -- extra - libs =- ldl -- enable - version3 -- enable - libopencore - amrnb -- enable - libopencore - amrwb -- enable - libvpx -- enable - libfaac -- enable - libmp3lame -- enable - libtheora -- enable - libvorbis -- enable - libx264 -- enable - libvo - aacenc -- enable - libxvid -- disable - ffplay -- enable - gpl -- enable - postproc -- enable - nonfree -- enable - avfilter -- enable - pthreads -- arch = x86_64 make install # Test the resulting ffmpeg binary cp $ HOME / bin / ffmpeg / usr / bin / ffmpeg - v openldap yum install openldap -* db4 -* - y sed - i /local4.*/d / etc / rsyslog . conf cat / etc / rsyslog . conf EOF local4 . * / var / log / slapd . log EOF service rsyslog restart cd / etc / openldap / cp / usr / share / openldap - servers / slapd . conf . obsolete slapd . conf slappasswd ,，, LDAP  New password : Re - enter new password : { SSHA } hEH5ZdU2atsKNI0kUniBdU / 9 eCf + VYkB vim / etc / openldap / slapd . conf # enable server status monitoring ( cn = monitor ) database monitor access to * by dn . exact = gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth read by dn . exact = cn=admin,dc=test,dc=com read by * none ####################################################################### # database definitions ####################################################################### database bdb suffix dc=test,dc=com checkpoint 1024 15 rootdn cn=admin,dc=test,dc=com # Cleartext passwords , especially for the rootdn , should # be avoided . See slappasswd ( 8 ) and slapd . conf ( 5 ) for details . # Use of strong authentication encouraged . # rootpw secret # rootpw { crypt } ijFYNcSNctBYg rootpw { SSHA } pfAJm + JJa4ec2y8GjTc8uMEJpoR5YKMn .......  cp / usr / share / openldap - servers / DB_CONFIG . example / var / lib / ldap / DB_CONFIG rm - rf / etc / openldap / slapd . d /* /etc/openldap/slapd.d，ldapadd /etc/init.d/slapd restart chkconfig slap on chkconfig slapd on chown -R ldap.ldap /var/lib/ldap chown -R ldap.ldap /etc/openldap/  slaptest -f /etc/openldap/slapd.conf -F /etc/openldap/slapd.d config file testing succeeded chown -R ldap:ldap /etc/openldap/slapd.d /etc/init.d/slapd restart ，（/etc/passwd/etc/shadow），LDAP，LDAP。 LDAP ldif（），/etc/passwd/etc/shadow。 migrationtoolsLDAP yum install migrationtools -y cd /usr/share/migrationtools/ vim migrate_common.ph # Default DNS domain $DEFAULT_MAIL_DOMAIN = test.com ; # Default base $DEFAULT_BASE = dc=test,dc=com ; K.pl/etc/passwd /etc/shadowLDAP，/tmp/ # ./migrate_base.pl /tmp/base.ldif # ./migrate_passwd.pl /etc/passwd /tmp/passwd.ldif # ./migrate_group.pl /etc/group /tmp/group.ldif L.LDAP，LDAP # ldapadd -x -D cn=admin,dc=example,dc=com -W -f /tmp/base.ldif # ldapadd -x -D cn=admin,dc=example,dc=com -W -f /tmp/passwd.ldif # ldapadd -x -D cn=admin,dc=example,dc=com -W -f /tmp/group.ldif ，LDAP M.slapd # service slapd restart N.NFS，ldapuser1NFS. REDHAT # yum install nfs* -y NFS： # vi /etc/exports -------------- /home/ldapuser1 *(rw,no_root_squash) -------------- nfs： # service rpcbind restart # service nfs restart PS.ldapLDAP DB，。 ： authconfig-tui ，setup Authentication configuration  ，： yum -y install openldap openldap-clients nss-pam-ldapd pam_ldap ： authconfig-tuisetup Authentication configuration ， ”Use LDAP““Use LDAP Authentication”， NEXT，“BASE DN”。，，。 authconfig --enablemkhomedir --disableldaptls --enableldap --enableldapauth --ldapserver=ldap://192.168.18.150, ldap://10.84.126.150,ldap://192.168.200.10 --ldapbasedn= ou=Common Linux servers,dc=synnex,dc=org --update ： /etc/openldap/ldap.conf，： URI ldap://10.11.15.78/ //LDAP BASE dc=52os,dc=net TLS_CACERTDIR /etc/openldap/cacerts /etc/nslcd.conf，： uri ldap://10.11.15.78/ base dc=52os,dc=net ssl no tls_cacertdir /etc/openldap/cacerts （NSS）LDAP， /etc/nsswitch.conf，： passwd: files ldap shadow: files ldap group: files ldap netgroup: files ldap automount: files ldap /etc/pam.d/system-auth，： auth sufficient pam_ldap.so use_first_pass account required pam_unix.so broken_shadow account [default=bad success=ok user_unknown=ignore] pam_ldap.so password sufficient pam_ldap.so use_authtok session required pam_unix.so session optional pam_ldap.so #pam_unix.so session optional pam_mkhomedir.so skel=/etc/skel/ umask=0022 # /etc/sysconfig/authconfig: USELDAPAUTH=yes USELDAP=yes nslcd， service nslcd start chkconfig nslcd on ： testldap server，，： id test ： getent passwd |grep test test。 、: 1. openLDAP，rsyslog。 /etc/openldap/slapd.conf ，： loglevel 1 loglevel，： man slapd.conf /etc/rsyslog.conf： local4.* /var/log/slapd.log rsyslogslapd： service rsyslog restart service slapd restart 2.sudo openldapsudo schemaopenldap cp /usr/share/doc/sudo-1.8.6p3/schema.OpenLDAP /etc/openldap/schema/sudo.schema sudo schema，/etc/openldap/slapd.conf　 ： include /etc/openldap/schema/sudo.schema ： rm -rf /etc/openldap/slapd.d/* sudo -u ldap slaptest -f /etc/openldap/slapd.conf -F /etc/openldap/slapd.d service slapd restart sudo.ldif，： dn: ou=Sudoers,dc=52os,dc=net objectClass: top objectClass: organizationalUnit ou: Sudoers dn: cn=defaults,ou=Sudoers,dc=52os,dc=net objectClass: top objectClass: sudoRole cn: defaults sudoOption: !visiblepw sudoOption: always_set_home sudoOption: env_reset sudoOption: requiretty dn: cn=test,ou=Sudoers,dc=52os,dc=net objectClass: top objectClass: sudoRole cn: test sudoCommand: ALL sudoHost: ALL sudoOption: !authenticate sudoRunAsUser: ALL sudoUser: test ，，ldif。sudotest，，sudo sudo.ldif: ldapadd -x -D cn=admin,dc=52os,dc=net -W -f sudo.ldif ： /etc/sudo-ldap.conf： uri ldap://10.11.15.78 sudoers_base ou=Sudoers,dc=52os,dc=net /etc/nsswitch.conf： Sudoers: files ldap test，sudo 3. Openldap，，。/home ，，，，。 ，，，， ，。 ，nfs，autofs。 nfs： yum install nfs-utils service rpcbind start service nfslock start service nfs start chkconfig。 /etc/exports，： /home *(rw,sync) nfs/home，autofs。 * ipip，nfs，： showmount -e localhost nfs。 autofsnfs-utils，nfs: yum install nfs-utils autofs autofs，/etc/auto.master： /home /etc/auto.nfs /etc/auto.nfs，： * -fstype=nfs 10.11.15.78:/home/ autofs： service autofs start su - test,mount： 10.11.15.78:/home/test on /home/test type nfs (rw,vers=4,addr=10.11.15.78,clientaddr=10.11.15.79) ， ，。 1.：1.TLS 2. 2. 3.web：phpldapadminLDAP Account Manager 、 1.  “could not chdir to home directory /home/user: No such file or directory” ：  /etc/pam.d/password-auth /etc/pam.d/system-auth ： session optional pam_mkhomedir.so skel=/etc/skel/ umask=0022 2.ldif ldap_bind: Invalid credentials (49) rootdn 3.autofs，su - test  Creating directory /home/test . Unable to create and initialize directory /home/test . su: warning: cannot change directory to /home/test: No such file or directory nfs/hometest，，autofs，。 3. LDAP： LDAP，bashopenldap-clients 。 1、 。： a、.schema，ldap ，sldapd.conf； b、，.schema，。 .ldif ，LDIF。、-。：  dn: dc=ldapuser1,ou=People,dc=test,dc=com objectClass: top objectClass: dcObject objectClass: organization .... ，： # ldapadd -x -h 192.168.1.10 -D cn=admin,dc=test,dc=com -W -f info.ldif ldapadd ： -x  -D DN（slapd.conf） -W ，-w password  -f LDIF -h IP 2、 LDAP，，，。，，， 。ldif ，。 # ldapsearch -x -b dc=test,dc=com ，ldapsearch 。，LDAP 。 -b ， 3、 ，： # ldapwhoami -x -D cn=ldapuser1,dc=test,dc=com -w yourpasswd dn:cn=admin,dc=test,dc=com Result: Success (0) 4、 LDIF 。，ldapsearch ： # ldapsearch -x -LLL -b dc=test,dc=com -LLL ，。 ，，： dn: uid=ldapuser1,ou=People,dc=test,dc=com changetype: modify replace: uidNumber uidNumber: 1000 test.ldif，： ldapmodify -x -D cn=admin,dc=test,dc=com -w yourpasswd -f test.ldif a、ldapadd ldapmodify -a  b、，Naming violation，schema，。 5、 ，DN： # ldapdelete -x -D cn=admin,dc=test,dc=com -w yourpasswd -r dc=test,dc=com -r ，。 web yum install httpd php php-bcmath php-gd php-mbstring php-xml php-ldap phpldapadmin vim /etc/httpd/conf.d/phpldapadmin.conf Order Deny,Allow Allow from all /etc/init.d/httpd restart vim /etc/phpldapadmin/config.php 397 //$servers- setValue( server , name , Local LDAP Server ); $servers- setValue( login , attr , dn );   cn=admin,dc=test,dc=com   web LDAP，，，Result: Insufficient access (50) vim /etc/openldap/slapd.conf ，database config（！） access to attrs=userPassword by self write by anonymous auth by * none access to * by * read rm -rf /etc/openldap/slapd.d/* slaptest -f /etc/openldap/slapd.conf -F /etc/openldap/slapd.d chown -R ldap:ldap /etc/openldap/slapd.d service slapd restart https://github.com/koppor/phpLdapPasswd http://tools.ltb-project.org/attachments/download/800/ltb-project-self-service-password-0.9.tar.gz openldap ， https : // github . com / ltb - project / self - service - password [ ltb - project - noarch ] name = LTB project packages ( noarch ) baseurl = http : // ltb - project . org / rpm / $ releasever / noarch enabled = 1 gpgcheck = 0 yum install httpd self - service - password php - mcrypt / etc / httpd / conf / httpd . conf  TraceEnable Off RewriteEngine on RewriteCond % { REQUEST_METHOD } ^ ( TRACE | TRACK ) RewriteRule . * - [ F ] / usr / share / self - service - password / conf / config . inc . php $ ldap_url = ldap://hostname ; $ ldap_starttls = false ; $ ldap_binddn = uid=admin,cn=users,cn=accounts,dc=l,dc=d01,dc=test,dc=com,dc=cn ; $ ldap_bindpw = admin passwd ; $ ldap_base = cn=users,cn=accounts,dc=l,dc=d01,dc=test,dc=com,dc=cn ; $ who_change_password = manager ;  $ mail_address_use_ldap = true ; centos6  $c rypt_tokens = false ; $ keyphrase = hgfrtygfhfgdd ; ， $defa ult_action = sendtoken ;  / usr / share / self - service - password / pages / sendtoken . php  103  $ mailValues = ldap_get_values ( $ ldap , $e ntry , $ mail_attribute ) ; unset ( $ mailValues [ count ] ) ;  $ mailValues = $ login . @test.cn ; # unset ( $ mailValues [ count ] ) ; 127  $ mail = $ mailValue ;  $mail = $mailValues; 201  $ mailcom = /usr/local/bin/sendEmail -s 127.0.0.1 -f test -t . $ mail . -u Reset Ldap Password -m . $ reset_url . ; if ( exec ( $ mailcom ) ) {  if ( send_mail ( $ mailer , $ mail , $ mail_from , $ mail_from_name .. ) { / usr / share / self - service - password / pages / resetbytoken . php 161  $ mailValues = ldap_get_values ( $ ldap , $e ntry , $ mail_attribute ) ; if ( $ mailValues [ count ] 0 ) { $ mail = $ mailValues [ 0 ] ;  $ mailValues = $ login . @test.cn ; if ( $ mailValues ) { $ mail = $ mailValues ; } kvm cpu  grep flag / proc / cpuinfo | egrep vmx|svm  centos6 . 5 yum install kvm kmod - kvm qemu kvm - qemu - img virt - viewer virt - manager bridge - utils tunctl libvirt device - mapper * / etc / init . d / libvirtd start lsmod | grep kvm  virsh - c qemu : /// system list  KVM  Id Name State ---------------------------------- xmanager  1 grep X11Forwarding --color /etc/ssh/sshd_config X11Forwarding yes xshell  X11Forwarding  2 yum install xorg - x11 - xauth xorg - x11 - xinit xorg - x11 - server - utils xorg - x11 - utils xorg - x11 - drv - ati - firmware 3 export DISPLAY = localhost : 10 . 0 4  Unable to set bridge virbr0 forward_delay :  mount - o rw , remount / sys / virt - manager   Bridge  Nat   kvm ： virt - install ： virsh list ： virsh list – all  kvm ： virsh dumpxml name  kvm ： virsh start name ： virsh destroy name ： virsh undefine name ： virsh define file - name . xml console ： virsh console name  ， # virsh edit your vm name ： graphics type = vnc port = -1 / ： graphics type = vnc port = -1 keymap = en-us / ， ， virt - install ， --keymap=en-us  iptables - F  nat  iptables - t nat - A PREROUTING - d 124 . 202 . 158 . 170 （ ip ） - p tcp - m tcp --dport 1937 -j DNAT --to-destination 192.168.122.100:22() iptables - t nat - A POSTROUTING - s 192 . 168 . 122 . 0 / 255 . 255 . 255 . 0 - d 192 . 168 . 122 . 100 - p tcp - m tcp --dport 22 -j SNAT --to-source 192.168.122.1 opennebula  http : // downloads . opennebula . org / packages / centos6 4 . xxx centos7 5 . xxx  epel  gem  wget http : // downloads . opennebula . org / packages / opennebula - 5 . 1 . 80 / centos7 / opennebula - 5 . 1 . 80 - 1 . tar . gz tar - zxf opennebula - 5 . 1 . 80 - 1 . tar . gz cd opennebula - 5 . 1 . 80 - 1 / （） opennebula  opennebula - sunstone ： gem install sinatra builder zendesk_api gem install treetop parse - cron ( opennebula - flow  ) yum localinstall opennebula - 5 . 1 . 80 - 1 . x86_64 . rpm opennebula - server - 5 . 1 . 80 - 1 . x86_64 . rpm opennebula - ruby - 5 . 1 . 80 - 1 . x86_64 . rpm opennebula - common - 5 . 1 . 80 - 1 . x86_64 . rpm opennebula - sunstone - 5 . 1 . 80 - 1 . x86_64 . rpm  kvm  opennebula - node - kvm ： yum install qemu - kvm qemu - kvm - tools libvirt yum localinstall opennebula - node - kvm - 5 . 1 . 80 - 1 . x86_64 . rpm / etc / init . d / libvirtd start ， OpenNebula ，： vi / etc / one / sunstone - server . conf  :host : 0 . 0 . 0 . 0 :port : 9869 systemctl start opennebula systemctl start opennebula - sunstone http : // 192 . 168 . 2 . 150 : 9869  cat / var / lib / one / . one / one_auth oneadmin : 0 dee417dfb22f2372866d686c7b12889  http : // www . chinacloud . cn / show . aspx ? id = 20875 cid = 22 OpenNebula 4 . 10  　　： 　　 CentOS 6 . 6 x86_64 　　： 　　 1 . . 　　 2 .  　　： 　　 cloud . webxury . com 192 . 168 . 15 . 100 (  ) 　　 cloud1 . webxury . com 192 . 168 . 15 . 101 (  ) 　　 storage . webxury . com 192 . 168 . 15 . 200 (  ) 　　 (  ) , IP ,,,,  / etc / hosts ,, SELINUX  IPTABLES ,,., ,,. 　　 　　 1 .  EPEL , EPEL  　　 yum – y install epel - release 　　 2 .  Opennebula  　　# vi / etc / yum . repos . d / opennebula . repo [ opennebula ] name = opennebula baseurl = http : // downloads . opennebula . org / repo / 4 . 10 / CentOS / 6 / x86_64 / enabled = 1 gpgcheck = 0 　　 3 .  (  ) 　　 yum makecache 　　 4 .  Opennebula . 　　 1 . ) # yum – y install opennebula - server opennebula - sunstone 　　： 　　# grep oneadmin / etc / passwd oneadmin : x : 9869 : 9869 :: / var / lib / one : / bin / bash # ls - ld / etc / one / // OpenNebula   drwxr - x --- . 11 root oneadmin 4096 Feb 2 11 : 35 / etc / one / # ls / etc / init . d / opennebula * / etc / init . d / opennebula / etc / init . d / opennebula - occi / etc / init . d / opennebula - sunstone # ls - ld / var / log / one / drwxr - x --- . 2 oneadmin oneadmin 4096 Feb 2 01 : 13 / var / log / one / 　　 2 ) . 　　# / usr / share / one / install_gems lsb_release command not found . If you are using a RedHat based distribution install redhat - lsb Select your distribution or press enter to continue without installing dependencies . 0 . CentOS / RedHat 1 . Ubuntu / Debian 　　, 0 　　 5 .  OpenNebula  sqlite ， MySQL ， 　　 1 ) . mysql  　　 yum – y install mysql mysql - server # service mysqld start # chkconfig mysqld on 　　 MYSQL  (  ) 　　 2 ) . 　　$ mysql - u root - p Enter password : Welcome to the MySQL monitor . [...] mysql GRANT ALL PRIVILEGES ON opennebula . * TO  IDENTIFIED BY  ; Query OK, 0 rows affected (0.00 sec) 　　 3 ) . 　　 mysql SET GLOBAL TRANSACTION ISOLATION LEVEL READ COMMITTED ; 　　 6 .  [、、、： 　　# vi / etc / one / oned . conf … … # DB = [ backend = sqlite ] (  ) # Sample configuration for DB = [ backend = mysql , server = localhost , port = 0 , (  0  MYSQL  3306 , ) user =  , passwd =  , db_name = opennebula ] … … 　　 7 .  sunstone  IP : 　　 vi / etc / one / sunstone - server . conf 　　 : host : 127 . 0 . 0 . 1 　　 : host : 0 . 0 . 0 . 0 　　 8 . 　　# service opennebula start # service opennebula - sunstone start # chkconfig opennebula on # chkconfig opennebula - sunstone on 　　 8 . NFS  　　 vi / etc / exports / var / lib / one / * ( rw , sync , no_subtree_check , root_squash ) 　　 　　# service rpcbind restart # service nfs restart # chkconfig nfs on # chkconfig rpcbind on 　　 9 . SSH  KEY 　　# su - oneadmin $ vi ~/ . ssh / config 　　 　　 Host * StrictHostKeyChecking no UserKnownHostsFile / dev / null 　　 　　$ chmod 600 ~/ . ssh / config 　　 10 . oneadmin  　　# su oneadmin $ passwd oneadmin 　　：， cookie ， OpenNebula Sunstone  Keep me logged in ，，， ok 。 　　 P . S : ， ! 　　， http : // ip : 9869  　　 　　: 　　 cloud . webxury . com 192 . 168 . 15 . 100 (  ) 　　 cloud1 . webxury . com 192 . 168 . 15 . 101 (  ) 　　 storage . webxury . com 192 . 168 . 15 . 200 (  ) 　　 (  ) , IP ,,,,  / etc / hosts ,, SELINUX  IPTABLES ,,. ,,,. 　　 　　 1 . EPEL , EPEL  　　 yum – y install epel - release 　　 2 . Opennebula  　　# vi / etc / yum . repos . d / opennebula . repo [ opennebula ] name = opennebula baseurl = http : // downloads . opennebula . org / repo / 4 . 10 / CentOS / 6 / x86_64 / enabled = 1 gpgcheck = 0 　　 3 . (  ) 　　 yum makecache 　　 4 . 　　 yum – y install opennebula - node - kvm 　　 　　# service messagebus start # service libvirtd start # chkconfig messagebus on # chkconfig libvirtd on 　　 5 . 　　 ifcfg - eth0 , ifcfg - br0 　　: / etc / sysconfig / network - scripts / ifcfg - eth0 　　 eth0 , br0 　　 cd / etc / sysconfig / network - scripts / 　　 cp ifcfg - eth0 ifcfg - br0 　　 eth0 　　 DEVICE = eth0 BOOTPROTO = none NM_CONTROLLED = no ONBOOT = yes TYPE = Ethernet BRIDGE = br0 　　 ifcfg - br0  　　 DEVICE = br0 ( , ) TYPE = Bridge IPADDR = 192 . 168 . 15 . 100 NETMASK = 255 . 255 . 255 . 0 GATEWAY = 192 . 168 . 15 . 1 DNS1 = 8 . 8 . 8 . 8 DNS2 = 8 . 8 . 4 . 4 ONBOOT = yes BOOTPROTO = static NM_CONTROLLED = no 　　 　　# service network restart 　　 6 .  NFS  　　: / etc / fstab 　　 　　 192 . 168 . 15 . 200 : / var / lib / one / var / lib / one / nfs soft , intr , rsize = 8192 , wsize = 8192 , noauto 　　 7 .  oneadmin  　　# passwd oneadmin 　　, SSH , 　　[ oneadmin @ storage ~ ]# su oneadmin [ oneadmin @ storage ~ ]$ ssh - keygen Generating public / private rsa key pair . Enter file in which to save the key ( / var / lib / one / . ssh / id_rsa ) : Enter passphrase ( empty for no passphrase ) : Enter same passphrase again : Your identification has been saved in / var / lib / one / . ssh / id_rsa . Your public key has been saved in / var / lib / one / . ssh / id_rsa . pub .  [ oneadmin @ storage ~ ]$ ssh - copy - id - i / var / lib / one / . ssh / id_rsa . pub oneadmin @ cloud . webxury . com oneadmin @ cloud . webxury . com s password: .ssh/authorized_keys 　　,,,, ssh ,,, ,,,. 　　:, storage  / var / lib / one / ,,  oneadmin , nobody , / etc / idmapd . conf , Nobody - User = XXX  oneadmin , Nobody - Group = XXX  oneadmin ,, service rpcidmapd restart . 　　,, UI . 　　, 2 ,, 3 .. 　　.　　 tmpfs mount - t tmpfs - o size = 20 m tmpfs / mnt / tmp mount - o remount , size = 25 G / data / mysql / data3326 /  20mVM / mnt / tmp ， df ，  / mnt / tmp20m ， tmpfs ，  ，  / mnt / tmp ， tmpfsVM 。 20mVM20m ，  ， tmpfsRM ， 128M ， tmpfs64M ， tmpfs ?  ， VM ，  ，  ， tmpfs 。  。 tmpfs ？ tmpfs tmpfsVM ，  ，  。 #mount - t tmpfs - o size = 2 m tmpfs / tmp 2mVM / tmp 。  / tmp ， tmpfs ，  / tmp ，  。  ，  / etc / fstab tmpfs / tmp tmpfs size = 2 m 0 0 tmpfs tmpfs ， tmpfsweb ， cache ， web ，  。 1.  ， tmpfs Nginx ，  / data / cdn_cachetmpfs 。 proxy_temp_path / data / cdn_cache / proxy_temp_dir ; proxy_cache_path / data / cdn_cache / proxy_cache_dirlevels = 1 : 2 keys_zone = cache_one : 50 m inactive = 1 d 2. phpsessiontmpfs PHPseesion , php . ini ， tmpfs ，  ： session . save_path = “ / data / php_session ” 3. sockettmpfs Web ， PHPFastCGIsocket 、 MySQL mysql . socksocket ， tmpfs 。 4.   ，  ， df – h 。  ， devtmpfs ， tmpfs 。 tmpfs ？ tmpfs tmpfsLinux / Unix 。 tmpfsswap 。 Redhat / CentOSlinux  。  ， df - h64G 。  ， tmpfs  ，  ， tmpfs “  ”。 Linux  ，  VM  ， SWAP ， tmpfs   。 tmpfs tmpfs ，  / dev / shm ，  ，  / dev / shm ，  。  ， tmpfs ，  / dev / shm12K ， 62237 。 [ root@linux-node1 ~ ] # df - h Filesystem Size Used Avail Use % Mounted on / dev / sda3 1.1 T 2.8 G 1.1 T 1 % / devtmpfs 32 G 0 32 G 0 % / dev tmpfs 32 G 12 K 32 G 1 % / dev / shm **  ** [ root@linux-node1 ~ ] # free - m total used free shared buff / cache available Mem : 64152 1444 60467 42 2239 62237 Swap : 16383 0 16383 81M ， tmpfs 。 # ls - lh / usr / local / src / total 81 M - rw - r --r-- 1 root root 81M Apr 14 22:46go1.6.1.linux-amd64.tar.gz # cp / usr / local / src / go1 .6.1 . linux - amd64 . tar . gz / dev / shm /  。  / dev / shm81M ， 62156 。 [ root@linux-node1 ~ ] # df - h Filesystem Size Used Avail Use % Mounted on / dev / sda3 1.1 T 2.8 G 1.1 T 1 % / devtmpfs 32 G 0 32 G 0 % / dev tmpfs 32 G 81 M 32 G 1 % / dev / shm **  ** [ root@linux-node1 ~ ] # free - m total used free shared buff / cache available Mem : 64152 1445 60386 123 2320 62156 Swap : 16383 0 16383   ： 62237 - 62156 = 81 ， 81M 。  ： 123 - 42 = 81 ，  / dev / shmLinux  ， 81M ，  ， tmpfs ，  ，   ，  ，  。 tmpfs  ， tmpfs  ，  mount  ： # mount - t tmpfs tmpfs / mnt / tmp # df - h Filesystem Size Used Avail Use % Mounted on / dev / sda3 1.1 T 2.7 G 1.1 T 1 % / **  ** tmpfs 32 G 0 32 G 0 % / mnt / tmp tmpfs / mnt / tmp ，  ，  ，  ，  ， tmpfs Linux tmpfs  ： size -  tmpfs  ，  。  ( % )  ， 0  。 nr_blocks -  size  ，  PAGE_CACHE_SIZE (  4 KiB ) 。 nr_inodes -  tmpfs  inode  ，  。 k 、 m 、 g 。  # mount - t tmpfs - o size = 1 G tmpfs / mnt / mytmpfs  ，  ( remount ) tmpfs  ： # mount - o remount , size = 512 m / mnt / tmp tmpfs tmpfs ，  。 1.  tmpfs ，  ，  ，  。 tmpf 。 2.   ，  。 tmpfs  。  tmpfs  ，  。  ，  。 3.   ，  ， tmpfs ，  tmpfs 。  ，  ，  。  tmpfs   。 tmpfs tmpfs ， tmpfsweb ， cache ， web ，  。 1.  ， tmpfs Nginx ，  / data / cdn_cachetmpfs 。 proxy_temp_path / data / cdn_cache / proxy_temp_dir ; proxy_cache_path / data / cdn_cache / proxy_cache_dirlevels = 1 : 2 keys_zone = cache_one : 50 m inactive = 1 d 2. phpsessiontmpfs PHPseesion , php . ini ， tmpfs ，  ： session . save_path = “ / data / php_session ” 3. sockettmpfs Web ， PHPFastCGIsocket 、 MySQL mysql . socksocket ， tmpfs 。 4.  ipa-server  00 1 * * * / home / ipabak . sh # !/ bin / bash backupdir =/ var / lib / ipa / backup / / sbin / ipa - backup -- log - file =/ var / lib / ipa / backup / ipa - backup . log find $bac kupdir - name ipa-full-* - type d - mtime + 10 - exec rm - rf {} \\ ; /dev/null 2 1  admin  LDAPTLS_CACERT =/ etc / ipa / ca . crt ldappasswd - D cn=directory manager - W - S uid = admin , cn = users , cn = accounts , dc = l , dc = test1 , dc = com  cat / etc / hosts ip ipaserver  ntpdate 0 . centos . pool . ntp . org yum install ipa - server bind - dyndb - ldap ipa - server - dns ipa - server - install -- uninstall ------------------------------------ NEW ---------------------------------  LDAP  DNS ， ipa - server - install -- hostname = ipaserver -- domain = l . d01 . test . com -- admin - password = 123456 . test -- setup - dns -- no - forwarders -- auto - reverse ------------------------------------ NEW ---------------------------------   ： https : // access . redhat . com / documentation / en - US / Red_Hat_Enterprise_Linux / 7 / html / Linux_Domain_Identity_Authentication_and_Policy_Guide / creating - the - replica . html  server2  yum install ipa - server bind - dyndb - ldap ipa - server - dns HOSTNAME = test1  dns  ldap / etc / resolv . conf nameserver ipaserver  ip hosts  ， xxx . l . xxxx . com  ntpdate  ipa selinux firewalld NetworkManager iptable  ipa - replica - install -- principal admin -- admin - password 123456 . test -- setup - dns -- no - forwarders -- setup - ca # -- setup - kra  ca  dns -- server  server ，  DNS ， LDAP2 ， Client configuration complete . ipa : ERROR Reverse DNS resolution of address Continue ? [ no ]: yes Run connection check to master ipaserver yum install sudo keyutils ipa - client -- nogpgcheck - y yes | ipa - client - install -- hostname = ` echo $ HOSTNAME | tr A - Z a - z ` -- domain = test . com - p admin - w 123456 . test -- mkhomedir - N  / etc / profile  PS1 = [\\u@\\h:\\l \\W] \\\\ $  windows DNS  dns  ! [] ( assets / import . png )  IPA - CLIENT  ntp / usr / sbin / ntpdate 10 . 21 . 10 . 8 rm - f / etc / ipa / ca . crt wget - O / etc / yum . repos . d / test - Base . repo repourl rm - rf / etc / yum . repos . d / cobbler - config . repo mv / etc / yum . repos . d / CentOS - Base . repo {,. bak }  IPA - CLIENT yum install sudo keyutils ipa - client -- nogpgcheck - y yum - y install salt - minion rm - rf / etc / salt /* salt-call --master=ip state.highstate -l debug echo no | ipa-client-install --uninstall rm /etc/ipa/ca.crt -f echo nameserver 192.168.41.113 gt; /etc/resolv.conf echo nameserver 192.168.41.114 gt; gt;/etc/resolv.conf HOSTNAME=`awk -F= /HOSTNAME/{print $2} /etc/sysconfig/network` hostname $HOSTNAME hostname yes|ipa-client-install --hostname=`echo $HOSTNAME |tr A-Z a-z` --domain=test1.com -p admin -w 123456.test --enable-dns-updates -N rm -f /var/lib/sss/db/* service sssd restart SALT salt -v -t 30 * cmd.run id shiwj backup and restore http://www.freeipa.org/page/Backup_and_Restore https://fedoraproject.org/wiki/QA:Testcase_freeipav3_backup_and_restore http://www.freeipa.org/page/V3/Backup_and_Restore https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Identity_Management_Guide/index.html ## ca https://www.freeipa.org/page/Certmonger ， watch -n 1 date -s 2019-01-15 ipa-getcert list|grep exp ipa-getcert list|grep ID ipa-getcert resubmit -i 20150320032117 ipa-getcert resubmit -i 20150320032156 ipa-getcert resubmit -i 201503200324554 4.0+  ipa-cacert-manage renew sendmail yum install sendmail m4 sendmail - cf vim / etc / mail / sendmail . mc  DAEMON_OPTIONS ( ` Port = smtp , Addr = 0 . 0 . 0 . 0 , Name = MTA )dnl vim / etc / mail / access  Connect : 10 . 141 . 10 RELAY  m4 / etc / mail / sendmail . mc / etc / mail / sendmail . cf service sendmail restart  1 、 sendEmail - s   2 、 host  / etc / hosts  127 . 0 . 0 . 1  / etc / sysconfig / network centos7  HOSTNAME =   sendmail sendmail  host ， sendmail  DNS ， / etc / hosts  / etc / mail / service . switch  sendmail hosts files aliases files  / etc / mail / mailertable ， mailserver smtp :[ 1 . 1 . 1 . 1 ]（）；  makemap hash / etc / mail / mailertable / etc / mail / mailertable service sendmail restart","title":"linux-soft"},{"location":"linux-soft/#mkdocs","text":"http : // mkdocs . org yum install python - pip pip install mkdocs pip install mkdocs - windmill mkdocs new [ dir - name ] - Create a new project . mkdocs help - Print this help message . mkdocs serve - a 0 . 0 . 0 . 0 : 8080 mkdocs build -- clean mkdocs build  find . - name *.md | awk - F / {print $3} | while read line ; do grep $line mkdocs.yml ; if [ $? -ne 0 ];then echo $line /tmp/diff; fi; done","title":"mkdocs"},{"location":"linux-soft/#ntopng","text":"http : // packages . ntop . org / centos - stable / wget http : // packages . ntop . org / centos - stable / ntop . repo - O / etc / yum . repos . d / ntop . repo yum install pfring n2disk nprobe ntopng ntopng - data cento pfring - drivers - zc - dkms redis systemctl start redis systemctl start ntopng IP : 3000 admin / admin","title":"ntopng"},{"location":"linux-soft/#dokuwiki","text":"、 : yum install httpd php php - gd php - ldap 、 1 .  dokuwiki  # wget http : // download . dokuwiki . org / src / dokuwiki / dokuwiki - stable . tgz 2 .  # tar - zvxf dokuwiki - stable . tgz //  # cd dokuwiki - 2016 - 06 - 26 a //  # cp - R dokuwiki - 2016 - 06 - 26 a / home / www / dokuwiki //  # chown - R www : www / home / www //  root  www  (  nginx  ) ： http : //  ip / install . php ： ， zh ，， ，， install . php ， 、 LDAP  1 、 LDAP  2 、 - ","title":"dokuwiki"},{"location":"linux-soft/#phpproxy","text":"wget https : // www . php - proxy . com / download / php - proxy . zip  / var / www / chmod 777 / vat / www - R vim / var / www / templates / url_form . php  style div id = top_form style = display:none;  form vim vendor / athlon1600 / php - proxy / src / helpers . php  http  https ，， nginx  yum install php - fpm php - curl php - mbstring youtube - dl root / var / www ; location / { index index . php ; } location ~ \\. php $ { fastcgi_pass 127 . 0 . 0 . 1 : 9000 ; fastcgi_index index . php ; fastcgi_param SCRIPT_FILENAME $d ocument_root $fa stcgi_script_name ; include fastcgi_params ; } apache yum install httpd php php - curl php - mbstring youtube - dl cd / etc / httpd rm conf . d / welcome . conf vim conf / httpd . conf  index . php IfModule dir_module DirectoryIndex index . html index . php / IfModule  php - proxy VirtualHost * : 80 DocumentRoot / var / www / / VirtualHost ServerLimit 10 IfModule mpm_prefork_module StartServers 5 MinSpareServers 5 MaxSpareServers 10 MaxClients 10 MaxRequestsPerChild 0 / IfModule ExtendedStatus On Location / proxy - status SetHandler server - status / Location","title":"phpproxy"},{"location":"linux-soft/#solr","text":"： ： http : //lucene.apache.org/solr/ ： http : //mirrors.cnnic.cn/apache/lucene/solr/ ：  apache java yum install java httpd java – version  java  openjdk version 1.8.0_65 OpenJDK Runtime Environment ( build 1.8.0 _65 - b17 ) OpenJDK 64 - Bit Server VM ( build 25.65 - b01 , mixed mode ) tar - zxf solr - 5.3.1 . tgz cd solr - 5.3.1 /  . / bin / solr start - e cloud - noprompt  . / bin / post - c gettingstarted  （） . / bin / solr stop - all ; rm - Rf example / cloud /  . / bin / post - c gettingstarted - d delete id SP2514N /id /delete ， */ 1 * * * * / bin / bash / root / add_file_solr . sh / dev / null ： #!/usr/bin/env bash file = ` find / var / www / html / logfile - type f - amin 1 ` for i in $ file do if [ $ i == ]; then / root / solr - 5.3.1 / bin / post - c gettingstarted $ i else exit fi done  http : //localhost:8983/solr  http : //localhost:8983/solr/gettingstarted/browse Documents （ solr command ）  add doc fieldname = url http : //localhost/myBlog/solr-rocks.html /field field name = title Solr Search is Simply Great / field field name = keywords solr , lucene , enterprise , search / field fieldname = creationDate 2007 - 01 - 06 T05 : 04 : 00.000 Z / field field name = rating 10 / field field name = content Solr is a really great open source searchserver . It scales , it s easy to configure and the Solr community is reallysupportive . / field field name = published on / field / doc / add  ID  delete id 0513 8022 / id / delete  delete query id : IW - 02 / query / delete  delete query *:* / query / delete Apache  Vim / etc / httpd / conf / httpd . conf  LoadModule proxy_module modules / mod_proxy . so  LoadModule proxy_http_module modules / mod_proxy_http . so  ： VirtualHost *: 80 ServerAdmin yunwei @3 mang . com ServerName log .3 mang . com ProxyRequests Off Proxy * AuthType Basic allowoverride AuthConfig order allow , deny allow from all AuthName admin AuthUserFile / etc / httpd / . htpassword  require valid - user / Proxy ProxyPass / solr http : //127.0.0.1:8983/solr ProxyPass / solr / admin / cores http : //127.0.0.1:8983/solr/admin/cores ProxyPassReverse / solr http : //127.0.0.1:8983/solr / VirtualHost htpasswd - cm / etc / httpd / . htpassword admin ， htpasswd - m / etc / httpd / . htpassword test  chown apache . apache / etc / httpd / . htpassword chmod 400 / etc / httpd / . htpassword","title":"solr"},{"location":"linux-soft/#smokeping","text":"https : // oss . oetiker . ch / smokeping / doc / smokeping_install . en . html yum - y install gcc httpd - devel libxml2 - devel libpng - devel glib pango pango - devel freetype freetype - devel fontconfig cairo cairo - devel libart_lgpl libart_lgpl - devel popt - devel rrdtool rrdtool - devel rrdtool - perl fping mod_fcgid perl - devel fcgi perl - Sys - Syslog  rrdtool cgilib fping echoping fcgi wget https : // launchpad . net / cgilib / main / 0 . 5 /+ download / cgilib - 0 . 5 . tar . gz tar zxvf cgilib - 0 . 5 . tar . gz cd cgilib - 0 . 5 make cp libcgi . a / usr / local / lib cp cgi . h / usr / include wget https : // fossies . org / linux / misc / old / echoping - 6 . 0 . 2 . tar . gz tar zxvf echoping - 6 . 0 . 2 . tar . gz cd echoping - 6 . 0 . 2 . / configure -- without - libidn make make install yum install perl - core - y wget https : // oss . oetiker . ch / smokeping / pub / smokeping - 2 . 7 . 2 . tar . gz tar zxvf smokeping - 2 . 7 . 2 . tar . gz cd smokeping - 2 . 7 . 2 . / configure -- prefix =/ usr / local / smokeping gmake install gmake install   smokeping cd / usr / local / smokeping / mkdir cache data var chmod 777 cache data var cd / usr / local / smokeping / htdocs / cp smokeping . fcgi . dist smokeping . fcgi cd / usr / local / smokeping / etc / cp config . dist config chmod 400 / usr / local / smokeping / etc / smokeping_secrets . dist ln - s / usr / local / smokeping / cache / usr / local / smokeping / htdocs / cache  vi / etc / rc . local  nohup / usr / local / smokeping / bin / smokeping -- logfile =/ var / log / smokeping . log 2 1  apache  Alias / smokeping / /usr/local/smokeping/htdocs/ Directory /usr/local/smokeping/ AllowOverride None Options All AddHandler cgi - script . fcgi . cgi Order allow , deny Allow from all apache2 . 4  allow order  Require all granted DirectoryIndex smokeping . fcgi / Directory  apache ， nohup / usr / local / smokeping / bin / smokeping -- logfile =/ var / log / smokeping . log 2 1 kill - 9 ` ps aux | grep smokeping | grep - v grep | awk {print $2} ` nohup / usr / local / smokeping / bin / smokeping -- logfile =/ var / log / smokeping . log 2 1  vim / usr / local / smokeping / etc / config  *** Presentation ***  charset = utf - 8 + TEST menu = TEST title = TEST ################ web server ############################ ++ TEST - web - bbs menu = TEST - web - bbs title = TEST  10 . 0 . 100 . 10 host = 61 . 160 . 248 . 10 ++ TEST - web - main menu = TEST  WEB  title = TEST  WEB  10 . 0 . 100 . 21 host = 10 . 0 . 100 . 21","title":"smokeping"},{"location":"linux-soft/#redmine","text":"http : // www . redmine . org / projects / redmine / wiki / RedmineInstall Step 1 - Redmine application  redmine http : // www . redmine . org / projects / redmine / wiki / Download  gem ， gem sources -- add http : // gems . ruby - china . org / -- remove http : // rubygems . org /  redmine vim Gemfile  source https://gems.ruby-china.org/  MySQL CREATE DATABASE redmine CHARACTER SET utf8 ; CREATE USER redmine @ localhost IDENTIFIED BY my_password ; GRANT ALL PRIVILEGES ON redmine . * TO redmine @ localhost ; For versions of MySQL prior to 5 . 0 . 2 - skip the create user step and instead : GRANT ALL PRIVILEGES ON redmine . * TO redmine @ localhost IDENTIFIED BY my_password ; PostgreSQL CREATE ROLE redmine LOGIN ENCRYPTED PASSWORD my_password NOINHERIT VALID UNTIL infinity ; CREATE DATABASE redmine WITH ENCODING = UTF8 OWNER = redmine ; SQL Server The database , login and user can be created within SQL Server Management Studio with a few clicks . If you prefer the command line option with SQLCMD , here s some basic example: Show SQL Step 3 - Database connection configuration  Copy config / database . yml . example to config / database . yml and edit this file in order to configure your database settings for production environment . Example for a MySQL database using ruby 1 . 8 or jruby : production : adapter : mysql database : redmine host : localhost username : redmine password : my_password Example for a MySQL database using ruby 1 . 9 ( adapter must be set to mysql2 ) : production : adapter : mysql2 database : redmine host : localhost username : redmine password : my_password If your server is not running on the standard port ( 3306 ) , use this configuration instead : production : adapter : mysql database : redmine host : localhost port : 3307 username : redmine password : my_password Example for a PostgreSQL database ( default port ) : production : adapter : postgresql database : your_database_name host : postgres_host username : postgres_user password : postgres_user_password encoding : utf8 schema_search_path : database_schema ( default - public ) Example for a SQL Server database ( default host localhost , default port 1433 ) : production : adapter : sqlserver database : redmine username : redmine # should match the database user name password : redminepassword # should match the login password Step 4 - Dependencies installation  Redmine uses Bundler to manage gems dependencies . gem install bundler Then you can install all the gems required by Redmine using the following command : bundle install -- without development test Optional dependencies RMagick ( allows the use of ImageMagick to manipulate images for PDF and PNG export ) If ImageMagick is not installed on your system , you should skip the installation of the rmagick gem using : bundle install -- without development test rmagick If you have trouble installing rmagick on Windows , refer to this HowTo . Database adapters Redmine automatically installs the adapter gems required by your database configuration by reading it from the config / database . yml file ( eg . if you configured only a connection using the mysql2 adapter , then only the mysql2 gem will be installed ) . Don t forget to re-run bundle install --without development test ... after adding or removing adapters in the config / database . yml file ! Additional dependencies ( Gemfile . local ) If you need to load gems that are not required by Redmine core ( eg . Puma , fcgi ) , create a file named Gemfile . local at the root of your redmine directory . It will be loaded automatically when running bundle install . Example : # Gemfile . local gem puma Step 5 - Session store secret generation This step generates a random key used by Rails to encode cookies storing session data thus preventing their tampering . Generating a new secret token invalidates all existing sessions after restart . with Redmine 1 . 4 . x : bundle exec rake generate_session_store with Redmine 2 . x : bundle exec rake generate_secret_token Alternatively , you can store this secret in config / secrets . yml : http : // guides . rubyonrails . org / upgrading_ruby_on_rails . html # config - secrets - yml Step 6 - Database schema objects creation  Create the database structure , by running the following command under the application root directory : RAILS_ENV = production bundle exec rake db : migrate Windows syntax : set RAILS_ENV = production bundle exec rake db : migrate It will create tables by running all migrations one by one then create the set of the permissions and the application administrator account , named admin . Ubuntu troubleshooting : If you get this error with Ubuntu : Rake aborted ! no such file to load -- net / https Then you need to install libopenssl - ruby1 . 8 just like this : apt - get install libopenssl - ruby1 . 8 . Step 7 - Database default data set Insert default configuration data in database , by running the following command : RAILS_ENV = production bundle exec rake redmine : load_default_data Redmine will prompt you for the data set language that should be loaded ; you can also define the REDMINE_LANG environment variable before running the command to a value which will be automatically and silently picked up by the task . E . g .: Unices : RAILS_ENV = production REDMINE_LANG = fr bundle exec rake redmine : load_default_data Windows : set RAILS_ENV = production set REDMINE_LANG = fr bundle exec rake redmine : load_default_data Step 8 - File system permissions NB : Windows users can skip this section . The user account running the application must have write permission on the following subdirectories : files ( storage of attachments ) log ( application log file production . log ) tmp and tmp / pdf ( create these ones if not present , used to generate PDF documents among other things ) public / plugin_assets ( assets of plugins ) E . g ., assuming you run the application with a redmine user account : mkdir - p tmp tmp / pdf public / plugin_assets chown - R redmine : redmine files log tmp public / plugin_assets chmod - R 755 files log tmp public / plugin_assets Step 9 - Test the installation Test the installation by running WEBrick web server : with Redmine 1 . 4 . x : bundle exec ruby script / server webrick - e production with Redmine 2 . x : bundle exec ruby script / rails server webrick - e production with Redmine 3 . x : bundle exec rails server webrick - e production Once WEBrick has started , point your browser to http : // localhost : 3000 / . You should now see the application welcome page . Note : Webrick is not suitable for production use , please only use webrick for testing that the installation up to this point is functional . Use one of the many other guides in this wiki to setup redmine to use either Passenger ( aka mod_rails ) , FCGI or a Rack server ( Unicorn , Thin , Puma , hellip ;) to serve up your redmine. Step 10 - Logging into the application Use default administrator account to log in : login : admin password : admin You can go to Administration menu and choose Settings to modify most of the application settings . Configuration Redmine settings are defined in a file named config / configuration . yml . If you need to override default application settings , simply copy config / configuration . yml . example to config / configuration . yml and edit the new file ; the file is well commented by itself, so you should have a look at it . These settings may be defined per Rails environment ( production / development / test ) . Important : don t forget to restart the application after any change. Email / SMTP server settings Email configuration is described in a dedicated page . SCM settings This configuration section allows you to : override default commands names if the SCM binaries present in the PATH variable doesn t use the standard name ( Windows . bat / NaNd names won t work) specify the full path to the binary Examples ( with Subversion ) : Command name override : scm_subversion_command : svn_replacement.exe Absolute path : scm_subversion_command : C:\\Program Files\\Subversion\\bin\\svn.exe Attachment storage settings You can set a path where Redmine attachments will be stored which is different from the default files directory of your Redmine instance using the attachments_storage_path setting . Examples : attachments_storage_path : / var / redmine / files attachments_storage_path : D : / redmine / files Logging configuration Redmine defaults to a log level of : info , writing to the log subdirectory . Depending on site usage , this can be a lot of data so to avoid the contents of the logfile growing without bound , consider rotating them , either through a system utility like logrotate or via theconfig / additional_environment . rb file . To use the latter , copy config / additional_environment . rb . example to config / additional_environment . rb and add the following lines . Note that the new logger defaults to a high log level and hence has to be explicitly set to info . # Logger . new ( PATH , NUM_FILES_TO_ROTATE , FILE_SIZE ) config . logger = Logger . new ( /path/to/logfile.log , 2 , 1000000 ) config . logger . level = Logger :: INFO Backups Redmine backups should include : data ( stored in your redmine database ) attachments ( stored in the files directory of your Redmine install ) Here is a simple shell script that can be used for daily backups ( assuming you re using a mysql database): # Database / usr / bin / mysqldump - u username - p password redmine_database | gzip / path / to / backup / db / redmine_ ` date +% y_ % m_ % d `. gz # Attachments rsync - a / path / to / redmine / files / path / to / backup / files Notes on Linux / Unix installation Be sure to disable security hardenning tools during the installation process if you run into bizarre permission problems . These problems are mostly silent and can be caused by tools like extended ACLs , SELinux , or AppArmor . There tools are mostly used in big companies with a strict security policy , default Linux / Unix distributions settings shouldn t be a problem. Notes on Windows installation There is an prebuilt installer of Ruby MRI available from http : // rubyinstaller . org . After installing it , select Start Command Prompt with Ruby in the start menu . Specifying the RAILS_ENV environment variable : When running command as described in this guide , you have to set the RAILS_ENV environment variable using a separate command . I . e . commands with the following syntaxes : RAILS_ENV = production any commmand any commmand RAILS_ENV = production have to be turned into 2 subsequent commands : set RAILS_ENV = production any commmand MySQL gem installation issue : You may need to manually install the mysql gem using the following command : gem install mysql","title":"redmine"},{"location":"linux-soft/#cobbler","text":"http : //blog.chinaunix.net/uid-16728139-id-4174109.html  ipv6 ： cat EOF / etc / modprobe . d / dist . conf alias net - pf - 10 off alias ipv6 off EOF yum install cobbler cobbler - web createrepo yum - utils dhcp httpd tftp cman pykickstart debmirror - y ： 1  cobbler  [ root @ locahost ~ ] # vim / etc / cobbler / settings next_server : 10.3.3.31 server : 10.3.3.31 manage_dhcp : 1 manage_rsync : 1  : [ root @ locahost ~ ] # openssl passwd - 1 - salt cobber 123456 $1$cobber$yV9XfOuaaiVDvImopK7o .1 openssl passwd - 1 - salt   ，， root 。。 [ root @ locahost ~ ] # vim / etc / cobbler / settings default_password_crypted : $1$cobber$yV9XfOuaaiVDvImopK7o.1 2  tfpt  rsync [ root @ locahost ~ ] # vim / etc / xinetd . d / tftp disable = no [ root @ locahost ~ ] # vim / etc / xinetd . d / rsync disable = no  [ root @ locahost ~ ] # / etc / init . d / xinetd restart 3  dhcp  vim / etc / cobbler / dhcp . template subnet 192.168.18.0 netmask 255.255.255.0 { option routers 192.168.18.5 ; option domain - name - servers 192.168.1.1 ; option subnet - mask 255.255.255.0 ; range dynamic - bootp 192.168.18.100 192.168.18.254 ; filename /pxelinux.0 ; default - lease - time 21600 ; max - lease - time 43200 ; next - server $next_server ; } [ root @ locahost ~ ] # vim / etc / debmirror . conf #@dists= sid ; @ sections = main,main/debian-installer,contrib,non-free ; #@arches= i386 ; [ root @ locahost ~ ] # / etc / init . d / cobblerd restart [ root @ locahost ~ ] # / etc / init . d / httpd restart [ root @ locahost ~ ] # / etc / init . d / xinetd restart #[root@locahost ~]# /etc/init.d/dhcpd restart [ root @ locahost ~ ] # cobbler get - loaders downloading http : //cobbler.github.io/loaders/README to /var/lib/cobbler/loaders/README () ......  :  web  htdigest / etc / cobbler / users . digest Cobbler cobbler https : //ip/cobbler_web 1 ： DVD ， [ root @ locahost ~ ] # mkdir - p / mnt / cdrom [ root @ locahost ~ ] # mount / dev / cdrom / mnt / cdrom / [ root @ locahost ~ ] # cobbler import -- path =/ mnt / cdrom / -- name = centos6 .4 -- arch = x86_64 cd / var / lib / cobbler / kickstarts / cp sample_end . ks centos6 . ks cobbler profile profile edit -- name = centos6 .4 -- distro = centos6 .4 -- kickstart =/ var / lib / cobbler / kickstarts / centos6 . ks cobbler report cobbler sync [ root @ locahost ~ ] # / etc / init . d / cobblerd restart [ root @ locahost ~ ] # cobbler sync ，： vim / etc / cobbler / pxe / pxedefault . template DEFAULT menu （）  kickstarts ： cd / var / lib / cobbler / kickstarts # Kickstart  vi / var / lib / cobbler / kickstarts / CentOS - 5.10 - x86_64 . ks # CentOS - 5.10 - x86_64  # Kickstart file automatically generated by anaconda. install url -- url = http : //192.168.21.128/cobbler/ks_mirror/CentOS-5.10-x86_64-x86_64/ lang en_US . UTF - 8 zerombr yes key -- skip keyboard us network -- device eth0 -- bootproto dhcp -- onboot on #network --device eth0 --bootproto static --ip 192.168.21.250 --netmask 255.255.255.0 --gateway 192.168.21.2 -- nameserver 8.8.8.8 -- hostname CentOS5 .10 rootpw -- iscrypted $1$QqobZZ1g$rYnrawi9kYlEeUuq1vcRS / firewall -- enabled -- port = 22 : tcp authconfig -- enableshadow -- enablemd5 selinux -- disabled timezone Asia / Shanghai bootloader -- location = mbr -- driveorder = sda # The following is the partition information you requested # Note that any partitions you deleted are not expressed # here so unless you clear all partitions first, this is # not guaranteed to work #clearpart --linux clearpart -- all -- initlabel part / -- bytes - per - inode = 4096 -- fstype = ext3 -- size = 2048 part / boot -- bytes - per - inode = 4096 -- fstype = ext3 -- size = 128 part swap -- bytes - per - inode = 4096 -- fstype = swap -- size = 500 part / data -- bytes - per - inode = 4096 -- fstype = ext3 -- grow -- size = 1 reboot %packages ntp @ base @ core @ dialup @ editors @ text - internet keyutils trousers fipscheck device - mapper - multipath %post # ntpdate cn . pool . ntp . org hwclock -- systohc echo - e 0 1 * * * root /usr/sbin/ntpdate cn.pool.ntp.org /dev/null / etc / crontab service crond restart #root sed - i s/#PermitRootLogin yes/PermitRootLogin no/g / etc / ssh / sshd_config service sshd restart # for i in ` chkconfig -- list | awk { print $1 } ` ; do if [[ $i = atd || $i = crond || $i = irqbalance || $i = network || $i = sshd || $i = rsyslog || $i = httpd || $i = salt -* || $i = zabbix_ * ]]; then chkconfig -- level 3 $i on else chkconfig $i off fi done grep - v ^# / etc / ssh / sshd_config | grep - v ^$ | grep ^UseDNS no / dev / null if [[ $ ? - ne 0 ]]; then sed - i 122 a \\ UseDNS no / etc / ssh / sshd_config / etc / init . d / sshd restart fi cat / etc / profile EOF if [ $SHELL = /bin/ksh ]; then ulimit - p 16384 ulimit - n 65536 ulimit - c unlimited else ulimit - u 16384 - n 65536 - c unlimited fi EOF source / etc / profile ##set ulimit file cat / etc / security / limits . conf EOF * soft nproc 10000 * hard nproc 16384 * soft nofile 65536 * hard nofile 65536 EOF #Ctrl+Alt+Del sed - i s/ca::ctrlaltdel:\\/sbin\\/shutdown -t3 -r now/#ca::ctrlaltdel:\\/sbin\\/shutdown -t3 -r now/g / etc / inittab # echo - e ulimit -c unlimited / etc / profile echo - e ulimit -s unlimited / etc / profile echo - e ulimit -SHn 65535 / etc / profile source / etc / profile sed - i s/net.ipv4.ip_forward = 0/net.ipv4.ip_forward = 1/g / etc / sysctl . conf echo - e net.core.somaxconn = 262144 / etc / sysctl . conf echo - e net.core.netdev_max_backlog = 262144 / etc / sysctl . conf echo - e net.core.wmem_default = 8388608 / etc / sysctl . conf echo - e net.core.rmem_default = 8388608 / etc / sysctl . conf echo - e net.core.rmem_max = 16777216 / etc / sysctl . conf echo - e net.core.wmem_max = 16777216 / etc / sysctl . conf echo - e net.ipv4.netfilter.ip_conntrack_max = 131072 / etc / sysctl . conf echo - e net.ipv4.netfilter.ip_conntrack_tcp_timeout_established = 180 / etc / sysctl . conf echo - e net.ipv4.route.gc_timeout = 20 / etc / sysctl . conf echo - e net.ipv4.ip_conntrack_max = 819200 / etc / sysctl . conf echo - e net.ipv4.ip_local_port_range = 10024 65535 / etc / sysctl . conf echo - e net.ipv4.tcp_retries2 = 5 / etc / sysctl . conf echo - e net.ipv4.tcp_fin_timeout = 30 / etc / sysctl . conf echo - e net.ipv4.tcp_syn_retries = 1 / etc / sysctl . conf echo - e net.ipv4.tcp_synack_retries = 1 / etc / sysctl . conf echo - e net.ipv4.tcp_timestamps = 0 / etc / sysctl . conf echo - e net.ipv4.tcp_tw_recycle = 1 / etc / sysctl . conf echo - e net.ipv4.tcp_tw_len = 1 / etc / sysctl . conf echo - e net.ipv4.tcp_tw_reuse = 1 / etc / sysctl . conf echo - e net.ipv4.tcp_keepalive_time = 120 / etc / sysctl . conf echo - e net.ipv4.tcp_keepalive_probes = 3 / etc / sysctl . conf echo - e net.ipv4.tcp_keepalive_intvl = 15 / etc / sysctl . conf echo - e net.ipv4.tcp_max_tw_buckets = 36000 / etc / sysctl . conf echo - e net.ipv4.tcp_max_orphans = 3276800 / etc / sysctl . conf echo - e net.ipv4.tcp_max_syn_backlog = 262144 / etc / sysctl . conf echo - e net.ipv4.tcp_wmem = 8192 131072 16777216 / etc / sysctl . conf echo - e net.ipv4.tcp_rmem = 32768 131072 16777216 / etc / sysctl . conf echo - e net.ipv4.tcp_mem = 94500000 915000000 927000000 / etc / sysctl . conf / sbin / sysctl - p # cd / root wget http : //192.168.21.128/cobbler/ks_mirror/config/autoip.sh sh / root / autoip . sh vi / var / www / cobbler / ks_mirror / config / autoip . sh #， Linux  IP 、 DNS 、、 #!/bin/sh ROUTE = $ ( route - n | grep ^0.0.0.0 | awk { print $2 } ) BROADCAST = $ ( / sbin / ifconfig eth0 | grep - i bcast | awk { print $3 } | awk - F : { print $2 } ) HWADDR = $ ( / sbin / ifconfig eth0 | grep - i HWaddr | awk { print $5 } ) IPADDR = $ ( / sbin / ifconfig eth0 | grep inet addr | awk { print $2 } | awk - F : { print $2 } ) NETMASK = $ ( / sbin / ifconfig eth0 | grep inet addr | awk { print $4 } | awk - F : { print $2 } ) cat / etc / sysconfig / network - scripts / ifcfg - eth0 EOF DEVICE = eth0 BOOTPROTO = static BROADCAST = $BROADCAST HWADDR = $HWADDR IPADDR = $IPADDR NETMASK = $NETMASK GATEWAY = $ROUTE ONBOOT = yes EOF IPADDR1 = $ ( echo $IPADDR | awk - F . { print $4 } ) cat / etc / sysconfig / network - scripts / ifcfg - eth1 EOF DEVICE = eth1 BOOTPROTO = static BROADCAST = 10.0.0.255 HWADDR = $ ( / sbin / ifconfig eth1 | grep - i HWaddr | awk { print $5 } ) IPADDR = 10.0.0 . $IPADDR1 NETMASK = 255.255.255.0 ONBOOT = yes EOF HOSTNAME = OsYunWei_HZ_ $ ( echo $IPADDR | awk - F . { print $4 } ) cat / etc / sysconfig / network EOF NETWORKING = yes NETWORKING_IPV6 = no HOSTNAME = $HOSTNAME GATEWAY = $ROUTE EOF echo 127.0.0.1 $HOSTNAME / etc / hosts hostname = $HOSTNAME echo nameserver 8.8.8.8 / etc / resolv . conf echo nameserver 8.8.4.4 / etc / resolv . conf","title":"cobbler"},{"location":"linux-soft/#tcpcopy","text":"wget https : // github . com / session - replay - tools / intercept / archive / master . zip wget https : // github . com / session - replay - tools / tcpcopy / archive / master . zip tomcat  session ， session  redis ，。  tcpcopy ip 192 . 168 . 1 . 6 . / configure make make install / usr / local / tcpcopy / sbin / tcpcopy - x 8180 - 192 . 168 . 1 . 3 : 8080 - s 192 . 168 . 1 . 3 - c 192 . 168 . 1 . 6 ， iptables - I INPUT - s 192 . 168 . 1 . 3 - p tcp --sport 8080-j DROP # tcpdump ，， tcpdump ， iptables  ip  drop ， ， ip ，， tcpdump ，  8180  192 . 168 . 1 . 3  8080 ， - s intercept  - n 3  3  - c  IP  127 . 0 . 0 . 1  62 . 135 . 200 . x  ==============  intercept ip 192 . 168 . 1 . 3  ip_forward yum install libpcap - devel - y . / configure make make install . / intercept - i eth0 - F tcp and src port 8080 - d tomcat  session  - d  - F ","title":"tcpcopy"},{"location":"linux-soft/#ffmpeng","text":" http : // johnvansickle . com / ffmpeg / wget http : // johnvansickle . com / ffmpeg / builds / ffmpeg - git - 64 bit - static . tar . xz  http : // www . yaosansi . com / post / ffmpeg - on - centos /  epel ， rpmforce   yum - y install glibc gcc gcc - c ++ autoconf automake libtool git make nasm pkgconfig SDL - devel a52dec a52dec - devel alsa - lib - devel faac faac - devel faad2 faad2 - devel freetype - devel giflib gsm gsm - devel imlib2 imlib2 - devel lame lame - devel libICE - devel libSM - devel libX11 - devel libXau - devel libXdmcp - devel libXext - devel libXrandr - devel libXrender - devel libXt - devel libogg libvorbis vorbis - tools mesa - libGL - devel mesa - libGLU - devel xorg - x11 - proto - devel zlib - devel libtheora theora - tools ncurses - devel libdc1394 libdc1394 - devel amrnb - devel amrwb - devel opencore - amr - devel cd / opt wget http : // downloads . xvid . org / downloads / xvidcore - 1 . 3 . 2 . tar . gz tar xzvf xvidcore - 1 . 3 . 2 . tar . gz rm - f xvidcore - 1 . 3 . 2 . tar . gz cd xvidcore / build / generic . / configure -- prefix = $HOME/ffmpeg_build make make install cd / opt wget http : // downloads . xiph . org / releases / ogg / libogg - 1 . 3 . 1 . tar . gz tar xzvf libogg - 1 . 3 . 1 . tar . gz rm - f libogg - 1 . 3 . 1 . tar . gz cd libogg - 1 . 3 . 1 . / configure -- prefix = $HOME/ffmpeg_build -- disable - shared make make install cd / opt wget http : // downloads . xiph . org / releases / vorbis / libvorbis - 1 . 3 . 4 . tar . gz tar xzvf libvorbis - 1 . 3 . 4 . tar . gz rm - f libvorbis - 1 . 3 . 4 . tar . gz cd libvorbis - 1 . 3 . 4 . / configure -- prefix = $HOME/ffmpeg_build -- with - ogg = $HOME/ffmpeg_build -- disable - shared make make install cd / opt wget http : // downloads . xiph . org / releases / theora / libtheora - 1 . 1 . 1 . tar . gz tar xzvf libtheora - 1 . 1 . 1 . tar . gz rm - f libtheora - 1 . 1 . 1 . tar . gz cd libtheora - 1 . 1 . 1 . / configure -- prefix = $HOME/ffmpeg_build -- with - ogg = $HOME/ffmpeg_build -- disable - examples -- disable - shared -- disable - sdltest -- disable - vorbistest make make install cd / opt wget http : // downloads . sourceforge . net / opencore - amr / vo - aacenc - 0 . 1 . 2 . tar . gz tar xzvf vo - aacenc - 0 . 1 . 2 . tar . gz rm - f vo - aacenc - 0 . 1 . 2 . tar . gz cd vo - aacenc - 0 . 1 . 2 . / configure -- prefix = $HOME/ffmpeg_build -- disable - shared make install yum - y remove yasm cd / opt wget http : // www . tortall . net / projects / yasm / releases / yasm - 1 . 2 . 0 . tar . gz tar xzfv yasm - 1 . 2 . 0 . tar . gz rm - f yasm - 1 . 2 . 0 . tar . gz cd yasm - 1 . 2 . 0 . / configure -- prefix = $HOME/ffmpeg_build -- bindir = $HOME/bin make install export PATH=$PATH:$HOME/bin cd / opt git clone http : // git . chromium . org / webm / libvpx . git cd libvpx git checkout tags / v1 . 3 . 0 . / configure -- prefix = $HOME/ffmpeg_build -- disable - examples make make install cd / opt git clone git : // git . videolan . org / x264 . git cd x264 . / configure -- prefix = $HOME/ffmpeg_build -- bindir = $HOME/bin -- enable - static make install export LD_LIBRARY_PATH =/ usr / local / lib / :$ HOME / ffmpeg_build / lib / echo / usr / local / lib / etc / ld . so . conf . d / custom - libs . conf echo $ HOME / ffmpeg_build / lib / / etc / ld . so . conf . d / custom - libs . conf ldconfig cd / opt git clone git : // source . ffmpeg . org / ffmpeg . git cd ffmpeg git checkout release / 2 . 2 PKG_CONFIG_PATH = $HOME/ffmpeg_build/lib/pkgconfig export PKG_CONFIG_PATH . / configure -- prefix = $HOME/ffmpeg_build -- extra - cflags = -I$HOME/ffmpeg_build/include -- extra - ldflags = -L$HOME/ffmpeg_build/lib -- bindir = $HOME/bin -- extra - libs =- ldl -- enable - version3 -- enable - libopencore - amrnb -- enable - libopencore - amrwb -- enable - libvpx -- enable - libfaac -- enable - libmp3lame -- enable - libtheora -- enable - libvorbis -- enable - libx264 -- enable - libvo - aacenc -- enable - libxvid -- disable - ffplay -- enable - gpl -- enable - postproc -- enable - nonfree -- enable - avfilter -- enable - pthreads -- arch = x86_64 make install # Test the resulting ffmpeg binary cp $ HOME / bin / ffmpeg / usr / bin / ffmpeg - v","title":"ffmpeng"},{"location":"linux-soft/#openldap","text":"yum install openldap -* db4 -* - y sed - i /local4.*/d / etc / rsyslog . conf cat / etc / rsyslog . conf EOF local4 . * / var / log / slapd . log EOF service rsyslog restart cd / etc / openldap / cp / usr / share / openldap - servers / slapd . conf . obsolete slapd . conf slappasswd ,，, LDAP  New password : Re - enter new password : { SSHA } hEH5ZdU2atsKNI0kUniBdU / 9 eCf + VYkB vim / etc / openldap / slapd . conf # enable server status monitoring ( cn = monitor ) database monitor access to * by dn . exact = gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth read by dn . exact = cn=admin,dc=test,dc=com read by * none ####################################################################### # database definitions ####################################################################### database bdb suffix dc=test,dc=com checkpoint 1024 15 rootdn cn=admin,dc=test,dc=com # Cleartext passwords , especially for the rootdn , should # be avoided . See slappasswd ( 8 ) and slapd . conf ( 5 ) for details . # Use of strong authentication encouraged . # rootpw secret # rootpw { crypt } ijFYNcSNctBYg rootpw { SSHA } pfAJm + JJa4ec2y8GjTc8uMEJpoR5YKMn .......  cp / usr / share / openldap - servers / DB_CONFIG . example / var / lib / ldap / DB_CONFIG rm - rf / etc / openldap / slapd . d /* /etc/openldap/slapd.d，ldapadd /etc/init.d/slapd restart chkconfig slap on chkconfig slapd on chown -R ldap.ldap /var/lib/ldap chown -R ldap.ldap /etc/openldap/  slaptest -f /etc/openldap/slapd.conf -F /etc/openldap/slapd.d config file testing succeeded chown -R ldap:ldap /etc/openldap/slapd.d /etc/init.d/slapd restart ，（/etc/passwd/etc/shadow），LDAP，LDAP。 LDAP ldif（），/etc/passwd/etc/shadow。 migrationtoolsLDAP yum install migrationtools -y cd /usr/share/migrationtools/ vim migrate_common.ph # Default DNS domain $DEFAULT_MAIL_DOMAIN = test.com ; # Default base $DEFAULT_BASE = dc=test,dc=com ; K.pl/etc/passwd /etc/shadowLDAP，/tmp/ # ./migrate_base.pl /tmp/base.ldif # ./migrate_passwd.pl /etc/passwd /tmp/passwd.ldif # ./migrate_group.pl /etc/group /tmp/group.ldif L.LDAP，LDAP # ldapadd -x -D cn=admin,dc=example,dc=com -W -f /tmp/base.ldif # ldapadd -x -D cn=admin,dc=example,dc=com -W -f /tmp/passwd.ldif # ldapadd -x -D cn=admin,dc=example,dc=com -W -f /tmp/group.ldif ，LDAP M.slapd # service slapd restart N.NFS，ldapuser1NFS. REDHAT # yum install nfs* -y NFS： # vi /etc/exports -------------- /home/ldapuser1 *(rw,no_root_squash) -------------- nfs： # service rpcbind restart # service nfs restart PS.ldapLDAP DB，。 ： authconfig-tui ，setup Authentication configuration  ，： yum -y install openldap openldap-clients nss-pam-ldapd pam_ldap ： authconfig-tuisetup Authentication configuration ， ”Use LDAP““Use LDAP Authentication”， NEXT，“BASE DN”。，，。 authconfig --enablemkhomedir --disableldaptls --enableldap --enableldapauth --ldapserver=ldap://192.168.18.150, ldap://10.84.126.150,ldap://192.168.200.10 --ldapbasedn= ou=Common Linux servers,dc=synnex,dc=org --update ： /etc/openldap/ldap.conf，： URI ldap://10.11.15.78/ //LDAP BASE dc=52os,dc=net TLS_CACERTDIR /etc/openldap/cacerts /etc/nslcd.conf，： uri ldap://10.11.15.78/ base dc=52os,dc=net ssl no tls_cacertdir /etc/openldap/cacerts （NSS）LDAP， /etc/nsswitch.conf，： passwd: files ldap shadow: files ldap group: files ldap netgroup: files ldap automount: files ldap /etc/pam.d/system-auth，： auth sufficient pam_ldap.so use_first_pass account required pam_unix.so broken_shadow account [default=bad success=ok user_unknown=ignore] pam_ldap.so password sufficient pam_ldap.so use_authtok session required pam_unix.so session optional pam_ldap.so #pam_unix.so session optional pam_mkhomedir.so skel=/etc/skel/ umask=0022 # /etc/sysconfig/authconfig: USELDAPAUTH=yes USELDAP=yes nslcd， service nslcd start chkconfig nslcd on ： testldap server，，： id test ： getent passwd |grep test test。 、: 1. openLDAP，rsyslog。 /etc/openldap/slapd.conf ，： loglevel 1 loglevel，： man slapd.conf /etc/rsyslog.conf： local4.* /var/log/slapd.log rsyslogslapd： service rsyslog restart service slapd restart 2.sudo openldapsudo schemaopenldap cp /usr/share/doc/sudo-1.8.6p3/schema.OpenLDAP /etc/openldap/schema/sudo.schema sudo schema，/etc/openldap/slapd.conf　 ： include /etc/openldap/schema/sudo.schema ： rm -rf /etc/openldap/slapd.d/* sudo -u ldap slaptest -f /etc/openldap/slapd.conf -F /etc/openldap/slapd.d service slapd restart sudo.ldif，： dn: ou=Sudoers,dc=52os,dc=net objectClass: top objectClass: organizationalUnit ou: Sudoers dn: cn=defaults,ou=Sudoers,dc=52os,dc=net objectClass: top objectClass: sudoRole cn: defaults sudoOption: !visiblepw sudoOption: always_set_home sudoOption: env_reset sudoOption: requiretty dn: cn=test,ou=Sudoers,dc=52os,dc=net objectClass: top objectClass: sudoRole cn: test sudoCommand: ALL sudoHost: ALL sudoOption: !authenticate sudoRunAsUser: ALL sudoUser: test ，，ldif。sudotest，，sudo sudo.ldif: ldapadd -x -D cn=admin,dc=52os,dc=net -W -f sudo.ldif ： /etc/sudo-ldap.conf： uri ldap://10.11.15.78 sudoers_base ou=Sudoers,dc=52os,dc=net /etc/nsswitch.conf： Sudoers: files ldap test，sudo 3. Openldap，，。/home ，，，，。 ，，，， ，。 ，nfs，autofs。 nfs： yum install nfs-utils service rpcbind start service nfslock start service nfs start chkconfig。 /etc/exports，： /home *(rw,sync) nfs/home，autofs。 * ipip，nfs，： showmount -e localhost nfs。 autofsnfs-utils，nfs: yum install nfs-utils autofs autofs，/etc/auto.master： /home /etc/auto.nfs /etc/auto.nfs，： * -fstype=nfs 10.11.15.78:/home/ autofs： service autofs start su - test,mount： 10.11.15.78:/home/test on /home/test type nfs (rw,vers=4,addr=10.11.15.78,clientaddr=10.11.15.79) ， ，。 1.：1.TLS 2. 2. 3.web：phpldapadminLDAP Account Manager 、 1.  “could not chdir to home directory /home/user: No such file or directory” ：  /etc/pam.d/password-auth /etc/pam.d/system-auth ： session optional pam_mkhomedir.so skel=/etc/skel/ umask=0022 2.ldif ldap_bind: Invalid credentials (49) rootdn 3.autofs，su - test  Creating directory /home/test . Unable to create and initialize directory /home/test . su: warning: cannot change directory to /home/test: No such file or directory nfs/hometest，，autofs，。 3. LDAP： LDAP，bashopenldap-clients 。 1、 。： a、.schema，ldap ，sldapd.conf； b、，.schema，。 .ldif ，LDIF。、-。：  dn: dc=ldapuser1,ou=People,dc=test,dc=com objectClass: top objectClass: dcObject objectClass: organization .... ，： # ldapadd -x -h 192.168.1.10 -D cn=admin,dc=test,dc=com -W -f info.ldif ldapadd ： -x  -D DN（slapd.conf） -W ，-w password  -f LDIF -h IP 2、 LDAP，，，。，，， 。ldif ，。 # ldapsearch -x -b dc=test,dc=com ，ldapsearch 。，LDAP 。 -b ， 3、 ，： # ldapwhoami -x -D cn=ldapuser1,dc=test,dc=com -w yourpasswd dn:cn=admin,dc=test,dc=com Result: Success (0) 4、 LDIF 。，ldapsearch ： # ldapsearch -x -LLL -b dc=test,dc=com -LLL ，。 ，，： dn: uid=ldapuser1,ou=People,dc=test,dc=com changetype: modify replace: uidNumber uidNumber: 1000 test.ldif，： ldapmodify -x -D cn=admin,dc=test,dc=com -w yourpasswd -f test.ldif a、ldapadd ldapmodify -a  b、，Naming violation，schema，。 5、 ，DN： # ldapdelete -x -D cn=admin,dc=test,dc=com -w yourpasswd -r dc=test,dc=com -r ，。 web yum install httpd php php-bcmath php-gd php-mbstring php-xml php-ldap phpldapadmin vim /etc/httpd/conf.d/phpldapadmin.conf Order Deny,Allow Allow from all /etc/init.d/httpd restart vim /etc/phpldapadmin/config.php 397 //$servers- setValue( server , name , Local LDAP Server ); $servers- setValue( login , attr , dn );   cn=admin,dc=test,dc=com   web LDAP，，，Result: Insufficient access (50) vim /etc/openldap/slapd.conf ，database config（！） access to attrs=userPassword by self write by anonymous auth by * none access to * by * read rm -rf /etc/openldap/slapd.d/* slaptest -f /etc/openldap/slapd.conf -F /etc/openldap/slapd.d chown -R ldap:ldap /etc/openldap/slapd.d service slapd restart https://github.com/koppor/phpLdapPasswd http://tools.ltb-project.org/attachments/download/800/ltb-project-self-service-password-0.9.tar.gz","title":"openldap"},{"location":"linux-soft/#openldap_1","text":"， https : // github . com / ltb - project / self - service - password [ ltb - project - noarch ] name = LTB project packages ( noarch ) baseurl = http : // ltb - project . org / rpm / $ releasever / noarch enabled = 1 gpgcheck = 0 yum install httpd self - service - password php - mcrypt / etc / httpd / conf / httpd . conf  TraceEnable Off RewriteEngine on RewriteCond % { REQUEST_METHOD } ^ ( TRACE | TRACK ) RewriteRule . * - [ F ] / usr / share / self - service - password / conf / config . inc . php $ ldap_url = ldap://hostname ; $ ldap_starttls = false ; $ ldap_binddn = uid=admin,cn=users,cn=accounts,dc=l,dc=d01,dc=test,dc=com,dc=cn ; $ ldap_bindpw = admin passwd ; $ ldap_base = cn=users,cn=accounts,dc=l,dc=d01,dc=test,dc=com,dc=cn ; $ who_change_password = manager ;  $ mail_address_use_ldap = true ; centos6  $c rypt_tokens = false ; $ keyphrase = hgfrtygfhfgdd ; ， $defa ult_action = sendtoken ;  / usr / share / self - service - password / pages / sendtoken . php  103  $ mailValues = ldap_get_values ( $ ldap , $e ntry , $ mail_attribute ) ; unset ( $ mailValues [ count ] ) ;  $ mailValues = $ login . @test.cn ; # unset ( $ mailValues [ count ] ) ; 127  $ mail = $ mailValue ;  $mail = $mailValues; 201  $ mailcom = /usr/local/bin/sendEmail -s 127.0.0.1 -f test -t . $ mail . -u Reset Ldap Password -m . $ reset_url . ; if ( exec ( $ mailcom ) ) {  if ( send_mail ( $ mailer , $ mail , $ mail_from , $ mail_from_name .. ) { / usr / share / self - service - password / pages / resetbytoken . php 161  $ mailValues = ldap_get_values ( $ ldap , $e ntry , $ mail_attribute ) ; if ( $ mailValues [ count ] 0 ) { $ mail = $ mailValues [ 0 ] ;  $ mailValues = $ login . @test.cn ; if ( $ mailValues ) { $ mail = $ mailValues ; }","title":"openldap"},{"location":"linux-soft/#kvm","text":"cpu  grep flag / proc / cpuinfo | egrep vmx|svm  centos6 . 5 yum install kvm kmod - kvm qemu kvm - qemu - img virt - viewer virt - manager bridge - utils tunctl libvirt device - mapper * / etc / init . d / libvirtd start lsmod | grep kvm  virsh - c qemu : /// system list  KVM  Id Name State ---------------------------------- xmanager  1 grep X11Forwarding --color /etc/ssh/sshd_config X11Forwarding yes xshell  X11Forwarding  2 yum install xorg - x11 - xauth xorg - x11 - xinit xorg - x11 - server - utils xorg - x11 - utils xorg - x11 - drv - ati - firmware 3 export DISPLAY = localhost : 10 . 0 4  Unable to set bridge virbr0 forward_delay :  mount - o rw , remount / sys / virt - manager   Bridge  Nat   kvm ： virt - install ： virsh list ： virsh list – all  kvm ： virsh dumpxml name  kvm ： virsh start name ： virsh destroy name ： virsh undefine name ： virsh define file - name . xml console ： virsh console name  ， # virsh edit your vm name ： graphics type = vnc port = -1 / ： graphics type = vnc port = -1 keymap = en-us / ， ， virt - install ， --keymap=en-us  iptables - F  nat  iptables - t nat - A PREROUTING - d 124 . 202 . 158 . 170 （ ip ） - p tcp - m tcp --dport 1937 -j DNAT --to-destination 192.168.122.100:22() iptables - t nat - A POSTROUTING - s 192 . 168 . 122 . 0 / 255 . 255 . 255 . 0 - d 192 . 168 . 122 . 100 - p tcp - m tcp --dport 22 -j SNAT --to-source 192.168.122.1","title":"kvm"},{"location":"linux-soft/#opennebula","text":" http : // downloads . opennebula . org / packages / centos6 4 . xxx centos7 5 . xxx  epel  gem  wget http : // downloads . opennebula . org / packages / opennebula - 5 . 1 . 80 / centos7 / opennebula - 5 . 1 . 80 - 1 . tar . gz tar - zxf opennebula - 5 . 1 . 80 - 1 . tar . gz cd opennebula - 5 . 1 . 80 - 1 / （） opennebula  opennebula - sunstone ： gem install sinatra builder zendesk_api gem install treetop parse - cron ( opennebula - flow  ) yum localinstall opennebula - 5 . 1 . 80 - 1 . x86_64 . rpm opennebula - server - 5 . 1 . 80 - 1 . x86_64 . rpm opennebula - ruby - 5 . 1 . 80 - 1 . x86_64 . rpm opennebula - common - 5 . 1 . 80 - 1 . x86_64 . rpm opennebula - sunstone - 5 . 1 . 80 - 1 . x86_64 . rpm  kvm  opennebula - node - kvm ： yum install qemu - kvm qemu - kvm - tools libvirt yum localinstall opennebula - node - kvm - 5 . 1 . 80 - 1 . x86_64 . rpm / etc / init . d / libvirtd start ， OpenNebula ，： vi / etc / one / sunstone - server . conf  :host : 0 . 0 . 0 . 0 :port : 9869 systemctl start opennebula systemctl start opennebula - sunstone http : // 192 . 168 . 2 . 150 : 9869  cat / var / lib / one / . one / one_auth oneadmin : 0 dee417dfb22f2372866d686c7b12889  http : // www . chinacloud . cn / show . aspx ? id = 20875 cid = 22 OpenNebula 4 . 10  　　： 　　 CentOS 6 . 6 x86_64 　　： 　　 1 . . 　　 2 .  　　： 　　 cloud . webxury . com 192 . 168 . 15 . 100 (  ) 　　 cloud1 . webxury . com 192 . 168 . 15 . 101 (  ) 　　 storage . webxury . com 192 . 168 . 15 . 200 (  ) 　　 (  ) , IP ,,,,  / etc / hosts ,, SELINUX  IPTABLES ,,., ,,. 　　 　　 1 .  EPEL , EPEL  　　 yum – y install epel - release 　　 2 .  Opennebula  　　# vi / etc / yum . repos . d / opennebula . repo [ opennebula ] name = opennebula baseurl = http : // downloads . opennebula . org / repo / 4 . 10 / CentOS / 6 / x86_64 / enabled = 1 gpgcheck = 0 　　 3 .  (  ) 　　 yum makecache 　　 4 .  Opennebula . 　　 1 . ) # yum – y install opennebula - server opennebula - sunstone 　　： 　　# grep oneadmin / etc / passwd oneadmin : x : 9869 : 9869 :: / var / lib / one : / bin / bash # ls - ld / etc / one / // OpenNebula   drwxr - x --- . 11 root oneadmin 4096 Feb 2 11 : 35 / etc / one / # ls / etc / init . d / opennebula * / etc / init . d / opennebula / etc / init . d / opennebula - occi / etc / init . d / opennebula - sunstone # ls - ld / var / log / one / drwxr - x --- . 2 oneadmin oneadmin 4096 Feb 2 01 : 13 / var / log / one / 　　 2 ) . 　　# / usr / share / one / install_gems lsb_release command not found . If you are using a RedHat based distribution install redhat - lsb Select your distribution or press enter to continue without installing dependencies . 0 . CentOS / RedHat 1 . Ubuntu / Debian 　　, 0 　　 5 .  OpenNebula  sqlite ， MySQL ， 　　 1 ) . mysql  　　 yum – y install mysql mysql - server # service mysqld start # chkconfig mysqld on 　　 MYSQL  (  ) 　　 2 ) . 　　$ mysql - u root - p Enter password : Welcome to the MySQL monitor . [...] mysql GRANT ALL PRIVILEGES ON opennebula . * TO  IDENTIFIED BY  ; Query OK, 0 rows affected (0.00 sec) 　　 3 ) . 　　 mysql SET GLOBAL TRANSACTION ISOLATION LEVEL READ COMMITTED ; 　　 6 .  [、、、： 　　# vi / etc / one / oned . conf … … # DB = [ backend = sqlite ] (  ) # Sample configuration for DB = [ backend = mysql , server = localhost , port = 0 , (  0  MYSQL  3306 , ) user =  , passwd =  , db_name = opennebula ] … … 　　 7 .  sunstone  IP : 　　 vi / etc / one / sunstone - server . conf 　　 : host : 127 . 0 . 0 . 1 　　 : host : 0 . 0 . 0 . 0 　　 8 . 　　# service opennebula start # service opennebula - sunstone start # chkconfig opennebula on # chkconfig opennebula - sunstone on 　　 8 . NFS  　　 vi / etc / exports / var / lib / one / * ( rw , sync , no_subtree_check , root_squash ) 　　 　　# service rpcbind restart # service nfs restart # chkconfig nfs on # chkconfig rpcbind on 　　 9 . SSH  KEY 　　# su - oneadmin $ vi ~/ . ssh / config 　　 　　 Host * StrictHostKeyChecking no UserKnownHostsFile / dev / null 　　 　　$ chmod 600 ~/ . ssh / config 　　 10 . oneadmin  　　# su oneadmin $ passwd oneadmin 　　：， cookie ， OpenNebula Sunstone  Keep me logged in ，，， ok 。 　　 P . S : ， ! 　　， http : // ip : 9869  　　 　　: 　　 cloud . webxury . com 192 . 168 . 15 . 100 (  ) 　　 cloud1 . webxury . com 192 . 168 . 15 . 101 (  ) 　　 storage . webxury . com 192 . 168 . 15 . 200 (  ) 　　 (  ) , IP ,,,,  / etc / hosts ,, SELINUX  IPTABLES ,,. ,,,. 　　 　　 1 . EPEL , EPEL  　　 yum – y install epel - release 　　 2 . Opennebula  　　# vi / etc / yum . repos . d / opennebula . repo [ opennebula ] name = opennebula baseurl = http : // downloads . opennebula . org / repo / 4 . 10 / CentOS / 6 / x86_64 / enabled = 1 gpgcheck = 0 　　 3 . (  ) 　　 yum makecache 　　 4 . 　　 yum – y install opennebula - node - kvm 　　 　　# service messagebus start # service libvirtd start # chkconfig messagebus on # chkconfig libvirtd on 　　 5 . 　　 ifcfg - eth0 , ifcfg - br0 　　: / etc / sysconfig / network - scripts / ifcfg - eth0 　　 eth0 , br0 　　 cd / etc / sysconfig / network - scripts / 　　 cp ifcfg - eth0 ifcfg - br0 　　 eth0 　　 DEVICE = eth0 BOOTPROTO = none NM_CONTROLLED = no ONBOOT = yes TYPE = Ethernet BRIDGE = br0 　　 ifcfg - br0  　　 DEVICE = br0 ( , ) TYPE = Bridge IPADDR = 192 . 168 . 15 . 100 NETMASK = 255 . 255 . 255 . 0 GATEWAY = 192 . 168 . 15 . 1 DNS1 = 8 . 8 . 8 . 8 DNS2 = 8 . 8 . 4 . 4 ONBOOT = yes BOOTPROTO = static NM_CONTROLLED = no 　　 　　# service network restart 　　 6 .  NFS  　　: / etc / fstab 　　 　　 192 . 168 . 15 . 200 : / var / lib / one / var / lib / one / nfs soft , intr , rsize = 8192 , wsize = 8192 , noauto 　　 7 .  oneadmin  　　# passwd oneadmin 　　, SSH , 　　[ oneadmin @ storage ~ ]# su oneadmin [ oneadmin @ storage ~ ]$ ssh - keygen Generating public / private rsa key pair . Enter file in which to save the key ( / var / lib / one / . ssh / id_rsa ) : Enter passphrase ( empty for no passphrase ) : Enter same passphrase again : Your identification has been saved in / var / lib / one / . ssh / id_rsa . Your public key has been saved in / var / lib / one / . ssh / id_rsa . pub .  [ oneadmin @ storage ~ ]$ ssh - copy - id - i / var / lib / one / . ssh / id_rsa . pub oneadmin @ cloud . webxury . com oneadmin @ cloud . webxury . com s password: .ssh/authorized_keys 　　,,,, ssh ,,, ,,,. 　　:, storage  / var / lib / one / ,,  oneadmin , nobody , / etc / idmapd . conf , Nobody - User = XXX  oneadmin , Nobody - Group = XXX  oneadmin ,, service rpcidmapd restart . 　　,, UI . 　　, 2 ,, 3 .. 　　.","title":"opennebula"},{"location":"linux-soft/#tmpfs","text":"mount - t tmpfs - o size = 20 m tmpfs / mnt / tmp mount - o remount , size = 25 G / data / mysql / data3326 /  20mVM / mnt / tmp ， df ，  / mnt / tmp20m ， tmpfs ，  ，  / mnt / tmp ， tmpfsVM 。 20mVM20m ，  ， tmpfsRM ， 128M ， tmpfs64M ， tmpfs ?  ， VM ，  ，  ， tmpfs 。  。 tmpfs ？ tmpfs tmpfsVM ，  ，  。 #mount - t tmpfs - o size = 2 m tmpfs / tmp 2mVM / tmp 。  / tmp ， tmpfs ，  / tmp ，  。  ，  / etc / fstab tmpfs / tmp tmpfs size = 2 m 0 0 tmpfs tmpfs ， tmpfsweb ， cache ， web ，  。 1.  ， tmpfs Nginx ，  / data / cdn_cachetmpfs 。 proxy_temp_path / data / cdn_cache / proxy_temp_dir ; proxy_cache_path / data / cdn_cache / proxy_cache_dirlevels = 1 : 2 keys_zone = cache_one : 50 m inactive = 1 d 2. phpsessiontmpfs PHPseesion , php . ini ， tmpfs ，  ： session . save_path = “ / data / php_session ” 3. sockettmpfs Web ， PHPFastCGIsocket 、 MySQL mysql . socksocket ， tmpfs 。 4.   ，  ， df – h 。  ， devtmpfs ， tmpfs 。 tmpfs ？ tmpfs tmpfsLinux / Unix 。 tmpfsswap 。 Redhat / CentOSlinux  。  ， df - h64G 。  ， tmpfs  ，  ， tmpfs “  ”。 Linux  ，  VM  ， SWAP ， tmpfs   。 tmpfs tmpfs ，  / dev / shm ，  ，  / dev / shm ，  。  ， tmpfs ，  / dev / shm12K ， 62237 。 [ root@linux-node1 ~ ] # df - h Filesystem Size Used Avail Use % Mounted on / dev / sda3 1.1 T 2.8 G 1.1 T 1 % / devtmpfs 32 G 0 32 G 0 % / dev tmpfs 32 G 12 K 32 G 1 % / dev / shm **  ** [ root@linux-node1 ~ ] # free - m total used free shared buff / cache available Mem : 64152 1444 60467 42 2239 62237 Swap : 16383 0 16383 81M ， tmpfs 。 # ls - lh / usr / local / src / total 81 M - rw - r --r-- 1 root root 81M Apr 14 22:46go1.6.1.linux-amd64.tar.gz # cp / usr / local / src / go1 .6.1 . linux - amd64 . tar . gz / dev / shm /  。  / dev / shm81M ， 62156 。 [ root@linux-node1 ~ ] # df - h Filesystem Size Used Avail Use % Mounted on / dev / sda3 1.1 T 2.8 G 1.1 T 1 % / devtmpfs 32 G 0 32 G 0 % / dev tmpfs 32 G 81 M 32 G 1 % / dev / shm **  ** [ root@linux-node1 ~ ] # free - m total used free shared buff / cache available Mem : 64152 1445 60386 123 2320 62156 Swap : 16383 0 16383   ： 62237 - 62156 = 81 ， 81M 。  ： 123 - 42 = 81 ，  / dev / shmLinux  ， 81M ，  ， tmpfs ，  ，   ，  ，  。 tmpfs  ， tmpfs  ，  mount  ： # mount - t tmpfs tmpfs / mnt / tmp # df - h Filesystem Size Used Avail Use % Mounted on / dev / sda3 1.1 T 2.7 G 1.1 T 1 % / **  ** tmpfs 32 G 0 32 G 0 % / mnt / tmp tmpfs / mnt / tmp ，  ，  ，  ，  ， tmpfs Linux tmpfs  ： size -  tmpfs  ，  。  ( % )  ， 0  。 nr_blocks -  size  ，  PAGE_CACHE_SIZE (  4 KiB ) 。 nr_inodes -  tmpfs  inode  ，  。 k 、 m 、 g 。  # mount - t tmpfs - o size = 1 G tmpfs / mnt / mytmpfs  ，  ( remount ) tmpfs  ： # mount - o remount , size = 512 m / mnt / tmp tmpfs tmpfs ，  。 1.  tmpfs ，  ，  ，  。 tmpf 。 2.   ，  。 tmpfs  。  tmpfs  ，  。  ，  。 3.   ，  ， tmpfs ，  tmpfs 。  ，  ，  。  tmpfs   。 tmpfs tmpfs ， tmpfsweb ， cache ， web ，  。 1.  ， tmpfs Nginx ，  / data / cdn_cachetmpfs 。 proxy_temp_path / data / cdn_cache / proxy_temp_dir ; proxy_cache_path / data / cdn_cache / proxy_cache_dirlevels = 1 : 2 keys_zone = cache_one : 50 m inactive = 1 d 2. phpsessiontmpfs PHPseesion , php . ini ， tmpfs ，  ： session . save_path = “ / data / php_session ” 3. sockettmpfs Web ， PHPFastCGIsocket 、 MySQL mysql . socksocket ， tmpfs 。 4. ","title":"tmpfs"},{"location":"linux-soft/#ipa-server","text":" 00 1 * * * / home / ipabak . sh # !/ bin / bash backupdir =/ var / lib / ipa / backup / / sbin / ipa - backup -- log - file =/ var / lib / ipa / backup / ipa - backup . log find $bac kupdir - name ipa-full-* - type d - mtime + 10 - exec rm - rf {} \\ ; /dev/null 2 1  admin  LDAPTLS_CACERT =/ etc / ipa / ca . crt ldappasswd - D cn=directory manager - W - S uid = admin , cn = users , cn = accounts , dc = l , dc = test1 , dc = com  cat / etc / hosts ip ipaserver  ntpdate 0 . centos . pool . ntp . org yum install ipa - server bind - dyndb - ldap ipa - server - dns ipa - server - install -- uninstall ------------------------------------ NEW ---------------------------------  LDAP  DNS ， ipa - server - install -- hostname = ipaserver -- domain = l . d01 . test . com -- admin - password = 123456 . test -- setup - dns -- no - forwarders -- auto - reverse ------------------------------------ NEW ---------------------------------   ： https : // access . redhat . com / documentation / en - US / Red_Hat_Enterprise_Linux / 7 / html / Linux_Domain_Identity_Authentication_and_Policy_Guide / creating - the - replica . html  server2  yum install ipa - server bind - dyndb - ldap ipa - server - dns HOSTNAME = test1  dns  ldap / etc / resolv . conf nameserver ipaserver  ip hosts  ， xxx . l . xxxx . com  ntpdate  ipa selinux firewalld NetworkManager iptable  ipa - replica - install -- principal admin -- admin - password 123456 . test -- setup - dns -- no - forwarders -- setup - ca # -- setup - kra  ca  dns -- server  server ，  DNS ， LDAP2 ， Client configuration complete . ipa : ERROR Reverse DNS resolution of address Continue ? [ no ]: yes Run connection check to master ipaserver yum install sudo keyutils ipa - client -- nogpgcheck - y yes | ipa - client - install -- hostname = ` echo $ HOSTNAME | tr A - Z a - z ` -- domain = test . com - p admin - w 123456 . test -- mkhomedir - N  / etc / profile  PS1 = [\\u@\\h:\\l \\W] \\\\ $  windows DNS  dns  ! [] ( assets / import . png )  IPA - CLIENT  ntp / usr / sbin / ntpdate 10 . 21 . 10 . 8 rm - f / etc / ipa / ca . crt wget - O / etc / yum . repos . d / test - Base . repo repourl rm - rf / etc / yum . repos . d / cobbler - config . repo mv / etc / yum . repos . d / CentOS - Base . repo {,. bak }  IPA - CLIENT yum install sudo keyutils ipa - client -- nogpgcheck - y yum - y install salt - minion rm - rf / etc / salt /* salt-call --master=ip state.highstate -l debug echo no | ipa-client-install --uninstall rm /etc/ipa/ca.crt -f echo nameserver 192.168.41.113 gt; /etc/resolv.conf echo nameserver 192.168.41.114 gt; gt;/etc/resolv.conf HOSTNAME=`awk -F= /HOSTNAME/{print $2} /etc/sysconfig/network` hostname $HOSTNAME hostname yes|ipa-client-install --hostname=`echo $HOSTNAME |tr A-Z a-z` --domain=test1.com -p admin -w 123456.test --enable-dns-updates -N rm -f /var/lib/sss/db/* service sssd restart SALT salt -v -t 30 * cmd.run id shiwj backup and restore http://www.freeipa.org/page/Backup_and_Restore https://fedoraproject.org/wiki/QA:Testcase_freeipav3_backup_and_restore http://www.freeipa.org/page/V3/Backup_and_Restore https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Identity_Management_Guide/index.html ## ca https://www.freeipa.org/page/Certmonger ， watch -n 1 date -s 2019-01-15 ipa-getcert list|grep exp ipa-getcert list|grep ID ipa-getcert resubmit -i 20150320032117 ipa-getcert resubmit -i 20150320032156 ipa-getcert resubmit -i 201503200324554 4.0+  ipa-cacert-manage renew","title":"ipa-server"},{"location":"linux-soft/#sendmail","text":"yum install sendmail m4 sendmail - cf vim / etc / mail / sendmail . mc  DAEMON_OPTIONS ( ` Port = smtp , Addr = 0 . 0 . 0 . 0 , Name = MTA )dnl vim / etc / mail / access  Connect : 10 . 141 . 10 RELAY  m4 / etc / mail / sendmail . mc / etc / mail / sendmail . cf service sendmail restart  1 、 sendEmail - s   2 、 host  / etc / hosts  127 . 0 . 0 . 1  / etc / sysconfig / network centos7  HOSTNAME =   sendmail sendmail  host ， sendmail  DNS ， / etc / hosts  / etc / mail / service . switch  sendmail hosts files aliases files  / etc / mail / mailertable ， mailserver smtp :[ 1 . 1 . 1 . 1 ]（）；  makemap hash / etc / mail / mailertable / etc / mail / mailertable service sendmail restart","title":"sendmail"},{"location":"log-analysis/","text":"elk  Kibana  JDK ElasticSearch redis2 .6 （  ） Logstash （  ）  JDK Logstash (  ，  ，  )  https : // www . elastic . co / downloads https : // mirrors . tuna . tsinghua . edu . cn / ELK /  ElasticSearchLogstashJDK ， JDK ： yum - y install java - 1.8.0 - openjdk java - 1.8.0 - openjdk - devel java - version redis 2 .6  Logstash http : // www . open - open . com / lib / view / open1473661753307 . html Logstash9292 。 rpm - ivh logstash - 2.0.0 - 1. noarch . rpm  / opt / logstash / bin / logstash - e input{stdin{}}output{stdout{codec= rubydebug}} hello world vim / etc / logstash / conf . d / agent . conf input { file { type = ugo_nginx_access ## ,  。  ，  path = /export1/log/access_20150407+00.log ## 。 } file { type = nginx_access path = /usr/local/nginx/logs/python-access.log } } output { #redis 。 redis { host = 103.41.54.16 port = 6379 data_type = list key = logstash } }  / opt / logstash / bin / logstash agent - f / usr / local / logstash / conf / agent . conf  server grok http : // grokdebug . herokuapp . com / / opt / logstash / bin / logstash agent - f / usr / local / logstash / conf / fserver . conf input { redis { host = 127.0.0.1 port = 6379 data_type = list key = logstash type = redis-input } } filter { grok { match = { message = %{COMBINEDAPACHELOG} %{QS:x_forwarded_for} } nginx } geoip { source = clientip target = geoip database = /opt/logstash/GeoLiteCity.dat add_field = [ [geoip ][ coordinates ] , % { [ geoip ][ longitude ] } ] add_field = [ [ geoip ][ coordinates ] , % { [ geoip ][ latitude ] } ] } mutate { convert = [ [ geoip ][ coordinates ] , float ] convert = [ response , integer ] convert = [ bytes , integer ] replace = { type = nginx_access } remove_field = message } date { match = [ timestamp , dd / MMM / yyyy : HH : mm : ss Z ] } mutate { remove_field = timestamp } } output { elasticsearch { hosts = [ 127.0.0.1 : 9200 ] manage_template = true ，geoip， # http://blog.csdn.net/yanggd1987/article/details/50469113 index = logstash - nginx - access -% { + YYYY . MM . dd } } stdout {codec = rubydebug} } ##， logstash 20154。 curl -XDELETE http://10.1.1.99:9200/logstash-2015.04.* ElasticSearch  ElasticSearchHTTP9200，TCP9300。 rpm -ivh elasticsearch-2.0.0.rpm vim /etc/elasticsearch/elasticsearch.yml  node.name: node-1 network.host: 0.0.0.0 path.data: /data/elasticsearch/ http.port: 9200 mkdir -pv /data/elasticsearch chown -R elasticsearch.elasticsearch /data/elasticsearch/ /etc/init.d/elasticsearch start ElasticSearch，200： curl -X GET http://localhost:9200 head wget https://github.com/mobz/elasticsearch-head/archive/master.zip unzip master.zip mv elasticsearch-head-master/ /usr/share/elasticsearch/plugins/head/ http://112.126.80.182:9200/_plugin/head/ ， curl -XPUT http://localhost:9200/logstash-qos -d ，map， { mappings : { _default_ : { properties : { timestamp :{ type : date } } } } } ; Kibana tar - zxf kibana - 4.2.0 - linux - x64 . tar . gz vim . / kibana / config / kibana . yml  elasticsearch . url : http : // 192.168.1.23 : 9200  . / kibana / bin / kibana kibana  ： http : // elasticsearch . cn / question / 232  http : // www .99 ya . net / archives / 523. html （  ） logstatsh http https : //www.elastic.co/blog/introducing-logstash-input-http-plugin How do I use this plugin ? By default it will bind the webserver to all hosts ( 0.0.0.0 ) and open the TCP port 8080 but it s possible configure these settings : input { http { host = 127.0.0.1 # default : 0.0.0.0 port = 31311 # default : 8080 } } That s all you need ! What about security ? You can configure basic authentication by setting a username and password . All requests done to Logstash will then have to set the right credentials or receive a 401 response . Only correctly authenticated requests will produce an event inside of Logstash . For SSL , it is necessary to specify the path to a Java Keystore that contains the certificate that clients use to validate the server . Here s an example : input { port = 3332 user = myuser password = $tr0ngP4ssWD! ssl = on keystore = /tmp/mykeystore.jks keystore_password = keystore_pass } OK , now show me this plugin in action ! Step 1 - starting Logstash with http input : bin / logstash - e input { http { } } output { stdout { codec = rubydebug} } Step 2 - That s it ! To test it , let s issue two requests : % curl - XPUT http : //127.0.0.1:8080/twitter/tweet/1 -d hello % curl - H content-type: application/json - XPUT http : //127.0.0.1:8080/twitter/tweet/1 -d { user : kimchy , post_date : 2009-11-15T14:12:12 , message : trying out Elasticsearch } Result in Logstash : { message = hello , @version = 1 , @timestamp = 2015-05-29T14:49:00.392Z , headers = { content_type = application/x-www-form-urlencoded , request_method = PUT , request_path = /twitter/tweet/1 , request_uri = /twitter/tweet/1 , http_version = HTTP/1.1 , http_user_agent = curl/7.37.1 , http_host = 127.0.0.1:8080 , http_accept = */* , content_length = 5 } } { user = kimchy , post_date = 2009-11-15T14:12:12 , message = trying out Elasticsearch , @version = 1 , @timestamp = 2015-05-29T14:49:04.105Z , headers = { content_type = application/json , request_method = PUT , request_path = /twitter/tweet/1 , request_uri = /twitter/tweet/1 , http_version = HTTP/1.1 , http_user_agent = curl/7.37.1 , http_host = 127.0.0.1:8080 , http_accept = */* , content_length = 110 } } You can see that in the second request , since the content - type was application / json , the body was deserialized and expanded to the event root ( notice the fields user , post_date and message ). Show me more concrete examples of how to use it ! Because , real world examples make everything clearer ! Elastic Watcher Integration In this section , we ’ ll show you how to integrate Elastic Watcher -- the new Elasticsearch plugin for alerting and notification -- with Logstash . Sending notifications to Logstash via this input provides you a powerful toolset to further transform notifications and use Logstash ’ s rich collection of outputs . Imagine that you have indices with Apache logs , and now we want to get a periodic update of how many requests are resulting in a 404 ( Not Found ) response . The required steps for this are : Installing Watcher Creating a new notification on Watcher that every minute reports the number of events that have a 404 response status Start Logstash with the HTTP input Send data to Elasticsearch and watch updates on Logstash Here we go ! 1. Installing Watcher cd elasticsearch - 1.5.2 bin / plugin - i elasticsearch / watcher / latest bin / plugin - i elasticsearch / license / latest bin / elasticsearch # restart the server 2. Creating a watch The Watcher plugin for elasticsearch provides an API to create and manipulate scheduled tasks , or watches . A Watch will query the data in the elasticsearch cluster according to its schedule , look for certain scenarios ( like the presence of an error event ) and execute actions . Examples of actions are sending an email , writing a document to an index , calling an outside HTTP endpoint , and more .. For this test , I created a simple watch that : every minute counts number of HTTP requests that resulted in a 404 posts result to http : //localhost:8080 This is the resulting JSON document I need to send to Watcher : { trigger : { schedule : { cron : 0 0/1 * * * ? } }, input : { search : { request : { indices : [ logstash* ], body : { query : { term : { response : 404 } } } } } }, actions : { my_webhook : { webhook : { auth : { basic : { username : guest , password : guest } }, method : POST , host : 127.0.0.1 , port : 8080 , path : /{{ctx.watch_id}} , body : {{ctx.payload.hits.total}} } } } } To install this watch you need to create it in Elasticsearch by executing a PUT request : curl - XPUT http : //localhost:9200/_watcher/watch/my-watch -d @create_webhook.json 3. Logstash setup wget http : //download.elastic.co/logstash/logstash/logstash-1.5.2.tar.gz tar - zxf logstash - 1.5.2 . tar . gz cd logstash - 1.5.2 bin / logstash - e input { http { } } output { stdout { codec = rubydebug} } 4. Results After launching an ingestion process in another terminal , Logstash starts receiving 1 notification per minute in the form of a HTTP POST : % bin / logstash - e input { http { } } output { stdout { codec = rubydebug} } Logstash startup completed { message = 330 , @version = 1 , @timestamp = 2015-06-02T12:53:00.037Z , headers = { content_type = application/x-www-form-urlencoded , request_method = POST , request_path = /my-watch , request_uri = /my-watch? , http_version = HTTP/1.1 , http_authorization = Basic Z3Vlc3Q6Z3Vlc3Q= , http_accept_charset = UTF-8 , http_cache_control = no-cache , http_pragma = no-cache , http_user_agent = Java/1.8.0_20 , http_host = 127.0.0.1:8080 , http_accept = text/html, image/gif, image/jpeg, *; q=.2, */*; q=.2 , http_connection = keep-alive , content_length = 12 } } { message = 3103 , @version = 1 , @timestamp = 2015-06-02T12:54:00.030Z , headers = { content_type = application/x-www-form-urlencoded , request_method = POST , request_path = /my-watch , request_uri = /my-watch? , http_version = HTTP/1.1 , http_authorization = Basic Z3Vlc3Q6Z3Vlc3Q= , http_accept_charset = UTF-8 , http_cache_control = no-cache , http_pragma = no-cache , http_user_agent = Java/1.8.0_20 , http_host = 127.0.0.1:8080 , http_accept = text/html, image/gif, image/jpeg, *; q=.2, */*; q=.2 , http_connection = keep-alive , content_length = 13 } } { message = 6071 , @version = 1 , @timestamp = 2015-06-02T12:55:00.031Z , headers = { content_type = application/x-www-form-urlencoded , request_method = POST , request_path = /my-watch , request_uri = /my-watch? , http_version = HTTP/1.1 , http_authorization = Basic Z3Vlc3Q6Z3Vlc3Q= , http_accept_charset = UTF-8 , http_cache_control = no-cache , http_pragma = no-cache , http_user_agent = Java/1.8.0_20 , http_host = 127.0.0.1:8080 , http_accept = text/html, image/gif, image/jpeg, *; q=.2, */*; q=.2 , http_connection = keep-alive , content_length = 13 } } A more complex example Now that we know how to trigger notification events from Watcher , we can leverage the plugin ecosystem in Logstash to escalate notifications depending in a certain criteria . This following config will : continuously update the number of 404 requests in statsd if the count reaches 10000 then send a message to HipChat , or if reaches 40000 , notify PagerDuty . input { http { } } filter { if [ headers ][ request_path ] == /my-watch { mutate { convert = [ message , integer ] } } } output { if [ headers ][ request_path ] == /my-watch { if [ message ] 40000 { # way too many , notify pagerduty pagerduty { description = %{host} - Apache: Very high number of 404 details = { timestamp = %{@timestamp} message = %{message} } service_key = apikeyforlogstashservice incident_key = logstash/apacheservice } } else if [ message ] 10000 { # unusual amount , notify devs in hipchat hipchat { from = logstash room_id = dev token = [api key] format = Very high number of 404 requests: %{message} } } # always update count of 404 in statsd statsd { gauge = [ http.status.404 , %{message} ] } } } geoip wget http : // geolite . maxmind . com / download / geoip / database / GeoLiteCountry / GeoIP . dat . gz wget http : // geolite . maxmind . com / download / geoip / database / GeoLiteCity . dat . gz elasticsearch  curl - XGET http://localhost:9200/_cat/indices/*?v  curl - XDELETE http://127.0.0.1:9200/winlogbeat-2016* curl - XDELETE http://127.0.0.1:9200/winlogbeat-2017.07.20  curl http : // 127 . 0 . 0 . 1 : 9200 / _nodes / hot_threads  curl - XGET http://localhost:9200/_cluster/stats?human pretty  curl - XGET http : // 127 . 0 . 0 . 1 : 9200 / _nodes / stats / thread_pool ? pretty  curl - XGET http : // 127 . 0 . 0 . 1 : 9200 / _cluster / settings  curl - XGET http : // 127 . 0 . 0 . 1 : 9200 / logstash - nginx - access - 2017 . 10 . 26 / _settings  egrep - v ^#|^$ / etc / elasticsearch / elasticsearch . yml cluster . name : es1 #   node . name : node - 1 # ， network . host : 0 . 0 . 0 . 0 path . data : / data / elasticsearch / http . port : 9200 discovery . zen . ping . multicast . enabled : false ##  discovery . zen . ping . unicast . hosts : [ 10.51.48.109 , 10.171.32.72 ] # #   logstash grop grok http://grokdebug.herokuapp.com/ Example  55.3.244.1 GET /index.html 15824 0.043  %{IP:client} %{WORD:method} %{URIPATHPARAM:request} %{NUMBER:bytes} %{NUMBER:duration} ？ input { file { path = “/var/log/http.log” } } filter { grok { match = [ \"message\", \"%{IP:client} %{WORD:method} %{URIPATHPARAM:request} %{NUMBER:bytes} %{NUMBER:duration}\" ] } } ，？ client: 55.3.244.1 method: GET request: /index.html bytes: 15824 duration: 0.043  (? field_name the pattern here) (? queue_id [0-9A-F]{10,11}) ，。 # in ./patterns/postfix POSTFIX_QUEUEID [0-9A-F]{10,11} filter { grok { patterns_dir = “./patterns” match = [ \"message\", \"%{SYSLOGBASE} %{POSTFIX_QUEUEID:queue_id}: %{GREEDYDATA:syslog_message}\" ] } } ############ logstash，，。 USERNAME [a-zA-Z0-9._-]+ USER %{USERNAME} INT (?:[+-]?(?:[0-9]+)) BASE10NUM (? ![0-9.+-])(? [+-]?(?:(?:[0-9]+(?:.[0-9]+)?)|(?:.[0-9]+))) NUMBER (?:%{BASE10NUM}) BASE16NUM (? ![0-9A-Fa-f])(?:[+-]?(?:0x)?(?:[0-9A-Fa-f]+)) BASE16FLOAT \\b(? ![0-9A-Fa-f.])(?:[+-]?(?:0x)?(?:(?:[0-9A-Fa-f]+(?:.[0-9A-Fa-f]*)?)|(?:.[0-9A-Fa-f]+)))\\b POSINT \\b(?:[1-9][0-9]*)\\b NONNEGINT \\b(?:[0-9]+)\\b WORD \\b\\w+\\b NOTSPACE \\S+ SPACE \\s* DATA .*? GREEDYDATA .* QUOTEDSTRING (? (? !\\)(? ”(? .|[^\\\"]+)+”|”\"|(? ’(? .|[^\\']+)+’)|”|(? (? .|[^\\]+)+)|`)) UUID [A-Fa-f0-9]{8}-(?:[A-Fa-f0-9]{4}-){3}[A-Fa-f0-9]{12} # Networking MAC (?:%{CISCOMAC}|%{WINDOWSMAC}|%{COMMONMAC}) CISCOMAC (?:(?:[A-Fa-f0-9]{4}.){2}[A-Fa-f0-9]{4}) WINDOWSMAC (?:(?:[A-Fa-f0-9]{2}-){5}[A-Fa-f0-9]{2}) COMMONMAC (?:(?:[A-Fa-f0-9]{2}:){5}[A-Fa-f0-9]{2}) IPV6 ((([0-9A-Fa-f]{1,4}:){7}([0-9A-Fa-f]{1,4}|:))|(([0-9A-Fa-f]{1,4}:){6}(:[0-9A-Fa-f]{1,4}|((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3})|:))|(([0-9A-Fa-f]{1,4}:){5}(((:[0-9A-Fa-f]{1,4}){1,2})|:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3})|:))|(([0-9A-Fa-f]{1,4}:){4}(((:[0-9A-Fa-f]{1,4}){1,3})|((:[0-9A-Fa-f]{1,4})?:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){3}(((:[0-9A-Fa-f]{1,4}){1,4})|((:[0-9A-Fa-f]{1,4}){0,2}:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){2}(((:[0-9A-Fa-f]{1,4}){1,5})|((:[0-9A-Fa-f]{1,4}){0,3}:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){1}(((:[0-9A-Fa-f]{1,4}){1,6})|((:[0-9A-Fa-f]{1,4}){0,4}:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:))|(:(((:[0-9A-Fa-f]{1,4}){1,7})|((:[0-9A-Fa-f]{1,4}){0,5}:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:)))(%.+)? IPV4 (? ![0-9])(?:(?:25[0-5]|2[0-4][0-9]|[0-1]?[0-9]{1,2})[.](?:25[0-5]|2[0-4][0-9]|[0-1]?[0-9]{1,2})[.](?:25[0-5]|2[0-4][0-9]|[0-1]?[0-9]{1,2})[.](?:25[0-5]|2[0-4][0-9]|[0-1]?[0-9]{1,2}))(?![0-9]) IP (?:%{IPV6}|%{IPV4}) HOSTNAME \\b(?:[0-9A-Za-z][0-9A-Za-z-]{0,62})(?:.(?:[0-9A-Za-z][0-9A-Za-z-]{0,62}))*(.?|\\b) HOST %{HOSTNAME} IPORHOST (?:%{HOSTNAME}|%{IP}) HOSTPORT (?:%{IPORHOST=~/./}:%{POSINT}) # paths PATH (?:%{UNIXPATH}|%{WINPATH}) UNIXPATH (? /(? [\\w_%!$@:.,-]+|.)*)+ TTY (?:/dev/(pts|tty([pq])?)(\\w+)?/?(?:[0-9]+)) WINPATH (? [A-Za-z]+:|\\)(?:\\[^\\?*]*)+ URIPROTO [A-Za-z]+(+[A-Za-z+]+)? URIHOST %{IPORHOST}(?::%{POSINT:port})? # uripath comes loosely from RFC1738, but mostly from what Firefox # doesn’t turn into %XX URIPATH (?:/[A-Za-z0-9$.+!*'(){},~:;=@#%_-]*)+ #URIPARAM \\?(?:[A-Za-z0-9]+(?:=(?:[^ ]*))?(?: (?:[A-Za-z0-9]+(?:=(?:[^ ]*))?)?)*)? URIPARAM \\?[A-Za-z0-9$.+!*’|(){},~@#% /=:;_?-\\[\\]]* URIPATHPARAM %{URIPATH}(?:%{URIPARAM})? URI %{URIPROTO}://(?:%{USER}(?::[^@]*)?@)?(?:%{URIHOST})?(?:%{URIPATHPARAM})? # Months: January, Feb, 3, 03, 12, December MONTH \\b(?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|Jul(?:y)?|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?)\\b MONTHNUM (?:0?[1-9]|1[0-2]) MONTHDAY (?:(?:0[1-9])|(?:[12][0-9])|(?:3[01])|[1-9]) # Days: Monday, Tue, Thu, etc… DAY (?:Mon(?:day)?|Tue(?:sday)?|Wed(?:nesday)?|Thu(?:rsday)?|Fri(?:day)?|Sat(?:urday)?|Sun(?:day)?) # Years? YEAR (? \\d\\d){1,2} HOUR (?:2[0123]|[01]?[0-9]) MINUTE (?:[0-5][0-9]) # ’60′ is a leap second in most time standards and thus is valid. SECOND (?:(?:[0-5][0-9]|60)(?:[:.,][0-9]+)?) TIME (?! [0-9])%{HOUR}:%{MINUTE}(?::%{SECOND})(?![0-9]) # datestamp is YYYY/MM/DD-HH:MM:SS.UUUU (or something like it) DATE_US %{MONTHNUM}[/-]%{MONTHDAY}[/-]%{YEAR} DATE_EU %{MONTHDAY}[./-]%{MONTHNUM}[./-]%{YEAR} ISO8601_TIMEZONE (?:Z|[+-]%{HOUR}(?::?%{MINUTE})) ISO8601_SECOND (?:%{SECOND}|60) TIMESTAMP_ISO8601 %{YEAR}-%{MONTHNUM}-%{MONTHDAY}[T ]%{HOUR}:?%{MINUTE}(?::?%{SECOND})?%{ISO8601_TIMEZONE}? DATE %{DATE_US}|%{DATE_EU} DATESTAMP %{DATE}[- ]%{TIME} TZ (?:[PMCE][SD]T|UTC) DATESTAMP_RFC822 %{DAY} %{MONTH} %{MONTHDAY} %{YEAR} %{TIME} %{TZ} DATESTAMP_OTHER %{DAY} %{MONTH} %{MONTHDAY} %{TIME} %{TZ} %{YEAR} # Syslog Dates: Month Day HH:MM:SS SYSLOGTIMESTAMP %{MONTH} +%{MONTHDAY} %{TIME} PROG (?:[\\w._/%-]+) SYSLOGPROG %{PROG:program}(?:\\[%{POSINT:pid}\\])? SYSLOGHOST %{IPORHOST} SYSLOGFACILITY %{NONNEGINT:facility}.%{NONNEGINT:priority} HTTPDATE %{MONTHDAY}/%{MONTH}/%{YEAR}:%{TIME} %{INT} # Shortcuts QS %{QUOTEDSTRING} # Log formats SYSLOGBASE %{SYSLOGTIMESTAMP:timestamp} (?:%{SYSLOGFACILITY} )?%{SYSLOGHOST:logsource} %{SYSLOGPROG}: COMMONAPACHELOG %{IPORHOST:clientip} %{USER:ident} %{USER:auth} \\[%{HTTPDATE:timestamp}\\] “(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})” %{NUMBER:response} (?:%{NUMBER:bytes}|-) COMBINEDAPACHELOG %{COMMONAPACHELOG} %{QS:referrer} %{QS:agent} # Log Levels LOGLEVEL ([A-a]lert|ALERT|[T|t]race|TRACE|[D|d]ebug|DEBUG|[N|n]otice|NOTICE|[I|i]nfo|INFO|[W|w]arn?(?:ing)?|WARN?(?:ING)?|[E|e]rr?(?:or)?|ERR?(?:OR)?|[C|c]rit?(?:ical)?|CRIT?(?:ICAL)?|[F|f]atal|FATAL|[S|s]evere|SEVERE|EMERG(?:ENCY)?|[Ee]merg(?:ency)?) awstats http : //blog.csdn.net/wanglipo/article/details/18080819 wget https : //prdownloads.sourceforge.net/awstats/awstats-7.5.tar.gz tar - zxf awstats - 7.5 . tar . gz mv awstats - 7.5 / usr / local / awstats cd / usr / local / awstats / tools / mkdir - pv / var / lib / awstats chmod 777 / var / lib / awstats perl awstats_configure . pl ----- AWStats awstats_configure 1.0 ( build 1.9 ) ( c ) Laurent Destailleur ----- This tool will help you to configure AWStats to analyze statistics for one web server . You can try to use it to let it do all that is possible in AWStats setup , however following the step by step manual setup documentation ( docs / index . html ) is often a better idea . Above all if : - You are not an administrator user , - You want to analyze downloaded log files without web server , - You want to analyze mail or ftp log files instead of web log files , - You need to analyze load balanced servers log files , - You want to understand all possible ways to use AWStats ... Read the AWStats documentation ( docs / index . html ). ----- Running OS detected : Linux , BSD or Unix ----- Check for web server install Enter full config file path of your Web server . Example : / etc / httpd / httpd . conf Example : / usr / local / apache2 / conf / httpd . conf Example : c : \\ Programfiles \\ apachegroup \\ apache \\ conf \\ httpd . conf Config file path ( none to skip web server setup ) : / etc / httpd / conf / httpd . conf  httpd  ----- Check and complete web server config file / etc / httpd / conf / httpd . conf Add Alias / awstatsclasses /usr/local/awstats/wwwroot/classes/ Add Alias / awstatscss /usr/local/awstats/wwwroot/css/ Add Alias / awstatsicons /usr/local/awstats/wwwroot/icon/ Add ScriptAlias / awstats / /usr/local/awstats/wwwroot/cgi-bin/ Add Directory directive AWStats directives added to Apache config file . ----- Update model config file / usr / local / awstats / wwwroot / cgi - bin / awstats . model . conf File awstats . model . conf updated . ----- Need to create a new config file ? Do you want me to build a new AWStats config / profile file ( required if first install ) [ y / N ] ? y ----- Define config file name to create What is the name of your web site or profile analysis ? Example : www . mysite . com Example : demo Your web site , virtual server or profile name : lingling ，，，。 ----- Define config file path In which directory do you plan to store your config file ( s ) ? Default : / etc / awstats Directory path to store config file ( s ) ( Enter for default ) :  awstats ，。 ----- Create config file / etc / awstats / awstats . lingling . conf Config file / etc / awstats / awstats . lingling . conf created . ----- Restart Web server with / sbin / service httpd restart Stopping httpd : [ OK ] Starting httpd : [ OK ] ----- Add update process inside a scheduler Sorry , configure . pl does not support automatic add to cron yet . You can do it manually by adding the following command to your cron : / usr / local / awstats / wwwroot / cgi - bin / awstats . pl - update - config = lingling Or if you have several config files and prefer having only one command : / usr / local / awstats / tools / awstats_updateall . pl now Press ENTER to continue ... A SIMPLE config file has been created : / etc / awstats / awstats . lingling . conf You should have a look inside to check and change manually main parameters . You can then manually update your statistics for lingling with command : perl awstats . pl - update - config = lingling You can also read your statistics for lingling with URL : http : //localhost/awstats/awstats.pl?config=lingling Press ENTER to finish ... 1 、 httpd  log  / var / log / httpd / access . log ，  / etc / awstats / awstats . lingling . conf  LogFile ：  LogFile = /var/log/httpd/mylog.log  LogFile = /var/log/httpd/access_log  LogFile = var/log/access_log.%YYYY-0%MM-0%DD-0.log 2 、，： # cd /usr/local/awstats/wwwroot/cgi-bin/ # perl awstats.pl –update –config=lingling 3 、， awstats ： http : //10.100.10.11/awstats/awstats.pl?config=lingling 4 、，，。 # crontab –e 10 1 * * * / usr / local / awstats / wwwroot / cgi - bin / awstats . pl - update - config = lingling / dev / null 2 1 、 awstats  tomcat  1 、 tomcat ，。  httpd ， awstats  httpd  awstats  tomcat 。  tomcat ： Valve className = org.apache.catalina.valves. AccessLogValve directory= logs prefix = localhost_access_log. suffix = .txt pattern = %h %l %u %t quot;%r quot; %s %b / % ... a :  IP  % ... A :  IP  % ... B : ， HTTP  % ... b : CLF ， HTTP 。 ，‘ - ’ 0 。 %e :  FOOBAR  % ... f :  % ... h :  % ... H  %i : Foobar ，。 % ... l : （ identd ，） % ... m  %n : “ Foobar ” %o : Foobar ， % ... p :  % ... P :  ID 。 % ... q （，“ ? ” ；，。） % ... r :  % ... s : 。， *  *  。 % ... s ，。 % ... t : （） %t :  format  % ... T : ， % ... u : （ auth ；（ %s ） 401 ） % ... U :  URL  % ... v :  ServerName % ... V :  UseCanonicalName   tomcat ： 203.156.200.162 - - [ 29 / Aug / 2012 : 11 : 16 : 58 + 0800 ] GET /front/magazine/getContent.htm?contentId=124504 HTTP/1.1 200 20001 2 、 tomcat ， tomcat  copy  / var / log / httpd / 。  copy ： localhost_access_log .2012 - 08 - 29. txt 3 、 awstats  ( tomcat  httpd ， httpd . conf  ) # cd /usr/local/awstats/tools # perl awstats_configure.pl ----- AWStats awstats_configure 1.0 ( build 1.9 ) ( c ) Laurent Destailleur ----- This tool will help you to configure AWStats to analyze statistics for one web server . You can try to use it to let it do all that is possible in AWStats setup , however following the step by step manual setup documentation ( docs / index . html ) is often a better idea . Above all if : - You are not an administrator user , - You want to analyze downloaded log files without web server , - You want to analyze mail or ftp log files instead of web log files , - You need to analyze load balanced servers log files , - You want to understand all possible ways to use AWStats ... Read the AWStats documentation ( docs / index . html ). ----- Running OS detected : Linux , BSD or Unix ----- Check for web server install Enter full config file path of your Web server . Example : / etc / httpd / httpd . conf Example : / usr / local / apache2 / conf / httpd . conf Example : c : \\ Program files \\ apache group \\ apache \\ conf \\ httpd . conf Config file path ( none to skip web server setup ) : none Your web server config file ( s ) could not be found . You will need to setup your web server manually to declare AWStats script as a CGI , if you want to build reports dynamically . See AWStats setup documentation ( file docs / index . html ) ----- Update model config file / usr / local / awstats / wwwroot / cgi - bin / awstats . model . conf File awstats . model . conf updated . ----- Need to create a new config file ? Do you want me to build a new AWStats config / profile file ( required if first install ) [ y / N ] ? y ----- Define config file name to create What is the name of your web site or profile analysis ? Example : www . mysite . com Example : demo Your web site , virtual server or profile name : buoqu . com ----- Define config file path In which directory do you plan to store your config file ( s ) ? Default : / etc / awstats Directory path to store config file ( s ) ( Enter for default ) : ----- Create config file / etc / awstats / awstats . buoqu . com . conf Config file / etc / awstats / awstats . buoqu . com . conf created . ----- Add update process inside a scheduler Sorry , configure . pl does not support automatic add to cron yet . You can do it manually by adding the following command to your cron : / usr / local / awstats / wwwroot / cgi - bin / awstats . pl - update - config = buoqu . com Or if you have several config files and prefer having only one command : / usr / local / awstats / tools / awstats_updateall . pl now Press ENTER to continue ... A SIMPLE config file has been created : / etc / awstats / awstats . buoqu . com . conf You should have a look inside to check and change manually main parameters . You can then manually update your statistics for buoqu . com with command : perl awstats . pl - update - config = buoqu . com You can also build static report pages for buoqu . com with command : perl awstats . pl - output = pagetype - config = buoqu . com Press ENTER to finish ... 4 、 # vim /etc/awstats/awstats.buoqu.com.conf  LogFile = /var/log/httpd/mylog.log  LogFile = /usr/local/awstats/tools/logresolvemerge.pl /usr/local/awstats/flashlog/china/localhost_access_log.% YYYY - 24 -% MM - 24 -% DD - 24. txt / usr / local / awstats / flashlog / usa / localhost_access_log . % YYYY - 24 -% MM - 24 -% DD - 24. txt | 5 、 httpd ， # service httpd restart # cd /usr/local/awstats/wwwroot/cgi-bin # perl awstats.pl -update -config=buoqu.com Setup ( / etc / awstats / awstats . buoqu . com . conf file , web server or permissions ) may be wrong . Check config file , permissions and AWStats documentation ( in docs directory ). ：。 ：， tomcat 。  / etc / awstats / awstats . buoqu . com . conf # vim /etc/awstats/awstats.buoqu.com.conf LogFormat = 1 LogFormat = %host %other %logname %time1 %methodurl %code %bytesd  # perl awstats.pl -update -config=buoqu.com 6 、： http : //10.100.10.11/awstats/awstats.pl?config=buoqu.com 7 、 crontab 。 ①、，， AllowToUpdateStatsFromBrowser = 1 ，。 ②、“”，， awstats 。 # cd /usr/local/awstats/wwwroot/cgi-bin # vim awstats.model.conf  AllowToUpdateStatsFromBrowser = 0  AllowToUpdateStatsFromBrowser = 1 。 ，。 ： httpd  ③、， apache  # chown apache.apache –R /var/lib/awstats # chmod 755 /var/log/httpd ： 、， awstats 。 IP  wget http : //geolite.maxmind.com/download/geoip/database/GeoLiteCountry/GeoIP.dat.gz wget http : //geolite.maxmind.com/download/geoip/database/GeoLiteCity.dat.gz gunzip GeoIP . dat . gz gunzip GeoLiteCity . dat . gz mv * . dat / opt / yum install GeoIP perl - Geo - IP perl - MCPAN - e install Geo::IP::PurePerl vim / etc / awstats / awstats . www . test . com . conf #： #LoadPlugin= tooltips html #LoadPlugin= decodeutfkeys UTF8 #LoadPlugin= geoip GEOIP_STANDARD /pathto/GeoIP.dat #1429 #LoadPlugin= geoip_city_maxmind GEOIP_STANDARD /pathto/GeoIPCity.dat #1438 ： LoadPlugin = geoip GEOIP_STANDARD /var/geoip/GeoIP.dat LoadPlugin = geoip_city_maxmind GEOIP_STANDARD /var/geoip/GeoLiteCity.dat  QQ  IP ( 1 )  awstats  wwwroot  plugin  cd / usr / local / awstats / wwwroot / cgi - bin / plugins # yum：/usr/share/awstats/wwwroot/cgi-bin/plugins ， wget http : //www.haiyun.me/download/qqwry.pl wget http : //www.haiyun.me/download/qqhostinfo.pm  IP ： update . cz88 . net  windows ， qqwry . dat ，。 ( 2 )  qqwry  awstats  wwwroot  plugin  . ( 3 )  #qqwry.plIP： my $ipfile = ${DIR}/plugins/qqwry.dat ; ( 4 )  awstats #awstats： LoadPlugin = qqhostinfo  rm - rf / var / lib / awstats /*  /usr/local/awstats/wwwroot/cgi-bin/awstats.pl -update -config= www.test.com ------------------------------------------------- #!/usr/bin/env bash rsync -avz /var/lib/awstats/ /usr/local/awstats/var-lib-awstats find /usr/local/awstats/flashlog/ -mtime +1 -exec rm -f {} \\; Date=$(date +%Y-%m-%d -d 1 day ago ) #101.200.131.163 flash china rsync -avz -e ssh -p 27554 10.44.28.154:/usr/local/tomcat/logs/localhost_access_log.$Date.txt /usr/local/awstats/flashlog/china/ rsync -avz -e ssh -p 27554 47.88.7.159:/usr/local/tomcat/logs/localhost_access_log.$Date.txt /usr/local/awstats/flashlog/usa/ /usr/local/awstats/wwwroot/cgi-bin/awstats.pl -update -config=flash # http://monitor.3mang.com/awstats/awstats.pl?config=flash ----------------------------------------------------------- #awstats log  0 1 * * * /bin/bash /usr/local/awstats/scplog.sh /usr/local/awstats/scplog.log 2 1 awstats ： LogFile= /usr/local/nginx/logs/host.access.log ： 1） LogFile= /usr/local/awstats/tools/logresolvemerge.pl /usr/local/nginx/logs/231.pcstars_access.log /usr/local/nginx/logs/232.pcstars_access.log /usr/local/nginx/logs/233.pcstars_access.log /usr/local/nginx/logs/234.pcstars_access.log /usr/local/nginx/logs/mg.pcstars_access.log| 2): LogFile= /usr/local/awstats/tools/logresolvemerge.pl /usr/local/nginx/logs/*.pcstars_access.log| ： awstats logresolvemerge.pl ， | ， awstats，： /usr/local/awstats/tools/awstats_updateall.pl now  /usr/local/awstats/wwwroot/cgi-bin/awstats.pl -update -config=www.nginx.log -configdir= /etc/awstats  PIWIK https : // piwik . org / Google Analytics https : // developers . google . com / analytics /? hl = zh - cn es_date elasticsearchdate，Kibana。。 date： ，。 ，ISO 8601，2015-02-27T00:07Z()、2015-02-27T08:07+08:00(),，，，。，es。，。phpISO 8601，date('c',time()）。 elasticsearchdate，，mapping'date_detection' = false 。 elasticsearchdate，jsondate。jsonelasticsearch，es，esdatedate。esdate，elasticsearchhttps://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-date-format.html。 date，json，es，kibanaes，，8。kibanaesdate，，kibana0，kibana，js，，kibanaes8。kibana“8”。 ：es，，：“2016-07-15T12:58:17.136+0800”。 logstash ， logstash  2  A  B ， A  kafka ， B  es 。  Input { file { path = a type = A } file { path = b type = B } } output { if [ type ] == A { kafka {...} } if [ type ] == B { es {...} } } ： bin / logstash - e input{ file { type = normal path = /data/log/test/abc*.log start_position = beginning exclude = *abc*.log } file { type = error path = /data/log/test/*error*.log start_position = beginning } } output { if [ type ] == error { kafka { bootstrap_servers = 127.0.0.1:9092,127.0.0.1:9092 topic_id = loga } } stdout { codec = rubydebug } } winlogbeat  winlogbeat.yml ignore_older， winlogbeat . event_logs : - name : Application ignore_older : 48 h provider : - Application Error - Application Hang - Windows Error Reporting - EMET - name : Security level : critical , error , warning event_id : 4624 , 4625 , 4700 - 4800 , - 4735 ignore_older : 48 h - name : System level : critical , error , warning ignore_older : 48 h - name : Microsoft - Windows - Windows Defender / Operational include_xml : true ignore_older : 48 h es scripts\\import_dashboards.exe -es http://192.168.33.60:9200  powershell .\\install-service-winlogbeat.ps1 scripts is disabled on this system  Set-ExecutionPolicy RemoteSigned net start/stop winlogbeat  .\\winlogbeat.exe -c .\\winlogbeat.yml filebeat https://www.elastic.co/guide/en/logstash/current/logstash-config-for-filebeat-modules.html#parsing-system Apache 2 Logs MySQL Logs Nginx Logs System Logs Apache 2 Access Logsedit Example Filebeat config: filebeat.prospectors: input_type: log paths: /var/log/apache2/access.log* /var/log/apache2/other_vhosts_access.log* exclude_files: [\".gz$\"] output.logstash: hosts: [\"localhost:5044\"] Example Logstash pipeline config: input { beats { # The port to listen on for filebeat connections. port = 5044 # The IP address to listen for filebeat connections. host = \"0.0.0.0\" } } filter { grok { match = { \"message\" = [\"%{IPORHOST:[apache2][access][remote_ip]} - %{DATA:[apache2][access][user_name]} \\[%{HTTPDATE:[apache2][access][time]}\\] \\\"%{WORD:[apache2][access][method]} %{DATA:[apache2][access][url]} HTTP/%{NUMBER:[apache2][access][http_version]}\\\" %{NUMBER:[apache2][access][response_code]} %{NUMBER:[apache2][access][body_sent][bytes]}( \\\"%{DATA:[apache2][access][referrer]}\\\")?( \\\"%{DATA:[apache2][access][agent]}\\\")?\", \"%{IPORHOST:[apache2][access][remote_ip]} - %{DATA:[apache2][access][user_name]} \\[%{HTTPDATE:[apache2][access][time]}\\] \\\"-\\\" %{NUMBER:[apache2][access][response_code]} -\" ] } remove_field = \"message\" } mutate { add_field = { \"read_timestamp\" = \"%{@timestamp}\" } } date { match = [ \"[apache2][access][time]\", \"dd/MMM/YYYY:H:m:s Z\" ] remove_field = \"[apache2][access][time]\" } useragent { source = \"[apache2][access][agent]\" target = \"[apache2][access][user_agent]\" remove_field = \"[apache2][access][agent]\" } geoip { source = \"[apache2][access][remote_ip]\" target = \"[apache2][access][geoip]\" } } output { elasticsearch { hosts = localhost manage_template = false index = \"%{[@metadata][beat]}-%{+YYYY.MM.dd}\" document_type = \"%{[@metadata][type]}\" } } Apache 2 Error Logsedit Example Filebeat config: filebeat.prospectors: input_type: log paths: /var/log/apache2/error.log* exclude_files: [\".gz$\"] output.logstash: hosts: [\"localhost:5044\"] Example Logstash pipeline config: input { beats { # The port to listen on for filebeat connections. port = 5044 # The IP address to listen for filebeat connections. host = \"0.0.0.0\" } } filter { grok { match = { \"message\" = [\"\\[%{APACHE_TIME:[apache2][error][timestamp]}\\] \\[%{LOGLEVEL:[apache2][error][level]}\\]( \\[client %{IPORHOST:[apache2][error][client]}\\])? %{GREEDYDATA:[apache2][error][message]}\", \"\\[%{APACHE_TIME:[apache2][error][timestamp]}\\] \\[%{DATA:[apache2][error][module]}:%{LOGLEVEL:[apache2][error][level]}\\] \\[pid %{NUMBER:[apache2][error][pid]}(:tid %{NUMBER:[apache2][error][tid]})?\\]( \\[client %{IPORHOST:[apache2][error][client]}\\])? %{GREEDYDATA:[apache2][error][message1]}\" ] } pattern_definitions = { \"APACHE_TIME\" = \"%{DAY} %{MONTH} %{MONTHDAY} %{TIME} %{YEAR}\" } remove_field = \"message\" } mutate { rename = { \"[apache2][error][message1]\" = \"[apache2][error][message]\" } } date { match = [ \"[apache2][error][timestamp]\", \"EEE MMM dd H:m:s YYYY\", \"EEE MMM dd H:m:s.SSSSSS YYYY\" ] remove_field = \"[apache2][error][timestamp]\" } } output { elasticsearch { hosts = localhost manage_template = false index = \"%{[@metadata][beat]}-%{+YYYY.MM.dd}\" document_type = \"%{[@metadata][type]}\" } } MySQL Logsedit Here are some configuration examples for shipping and parsing MySQL error and slowlog logs. MySQL Error Logsedit Example Filebeat config: filebeat.prospectors: input_type: log paths: /var/log/mysql/error.log* /var/log/mysqld.log* exclude_files: [\".gz$\"] output.logstash: hosts: [\"localhost:5044\"] Example Logstash pipeline config: input { beats { # The port to listen on for filebeat connections. port = 5044 # The IP address to listen for filebeat connections. host = \"0.0.0.0\" } } filter { grok { match = { \"message\" = [\"%{LOCALDATETIME:[mysql][error][timestamp]} (\\[%{DATA:[mysql][error][level]}\\] )?%{GREEDYDATA:[mysql][error][message]}\", \"%{TIMESTAMP_ISO8601:[mysql][error][timestamp]} %{NUMBER:[mysql][error][thread_id]} \\[%{DATA:[mysql][error][level]}\\] %{GREEDYDATA:[mysql][error][message1]}\", \"%{GREEDYDATA:[mysql][error][message2]}\"] } pattern_definitions = { \"LOCALDATETIME\" = \"[0-9]+ %{TIME}\" } remove_field = \"message\" } mutate { rename = { \"[mysql][error][message1]\" = \"[mysql][error][message]\" } } mutate { rename = { \"[mysql][error][message2]\" = \"[mysql][error][message]\" } } date { match = [ \"[mysql][error][timestamp]\", \"ISO8601\", \"YYMMdd H:m:s\" ] remove_field = \"[apache2][access][time]\" } } output { elasticsearch { hosts = localhost manage_template = false index = \"%{[@metadata][beat]}-%{+YYYY.MM.dd}\" document_type = \"%{[@metadata][type]}\" } } MySQL Slowlogedit Example Filebeat config: filebeat.prospectors: input_type: log paths: /var/log/mysql/mysql-slow.log* /var/lib/mysql/hostname-slow.log exclude_files: [\".gz$\"] multiline: pattern: \"^# User@Host: \" negate: true match: after output.logstash: hosts: [\"localhost:5044\"] Example Logstash pipeline config: input { beats { # The port to listen on for filebeat connections. port = 5044 # The IP address to listen for filebeat connections. host = \"0.0.0.0\" } } filter { grok { match = { \"message\" = [\"^# User@Host: %{USER:[mysql][slowlog][user]}(\\[[^\\]]+\\])? @ %{HOSTNAME:[mysql][slowlog][host]} \\[(IP:[mysql][slowlog][ip])?\\](\\s*Id:\\s* %{NUMBER:[mysql][slowlog][id]})?\\n# Query_time: %{NUMBER:[mysql][slowlog][query_time][sec]}\\s* Lock_time: %{NUMBER:[mysql][slowlog][lock_time][sec]}\\s* Rows_sent: %{NUMBER:[mysql][slowlog][rows_sent]}\\s* Rows_examined: %{NUMBER:[mysql][slowlog][rows_examined]}\\n(SET timestamp=%{NUMBER:[mysql][slowlog][timestamp]};\\n)?%{GREEDYMULTILINE:[mysql][slowlog][query]}\"] } pattern_definitions = { \"GREEDYMULTILINE\" = \"(.|\\n)*\" } remove_field = \"message\" } date { match = [ \"[mysql][slowlog][timestamp]\", \"UNIX\" ] } mutate { gsub = [\"[mysql][slowlog][query]\", \"\\n# Time: [0-9]+ [0-9][0-9]:[0-9][0-9]:[0-9][0-9](.[0-9]+)?$\", \"\"] } } output { elasticsearch { hosts = localhost manage_template = false index = \"%{[@metadata][beat]}-%{+YYYY.MM.dd}\" document_type = \"%{[@metadata][type]}\" } } Nginx Logsedit Here are some configuration examples for shipping and parsing Nginx access and error logs. Nginx Access Logsedit Example Filebeat config: filebeat.prospectors: input_type: log paths: /var/log/nginx/access.log* exclude_files: [\".gz$\"] output.logstash: hosts: [\"localhost:5044\"] Example Logstash pipeline config: input { beats { # The port to listen on for filebeat connections. port = 5044 # The IP address to listen for filebeat connections. host = \"0.0.0.0\" } } filter { grok { match = { \"message\" = [\"%{IPORHOST:[nginx][access][remote_ip]} - %{DATA:[nginx][access][user_name]} \\[%{HTTPDATE:[nginx][access][time]}\\] \\\"%{WORD:[nginx][access][method]} %{DATA:[nginx][access][url]} HTTP/%{NUMBER:[nginx][access][http_version]}\\\" %{NUMBER:[nginx][access][response_code]} %{NUMBER:[nginx][access][body_sent][bytes]} \\\"%{DATA:[nginx][access][referrer]}\\\" \\\"%{DATA:[nginx][access][agent]}\\\"\"] } remove_field = \"message\" } mutate { rename = { \"@timestamp\" = \"read_timestamp\" } } date { match = [ \"[nginx][access][time]\", \"dd/MMM/YYYY:H:m:s Z\" ] remove_field = \"[nginx][access][time]\" } useragent { source = \"[nginx][access][agent]\" target = \"[nginx][access][user_agent]\" remove_field = \"[nginx][access][agent]\" } geoip { source = \"[nginx][access][remote_ip]\" target = \"[nginx][access][geoip]\" } } output { elasticsearch { hosts = localhost manage_template = false index = \"%{[@metadata][beat]}-%{+YYYY.MM.dd}\" document_type = \"%{[@metadata][type]}\" } } Nginx Error Logsedit Example Filebeat config: filebeat.prospectors: input_type: log paths: /var/log/nginx/error.log* exclude_files: [\".gz$\"] output.logstash: hosts: [\"localhost:5044\"] Example Logstash pipeline config: input { beats { # The port to listen on for filebeat connections. port = 5044 # The IP address to listen for filebeat connections. host = \"0.0.0.0\" } } filter { grok { match = { \"message\" = [\"%{DATA:[nginx][error][time]} \\[%{DATA:[nginx][error][level]}\\] %{NUMBER:[nginx][error][pid]}#%{NUMBER:[nginx][error][tid]}: (\\*%{NUMBER:[nginx][error][connection_id]} )?%{GREEDYDATA:[nginx][error][message]}\"] } remove_field = \"message\" } mutate { rename = { \"@timestamp\" = \"read_timestamp\" } } date { match = [ \"[nginx][error][time]\", \"YYYY/MM/dd H:m:s\" ] remove_field = \"[nginx][error][time]\" } } output { elasticsearch { hosts = localhost manage_template = false index = \"%{[@metadata][beat]}-%{+YYYY.MM.dd}\" document_type = \"%{[@metadata][type]}\" } } System Logsedit Here are some configuration examples for shipping and parsing system logs. System Authorization Logsedit Example Filebeat config: filebeat.prospectors: input_type: log paths: /var/log/auth.log* /var/log/secure* exclude_files: [\".gz$\"] multiline: pattern: \"^\\s\" match: after output.logstash: hosts: [\"localhost:5044\"] Example Logstash pipeline config: input { beats { # The port to listen on for filebeat connections. port = 5044 # The IP address to listen for filebeat connections. host = \"0.0.0.0\" } } filter { grok { match = { \"message\" = [\"%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} sshd(?:\\[%{POSINT:[system][auth][pid]}\\])?: %{DATA:[system][auth][ssh][event]} %{DATA:[system][auth][ssh][method]} for (invalid user )?%{DATA:[system][auth][user]} from %{IPORHOST:[system][auth][ssh][ip]} port %{NUMBER:[system][auth][ssh][port]} ssh2(: %{GREEDYDATA:[system][auth][ssh][signature]})?\", \"%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} sshd(?:\\[%{POSINT:[system][auth][pid]}\\])?: %{DATA:[system][auth][ssh][event]} user %{DATA:[system][auth][user]} from %{IPORHOST:[system][auth][ssh][ip]}\", \"%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} sshd(?:\\[%{POSINT:[system][auth][pid]}\\])?: Did not receive identification string from %{IPORHOST:[system][auth][ssh][dropped_ip]}\", \"%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} sudo(?:\\[%{POSINT:[system][auth][pid]}\\])?: \\s*%{DATA:[system][auth][user]} :( %{DATA:[system][auth][sudo][error]} ;)? TTY=%{DATA:[system][auth][sudo][tty]} ; PWD=%{DATA:[system][auth][sudo][pwd]} ; USER=%{DATA:[system][auth][sudo][user]} ; COMMAND=%{GREEDYDATA:[system][auth][sudo][command]}\", \"%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} groupadd(?:\\[%{POSINT:[system][auth][pid]}\\])?: new group: name=%{DATA:system.auth.groupadd.name}, GID=%{NUMBER:system.auth.groupadd.gid}\", \"%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} useradd(?:\\[%{POSINT:[system][auth][pid]}\\])?: new user: name=%{DATA:[system][auth][user][add][name]}, UID=%{NUMBER:[system][auth][user][add][uid]}, GID=%{NUMBER:[system][auth][user][add][gid]}, home=%{DATA:[system][auth][user][add][home]}, shell=%{DATA:[system][auth][user][add][shell]}$\", \"%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} %{DATA:[system][auth][program]}(?:\\[%{POSINT:[system][auth][pid]}\\])?: %{GREEDYMULTILINE:[system][auth][message]}\"] } pattern_definitions = { \"GREEDYMULTILINE\"= \"(.|\\n)*\" } remove_field = \"message\" } date { match = [ \"[system][auth][timestamp]\", \"MMM d HH:mm:ss\", \"MMM dd HH:mm:ss\" ] } geoip { source = \"[system][auth][ssh][ip]\" target = \"[system][auth][ssh][geoip]\" } } output { elasticsearch { hosts = localhost manage_template = false index = \"%{[@metadata][beat]}-%{+YYYY.MM.dd}\" document_type = \"%{[@metadata][type]}\" } } Syslogedit Example Filebeat config: filebeat.prospectors: input_type: log paths: /var/log/messages* /var/log/syslog* exclude_files: [\".gz$\"] multiline: pattern: \"^\\s\" match: after output.logstash: hosts: [\"localhost:5044\"] Example Logstash pipeline config: input { beats { # The port to listen on for filebeat connections. port = 5044 # The IP address to listen for filebeat connections. host = \"0.0.0.0\" } } filter { grok { match = { \"message\" = [\"%{SYSLOGTIMESTAMP:[system][syslog][timestamp]} %{SYSLOGHOST:[system][syslog][hostname]} %{DATA:[system][syslog][program]}(?:\\[%{POSINT:[system][syslog][pid]}\\])?: %{GREEDYMULTILINE:[system][syslog][message]}\"] } pattern_definitions = { \"GREEDYMULTILINE\" = \"(.|\\n)*\" } remove_field = \"message\" } date { match = [ \"[system][syslog][timestamp]\", \"MMM d HH:mm:ss\", \"MMM dd HH:mm:ss\" ] } } output { elasticsearch { hosts = localhost manage_template = false index = \"%{[@metadata][beat]}-%{+YYYY.MM.dd}\" document_type = \"%{[@metadata][type]}\" } } elk refresh_interval for indexing Elasticsearch 。 1 。，，  logstash  5 。。  refresh_interval ， tmpl . json ： { order : 1 , template : logstash-* , settings : { index.refresh_interval : 30s , index.number_of_replicas : 0 # } }  curl - XPUT http : // localhost : 9200 / _template / template_newid - d @/root/tmpl.json 。 logstash ， order  0 ， id  logstash ， logstash / outputs / elasticsearch  template_name 。  order  logstash5 root vim /etc/logstash/startup.options LS_USER=root /usr/share/logstash/bin/system-install  logstash es elasticsearch ，，，，。，  kill ，。，，，， ，。 ： ： shard 。 curl - XPUT http : // 127 . 0 . 0 . 1 : 9200 / _cluster / settings - d { transient : { cluster.routing.allocation.enable : none } } ： shutdown  curl - XPOST http : // 127 . 0 . 0 . 1 : 9200 / _cluster / nodes / _local / _shutdown elasticsearch  2 . 0  shutdown ， pid 。 ：， ： 2 - 3 ，。 ： shard  curl - XPUT http : // 127 . 0 . 0 . 1 : 9200 / _cluster / settings - d { transient : { cluster.routing.allocation.enable : all } } 。 logio yum install npm -y npm install -g log . io  cd / root / . log . io cat log_server . conf  web_server . conf （） exports . config = { host : 0.0.0.0 , port : 28777 , auth : { user : admin , pass : xxxx } } cat harvester . conf exports . config = { nodeName : application_server , logStreams : { tomcat_pingtai : [ /usr/local/tomcat_pingtai/logs/catalina.out , ] , tomcat_pingtaitest : [ /usr/local/tomcat_pingtaitest/logs/catalina.out , ] , tomcat_cuishou : [ /usr/local/tomcat_cuishou/logs/catalina.out , ] , tomcat_cuishoutest : [ /usr/local/tomcat_cuishoutest/logs/catalina.out , ] , tomcat_blacklist : [ /usr/local/tomcat_blacklist/logs/catalina.out , ] } , server : { host : 0.0.0.0 , port : 28777 } } nohup log . io-server Launch server nohup log . io-harvester Start log harvester  http :// localhost : 28778 nginx  / etc / nginx / conf . d / default . conf location / logio { proxy_pass http : // 192.168.1.2 : 28778 / ; auth_basic secret ; auth_basic_user_file /etc/nginx/passwd.db ; } location / socket . io { proxy_pass http : // 192.168.1.2 : 28778 / socket . io ; proxy_http_version 1.1 ; proxy_set_header Upgrade $http_upgrade ; proxy_set_header Connection upgrade ; } htpasswd -c / etc / nginx / passwd . db admin chmod 400 / etc / nginx / passwd . db chown nginx . nginx / etc / nginx / passwd . db / etc / init . d / nginx reload","title":"log-analysis"},{"location":"log-analysis/#elk","text":" Kibana  JDK ElasticSearch redis2 .6 （  ） Logstash （  ）  JDK Logstash (  ，  ，  )  https : // www . elastic . co / downloads https : // mirrors . tuna . tsinghua . edu . cn / ELK /  ElasticSearchLogstashJDK ， JDK ： yum - y install java - 1.8.0 - openjdk java - 1.8.0 - openjdk - devel java - version redis 2 .6  Logstash http : // www . open - open . com / lib / view / open1473661753307 . html Logstash9292 。 rpm - ivh logstash - 2.0.0 - 1. noarch . rpm  / opt / logstash / bin / logstash - e input{stdin{}}output{stdout{codec= rubydebug}} hello world vim / etc / logstash / conf . d / agent . conf input { file { type = ugo_nginx_access ## ,  。  ，  path = /export1/log/access_20150407+00.log ## 。 } file { type = nginx_access path = /usr/local/nginx/logs/python-access.log } } output { #redis 。 redis { host = 103.41.54.16 port = 6379 data_type = list key = logstash } }  / opt / logstash / bin / logstash agent - f / usr / local / logstash / conf / agent . conf  server grok http : // grokdebug . herokuapp . com / / opt / logstash / bin / logstash agent - f / usr / local / logstash / conf / fserver . conf input { redis { host = 127.0.0.1 port = 6379 data_type = list key = logstash type = redis-input } } filter { grok { match = { message = %{COMBINEDAPACHELOG} %{QS:x_forwarded_for} } nginx } geoip { source = clientip target = geoip database = /opt/logstash/GeoLiteCity.dat add_field = [ [geoip ][ coordinates ] , % { [ geoip ][ longitude ] } ] add_field = [ [ geoip ][ coordinates ] , % { [ geoip ][ latitude ] } ] } mutate { convert = [ [ geoip ][ coordinates ] , float ] convert = [ response , integer ] convert = [ bytes , integer ] replace = { type = nginx_access } remove_field = message } date { match = [ timestamp , dd / MMM / yyyy : HH : mm : ss Z ] } mutate { remove_field = timestamp } } output { elasticsearch { hosts = [ 127.0.0.1 : 9200 ] manage_template = true ，geoip， # http://blog.csdn.net/yanggd1987/article/details/50469113 index = logstash - nginx - access -% { + YYYY . MM . dd } } stdout {codec = rubydebug} } ##， logstash 20154。 curl -XDELETE http://10.1.1.99:9200/logstash-2015.04.* ElasticSearch  ElasticSearchHTTP9200，TCP9300。 rpm -ivh elasticsearch-2.0.0.rpm vim /etc/elasticsearch/elasticsearch.yml  node.name: node-1 network.host: 0.0.0.0 path.data: /data/elasticsearch/ http.port: 9200 mkdir -pv /data/elasticsearch chown -R elasticsearch.elasticsearch /data/elasticsearch/ /etc/init.d/elasticsearch start ElasticSearch，200： curl -X GET http://localhost:9200 head wget https://github.com/mobz/elasticsearch-head/archive/master.zip unzip master.zip mv elasticsearch-head-master/ /usr/share/elasticsearch/plugins/head/ http://112.126.80.182:9200/_plugin/head/ ， curl -XPUT http://localhost:9200/logstash-qos -d ，map， { mappings : { _default_ : { properties : { timestamp :{ type : date } } } } } ; Kibana tar - zxf kibana - 4.2.0 - linux - x64 . tar . gz vim . / kibana / config / kibana . yml  elasticsearch . url : http : // 192.168.1.23 : 9200  . / kibana / bin / kibana kibana  ： http : // elasticsearch . cn / question / 232  http : // www .99 ya . net / archives / 523. html （  ）","title":"elk"},{"location":"log-analysis/#logstatsh-http","text":"https : //www.elastic.co/blog/introducing-logstash-input-http-plugin How do I use this plugin ? By default it will bind the webserver to all hosts ( 0.0.0.0 ) and open the TCP port 8080 but it s possible configure these settings : input { http { host = 127.0.0.1 # default : 0.0.0.0 port = 31311 # default : 8080 } } That s all you need ! What about security ? You can configure basic authentication by setting a username and password . All requests done to Logstash will then have to set the right credentials or receive a 401 response . Only correctly authenticated requests will produce an event inside of Logstash . For SSL , it is necessary to specify the path to a Java Keystore that contains the certificate that clients use to validate the server . Here s an example : input { port = 3332 user = myuser password = $tr0ngP4ssWD! ssl = on keystore = /tmp/mykeystore.jks keystore_password = keystore_pass } OK , now show me this plugin in action ! Step 1 - starting Logstash with http input : bin / logstash - e input { http { } } output { stdout { codec = rubydebug} } Step 2 - That s it ! To test it , let s issue two requests : % curl - XPUT http : //127.0.0.1:8080/twitter/tweet/1 -d hello % curl - H content-type: application/json - XPUT http : //127.0.0.1:8080/twitter/tweet/1 -d { user : kimchy , post_date : 2009-11-15T14:12:12 , message : trying out Elasticsearch } Result in Logstash : { message = hello , @version = 1 , @timestamp = 2015-05-29T14:49:00.392Z , headers = { content_type = application/x-www-form-urlencoded , request_method = PUT , request_path = /twitter/tweet/1 , request_uri = /twitter/tweet/1 , http_version = HTTP/1.1 , http_user_agent = curl/7.37.1 , http_host = 127.0.0.1:8080 , http_accept = */* , content_length = 5 } } { user = kimchy , post_date = 2009-11-15T14:12:12 , message = trying out Elasticsearch , @version = 1 , @timestamp = 2015-05-29T14:49:04.105Z , headers = { content_type = application/json , request_method = PUT , request_path = /twitter/tweet/1 , request_uri = /twitter/tweet/1 , http_version = HTTP/1.1 , http_user_agent = curl/7.37.1 , http_host = 127.0.0.1:8080 , http_accept = */* , content_length = 110 } } You can see that in the second request , since the content - type was application / json , the body was deserialized and expanded to the event root ( notice the fields user , post_date and message ). Show me more concrete examples of how to use it ! Because , real world examples make everything clearer ! Elastic Watcher Integration In this section , we ’ ll show you how to integrate Elastic Watcher -- the new Elasticsearch plugin for alerting and notification -- with Logstash . Sending notifications to Logstash via this input provides you a powerful toolset to further transform notifications and use Logstash ’ s rich collection of outputs . Imagine that you have indices with Apache logs , and now we want to get a periodic update of how many requests are resulting in a 404 ( Not Found ) response . The required steps for this are : Installing Watcher Creating a new notification on Watcher that every minute reports the number of events that have a 404 response status Start Logstash with the HTTP input Send data to Elasticsearch and watch updates on Logstash Here we go ! 1. Installing Watcher cd elasticsearch - 1.5.2 bin / plugin - i elasticsearch / watcher / latest bin / plugin - i elasticsearch / license / latest bin / elasticsearch # restart the server 2. Creating a watch The Watcher plugin for elasticsearch provides an API to create and manipulate scheduled tasks , or watches . A Watch will query the data in the elasticsearch cluster according to its schedule , look for certain scenarios ( like the presence of an error event ) and execute actions . Examples of actions are sending an email , writing a document to an index , calling an outside HTTP endpoint , and more .. For this test , I created a simple watch that : every minute counts number of HTTP requests that resulted in a 404 posts result to http : //localhost:8080 This is the resulting JSON document I need to send to Watcher : { trigger : { schedule : { cron : 0 0/1 * * * ? } }, input : { search : { request : { indices : [ logstash* ], body : { query : { term : { response : 404 } } } } } }, actions : { my_webhook : { webhook : { auth : { basic : { username : guest , password : guest } }, method : POST , host : 127.0.0.1 , port : 8080 , path : /{{ctx.watch_id}} , body : {{ctx.payload.hits.total}} } } } } To install this watch you need to create it in Elasticsearch by executing a PUT request : curl - XPUT http : //localhost:9200/_watcher/watch/my-watch -d @create_webhook.json 3. Logstash setup wget http : //download.elastic.co/logstash/logstash/logstash-1.5.2.tar.gz tar - zxf logstash - 1.5.2 . tar . gz cd logstash - 1.5.2 bin / logstash - e input { http { } } output { stdout { codec = rubydebug} } 4. Results After launching an ingestion process in another terminal , Logstash starts receiving 1 notification per minute in the form of a HTTP POST : % bin / logstash - e input { http { } } output { stdout { codec = rubydebug} } Logstash startup completed { message = 330 , @version = 1 , @timestamp = 2015-06-02T12:53:00.037Z , headers = { content_type = application/x-www-form-urlencoded , request_method = POST , request_path = /my-watch , request_uri = /my-watch? , http_version = HTTP/1.1 , http_authorization = Basic Z3Vlc3Q6Z3Vlc3Q= , http_accept_charset = UTF-8 , http_cache_control = no-cache , http_pragma = no-cache , http_user_agent = Java/1.8.0_20 , http_host = 127.0.0.1:8080 , http_accept = text/html, image/gif, image/jpeg, *; q=.2, */*; q=.2 , http_connection = keep-alive , content_length = 12 } } { message = 3103 , @version = 1 , @timestamp = 2015-06-02T12:54:00.030Z , headers = { content_type = application/x-www-form-urlencoded , request_method = POST , request_path = /my-watch , request_uri = /my-watch? , http_version = HTTP/1.1 , http_authorization = Basic Z3Vlc3Q6Z3Vlc3Q= , http_accept_charset = UTF-8 , http_cache_control = no-cache , http_pragma = no-cache , http_user_agent = Java/1.8.0_20 , http_host = 127.0.0.1:8080 , http_accept = text/html, image/gif, image/jpeg, *; q=.2, */*; q=.2 , http_connection = keep-alive , content_length = 13 } } { message = 6071 , @version = 1 , @timestamp = 2015-06-02T12:55:00.031Z , headers = { content_type = application/x-www-form-urlencoded , request_method = POST , request_path = /my-watch , request_uri = /my-watch? , http_version = HTTP/1.1 , http_authorization = Basic Z3Vlc3Q6Z3Vlc3Q= , http_accept_charset = UTF-8 , http_cache_control = no-cache , http_pragma = no-cache , http_user_agent = Java/1.8.0_20 , http_host = 127.0.0.1:8080 , http_accept = text/html, image/gif, image/jpeg, *; q=.2, */*; q=.2 , http_connection = keep-alive , content_length = 13 } } A more complex example Now that we know how to trigger notification events from Watcher , we can leverage the plugin ecosystem in Logstash to escalate notifications depending in a certain criteria . This following config will : continuously update the number of 404 requests in statsd if the count reaches 10000 then send a message to HipChat , or if reaches 40000 , notify PagerDuty . input { http { } } filter { if [ headers ][ request_path ] == /my-watch { mutate { convert = [ message , integer ] } } } output { if [ headers ][ request_path ] == /my-watch { if [ message ] 40000 { # way too many , notify pagerduty pagerduty { description = %{host} - Apache: Very high number of 404 details = { timestamp = %{@timestamp} message = %{message} } service_key = apikeyforlogstashservice incident_key = logstash/apacheservice } } else if [ message ] 10000 { # unusual amount , notify devs in hipchat hipchat { from = logstash room_id = dev token = [api key] format = Very high number of 404 requests: %{message} } } # always update count of 404 in statsd statsd { gauge = [ http.status.404 , %{message} ] } } }","title":"logstatsh http"},{"location":"log-analysis/#geoip","text":"wget http : // geolite . maxmind . com / download / geoip / database / GeoLiteCountry / GeoIP . dat . gz wget http : // geolite . maxmind . com / download / geoip / database / GeoLiteCity . dat . gz","title":"geoip"},{"location":"log-analysis/#elasticsearch","text":" curl - XGET http://localhost:9200/_cat/indices/*?v  curl - XDELETE http://127.0.0.1:9200/winlogbeat-2016* curl - XDELETE http://127.0.0.1:9200/winlogbeat-2017.07.20  curl http : // 127 . 0 . 0 . 1 : 9200 / _nodes / hot_threads  curl - XGET http://localhost:9200/_cluster/stats?human pretty  curl - XGET http : // 127 . 0 . 0 . 1 : 9200 / _nodes / stats / thread_pool ? pretty  curl - XGET http : // 127 . 0 . 0 . 1 : 9200 / _cluster / settings  curl - XGET http : // 127 . 0 . 0 . 1 : 9200 / logstash - nginx - access - 2017 . 10 . 26 / _settings  egrep - v ^#|^$ / etc / elasticsearch / elasticsearch . yml cluster . name : es1 #   node . name : node - 1 # ， network . host : 0 . 0 . 0 . 0 path . data : / data / elasticsearch / http . port : 9200 discovery . zen . ping . multicast . enabled : false ##  discovery . zen . ping . unicast . hosts : [ 10.51.48.109 , 10.171.32.72 ] # #  ","title":"elasticsearch"},{"location":"log-analysis/#logstash-grop","text":"grok http://grokdebug.herokuapp.com/ Example  55.3.244.1 GET /index.html 15824 0.043  %{IP:client} %{WORD:method} %{URIPATHPARAM:request} %{NUMBER:bytes} %{NUMBER:duration} ？ input { file { path = “/var/log/http.log” } } filter { grok { match = [ \"message\", \"%{IP:client} %{WORD:method} %{URIPATHPARAM:request} %{NUMBER:bytes} %{NUMBER:duration}\" ] } } ，？ client: 55.3.244.1 method: GET request: /index.html bytes: 15824 duration: 0.043  (? field_name the pattern here) (? queue_id [0-9A-F]{10,11}) ，。 # in ./patterns/postfix POSTFIX_QUEUEID [0-9A-F]{10,11} filter { grok { patterns_dir = “./patterns” match = [ \"message\", \"%{SYSLOGBASE} %{POSTFIX_QUEUEID:queue_id}: %{GREEDYDATA:syslog_message}\" ] } } ############ logstash，，。 USERNAME [a-zA-Z0-9._-]+ USER %{USERNAME} INT (?:[+-]?(?:[0-9]+)) BASE10NUM (? ![0-9.+-])(? [+-]?(?:(?:[0-9]+(?:.[0-9]+)?)|(?:.[0-9]+))) NUMBER (?:%{BASE10NUM}) BASE16NUM (? ![0-9A-Fa-f])(?:[+-]?(?:0x)?(?:[0-9A-Fa-f]+)) BASE16FLOAT \\b(? ![0-9A-Fa-f.])(?:[+-]?(?:0x)?(?:(?:[0-9A-Fa-f]+(?:.[0-9A-Fa-f]*)?)|(?:.[0-9A-Fa-f]+)))\\b POSINT \\b(?:[1-9][0-9]*)\\b NONNEGINT \\b(?:[0-9]+)\\b WORD \\b\\w+\\b NOTSPACE \\S+ SPACE \\s* DATA .*? GREEDYDATA .* QUOTEDSTRING (? (? !\\)(? ”(? .|[^\\\"]+)+”|”\"|(? ’(? .|[^\\']+)+’)|”|(? (? .|[^\\]+)+)|`)) UUID [A-Fa-f0-9]{8}-(?:[A-Fa-f0-9]{4}-){3}[A-Fa-f0-9]{12} # Networking MAC (?:%{CISCOMAC}|%{WINDOWSMAC}|%{COMMONMAC}) CISCOMAC (?:(?:[A-Fa-f0-9]{4}.){2}[A-Fa-f0-9]{4}) WINDOWSMAC (?:(?:[A-Fa-f0-9]{2}-){5}[A-Fa-f0-9]{2}) COMMONMAC (?:(?:[A-Fa-f0-9]{2}:){5}[A-Fa-f0-9]{2}) IPV6 ((([0-9A-Fa-f]{1,4}:){7}([0-9A-Fa-f]{1,4}|:))|(([0-9A-Fa-f]{1,4}:){6}(:[0-9A-Fa-f]{1,4}|((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3})|:))|(([0-9A-Fa-f]{1,4}:){5}(((:[0-9A-Fa-f]{1,4}){1,2})|:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3})|:))|(([0-9A-Fa-f]{1,4}:){4}(((:[0-9A-Fa-f]{1,4}){1,3})|((:[0-9A-Fa-f]{1,4})?:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){3}(((:[0-9A-Fa-f]{1,4}){1,4})|((:[0-9A-Fa-f]{1,4}){0,2}:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){2}(((:[0-9A-Fa-f]{1,4}){1,5})|((:[0-9A-Fa-f]{1,4}){0,3}:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){1}(((:[0-9A-Fa-f]{1,4}){1,6})|((:[0-9A-Fa-f]{1,4}){0,4}:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:))|(:(((:[0-9A-Fa-f]{1,4}){1,7})|((:[0-9A-Fa-f]{1,4}){0,5}:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:)))(%.+)? IPV4 (? ![0-9])(?:(?:25[0-5]|2[0-4][0-9]|[0-1]?[0-9]{1,2})[.](?:25[0-5]|2[0-4][0-9]|[0-1]?[0-9]{1,2})[.](?:25[0-5]|2[0-4][0-9]|[0-1]?[0-9]{1,2})[.](?:25[0-5]|2[0-4][0-9]|[0-1]?[0-9]{1,2}))(?![0-9]) IP (?:%{IPV6}|%{IPV4}) HOSTNAME \\b(?:[0-9A-Za-z][0-9A-Za-z-]{0,62})(?:.(?:[0-9A-Za-z][0-9A-Za-z-]{0,62}))*(.?|\\b) HOST %{HOSTNAME} IPORHOST (?:%{HOSTNAME}|%{IP}) HOSTPORT (?:%{IPORHOST=~/./}:%{POSINT}) # paths PATH (?:%{UNIXPATH}|%{WINPATH}) UNIXPATH (? /(? [\\w_%!$@:.,-]+|.)*)+ TTY (?:/dev/(pts|tty([pq])?)(\\w+)?/?(?:[0-9]+)) WINPATH (? [A-Za-z]+:|\\)(?:\\[^\\?*]*)+ URIPROTO [A-Za-z]+(+[A-Za-z+]+)? URIHOST %{IPORHOST}(?::%{POSINT:port})? # uripath comes loosely from RFC1738, but mostly from what Firefox # doesn’t turn into %XX URIPATH (?:/[A-Za-z0-9$.+!*'(){},~:;=@#%_-]*)+ #URIPARAM \\?(?:[A-Za-z0-9]+(?:=(?:[^ ]*))?(?: (?:[A-Za-z0-9]+(?:=(?:[^ ]*))?)?)*)? URIPARAM \\?[A-Za-z0-9$.+!*’|(){},~@#% /=:;_?-\\[\\]]* URIPATHPARAM %{URIPATH}(?:%{URIPARAM})? URI %{URIPROTO}://(?:%{USER}(?::[^@]*)?@)?(?:%{URIHOST})?(?:%{URIPATHPARAM})? # Months: January, Feb, 3, 03, 12, December MONTH \\b(?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|Jul(?:y)?|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?)\\b MONTHNUM (?:0?[1-9]|1[0-2]) MONTHDAY (?:(?:0[1-9])|(?:[12][0-9])|(?:3[01])|[1-9]) # Days: Monday, Tue, Thu, etc… DAY (?:Mon(?:day)?|Tue(?:sday)?|Wed(?:nesday)?|Thu(?:rsday)?|Fri(?:day)?|Sat(?:urday)?|Sun(?:day)?) # Years? YEAR (? \\d\\d){1,2} HOUR (?:2[0123]|[01]?[0-9]) MINUTE (?:[0-5][0-9]) # ’60′ is a leap second in most time standards and thus is valid. SECOND (?:(?:[0-5][0-9]|60)(?:[:.,][0-9]+)?) TIME (?! [0-9])%{HOUR}:%{MINUTE}(?::%{SECOND})(?![0-9]) # datestamp is YYYY/MM/DD-HH:MM:SS.UUUU (or something like it) DATE_US %{MONTHNUM}[/-]%{MONTHDAY}[/-]%{YEAR} DATE_EU %{MONTHDAY}[./-]%{MONTHNUM}[./-]%{YEAR} ISO8601_TIMEZONE (?:Z|[+-]%{HOUR}(?::?%{MINUTE})) ISO8601_SECOND (?:%{SECOND}|60) TIMESTAMP_ISO8601 %{YEAR}-%{MONTHNUM}-%{MONTHDAY}[T ]%{HOUR}:?%{MINUTE}(?::?%{SECOND})?%{ISO8601_TIMEZONE}? DATE %{DATE_US}|%{DATE_EU} DATESTAMP %{DATE}[- ]%{TIME} TZ (?:[PMCE][SD]T|UTC) DATESTAMP_RFC822 %{DAY} %{MONTH} %{MONTHDAY} %{YEAR} %{TIME} %{TZ} DATESTAMP_OTHER %{DAY} %{MONTH} %{MONTHDAY} %{TIME} %{TZ} %{YEAR} # Syslog Dates: Month Day HH:MM:SS SYSLOGTIMESTAMP %{MONTH} +%{MONTHDAY} %{TIME} PROG (?:[\\w._/%-]+) SYSLOGPROG %{PROG:program}(?:\\[%{POSINT:pid}\\])? SYSLOGHOST %{IPORHOST} SYSLOGFACILITY %{NONNEGINT:facility}.%{NONNEGINT:priority} HTTPDATE %{MONTHDAY}/%{MONTH}/%{YEAR}:%{TIME} %{INT} # Shortcuts QS %{QUOTEDSTRING} # Log formats SYSLOGBASE %{SYSLOGTIMESTAMP:timestamp} (?:%{SYSLOGFACILITY} )?%{SYSLOGHOST:logsource} %{SYSLOGPROG}: COMMONAPACHELOG %{IPORHOST:clientip} %{USER:ident} %{USER:auth} \\[%{HTTPDATE:timestamp}\\] “(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})” %{NUMBER:response} (?:%{NUMBER:bytes}|-) COMBINEDAPACHELOG %{COMMONAPACHELOG} %{QS:referrer} %{QS:agent} # Log Levels LOGLEVEL ([A-a]lert|ALERT|[T|t]race|TRACE|[D|d]ebug|DEBUG|[N|n]otice|NOTICE|[I|i]nfo|INFO|[W|w]arn?(?:ing)?|WARN?(?:ING)?|[E|e]rr?(?:or)?|ERR?(?:OR)?|[C|c]rit?(?:ical)?|CRIT?(?:ICAL)?|[F|f]atal|FATAL|[S|s]evere|SEVERE|EMERG(?:ENCY)?|[Ee]merg(?:ency)?)","title":"logstash grop"},{"location":"log-analysis/#awstats","text":"http : //blog.csdn.net/wanglipo/article/details/18080819 wget https : //prdownloads.sourceforge.net/awstats/awstats-7.5.tar.gz tar - zxf awstats - 7.5 . tar . gz mv awstats - 7.5 / usr / local / awstats cd / usr / local / awstats / tools / mkdir - pv / var / lib / awstats chmod 777 / var / lib / awstats perl awstats_configure . pl ----- AWStats awstats_configure 1.0 ( build 1.9 ) ( c ) Laurent Destailleur ----- This tool will help you to configure AWStats to analyze statistics for one web server . You can try to use it to let it do all that is possible in AWStats setup , however following the step by step manual setup documentation ( docs / index . html ) is often a better idea . Above all if : - You are not an administrator user , - You want to analyze downloaded log files without web server , - You want to analyze mail or ftp log files instead of web log files , - You need to analyze load balanced servers log files , - You want to understand all possible ways to use AWStats ... Read the AWStats documentation ( docs / index . html ). ----- Running OS detected : Linux , BSD or Unix ----- Check for web server install Enter full config file path of your Web server . Example : / etc / httpd / httpd . conf Example : / usr / local / apache2 / conf / httpd . conf Example : c : \\ Programfiles \\ apachegroup \\ apache \\ conf \\ httpd . conf Config file path ( none to skip web server setup ) : / etc / httpd / conf / httpd . conf  httpd  ----- Check and complete web server config file / etc / httpd / conf / httpd . conf Add Alias / awstatsclasses /usr/local/awstats/wwwroot/classes/ Add Alias / awstatscss /usr/local/awstats/wwwroot/css/ Add Alias / awstatsicons /usr/local/awstats/wwwroot/icon/ Add ScriptAlias / awstats / /usr/local/awstats/wwwroot/cgi-bin/ Add Directory directive AWStats directives added to Apache config file . ----- Update model config file / usr / local / awstats / wwwroot / cgi - bin / awstats . model . conf File awstats . model . conf updated . ----- Need to create a new config file ? Do you want me to build a new AWStats config / profile file ( required if first install ) [ y / N ] ? y ----- Define config file name to create What is the name of your web site or profile analysis ? Example : www . mysite . com Example : demo Your web site , virtual server or profile name : lingling ，，，。 ----- Define config file path In which directory do you plan to store your config file ( s ) ? Default : / etc / awstats Directory path to store config file ( s ) ( Enter for default ) :  awstats ，。 ----- Create config file / etc / awstats / awstats . lingling . conf Config file / etc / awstats / awstats . lingling . conf created . ----- Restart Web server with / sbin / service httpd restart Stopping httpd : [ OK ] Starting httpd : [ OK ] ----- Add update process inside a scheduler Sorry , configure . pl does not support automatic add to cron yet . You can do it manually by adding the following command to your cron : / usr / local / awstats / wwwroot / cgi - bin / awstats . pl - update - config = lingling Or if you have several config files and prefer having only one command : / usr / local / awstats / tools / awstats_updateall . pl now Press ENTER to continue ... A SIMPLE config file has been created : / etc / awstats / awstats . lingling . conf You should have a look inside to check and change manually main parameters . You can then manually update your statistics for lingling with command : perl awstats . pl - update - config = lingling You can also read your statistics for lingling with URL : http : //localhost/awstats/awstats.pl?config=lingling Press ENTER to finish ... 1 、 httpd  log  / var / log / httpd / access . log ，  / etc / awstats / awstats . lingling . conf  LogFile ：  LogFile = /var/log/httpd/mylog.log  LogFile = /var/log/httpd/access_log  LogFile = var/log/access_log.%YYYY-0%MM-0%DD-0.log 2 、，： # cd /usr/local/awstats/wwwroot/cgi-bin/ # perl awstats.pl –update –config=lingling 3 、， awstats ： http : //10.100.10.11/awstats/awstats.pl?config=lingling 4 、，，。 # crontab –e 10 1 * * * / usr / local / awstats / wwwroot / cgi - bin / awstats . pl - update - config = lingling / dev / null 2 1 、 awstats  tomcat  1 、 tomcat ，。  httpd ， awstats  httpd  awstats  tomcat 。  tomcat ： Valve className = org.apache.catalina.valves. AccessLogValve directory= logs prefix = localhost_access_log. suffix = .txt pattern = %h %l %u %t quot;%r quot; %s %b / % ... a :  IP  % ... A :  IP  % ... B : ， HTTP  % ... b : CLF ， HTTP 。 ，‘ - ’ 0 。 %e :  FOOBAR  % ... f :  % ... h :  % ... H  %i : Foobar ，。 % ... l : （ identd ，） % ... m  %n : “ Foobar ” %o : Foobar ， % ... p :  % ... P :  ID 。 % ... q （，“ ? ” ；，。） % ... r :  % ... s : 。， *  *  。 % ... s ，。 % ... t : （） %t :  format  % ... T : ， % ... u : （ auth ；（ %s ） 401 ） % ... U :  URL  % ... v :  ServerName % ... V :  UseCanonicalName   tomcat ： 203.156.200.162 - - [ 29 / Aug / 2012 : 11 : 16 : 58 + 0800 ] GET /front/magazine/getContent.htm?contentId=124504 HTTP/1.1 200 20001 2 、 tomcat ， tomcat  copy  / var / log / httpd / 。  copy ： localhost_access_log .2012 - 08 - 29. txt 3 、 awstats  ( tomcat  httpd ， httpd . conf  ) # cd /usr/local/awstats/tools # perl awstats_configure.pl ----- AWStats awstats_configure 1.0 ( build 1.9 ) ( c ) Laurent Destailleur ----- This tool will help you to configure AWStats to analyze statistics for one web server . You can try to use it to let it do all that is possible in AWStats setup , however following the step by step manual setup documentation ( docs / index . html ) is often a better idea . Above all if : - You are not an administrator user , - You want to analyze downloaded log files without web server , - You want to analyze mail or ftp log files instead of web log files , - You need to analyze load balanced servers log files , - You want to understand all possible ways to use AWStats ... Read the AWStats documentation ( docs / index . html ). ----- Running OS detected : Linux , BSD or Unix ----- Check for web server install Enter full config file path of your Web server . Example : / etc / httpd / httpd . conf Example : / usr / local / apache2 / conf / httpd . conf Example : c : \\ Program files \\ apache group \\ apache \\ conf \\ httpd . conf Config file path ( none to skip web server setup ) : none Your web server config file ( s ) could not be found . You will need to setup your web server manually to declare AWStats script as a CGI , if you want to build reports dynamically . See AWStats setup documentation ( file docs / index . html ) ----- Update model config file / usr / local / awstats / wwwroot / cgi - bin / awstats . model . conf File awstats . model . conf updated . ----- Need to create a new config file ? Do you want me to build a new AWStats config / profile file ( required if first install ) [ y / N ] ? y ----- Define config file name to create What is the name of your web site or profile analysis ? Example : www . mysite . com Example : demo Your web site , virtual server or profile name : buoqu . com ----- Define config file path In which directory do you plan to store your config file ( s ) ? Default : / etc / awstats Directory path to store config file ( s ) ( Enter for default ) : ----- Create config file / etc / awstats / awstats . buoqu . com . conf Config file / etc / awstats / awstats . buoqu . com . conf created . ----- Add update process inside a scheduler Sorry , configure . pl does not support automatic add to cron yet . You can do it manually by adding the following command to your cron : / usr / local / awstats / wwwroot / cgi - bin / awstats . pl - update - config = buoqu . com Or if you have several config files and prefer having only one command : / usr / local / awstats / tools / awstats_updateall . pl now Press ENTER to continue ... A SIMPLE config file has been created : / etc / awstats / awstats . buoqu . com . conf You should have a look inside to check and change manually main parameters . You can then manually update your statistics for buoqu . com with command : perl awstats . pl - update - config = buoqu . com You can also build static report pages for buoqu . com with command : perl awstats . pl - output = pagetype - config = buoqu . com Press ENTER to finish ... 4 、 # vim /etc/awstats/awstats.buoqu.com.conf  LogFile = /var/log/httpd/mylog.log  LogFile = /usr/local/awstats/tools/logresolvemerge.pl /usr/local/awstats/flashlog/china/localhost_access_log.% YYYY - 24 -% MM - 24 -% DD - 24. txt / usr / local / awstats / flashlog / usa / localhost_access_log . % YYYY - 24 -% MM - 24 -% DD - 24. txt | 5 、 httpd ， # service httpd restart # cd /usr/local/awstats/wwwroot/cgi-bin # perl awstats.pl -update -config=buoqu.com Setup ( / etc / awstats / awstats . buoqu . com . conf file , web server or permissions ) may be wrong . Check config file , permissions and AWStats documentation ( in docs directory ). ：。 ：， tomcat 。  / etc / awstats / awstats . buoqu . com . conf # vim /etc/awstats/awstats.buoqu.com.conf LogFormat = 1 LogFormat = %host %other %logname %time1 %methodurl %code %bytesd  # perl awstats.pl -update -config=buoqu.com 6 、： http : //10.100.10.11/awstats/awstats.pl?config=buoqu.com 7 、 crontab 。 ①、，， AllowToUpdateStatsFromBrowser = 1 ，。 ②、“”，， awstats 。 # cd /usr/local/awstats/wwwroot/cgi-bin # vim awstats.model.conf  AllowToUpdateStatsFromBrowser = 0  AllowToUpdateStatsFromBrowser = 1 。 ，。 ： httpd  ③、， apache  # chown apache.apache –R /var/lib/awstats # chmod 755 /var/log/httpd ： 、， awstats 。 IP  wget http : //geolite.maxmind.com/download/geoip/database/GeoLiteCountry/GeoIP.dat.gz wget http : //geolite.maxmind.com/download/geoip/database/GeoLiteCity.dat.gz gunzip GeoIP . dat . gz gunzip GeoLiteCity . dat . gz mv * . dat / opt / yum install GeoIP perl - Geo - IP perl - MCPAN - e install Geo::IP::PurePerl vim / etc / awstats / awstats . www . test . com . conf #： #LoadPlugin= tooltips html #LoadPlugin= decodeutfkeys UTF8 #LoadPlugin= geoip GEOIP_STANDARD /pathto/GeoIP.dat #1429 #LoadPlugin= geoip_city_maxmind GEOIP_STANDARD /pathto/GeoIPCity.dat #1438 ： LoadPlugin = geoip GEOIP_STANDARD /var/geoip/GeoIP.dat LoadPlugin = geoip_city_maxmind GEOIP_STANDARD /var/geoip/GeoLiteCity.dat  QQ  IP ( 1 )  awstats  wwwroot  plugin  cd / usr / local / awstats / wwwroot / cgi - bin / plugins # yum：/usr/share/awstats/wwwroot/cgi-bin/plugins ， wget http : //www.haiyun.me/download/qqwry.pl wget http : //www.haiyun.me/download/qqhostinfo.pm  IP ： update . cz88 . net  windows ， qqwry . dat ，。 ( 2 )  qqwry  awstats  wwwroot  plugin  . ( 3 )  #qqwry.plIP： my $ipfile = ${DIR}/plugins/qqwry.dat ; ( 4 )  awstats #awstats： LoadPlugin = qqhostinfo  rm - rf / var / lib / awstats /*  /usr/local/awstats/wwwroot/cgi-bin/awstats.pl -update -config= www.test.com ------------------------------------------------- #!/usr/bin/env bash rsync -avz /var/lib/awstats/ /usr/local/awstats/var-lib-awstats find /usr/local/awstats/flashlog/ -mtime +1 -exec rm -f {} \\; Date=$(date +%Y-%m-%d -d 1 day ago ) #101.200.131.163 flash china rsync -avz -e ssh -p 27554 10.44.28.154:/usr/local/tomcat/logs/localhost_access_log.$Date.txt /usr/local/awstats/flashlog/china/ rsync -avz -e ssh -p 27554 47.88.7.159:/usr/local/tomcat/logs/localhost_access_log.$Date.txt /usr/local/awstats/flashlog/usa/ /usr/local/awstats/wwwroot/cgi-bin/awstats.pl -update -config=flash # http://monitor.3mang.com/awstats/awstats.pl?config=flash ----------------------------------------------------------- #awstats log  0 1 * * * /bin/bash /usr/local/awstats/scplog.sh /usr/local/awstats/scplog.log 2 1 awstats ： LogFile= /usr/local/nginx/logs/host.access.log ： 1） LogFile= /usr/local/awstats/tools/logresolvemerge.pl /usr/local/nginx/logs/231.pcstars_access.log /usr/local/nginx/logs/232.pcstars_access.log /usr/local/nginx/logs/233.pcstars_access.log /usr/local/nginx/logs/234.pcstars_access.log /usr/local/nginx/logs/mg.pcstars_access.log| 2): LogFile= /usr/local/awstats/tools/logresolvemerge.pl /usr/local/nginx/logs/*.pcstars_access.log| ： awstats logresolvemerge.pl ， | ， awstats，： /usr/local/awstats/tools/awstats_updateall.pl now  /usr/local/awstats/wwwroot/cgi-bin/awstats.pl -update -config=www.nginx.log -configdir= /etc/awstats","title":"awstats"},{"location":"log-analysis/#_1","text":"PIWIK https : // piwik . org / Google Analytics https : // developers . google . com / analytics /? hl = zh - cn","title":""},{"location":"log-analysis/#es_date","text":"elasticsearchdate，Kibana。。 date： ，。 ，ISO 8601，2015-02-27T00:07Z()、2015-02-27T08:07+08:00(),，，，。，es。，。phpISO 8601，date('c',time()）。 elasticsearchdate，，mapping'date_detection' = false 。 elasticsearchdate，jsondate。jsonelasticsearch，es，esdatedate。esdate，elasticsearchhttps://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-date-format.html。 date，json，es，kibanaes，，8。kibanaesdate，，kibana0，kibana，js，，kibanaes8。kibana“8”。 ：es，，：“2016-07-15T12:58:17.136+0800”。","title":"es_date"},{"location":"log-analysis/#logstash","text":"， logstash  2  A  B ， A  kafka ， B  es 。  Input { file { path = a type = A } file { path = b type = B } } output { if [ type ] == A { kafka {...} } if [ type ] == B { es {...} } } ： bin / logstash - e input{ file { type = normal path = /data/log/test/abc*.log start_position = beginning exclude = *abc*.log } file { type = error path = /data/log/test/*error*.log start_position = beginning } } output { if [ type ] == error { kafka { bootstrap_servers = 127.0.0.1:9092,127.0.0.1:9092 topic_id = loga } } stdout { codec = rubydebug } }","title":"logstash"},{"location":"log-analysis/#winlogbeat","text":" winlogbeat.yml ignore_older， winlogbeat . event_logs : - name : Application ignore_older : 48 h provider : - Application Error - Application Hang - Windows Error Reporting - EMET - name : Security level : critical , error , warning event_id : 4624 , 4625 , 4700 - 4800 , - 4735 ignore_older : 48 h - name : System level : critical , error , warning ignore_older : 48 h - name : Microsoft - Windows - Windows Defender / Operational include_xml : true ignore_older : 48 h es scripts\\import_dashboards.exe -es http://192.168.33.60:9200  powershell .\\install-service-winlogbeat.ps1 scripts is disabled on this system  Set-ExecutionPolicy RemoteSigned net start/stop winlogbeat  .\\winlogbeat.exe -c .\\winlogbeat.yml","title":"winlogbeat"},{"location":"log-analysis/#filebeat","text":"https://www.elastic.co/guide/en/logstash/current/logstash-config-for-filebeat-modules.html#parsing-system Apache 2 Logs MySQL Logs Nginx Logs System Logs Apache 2 Access Logsedit Example Filebeat config: filebeat.prospectors: input_type: log paths: /var/log/apache2/access.log* /var/log/apache2/other_vhosts_access.log* exclude_files: [\".gz$\"] output.logstash: hosts: [\"localhost:5044\"] Example Logstash pipeline config: input { beats { # The port to listen on for filebeat connections. port = 5044 # The IP address to listen for filebeat connections. host = \"0.0.0.0\" } } filter { grok { match = { \"message\" = [\"%{IPORHOST:[apache2][access][remote_ip]} - %{DATA:[apache2][access][user_name]} \\[%{HTTPDATE:[apache2][access][time]}\\] \\\"%{WORD:[apache2][access][method]} %{DATA:[apache2][access][url]} HTTP/%{NUMBER:[apache2][access][http_version]}\\\" %{NUMBER:[apache2][access][response_code]} %{NUMBER:[apache2][access][body_sent][bytes]}( \\\"%{DATA:[apache2][access][referrer]}\\\")?( \\\"%{DATA:[apache2][access][agent]}\\\")?\", \"%{IPORHOST:[apache2][access][remote_ip]} - %{DATA:[apache2][access][user_name]} \\[%{HTTPDATE:[apache2][access][time]}\\] \\\"-\\\" %{NUMBER:[apache2][access][response_code]} -\" ] } remove_field = \"message\" } mutate { add_field = { \"read_timestamp\" = \"%{@timestamp}\" } } date { match = [ \"[apache2][access][time]\", \"dd/MMM/YYYY:H:m:s Z\" ] remove_field = \"[apache2][access][time]\" } useragent { source = \"[apache2][access][agent]\" target = \"[apache2][access][user_agent]\" remove_field = \"[apache2][access][agent]\" } geoip { source = \"[apache2][access][remote_ip]\" target = \"[apache2][access][geoip]\" } } output { elasticsearch { hosts = localhost manage_template = false index = \"%{[@metadata][beat]}-%{+YYYY.MM.dd}\" document_type = \"%{[@metadata][type]}\" } } Apache 2 Error Logsedit Example Filebeat config: filebeat.prospectors: input_type: log paths: /var/log/apache2/error.log* exclude_files: [\".gz$\"] output.logstash: hosts: [\"localhost:5044\"] Example Logstash pipeline config: input { beats { # The port to listen on for filebeat connections. port = 5044 # The IP address to listen for filebeat connections. host = \"0.0.0.0\" } } filter { grok { match = { \"message\" = [\"\\[%{APACHE_TIME:[apache2][error][timestamp]}\\] \\[%{LOGLEVEL:[apache2][error][level]}\\]( \\[client %{IPORHOST:[apache2][error][client]}\\])? %{GREEDYDATA:[apache2][error][message]}\", \"\\[%{APACHE_TIME:[apache2][error][timestamp]}\\] \\[%{DATA:[apache2][error][module]}:%{LOGLEVEL:[apache2][error][level]}\\] \\[pid %{NUMBER:[apache2][error][pid]}(:tid %{NUMBER:[apache2][error][tid]})?\\]( \\[client %{IPORHOST:[apache2][error][client]}\\])? %{GREEDYDATA:[apache2][error][message1]}\" ] } pattern_definitions = { \"APACHE_TIME\" = \"%{DAY} %{MONTH} %{MONTHDAY} %{TIME} %{YEAR}\" } remove_field = \"message\" } mutate { rename = { \"[apache2][error][message1]\" = \"[apache2][error][message]\" } } date { match = [ \"[apache2][error][timestamp]\", \"EEE MMM dd H:m:s YYYY\", \"EEE MMM dd H:m:s.SSSSSS YYYY\" ] remove_field = \"[apache2][error][timestamp]\" } } output { elasticsearch { hosts = localhost manage_template = false index = \"%{[@metadata][beat]}-%{+YYYY.MM.dd}\" document_type = \"%{[@metadata][type]}\" } } MySQL Logsedit Here are some configuration examples for shipping and parsing MySQL error and slowlog logs. MySQL Error Logsedit Example Filebeat config: filebeat.prospectors: input_type: log paths: /var/log/mysql/error.log* /var/log/mysqld.log* exclude_files: [\".gz$\"] output.logstash: hosts: [\"localhost:5044\"] Example Logstash pipeline config: input { beats { # The port to listen on for filebeat connections. port = 5044 # The IP address to listen for filebeat connections. host = \"0.0.0.0\" } } filter { grok { match = { \"message\" = [\"%{LOCALDATETIME:[mysql][error][timestamp]} (\\[%{DATA:[mysql][error][level]}\\] )?%{GREEDYDATA:[mysql][error][message]}\", \"%{TIMESTAMP_ISO8601:[mysql][error][timestamp]} %{NUMBER:[mysql][error][thread_id]} \\[%{DATA:[mysql][error][level]}\\] %{GREEDYDATA:[mysql][error][message1]}\", \"%{GREEDYDATA:[mysql][error][message2]}\"] } pattern_definitions = { \"LOCALDATETIME\" = \"[0-9]+ %{TIME}\" } remove_field = \"message\" } mutate { rename = { \"[mysql][error][message1]\" = \"[mysql][error][message]\" } } mutate { rename = { \"[mysql][error][message2]\" = \"[mysql][error][message]\" } } date { match = [ \"[mysql][error][timestamp]\", \"ISO8601\", \"YYMMdd H:m:s\" ] remove_field = \"[apache2][access][time]\" } } output { elasticsearch { hosts = localhost manage_template = false index = \"%{[@metadata][beat]}-%{+YYYY.MM.dd}\" document_type = \"%{[@metadata][type]}\" } } MySQL Slowlogedit Example Filebeat config: filebeat.prospectors: input_type: log paths: /var/log/mysql/mysql-slow.log* /var/lib/mysql/hostname-slow.log exclude_files: [\".gz$\"] multiline: pattern: \"^# User@Host: \" negate: true match: after output.logstash: hosts: [\"localhost:5044\"] Example Logstash pipeline config: input { beats { # The port to listen on for filebeat connections. port = 5044 # The IP address to listen for filebeat connections. host = \"0.0.0.0\" } } filter { grok { match = { \"message\" = [\"^# User@Host: %{USER:[mysql][slowlog][user]}(\\[[^\\]]+\\])? @ %{HOSTNAME:[mysql][slowlog][host]} \\[(IP:[mysql][slowlog][ip])?\\](\\s*Id:\\s* %{NUMBER:[mysql][slowlog][id]})?\\n# Query_time: %{NUMBER:[mysql][slowlog][query_time][sec]}\\s* Lock_time: %{NUMBER:[mysql][slowlog][lock_time][sec]}\\s* Rows_sent: %{NUMBER:[mysql][slowlog][rows_sent]}\\s* Rows_examined: %{NUMBER:[mysql][slowlog][rows_examined]}\\n(SET timestamp=%{NUMBER:[mysql][slowlog][timestamp]};\\n)?%{GREEDYMULTILINE:[mysql][slowlog][query]}\"] } pattern_definitions = { \"GREEDYMULTILINE\" = \"(.|\\n)*\" } remove_field = \"message\" } date { match = [ \"[mysql][slowlog][timestamp]\", \"UNIX\" ] } mutate { gsub = [\"[mysql][slowlog][query]\", \"\\n# Time: [0-9]+ [0-9][0-9]:[0-9][0-9]:[0-9][0-9](.[0-9]+)?$\", \"\"] } } output { elasticsearch { hosts = localhost manage_template = false index = \"%{[@metadata][beat]}-%{+YYYY.MM.dd}\" document_type = \"%{[@metadata][type]}\" } } Nginx Logsedit Here are some configuration examples for shipping and parsing Nginx access and error logs. Nginx Access Logsedit Example Filebeat config: filebeat.prospectors: input_type: log paths: /var/log/nginx/access.log* exclude_files: [\".gz$\"] output.logstash: hosts: [\"localhost:5044\"] Example Logstash pipeline config: input { beats { # The port to listen on for filebeat connections. port = 5044 # The IP address to listen for filebeat connections. host = \"0.0.0.0\" } } filter { grok { match = { \"message\" = [\"%{IPORHOST:[nginx][access][remote_ip]} - %{DATA:[nginx][access][user_name]} \\[%{HTTPDATE:[nginx][access][time]}\\] \\\"%{WORD:[nginx][access][method]} %{DATA:[nginx][access][url]} HTTP/%{NUMBER:[nginx][access][http_version]}\\\" %{NUMBER:[nginx][access][response_code]} %{NUMBER:[nginx][access][body_sent][bytes]} \\\"%{DATA:[nginx][access][referrer]}\\\" \\\"%{DATA:[nginx][access][agent]}\\\"\"] } remove_field = \"message\" } mutate { rename = { \"@timestamp\" = \"read_timestamp\" } } date { match = [ \"[nginx][access][time]\", \"dd/MMM/YYYY:H:m:s Z\" ] remove_field = \"[nginx][access][time]\" } useragent { source = \"[nginx][access][agent]\" target = \"[nginx][access][user_agent]\" remove_field = \"[nginx][access][agent]\" } geoip { source = \"[nginx][access][remote_ip]\" target = \"[nginx][access][geoip]\" } } output { elasticsearch { hosts = localhost manage_template = false index = \"%{[@metadata][beat]}-%{+YYYY.MM.dd}\" document_type = \"%{[@metadata][type]}\" } } Nginx Error Logsedit Example Filebeat config: filebeat.prospectors: input_type: log paths: /var/log/nginx/error.log* exclude_files: [\".gz$\"] output.logstash: hosts: [\"localhost:5044\"] Example Logstash pipeline config: input { beats { # The port to listen on for filebeat connections. port = 5044 # The IP address to listen for filebeat connections. host = \"0.0.0.0\" } } filter { grok { match = { \"message\" = [\"%{DATA:[nginx][error][time]} \\[%{DATA:[nginx][error][level]}\\] %{NUMBER:[nginx][error][pid]}#%{NUMBER:[nginx][error][tid]}: (\\*%{NUMBER:[nginx][error][connection_id]} )?%{GREEDYDATA:[nginx][error][message]}\"] } remove_field = \"message\" } mutate { rename = { \"@timestamp\" = \"read_timestamp\" } } date { match = [ \"[nginx][error][time]\", \"YYYY/MM/dd H:m:s\" ] remove_field = \"[nginx][error][time]\" } } output { elasticsearch { hosts = localhost manage_template = false index = \"%{[@metadata][beat]}-%{+YYYY.MM.dd}\" document_type = \"%{[@metadata][type]}\" } } System Logsedit Here are some configuration examples for shipping and parsing system logs. System Authorization Logsedit Example Filebeat config: filebeat.prospectors: input_type: log paths: /var/log/auth.log* /var/log/secure* exclude_files: [\".gz$\"] multiline: pattern: \"^\\s\" match: after output.logstash: hosts: [\"localhost:5044\"] Example Logstash pipeline config: input { beats { # The port to listen on for filebeat connections. port = 5044 # The IP address to listen for filebeat connections. host = \"0.0.0.0\" } } filter { grok { match = { \"message\" = [\"%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} sshd(?:\\[%{POSINT:[system][auth][pid]}\\])?: %{DATA:[system][auth][ssh][event]} %{DATA:[system][auth][ssh][method]} for (invalid user )?%{DATA:[system][auth][user]} from %{IPORHOST:[system][auth][ssh][ip]} port %{NUMBER:[system][auth][ssh][port]} ssh2(: %{GREEDYDATA:[system][auth][ssh][signature]})?\", \"%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} sshd(?:\\[%{POSINT:[system][auth][pid]}\\])?: %{DATA:[system][auth][ssh][event]} user %{DATA:[system][auth][user]} from %{IPORHOST:[system][auth][ssh][ip]}\", \"%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} sshd(?:\\[%{POSINT:[system][auth][pid]}\\])?: Did not receive identification string from %{IPORHOST:[system][auth][ssh][dropped_ip]}\", \"%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} sudo(?:\\[%{POSINT:[system][auth][pid]}\\])?: \\s*%{DATA:[system][auth][user]} :( %{DATA:[system][auth][sudo][error]} ;)? TTY=%{DATA:[system][auth][sudo][tty]} ; PWD=%{DATA:[system][auth][sudo][pwd]} ; USER=%{DATA:[system][auth][sudo][user]} ; COMMAND=%{GREEDYDATA:[system][auth][sudo][command]}\", \"%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} groupadd(?:\\[%{POSINT:[system][auth][pid]}\\])?: new group: name=%{DATA:system.auth.groupadd.name}, GID=%{NUMBER:system.auth.groupadd.gid}\", \"%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} useradd(?:\\[%{POSINT:[system][auth][pid]}\\])?: new user: name=%{DATA:[system][auth][user][add][name]}, UID=%{NUMBER:[system][auth][user][add][uid]}, GID=%{NUMBER:[system][auth][user][add][gid]}, home=%{DATA:[system][auth][user][add][home]}, shell=%{DATA:[system][auth][user][add][shell]}$\", \"%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} %{DATA:[system][auth][program]}(?:\\[%{POSINT:[system][auth][pid]}\\])?: %{GREEDYMULTILINE:[system][auth][message]}\"] } pattern_definitions = { \"GREEDYMULTILINE\"= \"(.|\\n)*\" } remove_field = \"message\" } date { match = [ \"[system][auth][timestamp]\", \"MMM d HH:mm:ss\", \"MMM dd HH:mm:ss\" ] } geoip { source = \"[system][auth][ssh][ip]\" target = \"[system][auth][ssh][geoip]\" } } output { elasticsearch { hosts = localhost manage_template = false index = \"%{[@metadata][beat]}-%{+YYYY.MM.dd}\" document_type = \"%{[@metadata][type]}\" } } Syslogedit Example Filebeat config: filebeat.prospectors: input_type: log paths: /var/log/messages* /var/log/syslog* exclude_files: [\".gz$\"] multiline: pattern: \"^\\s\" match: after output.logstash: hosts: [\"localhost:5044\"] Example Logstash pipeline config: input { beats { # The port to listen on for filebeat connections. port = 5044 # The IP address to listen for filebeat connections. host = \"0.0.0.0\" } } filter { grok { match = { \"message\" = [\"%{SYSLOGTIMESTAMP:[system][syslog][timestamp]} %{SYSLOGHOST:[system][syslog][hostname]} %{DATA:[system][syslog][program]}(?:\\[%{POSINT:[system][syslog][pid]}\\])?: %{GREEDYMULTILINE:[system][syslog][message]}\"] } pattern_definitions = { \"GREEDYMULTILINE\" = \"(.|\\n)*\" } remove_field = \"message\" } date { match = [ \"[system][syslog][timestamp]\", \"MMM d HH:mm:ss\", \"MMM dd HH:mm:ss\" ] } } output { elasticsearch { hosts = localhost manage_template = false index = \"%{[@metadata][beat]}-%{+YYYY.MM.dd}\" document_type = \"%{[@metadata][type]}\" } }","title":"filebeat"},{"location":"log-analysis/#elk_1","text":"refresh_interval for indexing Elasticsearch 。 1 。，，  logstash  5 。。  refresh_interval ， tmpl . json ： { order : 1 , template : logstash-* , settings : { index.refresh_interval : 30s , index.number_of_replicas : 0 # } }  curl - XPUT http : // localhost : 9200 / _template / template_newid - d @/root/tmpl.json 。 logstash ， order  0 ， id  logstash ， logstash / outputs / elasticsearch  template_name 。  order ","title":"elk"},{"location":"log-analysis/#logstash5-root","text":"vim /etc/logstash/startup.options LS_USER=root /usr/share/logstash/bin/system-install  logstash","title":"logstash5 root"},{"location":"log-analysis/#es","text":"elasticsearch ，，，，。，  kill ，。，，，， ，。 ： ： shard 。 curl - XPUT http : // 127 . 0 . 0 . 1 : 9200 / _cluster / settings - d { transient : { cluster.routing.allocation.enable : none } } ： shutdown  curl - XPOST http : // 127 . 0 . 0 . 1 : 9200 / _cluster / nodes / _local / _shutdown elasticsearch  2 . 0  shutdown ， pid 。 ：， ： 2 - 3 ，。 ： shard  curl - XPUT http : // 127 . 0 . 0 . 1 : 9200 / _cluster / settings - d { transient : { cluster.routing.allocation.enable : all } } 。","title":"es"},{"location":"log-analysis/#logio","text":"yum install npm -y npm install -g log . io  cd / root / . log . io cat log_server . conf  web_server . conf （） exports . config = { host : 0.0.0.0 , port : 28777 , auth : { user : admin , pass : xxxx } } cat harvester . conf exports . config = { nodeName : application_server , logStreams : { tomcat_pingtai : [ /usr/local/tomcat_pingtai/logs/catalina.out , ] , tomcat_pingtaitest : [ /usr/local/tomcat_pingtaitest/logs/catalina.out , ] , tomcat_cuishou : [ /usr/local/tomcat_cuishou/logs/catalina.out , ] , tomcat_cuishoutest : [ /usr/local/tomcat_cuishoutest/logs/catalina.out , ] , tomcat_blacklist : [ /usr/local/tomcat_blacklist/logs/catalina.out , ] } , server : { host : 0.0.0.0 , port : 28777 } } nohup log . io-server Launch server nohup log . io-harvester Start log harvester  http :// localhost : 28778 nginx  / etc / nginx / conf . d / default . conf location / logio { proxy_pass http : // 192.168.1.2 : 28778 / ; auth_basic secret ; auth_basic_user_file /etc/nginx/passwd.db ; } location / socket . io { proxy_pass http : // 192.168.1.2 : 28778 / socket . io ; proxy_http_version 1.1 ; proxy_set_header Upgrade $http_upgrade ; proxy_set_header Connection upgrade ; } htpasswd -c / etc / nginx / passwd . db admin chmod 400 / etc / nginx / passwd . db chown nginx . nginx / etc / nginx / passwd . db / etc / init . d / nginx reload","title":"logio"},{"location":"lvs/","text":"lvs_keepalived LAN ，，： 1 、 Proxy ARP —— ARP，，MACARP； 2 、 Routing Protocol ——  ( RIPOSPF ) ； 3 、 ICMP IRDP ( Router Discovery Protocol )  —— ICMP； ，，， 。，，。 ，LAN。 VRRP ( VRRP ) IP ( VIP ) ，VIP。 1VLAN，，Router A 、 B 、 CVRRP ，VIP10 .0.0.1 ，A，A master，BCbackup。 VRRP ，master ( A ) VIP，1、 2 、 3 VIP 。master，backupBCmasterVIP，masterA ，master。 VRRP “”，VRRP，。 VRRP ： VRRP ( VRRP router ) ： VRRP ： ：LAN，； ：LAN； VRRP：255VRRP； IP：IP，； ：masterbackupmaster； ：IANA224 .0.0.18 VRRP； VRRP ：VRRPVRRPmaster； keepalivedhaproxy： ! Configuration File for keepalived global_defs { notification_email { linuxedu@foxmail . com mageedu@ 126. com } notification_email_from kanotify@magedu . com smtp_connect_timeout 3 smtp_server 127.0.0.1 router_id LVS_DEVEL } vrrp_script chk_haproxy { script killall -0 haproxy interval 1 weight 2 } vrrp_script chk_mantaince_down { script [[ -f /etc/keepalived/down ]] exit 1 || exit 0 interval 1 weight 2 } vrrp_instance VI_1 { interface eth0 state MASTER # BACKUP for slave routers priority 101 # 100 for BACKUP virtual_router_id 51 garp_master_delay 1 authentication { auth_type PASS auth_pass password } track_interface { eth0 } virtual_ipaddress { 172.16.100.1 / 16 dev eth0 label eth0: 0 } track_script { chk_haproxy chk_mantaince_down } notify_master /etc/keepalived/notify.sh master notify_backup /etc/keepalived/notify.sh backup notify_fault /etc/keepalived/notify.sh fault } ： 1 、state，master / slave，MASTER，BACKUP。 2 、priority，masterslave； notify . sh： # ! / bin / bash # Author : MageEdu linuxedu@foxmail . com # description : An example of notify script # vip = 172.16.100.1 contact= root@localhost Notify () { mailsubject= `hostname` to be $1: $vip floating mailbody= `date +%F %H:%M:%S `: vrrp transition, `hostname` changed to be $1 echo $ mailbody | mail - s $mailsubject $ contact } case $1 in master ) notify master / etc / rc . d / init . d / haproxy start exit 0 ;; backup ) notify backup / etc / rc . d / init . d / haproxy restart exit 0 ;; fault ) notify fault exit 0 ;; * ) echo Usage: `basename $0` {master|backup|fault} exit 1 ;; esac keepalivedhaproxy： ：，。 ! Configuration File for keepalived global_defs { notification_email { linuxedu@foxmail . com mageedu@ 126. com } notification_email_from kanotify@magedu . com smtp_connect_timeout 3 smtp_server 127.0.0.1 router_id LVS_DEVEL } vrrp_script chk_haproxy { script killall -0 haproxy interval 1 weight 2 } vrrp_script chk_mantaince_down { script [[ -f /etc/keepalived/down ]] exit 1 || exit 0 interval 1 weight 2 } vrrp_instance VI_1 { interface eth0 state MASTER # BACKUP for slave routers priority 101 # 100 for BACKUP virtual_router_id 51 garp_master_delay 1 authentication { auth_type PASS auth_pass password } track_interface { eth0 } virtual_ipaddress { 172.16.100.1 / 16 dev eth0 label eth0: 0 } track_script { chk_haproxy chk_mantaince_down } notify_master /etc/keepalived/notify.sh master notify_backup /etc/keepalived/notify.sh backup notify_fault /etc/keepalived/notify.sh fault } vrrp_instance VI_2 { interface eth0 state BACKUP # BACKUP for slave routers priority 100 # 100 for BACKUP virtual_router_id 52 garp_master_delay 1 authentication { auth_type PASS auth_pass password } track_interface { eth0 } virtual_ipaddress { 172.16.100.2 / 16 dev eth0 label eth0: 1 } track_script { chk_haproxy chk_mantaince_down } } ： 1 、VI_1VI_2，； LVS + keepalived： ! Configuration File for keepalived global_defs { notification_email { linuxedu@foxmail . com mageedu@ 126. com } notification_email_from kanotify@magedu . com smtp_connect_timeout 3 smtp_server 127.0.0.1 router_id LVS_DEVEL } vrrp_script chk_schedown { script [[ -f /etc/keepalived/down ]] exit 1 || exit 0 interval 2 weight - 2 } vrrp_instance VI_1 { interface eth0 state MASTER priority 101 virtual_router_id 51 garp_master_delay 1 authentication { auth_type PASS auth_pass password } track_interface { eth0 } virtual_ipaddress { 172.16.100.1 / 16 dev eth0 label eth0: 0 } track_script { chk_schedown } } virtual_server 172.16.100.1 80 { delay_loop 6 lb_algo rr lb_kind DR persistence_timeout 50 protocol TCP # sorry_server 192.168.200.200 1358 real_server 172.16.100.11 80 { weight 1 HTTP_GET { url { path / status_code 200 } connect_timeout 3 nb_get_retry 3 delay_before_retry 3 } } real_server 172.16.100.12 80 { weight 1 HTTP_GET { url { path / status_code 200 } connect_timeout 3 nb_get_retry 3 delay_before_retry 3 } } } TCP_CHECKrealserver，，realserver： virtual_server 172.16.100.1 80 { delay_loop 6 lb_algo rr lb_kind DR persistence_timeout 300 protocol TCP sorry_server 127.0.0.1 80 real_server 172.16.100.11 80 { weight 1 TCP_CHECK { tcp_port 80 connect_timeout 3 } } real_server 172.16.100.12 80 { weight 1 TCP_CHECK { connect_port 80 connect_timeout 3 } } } ：sorry_serverrealserver。 keepalived： ，： - s , --service SERVICE ,... ：，、； - a , --address VIP : VIP； - m , --mode { mm | mb } ：，mm，mb；，VIP； - n , --notify { master | backup | fault } ：，vrrp； - h , --help：； # ! / bin / bash # Author : MageEdu linuxedu@foxmail . com # description : An example of notify script # Usage : notify . sh - m | --mode { mm | mb } - s | --service SERVICE1 ,... - a | --address VIP - n | --notify { master | backup | falut } - h | --help #contact= linuxedu@foxmail.com helpflag = 0 serviceflag = 0 modeflag = 0 addressflag = 0 notifyflag = 0 contact= root@localhost Usage () { echo Usage: notify.sh [-m|--mode {mm|mb}] [-s|--service SERVICE1,...] -a|--address VIP -n|--notify {master| backup|falut} echo Usage: notify.sh -h|--help } ParseOptions () { local I = 1 ; if [ $ # - gt 0 ]; then while [ $ I - le $ # ]; do case $ 1 in - s | --service ) [ $ # - lt 2 ] return 3 serviceflag = 1 services= ( ` echo $ 2 | awk - F , {for(i=1;i =NF;i++) print $i} ` ) shift 2 ;; - h | --help ) helpflag = 1 return 0 shift ;; - a | --address ) [ $ # - lt 2 ] return 3 addressflag = 1 vip= $ 2 shift 2 ;; - m | --mode ) [ $ # - lt 2 ] return 3 mode= $ 2 shift 2 ;; - n | --notify ) [ $ # - lt 2 ] return 3 notifyflag = 1 notify= $ 2 shift 2 ;; * ) echo Wrong options... Usage return 7 ;; esac done return 0 fi } #workspace= $ ( dirname $ 0 ) RestartService () { if [ $ { #@ } - gt 0 ]; then for I in $ @ ; do if [ - x / etc / rc . d / init . d/ $ I ]; then / etc / rc . d / init . d/ $ I restart else echo $I is not a valid service... fi done fi } StopService () { if [ $ { #@ } - gt 0 ]; then for I in $ @ ; do if [ - x / etc / rc . d / init . d/ $ I ]; then / etc / rc . d / init . d/ $ I stop else echo $I is not a valid service... fi done fi } Notify () { mailsubject= `hostname` to be $1: $vip floating mailbody= `date +%F %H:%M:%S `, vrrp transition, `hostname` changed to be $1. echo $ mailbody | mail - s $mailsubject $ contact } # Main Function ParseOptions $ @ [ $ ? - ne 0 ] Usage exit 5 [ $ helpflag - eq 1 ] Usage exit 0 if [ $ addressflag - ne 1 - o $ notifyflag - ne 1 ]; then Usage exit 2 fi mode= $ { mode : - mb } case $ notify in master ) if [ $ serviceflag - eq 1 ]; then RestartService $ { services [ * ]} fi Notify master ;; backup ) if [ $ serviceflag - eq 1 ]; then if [ $mode == mb ]; then StopService $ { services [ * ]} else RestartService $ { services [ * ]} fi fi Notify backup ;; fault ) Notify fault ;; * ) Usage exit 4 ;; esac keepalived . conf，： notify_master /etc/keepalived/notify.sh -n master -a 172.16.100.1 notify_backup /etc/keepalived/notify.sh -n backup -a 172.16.100.1 notify_fault /etc/keepalived/notify.sh -n fault -a 172.16.100.1  yum - y install httpd  httpd 。  192 . 168 . 1 . 103  192 . 168 . 1 . 104 ： [ root @ centos ~ ]# yum - y install httpd echo 103 / var / www / html / index . html #（ 104  103  104 ） [ root @ centos ~ ]# setenforce 0 # SELinux [ root @ centos ~ ]# / etc / rc . d / init . d / iptables stop # 4 、 LVS ： [ root @ centos1 ~ ]# mkdir download [ root @ centos1 ~ ]# cd download / [ root @ centos1 download ]# wget http : // www . linuxvirtualserver . org / software / kernel - 2 . 6 / ipvsadm - 1 . 24 . tar . gz 5 、 ： 192 . 168 . 1 . 101  192 . 168 . 1 . 104 ： [ root @ centos1 download ]# uname - r # linux  2 . 6 . 32 - 220 . el6 . x86_64 [ root @ centos1 download ]# ln - s / usr / src / kernels / 2 . 6 . 32 - 220 . el6 . x86_64 / / usr / src / linux #， ： ln  uname - r , / usr / src / kernels / 2 . 6 . 32 - 220 . el6 . x86_64 /  kernel - devel 。 [ root @ centos1 download ]# tar zxvf ipvsadm - 1 . 24 . tar . gz [ root @ centos1 download ]# cd ipvsadm - 1 . 24 [ root @ centos1 ipvsadm - 1 . 24 ]# make [ root @ centos1 ipvsadm - 1 . 24 ]# make install [ root @ centos1 ipvsadm - 1 . 24 ]# ipvsadm # ipvsadm ， LVS  linux  IP Virtual Server version 1 . 2 . 1 ( size = 4096 ) Prot LocalAddress : Port Scheduler Flags - RemoteAddress : Port Forward Weight ActiveConn InActConn [ root @ centos1 ipvsadm - 1 . 24 ]# lsmod | grep ip_vs # LVS  linux ，。 ip_vs 108133 0 ipv6 322029 154 ip_vs , ip6t_REJECT , nf_conntrack_ipv6 , nf_defrag_ipv6 6  LVS   192 . 168 . 1 . 101  192 . 168 . 1 . 114  LVS DR  1 ）、 LVS ， LVS ： 192 . 168 . 1 . 101  192 . 168 . 1 . 114  [ root @ centos1 bin ]# vim lvs_dr . sh # !/ bin / bash . / etc / init . d / functions vim lvs_dr . sh # !/ bin / bash GW = 192 . 168 . 1 . 1 # website director vip . SNS_VIP = 192 . 168 . 1 . 181 SNS_RIP1 = 192 . 168 . 1 . 103 SNS_RIP2 = 192 . 168 . 1 . 104 logger $0 called with $1 case $1 in start ) # set squid vip / sbin / ipvsadm -- set 30 5 60 / sbin / ifconfig eth0 : 0 $ SNS_VIP broadcast $ SNS_VIP netmask 255 . 255 . 255 . 255 up / sbin / route add - host $ SNS_VIP dev eth0 : 0 / sbin / ipvsadm - A - t $ SNS_VIP : 80 - s wrr - p 3 / sbin / ipvsadm - a - t $ SNS_VIP : 80 - r $ SNS_RIP1 : 80 - g - w 1 / sbin / ipvsadm - a - t $ SNS_VIP : 80 - r $ SNS_RIP2 : 80 - g - w 1 touch / var / lock / subsys / ipvsadm / dev / null 2 1 ;; stop ) / sbin / ipvsadm - C / sbin / ipvsadm - Z ifconfig eth0 : 0 down ifconfig eth0 : 1 down route del $ SNS_VIP route del $ SS_VIP rm - rf / var / lock / subsys / ipvsadm / dev / null 2 1 echo ipvsadm stoped ;; status ) if [ ! - e / var / lock / subsys / ipvsadm ] ;then echo ipvsadm stoped exit 1 else echo ipvsadm OK fi ;; * ) echo Usage: $0 {start|stop|status} exit 1 esac exit 0 [ root @ centos1 bin ]# chmod + x lvs_dr . sh [ root @ centos1 bin ]# cp lvs_dr . sh / etc / rc . d / init . d / # [ root @ centos1 bin ]# service lvs_dr . sh start # lvs   ipvsadm - Ln ， LVS  [ root @ centos1 bin ]# ipvsadm IP Virtual Server version 1 . 2 . 1 ( size = 4096 ) Prot LocalAddress : Port Scheduler Flags - RemoteAddress : Port Forward Weight ActiveConn InActConn TCP 192 . 168 . 1 . 181 : http wrr persistent 3 - 192 . 168 . 1 . 104 : http Route 1 0 0 - 192 . 168 . 1 . 103 : http Route 1 0 0 7 、 LVS RS  [ root @ centos bin ]# vim lvs_dr . sh # !/ bin / bash . / etc / init . d / functions SNS_VIP = 192 . 168 . 1 . 181 case $1 in start ) ifconfig lo : 0 $ SNS_VIP netmask 255 . 255 . 255 . 255 broadcast $ SNS_VIP / sbin / route add - host $ SNS_VIP dev lo : 0 echo 1 / proc / sys / net / ipv4 / conf / lo / arp_ignore echo 2 / proc / sys / net / ipv4 / conf / lo / arp_announce echo 1 / proc / sys / net / ipv4 / conf / all / arp_ignore echo 2 / proc / sys / net / ipv4 / conf / all / arp_announce sysctl - p / dev / null 2 1 echo RealServer Start OK ;; stop ) ifconfig lo : 0 down route del $ SNS_VIP / dev / null 2 1 echo 0 / proc / sys / net / ipv4 / conf / lo / arp_ignore echo 0 / proc / sys / net / ipv4 / conf / lo / arp_announce echo 0 / proc / sys / net / ipv4 / conf / all / arp_ignore echo 0 / proc / sys / net / ipv4 / conf / all / arp_announce echo RealServer Stoped ;; * ) echo Usage: $0 {start|stop} exit 1 esac exit 0 [ root @ centos bin ]# cp lvs_dr . sh / etc / rc . d / init . d / [ root @ centos bin ]# service lvs_dr . sh start # lvs RS  RealServer Start OK yum install - y keepalived global_defs { notification_email { edisonchou @ hotmail . com } notification_email_from sns - lvs @ gmail . com smtp_server 192 . 168 . 80 . 1 smtp_connection_timeout 30 router_id LVS_DEVEL #  lvs  id ， } vrrp_instance VI_1 { state MASTER # Keepalived ， MASTER ， BACKUP  interface eth1 # Keepalived ， MASTER ， BACKUP  virtual_router_id 51 #， priority 100 #，，， DR  DR advert_int 1 #， 1 s authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 192 . 168 . 80 . 200 # IP ( VIP )  192 . 168 . 2 . 33 ，， } } #  LVS  VIP  port virtual_server 192 . 168 . 80 . 200 80 { delay_loop 6 # ， lb_algo wrr #  wlc lb_kind DR #  LVS ， NAT 、 TUN 、 DR  nat_mask 255 . 255 . 255 . 0 persistence_timeout 0 protocol TCP real_server 192 . 168 . 80 . 102 80 { #  real server1  IP  weight 3 # ， TCP_CHECK { connect_timeout 10 nb_get_retry 3 delay_before_retry 3 connect_port 80 } } real_server 192 . 168 . 80 . 103 80 { #  real server2  IP  weight 3 # ， TCP_CHECK { connect_timeout 10 nb_get_retry 3 delay_before_retry 3 connect_port 80 } } } 3 . 5  ， keepalived ： （ 1 ） state  MASTER  BACKUP （ 2 ） priority  100  99 vrrp_instance VI_1 { state BACKUP #  BACKUP interface eth1 virtual_router_id 51 priority 99 #  99 ， master  100 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 192 . 168 . 80 . 200 } }  LVS  LVS  Linux Virtual Server ， Linux ；【 LB IP 】。 LVS  : · ( load balancer ) ： LVS ， client  [  LB IP ] ， client   IP 【 IP  IP / VIP 】 · ( server pool ) ： client ， web ； web ， FTP ， MAIL ， DNS · ( shared stored ) ： server pool ，， [  ] LVS  4 ， 4 ： LVS DR  1. DR ( Direct Routing ) ： 2. ： ( 1 ). client  pv  VIP ； VIP  LVS  LB  LB  realserver ， package  MAC  realserver  MAC ； package ：  Package ： src mac 、 dst mac 、 src ip 、 src prot 、 dst ip 、 dst ip ；  dst mac  LVS VIP  MAC [  TCP  dsp ip  dsp mac  ] · DR  packet  dst mac  realserver  MAC ； VIP  LAN ；， VIP   realserver ， LAN 。 ：，，， LAN  IP ；  LAN ？； IP  32 ， 32 ： + ；： 1 ，  0 ； = IP   ；， realserver  LVS ， DR ， IP 。 · ARP  realserver 【 MAC 】 · src ip ----- realserver  mac  hash ；， client  hash ，  realserver ； · realserver  pachet ， dst ip  IP ；；。， DR   realserver  VIP  ip ： [ html ] view plain copy 1. / sbin / ifconfig lo : 0 inet VIP netmask 255.255.255.255 ----- ！ ·  realserver  package  dst 【 2  IP 】，， package  src mac dst mac src ip dst ip  ARP  VIP ， VIP  client 。 realserver  VIP  package ： · realserver ， dst  client ip  client ip ； lvs ；，。 LVS DR  package ： http : //os.51cto.com/art/201105/264303.htm 3. LVS DR ： · LVS  VIP  realserver ，：  LVS /  LB ， ·  realserver  VIP  IP ， realserver  package  dst  I ，。 · realserver · package  dst IP  client ， LVS /  IP  LVS / VIP 。 【 realserver  ip ，】 LVS NAT  1. LVS NAT ： 2. NAT ： · NAT ： · client ： 202.100.1.2 VIP : 202.103.106.5 realserver : 172.16.0.2 172.16.0.3  http  ftp  ( 1 ).  client  [ package ]  VIP ； [ html ] view plain copy 1. # client  VIP  package ： 2. SOURCE 202.100.1.2 : 3478 EDST 202.103.106.5 : 80 ( 2 ). VIP  package ， LVS  LB  realserver ， package  DST IP  realserver ： [ html ] view plain copy 1. # VIP  realserver  package ： 2. SOURCE 202.100.1.2 : 3478 EDST 172.16.0.3 ： 8000 ( 3 ). realserver  package  dst ip ， package ， LVS VIP ： [ html ] view plain copy 1. # realserver  VIP  package ： 2. SOURCE 172.16.0.3 ： 8000 EDST 202.100.1.2 : 3478 # lvs  package  dst ip  ？ ( 4 ). LVS  package  sorce ip  VIP  IP ， dst ip  client ip  client ： [ html ] view plain copy 1. # VIP  package  sourceip  client ： 2. SOURCE 202.103.106.5.80 ： 80 EDST 202.100.1.2 : 3478 3. NAT ： · NAT  dst IP ， switch  pub  MAC ， VIP  realserver 。 · NAT  package in  package out  LVS ； LVS 。 LVS FULL NAT  1. FULL NATT ： FULL NAT  client  VIP ， package  dst ip ， package  src ip ； VIP  client  src ip ； NAT  FULL NAT ： ( 1 ).  client  [ package ]  VIP ； [ html ] view plain copy 1. # client  VIP  package ： 2. SOURCE 202.100.1.2 : 3478 EDST 202.103.106.5 : 80 ( 2 ). VIP  package ， LVS  LB  realserver ， package  DST IP  realserver ； sorce ip  lvs  LB IP [ html ] view plain copy 1. # VIP  realserver  package ： 2. SOURCE 172.24.101.135 [ lb ip ] EDST 172.16.0.3 ： 8000 ( 3 ). realserver  package  dst ip ， package ， LVS VIP ： [ html ] view plain copy 1. # realserver  VIP  package ： 2. SOURCE 172.16.0.3 ： 8000 EDST 172.24.101.135 [  ip  LVS VIP  ] ( 4 ). LVS  package  sorce ip  VIP  IP ， dst ip  client ip  client ： [ html ] view plain copy 1. # VIP  package  sourceip  client ： 2. SOURCE 202.103.106.5.80 ： 80 EDST 202.100.1.2 : 3478 2. FULL NAT ： · FULL NAT  LBIP  realserver ip ； · full nat  nat ： RS  LVS ； LVS --  · full nat  sorce ip  nat  10 % LVS IP TUNNEL  1. IP TUNNEL ： 2. IP TUNNEL ：  NAT  TUNNEL ： ( 1 ).  client  [ package ]  VIP ； [ html ] view plain copy 1. # client  VIP  package ： 2. SOURCE 202.100.1.2 : 3478 DST 202.103.106.5 : 80 ( 2 ). VIP  package ， LVS  LB  realserver ； client  package   IP ； IP  dst  realserver  IP [ html ] view plain copy 1. # VIP  realserver  package ： 2. client  strong DST 172.16.0.3 ： 8000 / strong ( 3 ). realserver  package  dst ip ， package  dst  VIP ；  VIP  ip ；，。  realserver  lo : 0  VIP  ip ，  [ html ] view plain copy 1. # realserver  client ： 2. SOURCE 172.16.0.3 ： 8000 DST 202.100.1.2 : 3478 【 client ip 】 3. IP TUNNEL ： · TUNNEL  realserver  VIP  IP  · TUNNEL  vip ------ realserver  TUNNEL ，， lvs vip  realserver  · TUNNEL  realserver  packet  client  lvs  · TUNNEL ，， LVS DR 、 NAT 、 FULL NAT 、 IP TUNNEL ： 1.  lvs vip  realserver ： DR  package  MAC  ARP  realserver ，  LVS  VIP  realserver  IP ， VIP  LVS ， DR  IP  LVS 。  DST ip  realserver  IP ， 2.  realserver  LVS vip  IP ： realserver  package  dst ip  ip ，； DR  dst  LVS  VIP ； realserver  VIP ； IP TUNNEL  package ， realserver  IP   DST  LVS  VIP ； realserver  VIP ； 3. ：  DR  TP TUNELL  package in  LVS ； package out  client ； NAT ；  IP TUNNEL  TUNNEL ， DR ； FULL NAT  DST IP  SOURCE IP  NAT  10 % ， 4 ： DR -- IP TUNNEL --- NAT ----- FULL NAT LVS  1. lvs   client  LVS VIP  server ， LVS  realserver  status . html ； LVS   realserver  LVS ； client ；【 client ； client  realserver 】； ； LVS ， RS ","title":"lvs"},{"location":"lvs/#lvs_keepalived","text":"LAN ，，： 1 、 Proxy ARP —— ARP，，MACARP； 2 、 Routing Protocol ——  ( RIPOSPF ) ； 3 、 ICMP IRDP ( Router Discovery Protocol )  —— ICMP； ，，， 。，，。 ，LAN。 VRRP ( VRRP ) IP ( VIP ) ，VIP。 1VLAN，，Router A 、 B 、 CVRRP ，VIP10 .0.0.1 ，A，A master，BCbackup。 VRRP ，master ( A ) VIP，1、 2 、 3 VIP 。master，backupBCmasterVIP，masterA ，master。 VRRP “”，VRRP，。 VRRP ： VRRP ( VRRP router ) ： VRRP ： ：LAN，； ：LAN； VRRP：255VRRP； IP：IP，； ：masterbackupmaster； ：IANA224 .0.0.18 VRRP； VRRP ：VRRPVRRPmaster； keepalivedhaproxy： ! Configuration File for keepalived global_defs { notification_email { linuxedu@foxmail . com mageedu@ 126. com } notification_email_from kanotify@magedu . com smtp_connect_timeout 3 smtp_server 127.0.0.1 router_id LVS_DEVEL } vrrp_script chk_haproxy { script killall -0 haproxy interval 1 weight 2 } vrrp_script chk_mantaince_down { script [[ -f /etc/keepalived/down ]] exit 1 || exit 0 interval 1 weight 2 } vrrp_instance VI_1 { interface eth0 state MASTER # BACKUP for slave routers priority 101 # 100 for BACKUP virtual_router_id 51 garp_master_delay 1 authentication { auth_type PASS auth_pass password } track_interface { eth0 } virtual_ipaddress { 172.16.100.1 / 16 dev eth0 label eth0: 0 } track_script { chk_haproxy chk_mantaince_down } notify_master /etc/keepalived/notify.sh master notify_backup /etc/keepalived/notify.sh backup notify_fault /etc/keepalived/notify.sh fault } ： 1 、state，master / slave，MASTER，BACKUP。 2 、priority，masterslave； notify . sh： # ! / bin / bash # Author : MageEdu linuxedu@foxmail . com # description : An example of notify script # vip = 172.16.100.1 contact= root@localhost Notify () { mailsubject= `hostname` to be $1: $vip floating mailbody= `date +%F %H:%M:%S `: vrrp transition, `hostname` changed to be $1 echo $ mailbody | mail - s $mailsubject $ contact } case $1 in master ) notify master / etc / rc . d / init . d / haproxy start exit 0 ;; backup ) notify backup / etc / rc . d / init . d / haproxy restart exit 0 ;; fault ) notify fault exit 0 ;; * ) echo Usage: `basename $0` {master|backup|fault} exit 1 ;; esac keepalivedhaproxy： ：，。 ! Configuration File for keepalived global_defs { notification_email { linuxedu@foxmail . com mageedu@ 126. com } notification_email_from kanotify@magedu . com smtp_connect_timeout 3 smtp_server 127.0.0.1 router_id LVS_DEVEL } vrrp_script chk_haproxy { script killall -0 haproxy interval 1 weight 2 } vrrp_script chk_mantaince_down { script [[ -f /etc/keepalived/down ]] exit 1 || exit 0 interval 1 weight 2 } vrrp_instance VI_1 { interface eth0 state MASTER # BACKUP for slave routers priority 101 # 100 for BACKUP virtual_router_id 51 garp_master_delay 1 authentication { auth_type PASS auth_pass password } track_interface { eth0 } virtual_ipaddress { 172.16.100.1 / 16 dev eth0 label eth0: 0 } track_script { chk_haproxy chk_mantaince_down } notify_master /etc/keepalived/notify.sh master notify_backup /etc/keepalived/notify.sh backup notify_fault /etc/keepalived/notify.sh fault } vrrp_instance VI_2 { interface eth0 state BACKUP # BACKUP for slave routers priority 100 # 100 for BACKUP virtual_router_id 52 garp_master_delay 1 authentication { auth_type PASS auth_pass password } track_interface { eth0 } virtual_ipaddress { 172.16.100.2 / 16 dev eth0 label eth0: 1 } track_script { chk_haproxy chk_mantaince_down } } ： 1 、VI_1VI_2，； LVS + keepalived： ! Configuration File for keepalived global_defs { notification_email { linuxedu@foxmail . com mageedu@ 126. com } notification_email_from kanotify@magedu . com smtp_connect_timeout 3 smtp_server 127.0.0.1 router_id LVS_DEVEL } vrrp_script chk_schedown { script [[ -f /etc/keepalived/down ]] exit 1 || exit 0 interval 2 weight - 2 } vrrp_instance VI_1 { interface eth0 state MASTER priority 101 virtual_router_id 51 garp_master_delay 1 authentication { auth_type PASS auth_pass password } track_interface { eth0 } virtual_ipaddress { 172.16.100.1 / 16 dev eth0 label eth0: 0 } track_script { chk_schedown } } virtual_server 172.16.100.1 80 { delay_loop 6 lb_algo rr lb_kind DR persistence_timeout 50 protocol TCP # sorry_server 192.168.200.200 1358 real_server 172.16.100.11 80 { weight 1 HTTP_GET { url { path / status_code 200 } connect_timeout 3 nb_get_retry 3 delay_before_retry 3 } } real_server 172.16.100.12 80 { weight 1 HTTP_GET { url { path / status_code 200 } connect_timeout 3 nb_get_retry 3 delay_before_retry 3 } } } TCP_CHECKrealserver，，realserver： virtual_server 172.16.100.1 80 { delay_loop 6 lb_algo rr lb_kind DR persistence_timeout 300 protocol TCP sorry_server 127.0.0.1 80 real_server 172.16.100.11 80 { weight 1 TCP_CHECK { tcp_port 80 connect_timeout 3 } } real_server 172.16.100.12 80 { weight 1 TCP_CHECK { connect_port 80 connect_timeout 3 } } } ：sorry_serverrealserver。 keepalived： ，： - s , --service SERVICE ,... ：，、； - a , --address VIP : VIP； - m , --mode { mm | mb } ：，mm，mb；，VIP； - n , --notify { master | backup | fault } ：，vrrp； - h , --help：； # ! / bin / bash # Author : MageEdu linuxedu@foxmail . com # description : An example of notify script # Usage : notify . sh - m | --mode { mm | mb } - s | --service SERVICE1 ,... - a | --address VIP - n | --notify { master | backup | falut } - h | --help #contact= linuxedu@foxmail.com helpflag = 0 serviceflag = 0 modeflag = 0 addressflag = 0 notifyflag = 0 contact= root@localhost Usage () { echo Usage: notify.sh [-m|--mode {mm|mb}] [-s|--service SERVICE1,...] -a|--address VIP -n|--notify {master| backup|falut} echo Usage: notify.sh -h|--help } ParseOptions () { local I = 1 ; if [ $ # - gt 0 ]; then while [ $ I - le $ # ]; do case $ 1 in - s | --service ) [ $ # - lt 2 ] return 3 serviceflag = 1 services= ( ` echo $ 2 | awk - F , {for(i=1;i =NF;i++) print $i} ` ) shift 2 ;; - h | --help ) helpflag = 1 return 0 shift ;; - a | --address ) [ $ # - lt 2 ] return 3 addressflag = 1 vip= $ 2 shift 2 ;; - m | --mode ) [ $ # - lt 2 ] return 3 mode= $ 2 shift 2 ;; - n | --notify ) [ $ # - lt 2 ] return 3 notifyflag = 1 notify= $ 2 shift 2 ;; * ) echo Wrong options... Usage return 7 ;; esac done return 0 fi } #workspace= $ ( dirname $ 0 ) RestartService () { if [ $ { #@ } - gt 0 ]; then for I in $ @ ; do if [ - x / etc / rc . d / init . d/ $ I ]; then / etc / rc . d / init . d/ $ I restart else echo $I is not a valid service... fi done fi } StopService () { if [ $ { #@ } - gt 0 ]; then for I in $ @ ; do if [ - x / etc / rc . d / init . d/ $ I ]; then / etc / rc . d / init . d/ $ I stop else echo $I is not a valid service... fi done fi } Notify () { mailsubject= `hostname` to be $1: $vip floating mailbody= `date +%F %H:%M:%S `, vrrp transition, `hostname` changed to be $1. echo $ mailbody | mail - s $mailsubject $ contact } # Main Function ParseOptions $ @ [ $ ? - ne 0 ] Usage exit 5 [ $ helpflag - eq 1 ] Usage exit 0 if [ $ addressflag - ne 1 - o $ notifyflag - ne 1 ]; then Usage exit 2 fi mode= $ { mode : - mb } case $ notify in master ) if [ $ serviceflag - eq 1 ]; then RestartService $ { services [ * ]} fi Notify master ;; backup ) if [ $ serviceflag - eq 1 ]; then if [ $mode == mb ]; then StopService $ { services [ * ]} else RestartService $ { services [ * ]} fi fi Notify backup ;; fault ) Notify fault ;; * ) Usage exit 4 ;; esac keepalived . conf，： notify_master /etc/keepalived/notify.sh -n master -a 172.16.100.1 notify_backup /etc/keepalived/notify.sh -n backup -a 172.16.100.1 notify_fault /etc/keepalived/notify.sh -n fault -a 172.16.100.1","title":"lvs_keepalived"},{"location":"lvs/#_1","text":"yum - y install httpd  httpd 。  192 . 168 . 1 . 103  192 . 168 . 1 . 104 ： [ root @ centos ~ ]# yum - y install httpd echo 103 / var / www / html / index . html #（ 104  103  104 ） [ root @ centos ~ ]# setenforce 0 # SELinux [ root @ centos ~ ]# / etc / rc . d / init . d / iptables stop # 4 、 LVS ： [ root @ centos1 ~ ]# mkdir download [ root @ centos1 ~ ]# cd download / [ root @ centos1 download ]# wget http : // www . linuxvirtualserver . org / software / kernel - 2 . 6 / ipvsadm - 1 . 24 . tar . gz 5 、 ： 192 . 168 . 1 . 101  192 . 168 . 1 . 104 ： [ root @ centos1 download ]# uname - r # linux  2 . 6 . 32 - 220 . el6 . x86_64 [ root @ centos1 download ]# ln - s / usr / src / kernels / 2 . 6 . 32 - 220 . el6 . x86_64 / / usr / src / linux #， ： ln  uname - r , / usr / src / kernels / 2 . 6 . 32 - 220 . el6 . x86_64 /  kernel - devel 。 [ root @ centos1 download ]# tar zxvf ipvsadm - 1 . 24 . tar . gz [ root @ centos1 download ]# cd ipvsadm - 1 . 24 [ root @ centos1 ipvsadm - 1 . 24 ]# make [ root @ centos1 ipvsadm - 1 . 24 ]# make install [ root @ centos1 ipvsadm - 1 . 24 ]# ipvsadm # ipvsadm ， LVS  linux  IP Virtual Server version 1 . 2 . 1 ( size = 4096 ) Prot LocalAddress : Port Scheduler Flags - RemoteAddress : Port Forward Weight ActiveConn InActConn [ root @ centos1 ipvsadm - 1 . 24 ]# lsmod | grep ip_vs # LVS  linux ，。 ip_vs 108133 0 ipv6 322029 154 ip_vs , ip6t_REJECT , nf_conntrack_ipv6 , nf_defrag_ipv6 6  LVS   192 . 168 . 1 . 101  192 . 168 . 1 . 114  LVS DR  1 ）、 LVS ， LVS ： 192 . 168 . 1 . 101  192 . 168 . 1 . 114  [ root @ centos1 bin ]# vim lvs_dr . sh # !/ bin / bash . / etc / init . d / functions vim lvs_dr . sh # !/ bin / bash GW = 192 . 168 . 1 . 1 # website director vip . SNS_VIP = 192 . 168 . 1 . 181 SNS_RIP1 = 192 . 168 . 1 . 103 SNS_RIP2 = 192 . 168 . 1 . 104 logger $0 called with $1 case $1 in start ) # set squid vip / sbin / ipvsadm -- set 30 5 60 / sbin / ifconfig eth0 : 0 $ SNS_VIP broadcast $ SNS_VIP netmask 255 . 255 . 255 . 255 up / sbin / route add - host $ SNS_VIP dev eth0 : 0 / sbin / ipvsadm - A - t $ SNS_VIP : 80 - s wrr - p 3 / sbin / ipvsadm - a - t $ SNS_VIP : 80 - r $ SNS_RIP1 : 80 - g - w 1 / sbin / ipvsadm - a - t $ SNS_VIP : 80 - r $ SNS_RIP2 : 80 - g - w 1 touch / var / lock / subsys / ipvsadm / dev / null 2 1 ;; stop ) / sbin / ipvsadm - C / sbin / ipvsadm - Z ifconfig eth0 : 0 down ifconfig eth0 : 1 down route del $ SNS_VIP route del $ SS_VIP rm - rf / var / lock / subsys / ipvsadm / dev / null 2 1 echo ipvsadm stoped ;; status ) if [ ! - e / var / lock / subsys / ipvsadm ] ;then echo ipvsadm stoped exit 1 else echo ipvsadm OK fi ;; * ) echo Usage: $0 {start|stop|status} exit 1 esac exit 0 [ root @ centos1 bin ]# chmod + x lvs_dr . sh [ root @ centos1 bin ]# cp lvs_dr . sh / etc / rc . d / init . d / # [ root @ centos1 bin ]# service lvs_dr . sh start # lvs   ipvsadm - Ln ， LVS  [ root @ centos1 bin ]# ipvsadm IP Virtual Server version 1 . 2 . 1 ( size = 4096 ) Prot LocalAddress : Port Scheduler Flags - RemoteAddress : Port Forward Weight ActiveConn InActConn TCP 192 . 168 . 1 . 181 : http wrr persistent 3 - 192 . 168 . 1 . 104 : http Route 1 0 0 - 192 . 168 . 1 . 103 : http Route 1 0 0 7 、 LVS RS  [ root @ centos bin ]# vim lvs_dr . sh # !/ bin / bash . / etc / init . d / functions SNS_VIP = 192 . 168 . 1 . 181 case $1 in start ) ifconfig lo : 0 $ SNS_VIP netmask 255 . 255 . 255 . 255 broadcast $ SNS_VIP / sbin / route add - host $ SNS_VIP dev lo : 0 echo 1 / proc / sys / net / ipv4 / conf / lo / arp_ignore echo 2 / proc / sys / net / ipv4 / conf / lo / arp_announce echo 1 / proc / sys / net / ipv4 / conf / all / arp_ignore echo 2 / proc / sys / net / ipv4 / conf / all / arp_announce sysctl - p / dev / null 2 1 echo RealServer Start OK ;; stop ) ifconfig lo : 0 down route del $ SNS_VIP / dev / null 2 1 echo 0 / proc / sys / net / ipv4 / conf / lo / arp_ignore echo 0 / proc / sys / net / ipv4 / conf / lo / arp_announce echo 0 / proc / sys / net / ipv4 / conf / all / arp_ignore echo 0 / proc / sys / net / ipv4 / conf / all / arp_announce echo RealServer Stoped ;; * ) echo Usage: $0 {start|stop} exit 1 esac exit 0 [ root @ centos bin ]# cp lvs_dr . sh / etc / rc . d / init . d / [ root @ centos bin ]# service lvs_dr . sh start # lvs RS  RealServer Start OK yum install - y keepalived global_defs { notification_email { edisonchou @ hotmail . com } notification_email_from sns - lvs @ gmail . com smtp_server 192 . 168 . 80 . 1 smtp_connection_timeout 30 router_id LVS_DEVEL #  lvs  id ， } vrrp_instance VI_1 { state MASTER # Keepalived ， MASTER ， BACKUP  interface eth1 # Keepalived ， MASTER ， BACKUP  virtual_router_id 51 #， priority 100 #，，， DR  DR advert_int 1 #， 1 s authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 192 . 168 . 80 . 200 # IP ( VIP )  192 . 168 . 2 . 33 ，， } } #  LVS  VIP  port virtual_server 192 . 168 . 80 . 200 80 { delay_loop 6 # ， lb_algo wrr #  wlc lb_kind DR #  LVS ， NAT 、 TUN 、 DR  nat_mask 255 . 255 . 255 . 0 persistence_timeout 0 protocol TCP real_server 192 . 168 . 80 . 102 80 { #  real server1  IP  weight 3 # ， TCP_CHECK { connect_timeout 10 nb_get_retry 3 delay_before_retry 3 connect_port 80 } } real_server 192 . 168 . 80 . 103 80 { #  real server2  IP  weight 3 # ， TCP_CHECK { connect_timeout 10 nb_get_retry 3 delay_before_retry 3 connect_port 80 } } } 3 . 5  ， keepalived ： （ 1 ） state  MASTER  BACKUP （ 2 ） priority  100  99 vrrp_instance VI_1 { state BACKUP #  BACKUP interface eth1 virtual_router_id 51 priority 99 #  99 ， master  100 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 192 . 168 . 80 . 200 } }","title":""},{"location":"lvs/#_2","text":"LVS  LVS  Linux Virtual Server ， Linux ；【 LB IP 】。 LVS  : · ( load balancer ) ： LVS ， client  [  LB IP ] ， client   IP 【 IP  IP / VIP 】 · ( server pool ) ： client ， web ； web ， FTP ， MAIL ， DNS · ( shared stored ) ： server pool ，， [  ] LVS  4 ， 4 ： LVS DR  1. DR ( Direct Routing ) ： 2. ： ( 1 ). client  pv  VIP ； VIP  LVS  LB  LB  realserver ， package  MAC  realserver  MAC ； package ：  Package ： src mac 、 dst mac 、 src ip 、 src prot 、 dst ip 、 dst ip ；  dst mac  LVS VIP  MAC [  TCP  dsp ip  dsp mac  ] · DR  packet  dst mac  realserver  MAC ； VIP  LAN ；， VIP   realserver ， LAN 。 ：，，， LAN  IP ；  LAN ？； IP  32 ， 32 ： + ；： 1 ，  0 ； = IP   ；， realserver  LVS ， DR ， IP 。 · ARP  realserver 【 MAC 】 · src ip ----- realserver  mac  hash ；， client  hash ，  realserver ； · realserver  pachet ， dst ip  IP ；；。， DR   realserver  VIP  ip ： [ html ] view plain copy 1. / sbin / ifconfig lo : 0 inet VIP netmask 255.255.255.255 ----- ！ ·  realserver  package  dst 【 2  IP 】，， package  src mac dst mac src ip dst ip  ARP  VIP ， VIP  client 。 realserver  VIP  package ： · realserver ， dst  client ip  client ip ； lvs ；，。 LVS DR  package ： http : //os.51cto.com/art/201105/264303.htm 3. LVS DR ： · LVS  VIP  realserver ，：  LVS /  LB ， ·  realserver  VIP  IP ， realserver  package  dst  I ，。 · realserver · package  dst IP  client ， LVS /  IP  LVS / VIP 。 【 realserver  ip ，】 LVS NAT  1. LVS NAT ： 2. NAT ： · NAT ： · client ： 202.100.1.2 VIP : 202.103.106.5 realserver : 172.16.0.2 172.16.0.3  http  ftp  ( 1 ).  client  [ package ]  VIP ； [ html ] view plain copy 1. # client  VIP  package ： 2. SOURCE 202.100.1.2 : 3478 EDST 202.103.106.5 : 80 ( 2 ). VIP  package ， LVS  LB  realserver ， package  DST IP  realserver ： [ html ] view plain copy 1. # VIP  realserver  package ： 2. SOURCE 202.100.1.2 : 3478 EDST 172.16.0.3 ： 8000 ( 3 ). realserver  package  dst ip ， package ， LVS VIP ： [ html ] view plain copy 1. # realserver  VIP  package ： 2. SOURCE 172.16.0.3 ： 8000 EDST 202.100.1.2 : 3478 # lvs  package  dst ip  ？ ( 4 ). LVS  package  sorce ip  VIP  IP ， dst ip  client ip  client ： [ html ] view plain copy 1. # VIP  package  sourceip  client ： 2. SOURCE 202.103.106.5.80 ： 80 EDST 202.100.1.2 : 3478 3. NAT ： · NAT  dst IP ， switch  pub  MAC ， VIP  realserver 。 · NAT  package in  package out  LVS ； LVS 。 LVS FULL NAT  1. FULL NATT ： FULL NAT  client  VIP ， package  dst ip ， package  src ip ； VIP  client  src ip ； NAT  FULL NAT ： ( 1 ).  client  [ package ]  VIP ； [ html ] view plain copy 1. # client  VIP  package ： 2. SOURCE 202.100.1.2 : 3478 EDST 202.103.106.5 : 80 ( 2 ). VIP  package ， LVS  LB  realserver ， package  DST IP  realserver ； sorce ip  lvs  LB IP [ html ] view plain copy 1. # VIP  realserver  package ： 2. SOURCE 172.24.101.135 [ lb ip ] EDST 172.16.0.3 ： 8000 ( 3 ). realserver  package  dst ip ， package ， LVS VIP ： [ html ] view plain copy 1. # realserver  VIP  package ： 2. SOURCE 172.16.0.3 ： 8000 EDST 172.24.101.135 [  ip  LVS VIP  ] ( 4 ). LVS  package  sorce ip  VIP  IP ， dst ip  client ip  client ： [ html ] view plain copy 1. # VIP  package  sourceip  client ： 2. SOURCE 202.103.106.5.80 ： 80 EDST 202.100.1.2 : 3478 2. FULL NAT ： · FULL NAT  LBIP  realserver ip ； · full nat  nat ： RS  LVS ； LVS --  · full nat  sorce ip  nat  10 % LVS IP TUNNEL  1. IP TUNNEL ： 2. IP TUNNEL ：  NAT  TUNNEL ： ( 1 ).  client  [ package ]  VIP ； [ html ] view plain copy 1. # client  VIP  package ： 2. SOURCE 202.100.1.2 : 3478 DST 202.103.106.5 : 80 ( 2 ). VIP  package ， LVS  LB  realserver ； client  package   IP ； IP  dst  realserver  IP [ html ] view plain copy 1. # VIP  realserver  package ： 2. client  strong DST 172.16.0.3 ： 8000 / strong ( 3 ). realserver  package  dst ip ， package  dst  VIP ；  VIP  ip ；，。  realserver  lo : 0  VIP  ip ，  [ html ] view plain copy 1. # realserver  client ： 2. SOURCE 172.16.0.3 ： 8000 DST 202.100.1.2 : 3478 【 client ip 】 3. IP TUNNEL ： · TUNNEL  realserver  VIP  IP  · TUNNEL  vip ------ realserver  TUNNEL ，， lvs vip  realserver  · TUNNEL  realserver  packet  client  lvs  · TUNNEL ，， LVS DR 、 NAT 、 FULL NAT 、 IP TUNNEL ： 1.  lvs vip  realserver ： DR  package  MAC  ARP  realserver ，  LVS  VIP  realserver  IP ， VIP  LVS ， DR  IP  LVS 。  DST ip  realserver  IP ， 2.  realserver  LVS vip  IP ： realserver  package  dst ip  ip ，； DR  dst  LVS  VIP ； realserver  VIP ； IP TUNNEL  package ， realserver  IP   DST  LVS  VIP ； realserver  VIP ； 3. ：  DR  TP TUNELL  package in  LVS ； package out  client ； NAT ；  IP TUNNEL  TUNNEL ， DR ； FULL NAT  DST IP  SOURCE IP  NAT  10 % ， 4 ： DR -- IP TUNNEL --- NAT ----- FULL NAT LVS  1. lvs   client  LVS VIP  server ， LVS  realserver  status . html ； LVS   realserver  LVS ； client ；【 client ； client  realserver 】； ； LVS ， RS ","title":""},{"location":"memcached/","text":"memcache telnet 127 . 0 . 0 . 1 11211 stats   echo stats | nc 192 . 168 . 1 . 123 11200 watch echo stats | nc 192.168.1.123 11200 (  ) memcache stats  stats ： memcached 。， stats  memcached ： STAT pid 22459  ID STAT uptime 1027046  STAT time 1273043062  unix  STAT version 1 . 4 . 4  STAT pointer_size 64  (  64  ) STAT rusage_user 0 . 040000  STAT rusage_system 0 . 260000  STAT curr_connections 10  STAT total_connections 82  STAT connection_structures 13  STAT cmd_get 54  get  STAT cmd_set 34  set  STAT cmd_flush 3  flush_all  STAT get_hits 9 get  STAT get_misses 45 get  STAT delete_misses 5 delete  STAT delete_hits 1 delete  STAT incr_misses 0 incr  STAT incr_hits 0 incr  STAT decr_misses 0 decr  STAT decr_hits 0 decr  STAT cas_misses 0 cas  STAT cas_hits 0 cas  STAT cas_badval 0  STAT auth_cmds 0 STAT auth_errors 0 STAT bytes_read 15785  STAT bytes_written 15222  STAT limit_maxbytes 1048576 （） STAT accepting_conns 1  STAT listen_disabled_num 0 STAT threads 4  STAT conn_yields 0 STAT bytes 0  item  STAT curr_items 0 item  STAT total_items 34 item  STAT evictions 0  item  magent 1 . mkdir magent 2 . cd magent / 3 . wget http : // memagent . googlecode . com / files / magent - 0 . 5 . tar . gz （） 4 . tar zxvf magent - 0 . 5 . tar . gz 5 . / sbin / ldconfig 6 . sed - i s#LIBS = -levent#LIBS = -levent -lm#g Makefile 7 . vi magent . c  # include limits . h 8 . yum install libevent - devel libevent 9 . make 10 . cp magent / usr / bin / magent 2 . magent ： 1 . - h this message 2 . - u uid 3 . - g gid 4 . - p port , default is 11211 . ( 0 to disable tcp support ) 5 . - s ip : port , set memcached server ip and port 6 . - b ip : port , set backup memcached server ip and port 7 . - l ip , local bind ip address , default is 0 . 0 . 0 . 0 8 . - n number , set max connections , default is 4096 9 . - D do not go to background 10 . - k use ketama key allocation algorithm 11 . - f file , unix socket path to listen on . default is off 12 . - i number , max keep alive connections for one memcached server , default is 20 13 . - v verbose memcached - m 1 - u root - d - l 192 . 168 . 1 . 219 - p 11211 memcached - m 1 - u root - d - l 192 . 168 . 1 . 219 - p 11212 memcached - m 1 - u root - d - l 192 . 168 . 1 . 219 - p 11213 magent - u root - n 51200 - l 192 . 168 . 1 . 219 - p 12000 - s 192 . 168 . 1 . 219 : 11211 - s 192 . 168 . 1 . 219 : 11212 - b 192 . 168 . 1 . 219 : 11213 1 、 11211 、 11212 、 11213  3  Memcached ， 12000  magent ； 2 、 11211 、 11212  Memcached ， 11213  Memcached ； 3 、 12000  magent ， set key1  set key2 ，， key1  11212  11213  Memcached ， key2  11212  11213  Memcached ； 4 、 11211 、 11212  Memcached ， 12000  magent ， 11213  Memcached 。 ： # telnet 192 . 168 . 1 . 219 12000 Trying 1192 . 168 . 1 . 219 ... Connected to 192 . 168 . 1 。 219 . Escape character is ^] . stats memcached agent v0 . 4 matrix 1 - 192 . 168 . 1 . 219 : 11211 , pool size 0 matrix 2 - 192 . 168 . 1 . 219 : 11212 , pool size 0 END set key1 0 0 5 reesu  5 STORED set key2 0 0 6 reesu1  5 STORED quit Connection closed by foreign host . # telnet 192 . 168 . 1 . 219 11211 Trying 192 . 168 . 1 . 219 ... Connected to 192 . 168 . 1 . 219 . Escape character is ^] . get key1 END get key2 VALUE key2 0 6 reesun1 END quit Connection closed by foreign host . # telnet 192 . 168 . 1 . 219 11212 Trying 192 . 168 . 1 . 219 ... Connected to 1192 . 168 . 1 . 219 . Escape character is ^] . get key1 VALUE key1 0 5 reesun END get key2 END quit Connection closed by foreign host . # telnet 192 . 168 . 1 . 219 11213 Trying 192 . 168 . 1 . 219 ... Connected to 1192 . 168 . 1 . 219 . Escape character is ^] . get key1 VALUE key1 0 5 ( key  ) hello END get key2 VALUE key2 0 6 reesun END quit Connection closed by foreign host .   flush_all  / 。  flush_all ，，，，， ，，，。 key 1 . cmd  memcache telnet 127 . 0 . 0 . 1 11211 2 .  keys stats items //  STAT items : 7 : number 1 STAT items : 7 : age 188 END 3 .  itemid  key  items id ， 7 ， 2 ， 0  stats cachedump 7 0 //  ITEM Sess_sidsvpc1473t1np08qnkvhf6j2 [ 183 b ; 1394527347 s] END 4 .  get  key   stats cachedump  session key ， get  session  get Sess_sidsvpc1473t1np08qnkvhf6j2 //  VALUE Sess_sidsvpc1473t1np08qnkvhf6j2 1440 1 83 Sess_ | a : 5 :{ s : 6 : verify ;s:32: e70981fd305170c41a5632b2a24bbcaa ;s:3: uid ;s:1: 1 ;s:8: username ;s:5: admin ;s:9: logintime ;s:19: 2014 - 03 - 11 16 : 24 : 25 ;s:7: log inip ;s:9: 127 . 0 . 0 . 1 ;} memcache yum  yum install memcached memcached - devel - y vim / etc / sysconfig / memcached PORT = 11211 USER = memcached MAXCONN = 1024  CACHESIZE = 128  （ M ） OPTIONS = / etc / init . d / memcached start  Memcached ： wget http : // memcached . googlecode . com / files / memcached - 1 . 4 . 4 . tar . gz tar - xzvf memcached - 1 . 4 . 4 . tar . gz cd memcached - 1 . 4 . 4 . / configure -- prefix =/ usr / local / memcached -- with - libevent =/ usr / local / libevent make make install ln - s / usr / local / libevent / lib / libevent - 1 . 4 . so . 2 / usr / lib / memcached - m 500 - u root - d - l 192 . 168 . 1 . 219 - p 11211 memcached : - d ：， - m ： Memcache ， MB ， 64 MB ， - u ： Memcache  - l ： IP  - p ： Memcache ， 11211 ： - p ( p  ) - c ：， 1024 - P ： Memcache  pid ： - P ( P  ) - h   memcached ： telnet ip ， telnet 192 . 168 . 100 . 11 11211 stats ， flush_all :  memcached ，： STAT pid 22459  ID STAT uptime 1027046  STAT time 1273043062  unix  STAT version 1 . 4 . 4  STAT pointer_size 64  (  64  ) STAT rusage_user 0 . 040000  STAT rusage_system 0 . 260000  STAT curr_connections 10  STAT total_connections 82  STAT connection_structures 13  STAT cmd_get 54  get  STAT cmd_set 34  set  STAT cmd_flush 3  flush_all  STAT get_hits 9 get  STAT get_misses 45 get  STAT delete_misses 5 delete  STAT delete_hits 1 delete  STAT incr_misses 0 incr  STAT incr_hits 0 incr  STAT decr_misses 0 decr  STAT decr_hits 0 decr  STAT cas_misses 0 cas  STAT cas_hits 0 cas  STAT cas_badval 0  STAT auth_cmds 0 STAT auth_errors 0 STAT bytes_read 15785  STAT bytes_written 15222  STAT limit_maxbytes 1048576 （） STAT accepting_conns 1  STAT listen_disabled_num 0 STAT threads 4  STAT conn_yields 0 STAT bytes 0  item  STAT curr_items 0 item  STAT total_items 34 item  STAT evictions 0  item   echo stats | nc 192 . 168 . 1 . 123 11200 watch echo stats | nc 192.168.1.123 11200 (  )","title":"memcached"},{"location":"memcached/#memcache","text":"telnet 127 . 0 . 0 . 1 11211 stats   echo stats | nc 192 . 168 . 1 . 123 11200 watch echo stats | nc 192.168.1.123 11200 (  ) memcache stats  stats ： memcached 。， stats  memcached ： STAT pid 22459  ID STAT uptime 1027046  STAT time 1273043062  unix  STAT version 1 . 4 . 4  STAT pointer_size 64  (  64  ) STAT rusage_user 0 . 040000  STAT rusage_system 0 . 260000  STAT curr_connections 10  STAT total_connections 82  STAT connection_structures 13  STAT cmd_get 54  get  STAT cmd_set 34  set  STAT cmd_flush 3  flush_all  STAT get_hits 9 get  STAT get_misses 45 get  STAT delete_misses 5 delete  STAT delete_hits 1 delete  STAT incr_misses 0 incr  STAT incr_hits 0 incr  STAT decr_misses 0 decr  STAT decr_hits 0 decr  STAT cas_misses 0 cas  STAT cas_hits 0 cas  STAT cas_badval 0  STAT auth_cmds 0 STAT auth_errors 0 STAT bytes_read 15785  STAT bytes_written 15222  STAT limit_maxbytes 1048576 （） STAT accepting_conns 1  STAT listen_disabled_num 0 STAT threads 4  STAT conn_yields 0 STAT bytes 0  item  STAT curr_items 0 item  STAT total_items 34 item  STAT evictions 0  item ","title":"memcache"},{"location":"memcached/#magent","text":"1 . mkdir magent 2 . cd magent / 3 . wget http : // memagent . googlecode . com / files / magent - 0 . 5 . tar . gz （） 4 . tar zxvf magent - 0 . 5 . tar . gz 5 . / sbin / ldconfig 6 . sed - i s#LIBS = -levent#LIBS = -levent -lm#g Makefile 7 . vi magent . c  # include limits . h 8 . yum install libevent - devel libevent 9 . make 10 . cp magent / usr / bin / magent 2 . magent ： 1 . - h this message 2 . - u uid 3 . - g gid 4 . - p port , default is 11211 . ( 0 to disable tcp support ) 5 . - s ip : port , set memcached server ip and port 6 . - b ip : port , set backup memcached server ip and port 7 . - l ip , local bind ip address , default is 0 . 0 . 0 . 0 8 . - n number , set max connections , default is 4096 9 . - D do not go to background 10 . - k use ketama key allocation algorithm 11 . - f file , unix socket path to listen on . default is off 12 . - i number , max keep alive connections for one memcached server , default is 20 13 . - v verbose memcached - m 1 - u root - d - l 192 . 168 . 1 . 219 - p 11211 memcached - m 1 - u root - d - l 192 . 168 . 1 . 219 - p 11212 memcached - m 1 - u root - d - l 192 . 168 . 1 . 219 - p 11213 magent - u root - n 51200 - l 192 . 168 . 1 . 219 - p 12000 - s 192 . 168 . 1 . 219 : 11211 - s 192 . 168 . 1 . 219 : 11212 - b 192 . 168 . 1 . 219 : 11213 1 、 11211 、 11212 、 11213  3  Memcached ， 12000  magent ； 2 、 11211 、 11212  Memcached ， 11213  Memcached ； 3 、 12000  magent ， set key1  set key2 ，， key1  11212  11213  Memcached ， key2  11212  11213  Memcached ； 4 、 11211 、 11212  Memcached ， 12000  magent ， 11213  Memcached 。 ： # telnet 192 . 168 . 1 . 219 12000 Trying 1192 . 168 . 1 . 219 ... Connected to 192 . 168 . 1 。 219 . Escape character is ^] . stats memcached agent v0 . 4 matrix 1 - 192 . 168 . 1 . 219 : 11211 , pool size 0 matrix 2 - 192 . 168 . 1 . 219 : 11212 , pool size 0 END set key1 0 0 5 reesu  5 STORED set key2 0 0 6 reesu1  5 STORED quit Connection closed by foreign host . # telnet 192 . 168 . 1 . 219 11211 Trying 192 . 168 . 1 . 219 ... Connected to 192 . 168 . 1 . 219 . Escape character is ^] . get key1 END get key2 VALUE key2 0 6 reesun1 END quit Connection closed by foreign host . # telnet 192 . 168 . 1 . 219 11212 Trying 192 . 168 . 1 . 219 ... Connected to 1192 . 168 . 1 . 219 . Escape character is ^] . get key1 VALUE key1 0 5 reesun END get key2 END quit Connection closed by foreign host . # telnet 192 . 168 . 1 . 219 11213 Trying 192 . 168 . 1 . 219 ... Connected to 1192 . 168 . 1 . 219 . Escape character is ^] . get key1 VALUE key1 0 5 ( key  ) hello END get key2 VALUE key2 0 6 reesun END quit Connection closed by foreign host .","title":"magent"},{"location":"memcached/#_1","text":" flush_all  / 。  flush_all ，，，，， ，，，。","title":""},{"location":"memcached/#key","text":"1 . cmd  memcache telnet 127 . 0 . 0 . 1 11211 2 .  keys stats items //  STAT items : 7 : number 1 STAT items : 7 : age 188 END 3 .  itemid  key  items id ， 7 ， 2 ， 0  stats cachedump 7 0 //  ITEM Sess_sidsvpc1473t1np08qnkvhf6j2 [ 183 b ; 1394527347 s] END 4 .  get  key   stats cachedump  session key ， get  session  get Sess_sidsvpc1473t1np08qnkvhf6j2 //  VALUE Sess_sidsvpc1473t1np08qnkvhf6j2 1440 1 83 Sess_ | a : 5 :{ s : 6 : verify ;s:32: e70981fd305170c41a5632b2a24bbcaa ;s:3: uid ;s:1: 1 ;s:8: username ;s:5: admin ;s:9: logintime ;s:19: 2014 - 03 - 11 16 : 24 : 25 ;s:7: log inip ;s:9: 127 . 0 . 0 . 1 ;}","title":"key"},{"location":"memcached/#memcache_1","text":"yum  yum install memcached memcached - devel - y vim / etc / sysconfig / memcached PORT = 11211 USER = memcached MAXCONN = 1024  CACHESIZE = 128  （ M ） OPTIONS = / etc / init . d / memcached start  Memcached ： wget http : // memcached . googlecode . com / files / memcached - 1 . 4 . 4 . tar . gz tar - xzvf memcached - 1 . 4 . 4 . tar . gz cd memcached - 1 . 4 . 4 . / configure -- prefix =/ usr / local / memcached -- with - libevent =/ usr / local / libevent make make install ln - s / usr / local / libevent / lib / libevent - 1 . 4 . so . 2 / usr / lib / memcached - m 500 - u root - d - l 192 . 168 . 1 . 219 - p 11211 memcached : - d ：， - m ： Memcache ， MB ， 64 MB ， - u ： Memcache  - l ： IP  - p ： Memcache ， 11211 ： - p ( p  ) - c ：， 1024 - P ： Memcache  pid ： - P ( P  ) - h   memcached ： telnet ip ， telnet 192 . 168 . 100 . 11 11211 stats ， flush_all :  memcached ，： STAT pid 22459  ID STAT uptime 1027046  STAT time 1273043062  unix  STAT version 1 . 4 . 4  STAT pointer_size 64  (  64  ) STAT rusage_user 0 . 040000  STAT rusage_system 0 . 260000  STAT curr_connections 10  STAT total_connections 82  STAT connection_structures 13  STAT cmd_get 54  get  STAT cmd_set 34  set  STAT cmd_flush 3  flush_all  STAT get_hits 9 get  STAT get_misses 45 get  STAT delete_misses 5 delete  STAT delete_hits 1 delete  STAT incr_misses 0 incr  STAT incr_hits 0 incr  STAT decr_misses 0 decr  STAT decr_hits 0 decr  STAT cas_misses 0 cas  STAT cas_hits 0 cas  STAT cas_badval 0  STAT auth_cmds 0 STAT auth_errors 0 STAT bytes_read 15785  STAT bytes_written 15222  STAT limit_maxbytes 1048576 （） STAT accepting_conns 1  STAT listen_disabled_num 0 STAT threads 4  STAT conn_yields 0 STAT bytes 0  item  STAT curr_items 0 item  STAT total_items 34 item  STAT evictions 0  item   echo stats | nc 192 . 168 . 1 . 123 11200 watch echo stats | nc 192.168.1.123 11200 (  )","title":"memcache"},{"location":"mongodb/","text":"authSchema mongodb3 .03  ，  --auth mongodb，： （  ， db . addUser ，  ） Windowsbat ， mongodb ，  ： mongod --dbpath db\\data --port 27017 --directoryperdb --logpath db\\logs\\mongodb.log --logappend --auth  ， conf ， auth = truefalse 1 ，  ，  --auth，mongodb 2 ， mongodb ， mongo ， test 3 ， use userdb  ， db ， userdb 4 ，  ， dbOwner ， userdb ， db . createUser ( { user : myuser , pwd : 123456 , roles : [ {role: dbOwner ,db: userdb } ] } ) 5 ， admin ， use admin ， db ， admin ， db . shutdownServer ()  ，  ， mongodb ； mongovuemyuseruserdb ， 3 .0.3  ， mongodb . log authenticate db : userdb { authenticate : 1 , nonce : xxx , user : myuser , key : xxx } 2015 - 06 - 02 T09 : 57 : 18.877 + 0800 I ACCESS [ conn2 ] Failed to authenticate myuser @userdb with mechanism MONGODB - CR : AuthenticationFailed MONGODB - CR credentials missing in the user document 1 - 5 3 .0.3 ok ， 3 .0.3 ， mongodbSCRAM - SHA - 1  ，  ，  ：  ， system . versionauthSchema3 ， 5 ，  ： use admin switched to db admin var schema = db . system . version . findOne ( { _id : authSchema } ) schema . currentVersion = 3 3 db . system . version . save ( schema ) WriteResult ( { nMatched : 1 , nUpserted : 0 , nModified : 1 } )  ， AuthenticationFailed MONGODB - CR credentials missing in the user document SCRAM - SHA - 1  use admin switched to db admin db . system . users . find () [ ... ] { _id : userdb.myuser , user : myuser , db : userdb , credentials : { SCRAM-SHA-1 : { iterationCount : 10000 , salt : XXXXXXXXXXXXXXXXXXXXXXXX , storedKey : XXXXXXXXXXXXXXXXXXXXXXXXXXX , serverKey : XXXXXXXXXXXXXXXXXXXXXXXXXXX } } , roles : [ { role : dbOwner , db : userdb } ] }  ，  ： use userdb switched to db userdb db . dropUser ( myuser ) true db . createUser ( { user : myuser , pwd : 123456 , roles : [ {role: dbOwner ,db: userdb } ] } )  ，  ，  ， mongovue ， OK   mongodb3 . 2  shard 。 1 ： mongos  [ mongodb @ node1 keyfile ]$ openssl rand - base64 741 / data / keyfile / zxl [ mongodb @ node1 keyfile ]$ chmod 600 / data / keyfile / zxl 2 ： / data / keyfile / zxl  / data / keyfile /   600 3 ： [ mongodb @ node1 config ]$ mongo -- port 10005 MongoDB shell version : 3 . 2 . 3 connecting to : 127 . 0 . 0 . 1 : 10005 / test mongos use admin switched to db admin db . createUser ( { user : zxl , pwd : 123 , roles : [ { role : userAdminAnyDatabase , db : admin } ] } ) db . createUser ( { user : zxl , pwd : 123 , roles : [ { role : root , db : admin } ] } ) ; mongos db . auth ( zxl , 123 ) ： userAdminAnyDatabase ： admin ， userAdmin ， root ：  admin 。，，  userAdminAnyDatabase ， N 。。。 4 ： mongod  configsvr  mongos  [ mongodb @ node1 keyfile ]$ netstat - ntpl | grep mongo | awk {print $NF} | awk - F / {print $1} | xargs kill 5 ： shard1 . conf 、 shard2 . conf 、 shard3 . conf 、 configsvr . conf 、 mongos . conf ，  # security : # keyFile : /data/keyfile/zxl # clusterAuthMode : keyFile  security : keyFile : /data/keyfile/zxl clusterAuthMode : keyFile  shard1 、 shard2 、 shard3  configsvr  mongos  [ mongodb @ node1 ~ ]$ mongod - f / data / config / shard1 . conf [ mongodb @ node1 ~ ]$ mongod - f / data / config / shard2 . conf [ mongodb @ node1 ~ ]$ mongod - f / data / config / shard3 . conf [ mongodb @ node1 logs ]$ mongod - f / data / config / configsvr . conf [ mongodb @ node1 logs ]$ mongos - f / data / config / mongos . conf  mongos [ mongodb @ node1 config ]$ mongo -- port 10005 MongoDB shell version : 3 . 2 . 3 connecting to : 127 . 0 . 0 . 1 : 10005 / test mongos use admin switched to db admin mongos db . auth ( zxl , 123 ) mongos sh . enableSharding ( av ) //  shard  { ok : 1 } mongos sh . shardCollection ( av.xxoo ,{ name : 1 } ) // ，， av ， xxoo  { collectionsharded : av.xxoo , ok : 1 } ： ， # security . keyFile ：  security . authorization ， -- keyFile 。 -- keyFile file : ， auth ，  (  +  ) ，；  userAdminAnyDatabase ， root 。 [ mongodb @ node1 config ]$ mongo 192 . 168 . 75 . 128 : 10005 / admin - u zxl - p 123 -- authenticationDatabase admin MongoDB shell version : 3 . 2 . 3 connecting to : 192 . 168 . 75 . 128 : 10005 / admin mongos show dbs ad 0 . 000 GB admin 0 . 000 GB config 0 . 001 GB mongos db . createUser ( { user : root , pwd : 123456 , roles : [ root ]} ) Successfully added user : { user : root , roles : [ root ] } mongos db . auth ( root , 123456 ) mongos bye  [ mongodb @ node1 config ]$ mongo 192 . 168 . 75 . 128 : 10005 / admin - u root - p 123456 -- authenticationDatabase MongoDB shell version : 3 . 2 . 3 connecting to : 192 . 168 . 75 . 128 : 10005 / admin mongos show dbs ad 0 . 000 GB admin 0 . 000 GB av 0 . 000 GB config 0 . 001 GB  https : // www . mongodb . com / download - center # community   mkdir conf data log pid cat conf / shard11 . conf dbpath =/ usr / local / mongodb / data / shard11 logpath =/ usr / local / mongodb / log / shard11 . log pidfilepath =/ usr / local / mongodb / pid / shard11 . pid directoryperdb = true logappend = true replSet = shard1 port = 10011 fork = true shardsvr = true journal = true cat conf / shard21 . conf dbpath =/ usr / local / mongodb / data / shard21 logpath =/ usr / local / mongodb / log / shard21 . log pidfilepath =/ usr / local / mongodb / pid / shard21 . pid directoryperdb = true logappend = true replSet = shard2 port = 10021 fork = true shardsvr = true journal = true cat conf / config . conf dbpath =/ usr / local / mongodb / data / config logpath =/ usr / local / mongodb / log / config . log pidfilepath =/ usr / local / mongodb / pid / config . pid directoryperdb = true logappend = true port = 10031 fork = true configsvr = true replSet = configRS journal = true cat conf / route . conf configdb = configRS / 192 . 168 . 1 . 5 : 10031 , 192 . 168 . 1 . 6 : 10031 , 192 . 168 . 1 . 2 : 10031 pidfilepath =/ usr / local / mongodb / pid / route . pid port = 10040 logpath =/ usr / local / mongodb / log / route . log logappend = true fork = true  . / bin / mongod - f conf / config . conf  . / bin / mongo -- port 10031 -- host 127 . 0 . 0 . 1  host  config  rs . initiate ( { _id : configRS , configsvr : true , members :[{ _id : 0 , host : 192.168.1.5:10031 }, { _id : 1 , host : 192.168.1.6:10031 },{ _id : 2 , host : 192.168.1.2:10031 }]} )   shard  . / bin / mongod - f conf / shard11 . conf . / bin / mongod - f conf / shard21 . conf  shard1 . / bin / mongo -- port 10011 -- host 127 . 0 . 0 . 1  rs . initiate ( { _id : shard1 , members :[{ _id : 0 , host : 192.168.1.5:10011 },{ _id : 1 , host : 192.168.1.6:10011 }, { _id : 2 , host : 192.168.1.2:10011 }]} ) arbiterOnly : true  shard2 . / bin / mongo -- port 10021 -- host 127 . 0 . 0 . 1  rs . initiate ( { _id : shard2 , members :[{ _id : 0 , host : 192.168.1.5:10021 },{ _id : 1 , host : 192.168.1.6:10021 }, { _id : 2 , host : 192.168.1.2:10021 }]} )  . / bin / mongos - f conf / route . conf . / bin / mongos -- host 127 . 0 . 0 . 1 -- port 10040 use admin db . runCommand ( { addshard : shard1/192.168.1.5:10011,192.168.1.6:10011,192.168.1.2:10011 } ) db . runCommand ( { addshard : shard2/192.168.1.5:10021,192.168.1.6:10021,192.168.1.2:10021 } ) db . runCommand ( { listshards : 1 } )  (  ) db . runCommand ( { enablesharding : friends } ) ; # friends shard db . runCommand ( { shardcollection : friends.user , key : { id : 1 }, unique : true } ) # user ,  id  #1   1 ， db . runCommand ( { shardcollection : friends.user , key : { id : hashed } } ) #  use runoob  db . runoob . insert ( { name :  } ) show dbs db . runoob . find () ;  rs . status () shard config  db . status () route  mongo  runoob : use runoob switched to db runoob db runoob ， show dbs ： show dbs local 0.078 GB test 0.078 GB ， runoob ， ， runoob 。 db . collection . insert ({ name :  }) collection  WriteResult ({ nInserted : 1 }) show dbs local 0.078 GB runoob 0.078 GB test 0.078 GB MongoDB  test ，， test 。  dos2unix e_client_order . json sed s/},/} \\n /g e_client_order . json 1.j son ./ bin / mongoimport -- db weituofang -- collection lecture -- file 1.j son -- port 10040 ./ bin / mongoexport - d weituofang - c yinghui1 - o yinghui1 . json -- port 10040 shard MongoDBShard ( Shard ) --  ： MongoDBShard ( Shard ) -- MongoDBShard ，  ， AddShard 。  (  )  。  ， Shard 。  ： http : // docs . mongodb . org / manual / tutorial / remove - shards - from - cluster / 1 、 RemoveShard db . runCommand ( { removeshard : your_shard_name } ) { msg : draining started successfully , state : started , shard : mongodb0 , ok : 1 } “  ：  ， statecompleted ，  ，  draining : true ，  ，  ， removeshard ，  ， statecompleted ；  ：  ， data ，  ，   ：  draining : true ，  ，   ，  ： configconfigshard ， draining TrueFalse ,  ”  ，  。 2 、   ，  。 db . runCommand ( { removeshard : your_shard_name } ) { msg : draining ongoing , state : ongoing , remaining : { chunks : 42 , dbs : 1 } , ok : 1 }  ，  ， 42 。 remain0 ，  。 3 、 Shard （ primary 34 ， 1 2 ） Shardprimary ，  ，  ！ db . runCommand ( { movePrimary :  , to :  } )  ，  ，  ： { primary : mongodb1 , ok : 1 } 4 、   ， RemoveShard ，  。 db . runCommand ( { removeshard : mongodb0 } )  ，  ： { msg : remove shard completed succesfully , stage : completed , host : mongodb0 , ok : 1 } completed ， mongod 。  ： http : // www . myexception . cn / go / 1862417. html webmongo https : // github . com / iwind / rockmongo  lamp  yum install php - pecl - mongo cd / var / ww / html  https : // github . com / iwind / rockmongo / archive / master . zip vim rockmongo - master / config . php  mongo  http : // ip / rockmongo - master / index . php","title":"mongodb"},{"location":"mongodb/#authschema","text":"mongodb3 .03  ，  --auth mongodb，： （  ， db . addUser ，  ） Windowsbat ， mongodb ，  ： mongod --dbpath db\\data --port 27017 --directoryperdb --logpath db\\logs\\mongodb.log --logappend --auth  ， conf ， auth = truefalse 1 ，  ，  --auth，mongodb 2 ， mongodb ， mongo ， test 3 ， use userdb  ， db ， userdb 4 ，  ， dbOwner ， userdb ， db . createUser ( { user : myuser , pwd : 123456 , roles : [ {role: dbOwner ,db: userdb } ] } ) 5 ， admin ， use admin ， db ， admin ， db . shutdownServer ()  ，  ， mongodb ； mongovuemyuseruserdb ， 3 .0.3  ， mongodb . log authenticate db : userdb { authenticate : 1 , nonce : xxx , user : myuser , key : xxx } 2015 - 06 - 02 T09 : 57 : 18.877 + 0800 I ACCESS [ conn2 ] Failed to authenticate myuser @userdb with mechanism MONGODB - CR : AuthenticationFailed MONGODB - CR credentials missing in the user document 1 - 5 3 .0.3 ok ， 3 .0.3 ， mongodbSCRAM - SHA - 1  ，  ，  ：  ， system . versionauthSchema3 ， 5 ，  ： use admin switched to db admin var schema = db . system . version . findOne ( { _id : authSchema } ) schema . currentVersion = 3 3 db . system . version . save ( schema ) WriteResult ( { nMatched : 1 , nUpserted : 0 , nModified : 1 } )  ， AuthenticationFailed MONGODB - CR credentials missing in the user document SCRAM - SHA - 1  use admin switched to db admin db . system . users . find () [ ... ] { _id : userdb.myuser , user : myuser , db : userdb , credentials : { SCRAM-SHA-1 : { iterationCount : 10000 , salt : XXXXXXXXXXXXXXXXXXXXXXXX , storedKey : XXXXXXXXXXXXXXXXXXXXXXXXXXX , serverKey : XXXXXXXXXXXXXXXXXXXXXXXXXXX } } , roles : [ { role : dbOwner , db : userdb } ] }  ，  ： use userdb switched to db userdb db . dropUser ( myuser ) true db . createUser ( { user : myuser , pwd : 123456 , roles : [ {role: dbOwner ,db: userdb } ] } )  ，  ，  ， mongovue ， OK","title":"authSchema"},{"location":"mongodb/#_1","text":" mongodb3 . 2  shard 。 1 ： mongos  [ mongodb @ node1 keyfile ]$ openssl rand - base64 741 / data / keyfile / zxl [ mongodb @ node1 keyfile ]$ chmod 600 / data / keyfile / zxl 2 ： / data / keyfile / zxl  / data / keyfile /   600 3 ： [ mongodb @ node1 config ]$ mongo -- port 10005 MongoDB shell version : 3 . 2 . 3 connecting to : 127 . 0 . 0 . 1 : 10005 / test mongos use admin switched to db admin db . createUser ( { user : zxl , pwd : 123 , roles : [ { role : userAdminAnyDatabase , db : admin } ] } ) db . createUser ( { user : zxl , pwd : 123 , roles : [ { role : root , db : admin } ] } ) ; mongos db . auth ( zxl , 123 ) ： userAdminAnyDatabase ： admin ， userAdmin ， root ：  admin 。，，  userAdminAnyDatabase ， N 。。。 4 ： mongod  configsvr  mongos  [ mongodb @ node1 keyfile ]$ netstat - ntpl | grep mongo | awk {print $NF} | awk - F / {print $1} | xargs kill 5 ： shard1 . conf 、 shard2 . conf 、 shard3 . conf 、 configsvr . conf 、 mongos . conf ，  # security : # keyFile : /data/keyfile/zxl # clusterAuthMode : keyFile  security : keyFile : /data/keyfile/zxl clusterAuthMode : keyFile  shard1 、 shard2 、 shard3  configsvr  mongos  [ mongodb @ node1 ~ ]$ mongod - f / data / config / shard1 . conf [ mongodb @ node1 ~ ]$ mongod - f / data / config / shard2 . conf [ mongodb @ node1 ~ ]$ mongod - f / data / config / shard3 . conf [ mongodb @ node1 logs ]$ mongod - f / data / config / configsvr . conf [ mongodb @ node1 logs ]$ mongos - f / data / config / mongos . conf  mongos [ mongodb @ node1 config ]$ mongo -- port 10005 MongoDB shell version : 3 . 2 . 3 connecting to : 127 . 0 . 0 . 1 : 10005 / test mongos use admin switched to db admin mongos db . auth ( zxl , 123 ) mongos sh . enableSharding ( av ) //  shard  { ok : 1 } mongos sh . shardCollection ( av.xxoo ,{ name : 1 } ) // ，， av ， xxoo  { collectionsharded : av.xxoo , ok : 1 } ： ， # security . keyFile ：  security . authorization ， -- keyFile 。 -- keyFile file : ， auth ，  (  +  ) ，；  userAdminAnyDatabase ， root 。 [ mongodb @ node1 config ]$ mongo 192 . 168 . 75 . 128 : 10005 / admin - u zxl - p 123 -- authenticationDatabase admin MongoDB shell version : 3 . 2 . 3 connecting to : 192 . 168 . 75 . 128 : 10005 / admin mongos show dbs ad 0 . 000 GB admin 0 . 000 GB config 0 . 001 GB mongos db . createUser ( { user : root , pwd : 123456 , roles : [ root ]} ) Successfully added user : { user : root , roles : [ root ] } mongos db . auth ( root , 123456 ) mongos bye  [ mongodb @ node1 config ]$ mongo 192 . 168 . 75 . 128 : 10005 / admin - u root - p 123456 -- authenticationDatabase MongoDB shell version : 3 . 2 . 3 connecting to : 192 . 168 . 75 . 128 : 10005 / admin mongos show dbs ad 0 . 000 GB admin 0 . 000 GB av 0 . 000 GB config 0 . 001 GB","title":""},{"location":"mongodb/#_2","text":"https : // www . mongodb . com / download - center # community   mkdir conf data log pid cat conf / shard11 . conf dbpath =/ usr / local / mongodb / data / shard11 logpath =/ usr / local / mongodb / log / shard11 . log pidfilepath =/ usr / local / mongodb / pid / shard11 . pid directoryperdb = true logappend = true replSet = shard1 port = 10011 fork = true shardsvr = true journal = true cat conf / shard21 . conf dbpath =/ usr / local / mongodb / data / shard21 logpath =/ usr / local / mongodb / log / shard21 . log pidfilepath =/ usr / local / mongodb / pid / shard21 . pid directoryperdb = true logappend = true replSet = shard2 port = 10021 fork = true shardsvr = true journal = true cat conf / config . conf dbpath =/ usr / local / mongodb / data / config logpath =/ usr / local / mongodb / log / config . log pidfilepath =/ usr / local / mongodb / pid / config . pid directoryperdb = true logappend = true port = 10031 fork = true configsvr = true replSet = configRS journal = true cat conf / route . conf configdb = configRS / 192 . 168 . 1 . 5 : 10031 , 192 . 168 . 1 . 6 : 10031 , 192 . 168 . 1 . 2 : 10031 pidfilepath =/ usr / local / mongodb / pid / route . pid port = 10040 logpath =/ usr / local / mongodb / log / route . log logappend = true fork = true  . / bin / mongod - f conf / config . conf  . / bin / mongo -- port 10031 -- host 127 . 0 . 0 . 1  host  config  rs . initiate ( { _id : configRS , configsvr : true , members :[{ _id : 0 , host : 192.168.1.5:10031 }, { _id : 1 , host : 192.168.1.6:10031 },{ _id : 2 , host : 192.168.1.2:10031 }]} )   shard  . / bin / mongod - f conf / shard11 . conf . / bin / mongod - f conf / shard21 . conf  shard1 . / bin / mongo -- port 10011 -- host 127 . 0 . 0 . 1  rs . initiate ( { _id : shard1 , members :[{ _id : 0 , host : 192.168.1.5:10011 },{ _id : 1 , host : 192.168.1.6:10011 }, { _id : 2 , host : 192.168.1.2:10011 }]} ) arbiterOnly : true  shard2 . / bin / mongo -- port 10021 -- host 127 . 0 . 0 . 1  rs . initiate ( { _id : shard2 , members :[{ _id : 0 , host : 192.168.1.5:10021 },{ _id : 1 , host : 192.168.1.6:10021 }, { _id : 2 , host : 192.168.1.2:10021 }]} )  . / bin / mongos - f conf / route . conf . / bin / mongos -- host 127 . 0 . 0 . 1 -- port 10040 use admin db . runCommand ( { addshard : shard1/192.168.1.5:10011,192.168.1.6:10011,192.168.1.2:10011 } ) db . runCommand ( { addshard : shard2/192.168.1.5:10021,192.168.1.6:10021,192.168.1.2:10021 } ) db . runCommand ( { listshards : 1 } )  (  ) db . runCommand ( { enablesharding : friends } ) ; # friends shard db . runCommand ( { shardcollection : friends.user , key : { id : 1 }, unique : true } ) # user ,  id  #1   1 ， db . runCommand ( { shardcollection : friends.user , key : { id : hashed } } ) #  use runoob  db . runoob . insert ( { name :  } ) show dbs db . runoob . find () ;  rs . status () shard config  db . status () route ","title":""},{"location":"mongodb/#mongo","text":" runoob : use runoob switched to db runoob db runoob ， show dbs ： show dbs local 0.078 GB test 0.078 GB ， runoob ， ， runoob 。 db . collection . insert ({ name :  }) collection  WriteResult ({ nInserted : 1 }) show dbs local 0.078 GB runoob 0.078 GB test 0.078 GB MongoDB  test ，， test 。  dos2unix e_client_order . json sed s/},/} \\n /g e_client_order . json 1.j son ./ bin / mongoimport -- db weituofang -- collection lecture -- file 1.j son -- port 10040 ./ bin / mongoexport - d weituofang - c yinghui1 - o yinghui1 . json -- port 10040","title":"mongo"},{"location":"mongodb/#shard","text":"MongoDBShard ( Shard ) --  ： MongoDBShard ( Shard ) -- MongoDBShard ，  ， AddShard 。  (  )  。  ， Shard 。  ： http : // docs . mongodb . org / manual / tutorial / remove - shards - from - cluster / 1 、 RemoveShard db . runCommand ( { removeshard : your_shard_name } ) { msg : draining started successfully , state : started , shard : mongodb0 , ok : 1 } “  ：  ， statecompleted ，  ，  draining : true ，  ，  ， removeshard ，  ， statecompleted ；  ：  ， data ，  ，   ：  draining : true ，  ，   ，  ： configconfigshard ， draining TrueFalse ,  ”  ，  。 2 、   ，  。 db . runCommand ( { removeshard : your_shard_name } ) { msg : draining ongoing , state : ongoing , remaining : { chunks : 42 , dbs : 1 } , ok : 1 }  ，  ， 42 。 remain0 ，  。 3 、 Shard （ primary 34 ， 1 2 ） Shardprimary ，  ，  ！ db . runCommand ( { movePrimary :  , to :  } )  ，  ，  ： { primary : mongodb1 , ok : 1 } 4 、   ， RemoveShard ，  。 db . runCommand ( { removeshard : mongodb0 } )  ，  ： { msg : remove shard completed succesfully , stage : completed , host : mongodb0 , ok : 1 } completed ， mongod 。  ： http : // www . myexception . cn / go / 1862417. html","title":"shard"},{"location":"mongodb/#webmongo","text":"https : // github . com / iwind / rockmongo  lamp  yum install php - pecl - mongo cd / var / ww / html  https : // github . com / iwind / rockmongo / archive / master . zip vim rockmongo - master / config . php  mongo  http : // ip / rockmongo - master / index . php","title":"webmongo"},{"location":"mysql/","text":" d_debtor_contacts_bak  d_debtor_contacts_0  d_debtor_contacts_1  debtor_info_id  INSERT INTO d_debtor_contacts_0 SELECT * FROM d_debtor_contacts_bak WHERE debtor_info_id MOD 2 = 0 ; INSERT INTO d_debtor_contacts_1 SELECT * FROM d_debtor_contacts_bak WHERE debtor_info_id MOD 2 = 1 ; https : // github . com / Qihoo360 / Atlas / wiki / Atlas % E7 % 9 A % 84 % E5 % 88 % 86 % E8 % A1 % A8 % E5 % 8 A % 9 F % E8 % 83 % BD % E7 % AE % 80 % E4 % BB % 8 B 1 .  Atlas ，（ test . cnf ） tables 。 2 . tables ： .  .  . ， school ， stu ， id ， 100 ，  school . stu . id . 100 ，，。 100 （ stu_0 , stu_1 , … stu_99 ，  0 ）。 DB  database 。 3 .  Atlas （ SELECT 、 DELETE 、 UPDATE 、 INSERT 、 REPLACE ）， Atlas （ id % 100 = k ）， （ stu_k ）。， select * from stu where id = 110 ; ， Atlas  stu_10 。 SQL  （ select * from stu ; ） id ， stu 。 4 . Atlas 。 5 . Atlas  SELECT 、 DELETE 、 UPDATE 、 INSERT 、 REPLACE 。   mysql_install_db --defaults-file=/etc/my3316.cnf --user=mysql --basedir=/data/mysql/ --datadir=/data/mysql/data3316/ mysql ： mysqld_safe --defaults-file=/etc/my3316.cnf 2 1 /var/log/mysqld3316.log mysql ： mysqladmin - u root - p123456 - S / var / lib / mysql / mysql3316 . sock shutdown  mysql --defaults-file=/etc/my3316.cnf  [ client ] port = 3316 socket = / var / lib / mysql / mysql3316 . sock default - character - set = UTF8 [ mysqld ] port = 3316 datadir =/ data / mysql / data3316 socket =/ var / lib / mysql / mysql3316 . sock  UPDATE d_debtor_info set debtor_id_num = insert ( debtor_id_num , 8 , 4 , **** ) where id = 2667 ; UPDATE d_debtor_info set work_telephone = insert ( work_telephone , 4 , 4 , **** ) where id = 2667 ; insert ( debtor_id_num , 8 , 4 , **** )  8 ， 4  ****  https : // github . com / nuodb / sysbench wget https : // github . com / nuodb / sysbench / archive / master . zip cd sysbench - master . / autogen . sh . / configure -- with - mysql - includes =/ data / mysql / include / -- with - mysql - libs =/ data / mysql / lib / make export LD_LIBRARY_PATH =/ data / mysql / lib / . / sysbench / sysbench -- help ： / usr / local / sysbench - 0 . 5 / bin / sysbench -- mysql - host = test . mysql . rds . aliyuncs . com # host -- mysql - port = 3306 # -- mysql - user = your_username # -- mysql - password = your_password # -- mysql - socket = -- mysql - db = your_db_for_test # -- mysql - table - engine = innodb -- oltp - tables - count = 10 #， -- oltp - table - size = 6000000 #， -- num - threads = 50 #， -- max - requests = 100000000 # -- max - time = 20 #（ -- max - requests ，） -- report - interval = 1 # 1  QPS  -- test =/ tmp / sysbench - 0 . 5 / sysbench / tests / db / oltp . lua # ( lua ) ， sysbench - 0 . 5  [ prepare | run | cleanup ] # prepare ， run ， cleanup  ： sysbench 0 . 5 : multi - threaded system evaluation benchmark Running the test with following options : Number of threads : 8 Report intermediate results every 10 second ( s ) Random number generator seed is 0 and will be ignored Threads started ! --  10 ， tps 、、、 99 %  [ 10 s ] threads : 8 , tps : 1111 . 51 , reads / s : 15568 . 42 , writes / s : 4446 . 13 , response time : 9 . 95 ms ( 99 % ) [ 20 s ] threads : 8 , tps : 1121 . 90 , reads / s : 15709 . 62 , writes / s : 4487 . 80 , response time : 9 . 78 ms ( 99 % ) [ 30 s ] threads : 8 , tps : 1120 . 00 , reads / s : 15679 . 10 , writes / s : 4480 . 20 , response time : 9 . 84 ms ( 99 % ) [ 40 s ] threads : 8 , tps : 1114 . 20 , reads / s : 15599 . 39 , writes / s : 4456 . 30 , response time : 9 . 90 ms ( 99 % ) [ 50 s ] threads : 8 , tps : 1114 . 00 , reads / s : 15593 . 60 , writes / s : 4456 . 70 , response time : 9 . 84 ms ( 99 % ) [ 60 s ] threads : 8 , tps : 1119 . 30 , reads / s : 15671 . 60 , writes / s : 4476 . 50 , response time : 9 . 99 ms ( 99 % ) OLTP test statistics : queries performed : read : 938224 --  write : 268064 --  other : 134032 --  ( SELECT 、 INSERT 、 UPDATE 、 DELETE ， COMMIT  ) total : 1340320 --  transactions : 67016 ( 1116 . 83 per sec . ) --  (  ) deadlocks : 0 ( 0 . 00 per sec . ) --  read / write requests : 1206288 ( 20103 . 01 per sec . ) --  (  ) other operations : 134032 ( 2233 . 67 per sec . ) --  (  ) General statistics : --  total time : 60 . 0053 s --  total number of events : 67016 --  total time taken by event execution : 479 . 8171 s --  (  ) response time : --  min : 4 . 27 ms --  avg : 7 . 16 ms --  max : 13 . 80 ms --  approx . 99 percentile : 9 . 88 ms --  99 %  Threads fairness : events ( avg / stddev ) : 8377 . 0000 / 44 . 33 execution time ( avg / stddev ) : 59 . 9771 / 0 . 00 sysbench ： CREATE TABLE sbtest ( id int ( 10 ) unsigned NOT NULL AUTO_INCREMENT , k int ( 10 ) unsigned NOT NULL DEFAULT 0 , c char ( 120 ) NOT NULL DEFAULT , pad char ( 60 ) NOT NULL DEFAULT , PRIMARY KEY ( id ) , KEY k ( k ) ) ENGINE = InnoDB AUTO_INCREMENT = 1 DEFAULT CHARSET = latin1 mariadb https : //downloads.mariadb.org/ wget http : //mirrors.neusoft.edu.cn/mariadb//mariadb-10.2.6/source/mariadb-10.2.6.tar.gz tar - zxf mariadb - 10.2.6 . tar . gz cd mariadb - 10.2.6 groupadd - r mariadb useradd - g mariadb - r - M - s / sbin / nologin mariadb mkdir / etc / mariadb  yum - y install gcc gcc - c ++ make cmake ncurses ncurses libxml2 libxml2 - devel openssl - devel bison bison - devel cmake . - DMYSQL_UNIX_ADDR =/ tmp / mariadb . sock - DSYSCONFDIR =/ etc / mariadb - DMYSQL_TCP_PORT = 3309 - DEXTRA_CHARSETS = all - DMYSQL_USER = mariadb - DCMAKE_INSTALL_PREFIX =/ data / mariadb - DMYSQL_DATADIR =/ data / mariadb / data - DWITH_XTRADB_STORAGE_ENGINE = 1 - DWITH_FEDERATEDX_STORAGE_ENGINE = 1 - DWITH_ARCHIVE_STORAGE_ENGINE = 1 - DWITH_MYISAM_STORAGE_ENGINE = 1 - DWITH_INNOBASE_STORAGE_ENGINE = 1 - DWITH_ARCHIVE_STPRAGE_ENGINE = 1 - DWITH_BLACKHOLE_STORAGE_ENGINE = 1 - DWIYH_READLINE = 1 - DWIYH_SSL = system - DVITH_ZLIB = system - DWITH_LOBWRAP = 0 - DDEFAULT_CHARSET = utf8 - DDEFAULT_COLLATION = utf8_general_ci make - j 4 make install cp support - files / my - large . cnf / etc / mariadb / my . cnf  / etc / mariadb / my . cnf  [ mysqld ] ： log - error =/ var / log / mariadb_error . log pid - file =/ var / run / mysqld / mariadb . pid user = mariadb datadir =/ data / mariadb / data basedir =/ data / mariadb /  mysqld_safe  [ mysqld_safe ] log - error =/ var / log / mariadb_error . log pid - file =/ var / run / mysqld / mariadb . pid  . / scripts / mysql_install_db -- basedir =/ data / mariadb / -- datadir =/ data / mariadb / data / -- user = mariadb -- defaults - file =/ etc / mariadb / my . cnf cp support - files / mysql . server / etc / init . d / mariadb chmod 755 / etc / init . d / mariadb vim / etc / init . d / mariadb  mysql ， mysql   $ bindir / mysqld_safe -- datadir = $datadir -- pid - file = $mysqld_pid_file_path  $ bindir / mysqld_safe -- defaults - file =/ etc / mariadb / my . cnf -- datadir = /data/mariadb/data -- pid - file = /var/run/mysqld/mariadb.pid  parse_server_arguments `$ print_defaults $ extra_args -- mysqld mysql . server `  parse_server_arguments `$ print_defaults $ extra_args -- defaults - file =/ etc / mariadb / my . cnf mysqld `  # chown -R mariadb:mariadb /data/mariadb/  MariaDB : # /etc/init.d/mariadb start ：， / var / log / mariadb_error . log ，。  root  #/home/local/mariadb/bin/mysqladmin -u root password 123456  MariaDB  shell  [ root @ localhost mariadb ] # / data / mariadb / bin / mysql - u root - p Type help ; or \\h for help . Type \\c to clear the current input statement . MariaDB [( none )] show engines \\ G ; MariaDB [ mysql ] use mysql ; //mysql MariaDB [ mysql ] select Host , User , Password from user ; // MariaDB [ mysql ] delete from user where password = ; MariaDB [ mysql ] GRANT ALL PRIVILEGES ON * . * TO root @ % IDENTIFIED BY 123456 ; //root  MariaDB [ mysql ] flush privileges ; MariaDB [ mysql ] select Host , User , Password from user ; // MariaDB [ mysql ] exit ; ， vi / etc / sysconfig / iptables - A INPUT - m state -- state NEW - m tcp - p tcp -- dport 3309 - j ACCEPT / etc / init . d / iptables restart  mount - t tmpfs - o size = 20 m tmpfs / mnt / ramdisk / etc / fstab tmpfs / mnt / ramdisk / tmpfs size = 20 m 0 0 SHOW GLOBAL VARIABLES LIKE tmpdir ; my . cnf [ mysqld ] max_heap_table_size = 1024 M # tmp_table_size = 1024 M # tmpdir =/ mnt / ramdisk sqladvisor  sql  https : // github . com / Meituan - Dianping / SQLAdvisor slow_kill.sh 1 2 3 4 5 6 7 8 9 10 11 12 #!/usr/bin/env bash mysql --login-path = test -e show full processlist | grep -i select | awk {print $1,$6} /script/slow.txt while read line do time1 = $( echo $line | awk {print $2} ) if [ $time1 -gt 5 ] ; then 5s id = $( echo $line | awk {print $1} ) echo $id , $time1 mysql --login-path = test -e kill $id fi done /script/slow.txt  ， ， ： ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  1. ，， ： mysql flush tables with read lock ; ：， ， grant replication slave on * . * to repl @ 192.168.0 . % identified by 123456 ; flush privileges ; 2.  #all.sql mysqldump -- master - data = 2 -- single - transaction - R -- triggers - A all . sql  -- master - data = 2  master  Binlog  Position -- single - transaction  - R  -- triggres  - A 。 mysqldump -- help 。 ：， shell  python ，， 3.  binlog ， MASTER_LOG_FILE  MASTER_LOG_POS ： [ root @192.168.0.50 ~ ] # head - n 30 all . sql | grep CHANGE MASTER TO -- CHANGE MASTER TO MASTER_LOG_FILE = mysql - bin .000010 , MASTER_LOG_POS = 112 ; 4  [ root @ master ~ ] # mysql - uroot - p (  ) mysql unlock tables ; Query OK , 0 rows affected ( 0.00 sec ) 5 .  mysql ， #scp [ root @ server01 mysql ] # scp all . sql root @192.168.128.101 :/ tmp / ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~   server - id 5.  mysql stop slave ; 6.  mysql ， mysql source / tmp / mysql . bak . sql 7. ，， show master status  | File | Position  CHANGE MASTER TO MASTER_HOST = 192.168.0.50 , MASTER_USER = repl , MASTER_PASSWORD = 123456 , MASTER_LOG_FILE = mysql - bin .000010 , MASTER_LOG_POS = 112 ; 8.  mysql start slave ; 9.  mysql show slave status \\ G ： Slave_IO_Running : Yes Slave_SQL_Running : Yes Seconds_Behind_Master : 0  0  ，。 mysql ftp : // mirror . switch . ch / mirror / mysql / Downloads /  http : // mirrors . sohu . com / mysql / yum install rpm - build gperf ncurses - devel cmake libaio - devel rpm - ivh MySQL - 5 . 6 . 30 - 1 . el6 . src . rpm cd . / rpmbuild / SPECS / rpmbuild - bb mysql . spec --define= runselftest 0 cd .. / RPMS / x86_64 /  rpm   wget http : // mirrors . sohu . com / mysql / MySQL - 5 . 6 / mysql - 5 . 6 . 34 . tar . gz yum - y install make gcc - c ++ cmake bison - devel ncurses - devel groupadd mysql useradd - g mysql mysql cmake \\ - DCMAKE_INSTALL_PREFIX =/ data / mysql / \\ - DMYSQL_DATADIR =/ data / mysql / data \\ - DSYSCONFDIR =/ etc \\ - DWITH_MYISAM_STORAGE_ENGINE = 1 \\ - DWITH_INNOBASE_STORAGE_ENGINE = 1 \\ - DWITH_MEMORY_STORAGE_ENGINE = 1 \\ - DWITH_READLINE = 1 \\ - DMYSQL_UNIX_ADDR =/ var / lib / mysql / mysql . sock \\ - DMYSQL_TCP_PORT = 3306 \\ - DENABLED_LOCAL_INFILE = 1 \\ - DWITH_PARTITION_STORAGE_ENGINE = 1 \\ - DEXTRA_CHARSETS = all \\ - DDEFAULT_CHARSET = utf8 \\ - DDEFAULT_COLLATION = utf8_general_ci make make install cp cp support - files / my - default . cnf / etc / my . cnf ## config file edit vim / etc / my . cnf skip - name - resolve = 1 cp support - files / mysql . server / etc / init . d / mysql chmod 755 / etc / init . d / mysql chown mysql . mysql / data / mysql / - R ## init mysql datadir chmod 755 scripts / mysql_install_db scripts / mysql_install_db --user=mysql --basedir=/data/mysql/ --datadir=/data/mysql/data/ / etc / init . d / mysql start  sql / data / mysql / bin / mysql delete from mysql . user where user = ;  set password = PASSWORD ( pass );  FLUSH PRIVILEGES ; Last_SQL_error ， slave  insert 。 : 1 .  slave MySQL stop slave ; 2 .  slave  1  mysql set global sql_slave_skip_counter = 1 ; 3 . slave  mysql insert into ... 4 . slave mysql start slave ; 5 .， Seconds_Behind_Master  0  mysql pager grep - i - E Running|Seconds mysql show slave status \\ G Slave_IO_Running : Yes Slave_SQL_Running : Yes Seconds_Behind_Master : 0 Slave_SQL_Running_State : Slave has read all relay log ; waiting for the slave I/O thread to update it 1 row in set ( 0 . 00 sec ) 6 .， slave  master  mysql select count ( 1 ) from test ;  master  test 。  master  binlog ： # at 666 #141121 14 : 23 : 38 server id 150 end_log_pos 755 CRC32 0 x10a3f34c Query thread_id = 411 exec_time = 0 error_code = 0 SET TIMESTAMP = 1416551018 /*!*/ ; BEGIN /*!*/ ; # at 755 #141121 14 : 23 : 38 server id 150 end_log_pos 865 CRC32 0 xca82b435 Query thread_id = 411 exec_time = 0 error_code = 0 SET TIMESTAMP = 1416551018 /*!*/ ; insert into test values (  ) /*!*/ ; # at 865 #141121 14 : 23 : 38 server id 150 end_log_pos 975 CRC32 0 xd377f37e Query thread_id = 411 exec_time = 0 error_code = 0 SET TIMESTAMP = 1416551018 /*!*/ ; insert into test values ( ‘’ ) /*!*/ ; # at 975 #141121 14 : 23 : 38 server id 150 end_log_pos 1006 CRC32 0 x91c3fc01 Xid = 2745705 COMMIT /*!*/ ;  BEGIN / insert / COMMIT ， slave 。  master 。 slave ，。  event ， event 。  set global sql_slave_skip_counter = 1 ; ： 1 .  event  2 .  slave  event 。 3 .  master  binglog  evnet 。  long_query_time = 10  SQL ， slow_query_log = 1  # 5 . 6  slow_query_log_file =/ data / mysql / data / mysql - master - slow . log # log_queries_not_using_indexes = 1 show variables like %slow% ; show variables like %index% ;  mysql . slow_log select @@ global . log_output ; set @@ global . log_output = TABLE ;  1 .，， where  order by 。 ，。，。 。： a .、 ( , , = , = )  order by 、 group by ， ; b .，，  c .，。 ， 。， 。 2 . where  null ，， Sql  : select id from t where num is null ;  num  0 , num  null ，： Sql  : select id from t where num = 0 ; 3 . where  !=  ，。 4 . where  or ，， Sql  : select id from t where num = 10 or num = 20 ; ： Sql  : select id from t where num = 10 union all select id from t where num = 20 ; 5 . in  not in ，，： Sql  : select id from t where num in ( 1 , 2 , 3 ) ; ， between  in ： Sql  : select id from t where num between 1 and 3 ; 6 .： Sql  : select id from t where name like %c% ; ，。 7 . where ，。 SQL ，   ;。 ， ，，。 ： Sql  : select id from t where num = @ num ; ： Sql  : select id from t with ( index (  )) where num = @ num ; 8 . where ， 。 Sql  : select id from t where num / 2 = 100 ; ： Sql  : select id from t where num = 100 * 2 ; 9 . where ，。： Sql  : select id from t where substring ( name , 1 , 3 ) = abc ;#name  abc  id ： Sql  : select id from t where name like abc% ; 10 . where “ = ”、， 。 11 .，， ，   ， 。 12 .，： Sql  : select col1 , col2 into # t from t where 1 = 0 ; ，，： Sql  : create table # t ( … ) ; 13 . exists  in ： Sql  : select num from a where num in ( select num from b ) ; ： Sql  : select num from a where exists ( select 1 from b where num = a . num ) ; 14 .， SQL ，， SQL ，  *** , male 、 female ， ***  。 15 .， select ， insert  update ， insert  update ，，。 6 ， 。 16 . clustered ，  clustered ， ，。 clustered ， clustered 。 17 .，，， 。 ， 。 18 . varchar / nvarchar  char / nchar , ， ， ， 。 19 . select * from t ,“ * ”,。 20 .。， (  ) 。 21 .，。 22 .，，， 。， ， 。 23 .，， select into  create table , log , ; ，， create table , insert . 24 .， ，  truncate table , drop table , 。 25 .，， 1 ，。 26 .，， 。 27 .，。 FAST_FORWARD ， 。“”。 ， ，。 28 . SET NOCOUNT ON , SET NOCOUNT OFF .  DONE_IN_PROC 。 29 .，。 30 .。 ： ANALYZE [ LOCAL | NO_WRITE_TO_BINLOG ] TABLE tb1_name [, tbl_name ]... ，， SQL 。  ，。，。 MyISAM ， DBD  InnoDB  。 ： analyze table table_name ： CHECK TABLE tb1_name [, tbl_name ]...[ option ]... option = { QUICK | FAST | MEDIUM | EXTENDED | CHANGED } ， CHECK TABLE  MyISAM  InnoDB ， MyISAM ， CHECK TABLE ，。 31 .。 ： OPTIMIZE [ LOCAL | NO_WRITE_TO_BINLOG ] TABLE tb1_name [, tbl_name ]... ， (  VARCHAR 、 BLOB  TEXT  ) ， OPTIMIZE TABLE 。，， OPTIMIZE TABLE  MyISAM 、 BDB  InnoDB 。 ： optimize table table_name ： analyze 、 check 、 optimize ， MySQL 。 32 . ， InnoDB ， ACID 。， MyISAM 。 MyISAM ，。 update ，， ， 。， MyISAM  SELECT COUNT ( * ) 。 InnoDB ，， MyISAM 。“” ，， 。，，：。 33 、 explain  SQL  34 、 EXPLAIN  SELECT   EXPLAIN  MySQL  SQL 。。 EXPLAIN ，……，。  SELECT （，）， EXPLAIN 。 phpmyadmin 。， 。， group_id ，：  group_id ： ， 7883 ， 9  16 。 rows 。 35 、  LIMIT 1 ，， fetch ，。 ， LIMIT 1 。， MySQL ， 。 ，“”，，。（， Select * ， Select 1 ）  // ： $ r = mysql_query ( SELECT * FROM user WHERE country = China ) ; if ( mysql_num_rows ( $ r ) 0 ) { // ...} // ： $ r = mysql_query ( SELECT 1 FROM user WHERE country = China LIMIT 1 ) ; if ( mysql_num_rows ( $ r ) 0 ) { // ... }  36 .  Join ，  JOIN ， Join 。， MySQL  Join  SQL 。 ， Join ，。： DECIMAL  INT  Join ， MySQL  。 STRING ，。（） //  state  company $ r = mysql_query ( SELECT company_name FROM users LEFT JOIN companies ON ( users . state = companies . state ) WHERE users . id = $ user_id );  state ，，。 37 、 ORDER BY RAND () ？？，。。  ， N 。。： MySQL  RAND () （ CPU ），，。 Limit 1 （）   // ： $ r = mysql_query ( SELECT username FROM user ORDER BY RAND() LIMIT 1 ) ; // ： $ r = mysql_query ( SELECT count(*) FROM user ) ; $d = mysql_fetch_row ( $ r ) ; $ rand = mt_rand ( 0 , $d [ 0 ] - 1 ) ; $ r = mysql_query ( SELECT username FROM user LIMIT $rand, 1 ) ;  38 .  ID  ID ， INT （ UNSIGNED ）， AUTO_INCREMENT 。  users  “ email ”，。 VARCHAR 。， ， ID 。 ， MySQL ，，，，，，……  ，，“”“”，，，。 “”。： “” ID ，“” ID ，，“”“”， ，， ID  ID  “”。 39 .  PROCEDURE ANALYSE ()  PROCEDURE ANALYSE ()  MySQL ，。， ，。  ， INT ，，， PROCEDURE ANALYSE ()   MEDIUMINT 。 VARCHAR ，， ENUM 。， ，。  phpmyadmin ，， “ Propose table structure ”  ，，，。，。 40 .  NOT NULL   NULL ， NOT NULL 。，。 ，“ Empty ”“ NULL ”（ INT ， 0  NULL ）？，  NULL 。（？ Oracle ， NULL  Empty ！ )  NULL ，，，，。 ，  NULL ，，， NULL 。  MySQL ： “ NULL columns require additional space in the row to record whether their values are NULL . For MyISAM tables , each NULL column takes one bit extra , rounded up to the nearest byte .”  NULL ,，。  0 、 NULL  41 . Prepared Statements Prepared Statements ， SQL ， prepared statements ， 。 Prepared Statements ，“ SQL ”。， ，，， 。 framework  ORM ，。 ，，。 Prepared Statements ，  MySQL 。  MySQL  Prepared Statements ，。 ，， Prepared Statements ，。 5 . 1 。 42 .  IP  UNSIGNED INT   VARCHAR ( 15 )  IP  IP 。， 4 ， 。，，  WHERE ： IP between ip1 and ip2 。  UNSIGNED INT ， IP  32 。 ， INET_ATON ()  IP ， INET_NTOA ()  IP 。 PHP ，  ip2long ()  long2ip () 。 1 $ r = UPDATE users SET ip = INET_ATON( {$_SERVER[ REMOTE_ADDR ]} ) WHERE user_id = $user_id ; 43 .   “”， “ static ”  “ fixed - length ”。 ，： VARCHAR ， TEXT ， BLOB 。，“”，， MySQL  。 ， MySQL ，， 。，，，。 ，。，，， ，。 “”（），，。 45 .  “”，，。（， ， 100 ，）  ： Users ，，，，  。，？ ，， ，， ID ，，，。 。 ：  “ last_login ” ，。，。 ，， ID ，，， 。 ，，， Join ，，，， 。 46 .  DELETE  INSERT   DELETE  INSERT ，， 。，，。 Apache 。，，，， ，。 ， 30 ，， 30  / ，， ， WEB  Crash ，。 ，，， LIMIT 。：  while ( 1 ) { //  1000  mysql_query ( DELETE FROM logs WHERE log_date = 2009-11-01 LIMIT 1000 ) ; if ( mysql_affected_rows () == 0 ) { // ，！ break ; } //  usleep ( 50000 ) ; }  47 .  ，。，，。  MySQL  Storage Requirements 。 （，），， INT ， MEDIUMINT , SMALLINT  TINYINT 。， DATE  DATETIME 。 ，，，，， Slashdot （ 2009  11  06 ）， ALTER TABLE  3 ，。 48 . （ Object Relational Mapper ）  ORM ( Object Relational Mapper ) ，。 ORM ，。， 。 ORM “ Lazy Loading ”，，。，  。 ORM  SQL ，。 49 . “” “ ” MySQL 。，，。，  Apache ——， HTTP  Apache ， MySQL 。 50 、 ( , , between and ) ，。，，  51 、，。 ： ALTER TABLE table_name ADD KEY ( column_name ( prefix_length )) ; 52 、 、，，，， IO , 。 53 、 MYSQL ，， DDL 。 （ TIPS :， ： 10 ，， 10 ， 20 ） 54 、，， IO 。（ a , b , c ）、（ a , b ），。， 。 55 、 WHERE  30 %  prefix_length ，：， ： 》、。 》、，、， 。 》、 IN 、 OR ，。，。 。 》、 CLOB 、 TEXT 、 BLOB  》、。 ENUM  ENUM 。， TINYINT ，。， 。 ，“”，“”，“”，“”“”，，， ENUM   VARCHAR 。 MySQL “”（）。 VARCHAR ， ENUM 。  PROCEDURE ANALYSE () 。 》、、。： Mysql 、 ，，：  ：  where  order by  ，， ，、 ( , , = , = )  order by 、 group by ， ，   6    where ：  where  null 、 !=  、 or 、 in  not in 、 like  % 、， where num = @ num 、 ， where num / 2 = 100 、 ( “ = ” ) ， substring ( name , 1 , 3 ) = abc ;#name、 exists  in  WHERE  30 % ：   varchar / nvarchar  char / nchar  NOT NULL  IP  UNSIGNED INT   ：     ，， select into  create table ， truncate table , drop table ：  select *   SET NOCOUNT ON , SET NOCOUNT OFF  ANALYZE 、 CHECK 、 OPTIMIZE  EXPLAIN  SELECT   LIMIT   Join ，  ORDER BY RAND ()   ID Prepared Statements “”   DELETE  INSERT  insert .. into .. select ..    orm ，，、 redis 、 memcace  、  ： mysql  truncate table mysql . slow_log ; select db , query_TIME , lock_time , rows_examined , sql_text from mysql . slow_log ： http : // blog . csdn . net / xyw591238 / article / details / 51965389 5.6 mysql - uroot - pxxx - e show slave status\\G  Warning : Using a password on the command line interface can be insecure . 5 . 6  mysql_config_editor  login - path mysql_config_editor set -- login - path = test -- user = root -- password -- host = localhost Enter password : ，. mylogin . cnf ，，， mysql -- login - path = test  mysql -- login - path = test - e show slave status\\G  . mylogin . cnf  mysql_config_editor print -- all mysql_config_editor print -- login - path = test . mylogin . cnf ， mysql_config_editor remove -- login - path = test   mysqldump -- master - data = 2 -- single - transaction - R -- triggers - A all . sql  -- master - data = 2  master  Binlog  Position ， -- single - transaction ， - R ， -- triggres ， - A   binlog ， MASTER_LOG_FILE  MASTER_LOG_POS ： head - n 30 all . sql | grep CHANGE MASTER TO -- CHANGE MASTER TO MASTER_LOG_FILE = mysql - bin .000010 , MASTER_LOG_POS = 112 ; mysql / data / all . sql ============================================    mysql （ database is folder ）。  mysql ，（ / var / lib / mysql ），，  musql 。 myisam engine （ xt701 . frm  xt701 . myd  xt701 . myi ） innodb engine  innodb ，  mysql  mysqldump command  mysqldump - u root - p xxxx xt701 xt701 . bak . sql  xt701    xt701 mysql - u root - p xxx xt701 . bak . sql  mydumper soft mysqldump Usage : mysqldump [ OPTIONS ] database [ tables ] OR mysqldump [ OPTIONS ] -- databases [ OPTIONS ] DB1 [ DB2 DB3 ...] OR mysqldump [ OPTIONS ] -- all - databases [ OPTIONS ]  [ root @ convirt tmp ] # mysqldump - A - x quanbei . sql  [ root @ convirt tmp ] # mysqldump vfast vvv . sql [ root @ convirt tmp ] # mysqldump -- databases vfast / opt / 5. sql  vfast  T6  mysqldump - x vfast T6 / opt / t6 . sql vfast   1 ） 2 ） mysql create database vfast ; Query OK , 1 row affected ( 0.00 sec ) mysql exit Bye [ root @ convirt tmp ] # mysql vfast vvv . sql # vfast and test [ root @ instructor ~ ] # mysqldump -- database vfast test / opt / backup / vfast_no2 . sql  [ root @ convirt tmp ] # mysqldump -- lock - tables -- flush - logs -- master - data = 1 vfast test / opt / 1. sql or [ root @ convirt tmp ] # mysqldump -- lock - tables -- flush - logs -- master - data = 2 vfast test / opt / 3. sql mysql flush logs ;  binlog  binlog  mysqldump - h localhost - uroot - p123456 database table dump . sql mysqldump test H1 1. sql  test  H1   [ root @ convirt tmp ] # mysqldump -- no - data -- databases vfast bb . sql  [ root @ convirt tmp ] # mysql - u root - p [ database name ] [ backup file name ]  vim / etc / my . cnf log - bin = binlog  log - bin - index = binlog . index  sync - binlog = 1 ( 1 ， 0  ) expire_logs_days = 10 binlog 　 10  max_binlog_size = 2 G  binlog  binlog_do_db =   binlog  binlog mysql show master logs ;  binlog mysql purge binary logs to binlog .000004 ;  3     http : //www.jb51.net/article/45023.htm  binlog   binlog .000003 mysqlbinlog / var / lib / mysql / binlog .000003 | mysql  binlog  sql  mysqlbinlog / var / lib / mysql / binlog .000007 7. sql  binlog  mysqlbinlog / var / lib / mysql / binlog .[ 0 - 10 ] * 7. sql -- start - datatime  -- stop - datatime 。 - – start - position = #  position - – stop - position = # [ root @ convirt mysql ] # / usr / local / mysql / bin / mysqlbinlog -- start - position = 370 -- stop - position = 440 / var / lib / mysql / mysql - bin .000002 -- start - position = 370 -- stop - position = 440 ？ [ root @ convirt mysql ] # mysqlbinlog / usr / local / mysql / bin / mysqlbinlog # at 370 #100929 21:35:25 server id 1 end_log_pos 440 Query thread_id=1 exec_time=0 error_code=0 SET TIMESTAMP = 1285767325 /*!*/ ; 【】 mysqlbinlog binlog .[ 0 - 10 ] * -- start - datetime = 2014-03-02 10:30:00 | mysql  【，】 mysqlbinlog / var / lib / mysql / binlog .[ 0 - 7 ] * -- stop - datetime = 2014-02-26 11:38:58 | mysql  mysql  1 、 / etc / my . cnf ，  server - id = 1 log - bin = logbin 2 、，。 mysql grant replication slave , reload , super on * . * to slave @ 10.255.254.109 identified by 123456 ; mysql flush privileges ; 3 、。 mysql - u slave - p123456 - h 192.168.0.1  4 、， / etc / my . cnf ，： server - id = 2 master_host = 10.255.254.129 master_user = slave master_password = 123456 relay_log =/ var / lib / mysql / mysql - relay - bin relay_log_index =/ var / lib / mysql / mysql - relay - bin . index 5 、， / opt / mysql / share / mysql / mysql start / opt / mysql / bin / mysql - u root - p mysql load data from master ; ：。 6 、： ① mysql show databases ; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | test | +--------------------+ 3 rows in set ( 0.01 sec ) ② mysql show databases ; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | test | +--------------------+ 3 rows in set ( 0.01 sec )  ③， mysql create database xxx ; Query OK , 1 row affected ( 0.00 sec ) ，： mysql show databases ; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | test | | xxx | | +--------------------+ 4 rows in set ( 0.01 sec ) 。 7 、： slave stop ; slave start ; 。 show slave status \\ G ;  show master status \\ G ;  purge master logs to ’ binlog .000004 ’ ; ，。，。 change master ； ，， my . cnf ， MSQL  。， master . info  mysql 。 ： a 、 master . info  。 / var / lib / mysql 。 ，。 b 、 mysql  ， mysql 。 ，： mysql show master status \\ G ; +---------------+----------+--------------+------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | +---------------+----------+--------------+------------------+ | mysql - bin .003 | 73 | test | manual , mysql | +---------------+----------+--------------+------------------+  File  Position 。，： mysql slave stop ; mysql CHANGE MASTER TO - MASTER_HOST = master_host_name , //IP - MASTER_USER = replication_user_name , // - MASTER_PASSWORD = replication_password , // - MASTER_LOG_FILE = recorded_log_file_name , //(  ) - MASTER_LOG_POS = recorded_log_position ; //() mysql slave start ; AB ： 1.  slave  show slave status \\ G ;   I ／ O SQL  YES  2.   （）   1 ） sql  tailf / var / log / mysqld . log 140304 11 : 59 : 18 [ Note ] Slave I / O thread : connected to master slave @192.168.18.254 : 3306 , replication started in log binlog .000011 at position 294 ＃  / etc / my . cnf / var / lib / mysql / master . info 2 )  sql  140304 11 : 59 : 08 [ Note ] Slave SQL thread initialized , starting replication in log binlog .000011 at position 294 , relay log / var / lib / mysql / mysql - relay - bin .000001 position : 4  1 ） mysql slave stop ; 2 ) mysql CHANGE MASTER TO MASTER_HOST = 192.168.18.254 , MASTER_USER = slave , MASTER_PASSWORD = 123456 , MASTER_LOG_FILE = binlog .000011 ; 3 ) mysql slave start ;   AB      1 ， 2 ， 3   MySQL Replication ，，，。  mysql 。， master ， slave  server_id 。， 。。。 ，，。   sync_binlog ，。 I / O  。，， 。。。  pt - table - checksum 。 sync_binlog ， myisam 。 innodb ， innodb_flush_log_at_trx_commit  1 ，，。  sync_binlog = 1 innodb - flush - log - at - trx - commit = 1 MySQL 5.6  bug ，， InnoDB  group commit ， 。 group commit ？， sync_binlog = 1 , innodb - flush - log - at - trx - commit = 1 ？，。 ，， innodb - flush - log - at - trx - commit  2 ， master  crash safe ，。 innodb_flush_log_at_trx_commit  0 , 1 , 2 。， ， ^ _ ^ 0 ，，。， 1 。 1  2 ，： 1  commit ， fsync 。 2  ，。。 commit ，。  ACID ， innodb_flush_log_at_trx_commit  1 ，， 。，，。  0  2 ，。， 2 ， mysql  ，，。 ， RAID ， Write Back ， RAID （ BBU , Battery Backup Unit ），，。 ： ， master . info 。，， ， master . info 。， ，， 1062 。（），。 ， replication  SQL thread  IO thread 。 SQL thread ，： 1.  relay log  2.  relay - info . log   relay - info . log  relay log ， slave  relay log 。， ，，，。， MySQL   relay - info . log ，， SQL ， 。 MySQL 5.5  sync_relay_log_info ,  relay - info . log  fdatasync ， ，。 IO thread  master ， crash 。 IO thread  relay log ， log event ， log event  master - info . log 。 relay - info . log ， ， sync_master_info  fdatasync 。 IO thread  SQL thread  ，， log event  relay log 。  MySQL 5.5  relay_log_recovery ， crash  master ， master - info . log  ， relay - info  master  master （ master ，。。。） so ， mysql 5.5 ： sync_master_info = 1 sync_relay_log = 1 sync_relay_log_info = 1 read_only #， super  relay_log_recovery = 1 skip_slave_start # ， io  sql ， start slave   ，，，， ，，。 binlog ，。 。，，，，，。 。 ，， yayun  replicate_do_db = yayun ：  mysql select * from t1 ; +----+-------+ | id | name | +----+-------+ | 1 | yayun | | 2 | atlas | | 3 | mysql | +----+-------+ 3 rows in set ( 0.00 sec ) mysql  ：  mysql select * from t1 ; +----+-------+ | id | name | +----+-------+ | 1 | yayun | | 2 | atlas | | 3 | mysql | +----+-------+ 3 rows in set ( 0.00 sec ) mysql    mysql use test ; Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with - A Database changed mysql insert into yayun . t1 ( name ) values ( good yayun ); Query OK , 1 row affected ( 0.01 sec ) mysql select * from yayun . t1 ; +----+------------+ | id | name | +----+------------+ | 1 | yayun | | 2 | atlas | | 3 | mysql | | 5 | good yayun | +----+------------+ 4 rows in set ( 0.00 sec ) mysql  ：  mysql select * from t1 ; +----+-------+ | id | name | +----+-------+ | 1 | yayun | | 2 | atlas | | 3 | mysql | +----+-------+ 3 rows in set ( 0.00 sec ) mysql  ？？，： use test insert into yayun . t1 ( name ) values ( good yayun )  2 B ，， 2 B 。 2  replicate_wild_do_table replicate_wild_ignore_table ，， replicate_wild_do_table = yayun . %  yayun ，。   ROW ，？ MySQL  InnoDB   Seconds_Behind_Master  MySQL  。 ： ，，，，， 。 mha  Mysql ，  MHA  ssh  ssh - keygen - t rsa ssh - copy - id - i . ssh / id_rsa . pub - p 27005 root @192.168.3.129 ssh - copy - id - i . ssh / id_rsa . pub - p 27005 root @192.168.3.128 ssh - copy - id - i . ssh / id_rsa . pub - p 27005 root @192.168.3.132 ssh   MHA node  yum install perl - DBD - MySQL - y rpm - ivh mha4mysql - node - 0.56 - 0. el6 . noarch . rpm  / usr / bin / apply_diff_relay_logs / usr / bin / filter_mysqlbinlog / usr / bin / purge_relay_logs / usr / bin / save_binary_logs  relay log   slave ： Sql set global relay_log_purge = 0 ; show variables like %relay_log_purge% ; ： MHA ， relay log ， relay log  OFF ，  relay log 。  relay （ slave ） cat purge_relay_log . sh #!/bin/bash user = root passwd = 1 port = 3306 log_dir = / var / log purge = / usr / bin / purge_relay_logs if [ ! - d $ log_dir ] then mkdir $ log_dir - p fi $ purge -- user = $ user -- password = $ passwd -- disable_relay_log_purge -- port = $ port -- workdir = $ work_dir $ log_dir / purge_relay_logs . log 2 1 crontab - l 0 4 * * * / bin / bash / root / purge_relay_log . sh  MHA Manager  : / etc / hosts  mha  192.168.3.129 server1 192.168.3.128 server2 192.168.3.132 server3  ssh  vim ~/ . ssh / config Port 27005 cd ~/ . ssh chmod 600 config  MHA Node ，  yum install perl - DBD - MySQL perl - Config - Tiny perl - Log - Dispatch perl - Parallel - ForkManager perl - Time - HiRes - y rpm - ivh mha4mysql - manager - 0.56 - 0. el6 . noarch . rpm mkdir - p / etc / masterha cat / etc / masterha / app1 . cnf [ server default ] manager_workdir =/ var / log / masterha / app1 manager_log =/ var / log / masterha / app1 / manager . log master_binlog_dir =/ data / mysql / data / # master  binlog  master_ip_failover_script = / usr / local / bin / master_ip_failover #master_ip_online_change_script= password = 123456 #， user = root ping_interval = 1 remote_workdir =/ tmp repl_password = 123456 # repl_user = slave report_script =/ usr / local / send_report # secondary_check_script =/ usr / bin / masterha_secondary_check - s server3 - s server2 #shutdown_script= #（,） ssh_user = root ssh_port = 27005 [ server1 ] hostname = 192.168.3.129 port = 3306 [ server2 ] hostname = 192.168.3.128 port = 3306 candidate_master = 1 # master ，，，  slave check_repl_delay = 0 # slave  master 100 M  relay logs ， MHA  slave  master ，  slave ， check_repl_delay = 0 , MHA  master ，  candidate_master = 1 ， master [ server3 ] hostname = 192.168.3.132 port = 3306 vim / usr / bin / masterha_secondary_check 72  ssh   : / usr / local / bin / master_ip_failover (  mysql  ifconfig eth0 : 1 192.168.3.130 / 24 ) masterha_check_ssh -- conf =/ etc / masterha / app1 . cnf  ssh masterha_check_repl -- conf =/ etc / masterha / app1 . cnf  mysql  masterha_check_status -- conf =/ etc / masterha / app1 . cnf  MHA Manager   MHA nohup masterha_manager -- conf =/ etc / masterha / app1 . cnf -- remove_dead_master_conf -- ignore_last_failover / dev / null / var / log / masterha / mha . log 2 1  MHA Manager  -- remove_dead_master_conf ， ip 。 -- manger_log  -- ignore_last_failover ， MHA ， 8 ， Failover ， ping - pong   MHA  mysql ， masterha_stop -- conf =/ etc / masterha / app1 . cnf  MHA Manage  ，， mha ，  sql ： set global relay_log_purge = 0 ;  yum install sysbench – y sysbench -- test = oltp -- oltp - table - size = 1000000 -- oltp - read - only = off -- init - rng = on -- num - threads = 16 -- max - requests = 0 -- oltp - dist - type = uniform -- max - time = 1800 -- mysql - user = root -- mysql - socket =/ var / lib / mysql / mysql . sock -- mysql - password = 1 -- db - driver = mysql -- mysql - table - engine = innodb -- oltp - test - mode = complex prepare  sysbench -- test = oltp -- oltp - table - size = 1000000 -- oltp - read - only = off -- init - rng = on -- num - threads = 16 -- max - requests = 0 -- oltp - dist - type = uniform -- max - time = 180 -- mysql - user = root -- mysql - socket =/ var / lib / mysql / mysql . sock -- mysql - password = 1 -- db - driver = mysql -- mysql - table - engine = innodb -- oltp - test - mode = complex run  mysql mysql  clint --- httpd --- php --- mysql ： tar fzxv mysqlreport - 3 . 5 . tgz ( ， ) cd mysqlreport - 3 . 5 cp mysqlreport / usr / bin mysqlreport -- user root -- password 123 (  ) # yum serach DBI - y # yum install perl - DBD - MySQL - y mysqlreport -- outfile / tmp / mysql  vim / tmp / mysql Myisam  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ Key ---- Mysam  Read hit ---- （）  key_buffer  1 ： show variables like %key% ; set global key_buffer_size = 16777216 ;  2 ： vim / etc / my . cnf key_buffer_size = 16777216 \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ Qusetion Total  DMS 、、、、 Slow 10 s  10 S ， vim / etc / my . cnf log - slow - queries =/ tmp / slow . log  long - query - time = 20  ： slow ，， IO Qc Hits   Query Cache show variables like %query% ; set global query_cache_size = 8384512 ; mysqlreport \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ SELECT and Sort Sort ， mysql ，， show variables like %sort% ; set global sort_buffer_size = 2097144 ; \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ Table locks Waited  show full processlist ; \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ Tables  open  opend  show variables like %table% ; table_cache set global table_cache = 128 ;  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ Connections Max used  show variables like %max% ; set global max_connections = 100 ; \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ Created Temp （、） show variables like %tmp% ; tmpdir / tmp /  tmp_table_size  32 M  Disk table  ： 1 、 2 、 \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ Threads ， show variables like %thread% ; thread_cache_size \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ Bytes  Sent  Recevied  ： B InnoDB  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ InnoDB Buffer Pool Usage  show variables like %innodb% ; set global innodb_buffer_pool_size = 8388608 ; ： 80 % Pages ： 16 K \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ InnoDB  back_log ，， tcp . max_syn_backlog somaxconn  show variables like %max_allowed_packet% ; default 1 M show variables like %timeout% ; connect_timeout  interactive_timeout  timeout ， wait_timeout net_read_timeout net_write_timeout  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ Innodb  IO  show variables like %innodb_flush_log% ; innodb_flush_log_at_trx_commit 0 ，，，， 1 ， 2 ，， mysql ，，， ，， vim / etc / my . cnf innodb_flush_medthod = O_DIRECT / etc / init . d / mysqld restart \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ InnoDB  cpu   taskset  select table_schema as DBname , sum ( data_length + index_length ) / 1024 / 1024 as DB size(MB) , sum ( data_free ) / 1024 / 1024 as free space (MB) from information_schema . tables group by table_schema ; mysql vm ey_buffer ( myisam ) query_cache_size sort_buffer_size table_cache tmp_table_size thread_cache_size innodb_buffer_pool_size ( innodb ) mysql net back_log max_connections / proc / sys / net / core / somaxconn / proc / sys / net / ipv4 / tcp_max_syn_backlog connect_timeout  interactive_timeout  timeout ， wait_timeout net_read_timeout net_write_timeout  max_allowed_packet ( 1 M ) mysql io innodb_flush_log_at_trx_commit 0 ，，，， 1 ， 2 ，， mysql ，，， innodb_flush_medthod = O_DIRECT mysql cpu   show variables like %char% ; SHOW VARIABLES LIKE character_set_% ; SHOW VARIABLES LIKE collation_% ; SET NAMES utf8 ; ： SET character_set_client = utf8 ; SET character_set_results = utf8 ; SET character_set_connection = utf8 ;  mysql create database name character set utf8 ;  CREATE TABLE ` type ` ( ` id ` int ( 10 ) unsigned NOT NULL auto_increment , ` flag_deleted ` enum ( Y , N ) character set utf8 NOT NULL default N , ` flag_type ` int ( 5 ) NOT NULL default 0 , ` type_name ` varchar ( 50 ) character set utf8 NOT NULL default , PRIMARY KEY ( ` id ` ) ) DEFAULT CHARSET = utf8 ;  utf8 . mysql alter database name character set utf8 ;  utf8 . mysql alter table type character set utf8 ;  utf8 mysql alter table type modify type_name varchar ( 50 ) CHARACTER SET utf8 ; / etc / my . cnf --  [ mysqld ]  character - set - server = utf8 ##### default - character - set = utf8 (  ) lower_case_table_names = 1 // （） --  [ mysql ]  default - character - set = utf8 --  [ mysql . server ] default - character - set = utf8 --  [ mysqld_safe ] default - character - set = utf8 --  [ client ] default - character - set = utf8  MySql ","title":"mysql"},{"location":"mysql/#_1","text":"d_debtor_contacts_bak  d_debtor_contacts_0  d_debtor_contacts_1  debtor_info_id  INSERT INTO d_debtor_contacts_0 SELECT * FROM d_debtor_contacts_bak WHERE debtor_info_id MOD 2 = 0 ; INSERT INTO d_debtor_contacts_1 SELECT * FROM d_debtor_contacts_bak WHERE debtor_info_id MOD 2 = 1 ; https : // github . com / Qihoo360 / Atlas / wiki / Atlas % E7 % 9 A % 84 % E5 % 88 % 86 % E8 % A1 % A8 % E5 % 8 A % 9 F % E8 % 83 % BD % E7 % AE % 80 % E4 % BB % 8 B 1 .  Atlas ，（ test . cnf ） tables 。 2 . tables ： .  .  . ， school ， stu ， id ， 100 ，  school . stu . id . 100 ，，。 100 （ stu_0 , stu_1 , … stu_99 ，  0 ）。 DB  database 。 3 .  Atlas （ SELECT 、 DELETE 、 UPDATE 、 INSERT 、 REPLACE ）， Atlas （ id % 100 = k ）， （ stu_k ）。， select * from stu where id = 110 ; ， Atlas  stu_10 。 SQL  （ select * from stu ; ） id ， stu 。 4 . Atlas 。 5 . Atlas  SELECT 、 DELETE 、 UPDATE 、 INSERT 、 REPLACE 。","title":""},{"location":"mysql/#_2","text":" mysql_install_db --defaults-file=/etc/my3316.cnf --user=mysql --basedir=/data/mysql/ --datadir=/data/mysql/data3316/ mysql ： mysqld_safe --defaults-file=/etc/my3316.cnf 2 1 /var/log/mysqld3316.log mysql ： mysqladmin - u root - p123456 - S / var / lib / mysql / mysql3316 . sock shutdown  mysql --defaults-file=/etc/my3316.cnf  [ client ] port = 3316 socket = / var / lib / mysql / mysql3316 . sock default - character - set = UTF8 [ mysqld ] port = 3316 datadir =/ data / mysql / data3316 socket =/ var / lib / mysql / mysql3316 . sock","title":""},{"location":"mysql/#_3","text":"UPDATE d_debtor_info set debtor_id_num = insert ( debtor_id_num , 8 , 4 , **** ) where id = 2667 ; UPDATE d_debtor_info set work_telephone = insert ( work_telephone , 4 , 4 , **** ) where id = 2667 ; insert ( debtor_id_num , 8 , 4 , **** )  8 ， 4  ****","title":""},{"location":"mysql/#_4","text":"https : // github . com / nuodb / sysbench wget https : // github . com / nuodb / sysbench / archive / master . zip cd sysbench - master . / autogen . sh . / configure -- with - mysql - includes =/ data / mysql / include / -- with - mysql - libs =/ data / mysql / lib / make export LD_LIBRARY_PATH =/ data / mysql / lib / . / sysbench / sysbench -- help ： / usr / local / sysbench - 0 . 5 / bin / sysbench -- mysql - host = test . mysql . rds . aliyuncs . com # host -- mysql - port = 3306 # -- mysql - user = your_username # -- mysql - password = your_password # -- mysql - socket = -- mysql - db = your_db_for_test # -- mysql - table - engine = innodb -- oltp - tables - count = 10 #， -- oltp - table - size = 6000000 #， -- num - threads = 50 #， -- max - requests = 100000000 # -- max - time = 20 #（ -- max - requests ，） -- report - interval = 1 # 1  QPS  -- test =/ tmp / sysbench - 0 . 5 / sysbench / tests / db / oltp . lua # ( lua ) ， sysbench - 0 . 5  [ prepare | run | cleanup ] # prepare ， run ， cleanup  ： sysbench 0 . 5 : multi - threaded system evaluation benchmark Running the test with following options : Number of threads : 8 Report intermediate results every 10 second ( s ) Random number generator seed is 0 and will be ignored Threads started ! --  10 ， tps 、、、 99 %  [ 10 s ] threads : 8 , tps : 1111 . 51 , reads / s : 15568 . 42 , writes / s : 4446 . 13 , response time : 9 . 95 ms ( 99 % ) [ 20 s ] threads : 8 , tps : 1121 . 90 , reads / s : 15709 . 62 , writes / s : 4487 . 80 , response time : 9 . 78 ms ( 99 % ) [ 30 s ] threads : 8 , tps : 1120 . 00 , reads / s : 15679 . 10 , writes / s : 4480 . 20 , response time : 9 . 84 ms ( 99 % ) [ 40 s ] threads : 8 , tps : 1114 . 20 , reads / s : 15599 . 39 , writes / s : 4456 . 30 , response time : 9 . 90 ms ( 99 % ) [ 50 s ] threads : 8 , tps : 1114 . 00 , reads / s : 15593 . 60 , writes / s : 4456 . 70 , response time : 9 . 84 ms ( 99 % ) [ 60 s ] threads : 8 , tps : 1119 . 30 , reads / s : 15671 . 60 , writes / s : 4476 . 50 , response time : 9 . 99 ms ( 99 % ) OLTP test statistics : queries performed : read : 938224 --  write : 268064 --  other : 134032 --  ( SELECT 、 INSERT 、 UPDATE 、 DELETE ， COMMIT  ) total : 1340320 --  transactions : 67016 ( 1116 . 83 per sec . ) --  (  ) deadlocks : 0 ( 0 . 00 per sec . ) --  read / write requests : 1206288 ( 20103 . 01 per sec . ) --  (  ) other operations : 134032 ( 2233 . 67 per sec . ) --  (  ) General statistics : --  total time : 60 . 0053 s --  total number of events : 67016 --  total time taken by event execution : 479 . 8171 s --  (  ) response time : --  min : 4 . 27 ms --  avg : 7 . 16 ms --  max : 13 . 80 ms --  approx . 99 percentile : 9 . 88 ms --  99 %  Threads fairness : events ( avg / stddev ) : 8377 . 0000 / 44 . 33 execution time ( avg / stddev ) : 59 . 9771 / 0 . 00 sysbench ： CREATE TABLE sbtest ( id int ( 10 ) unsigned NOT NULL AUTO_INCREMENT , k int ( 10 ) unsigned NOT NULL DEFAULT 0 , c char ( 120 ) NOT NULL DEFAULT , pad char ( 60 ) NOT NULL DEFAULT , PRIMARY KEY ( id ) , KEY k ( k ) ) ENGINE = InnoDB AUTO_INCREMENT = 1 DEFAULT CHARSET = latin1","title":""},{"location":"mysql/#mariadb","text":"https : //downloads.mariadb.org/ wget http : //mirrors.neusoft.edu.cn/mariadb//mariadb-10.2.6/source/mariadb-10.2.6.tar.gz tar - zxf mariadb - 10.2.6 . tar . gz cd mariadb - 10.2.6 groupadd - r mariadb useradd - g mariadb - r - M - s / sbin / nologin mariadb mkdir / etc / mariadb  yum - y install gcc gcc - c ++ make cmake ncurses ncurses libxml2 libxml2 - devel openssl - devel bison bison - devel cmake . - DMYSQL_UNIX_ADDR =/ tmp / mariadb . sock - DSYSCONFDIR =/ etc / mariadb - DMYSQL_TCP_PORT = 3309 - DEXTRA_CHARSETS = all - DMYSQL_USER = mariadb - DCMAKE_INSTALL_PREFIX =/ data / mariadb - DMYSQL_DATADIR =/ data / mariadb / data - DWITH_XTRADB_STORAGE_ENGINE = 1 - DWITH_FEDERATEDX_STORAGE_ENGINE = 1 - DWITH_ARCHIVE_STORAGE_ENGINE = 1 - DWITH_MYISAM_STORAGE_ENGINE = 1 - DWITH_INNOBASE_STORAGE_ENGINE = 1 - DWITH_ARCHIVE_STPRAGE_ENGINE = 1 - DWITH_BLACKHOLE_STORAGE_ENGINE = 1 - DWIYH_READLINE = 1 - DWIYH_SSL = system - DVITH_ZLIB = system - DWITH_LOBWRAP = 0 - DDEFAULT_CHARSET = utf8 - DDEFAULT_COLLATION = utf8_general_ci make - j 4 make install cp support - files / my - large . cnf / etc / mariadb / my . cnf  / etc / mariadb / my . cnf  [ mysqld ] ： log - error =/ var / log / mariadb_error . log pid - file =/ var / run / mysqld / mariadb . pid user = mariadb datadir =/ data / mariadb / data basedir =/ data / mariadb /  mysqld_safe  [ mysqld_safe ] log - error =/ var / log / mariadb_error . log pid - file =/ var / run / mysqld / mariadb . pid  . / scripts / mysql_install_db -- basedir =/ data / mariadb / -- datadir =/ data / mariadb / data / -- user = mariadb -- defaults - file =/ etc / mariadb / my . cnf cp support - files / mysql . server / etc / init . d / mariadb chmod 755 / etc / init . d / mariadb vim / etc / init . d / mariadb  mysql ， mysql   $ bindir / mysqld_safe -- datadir = $datadir -- pid - file = $mysqld_pid_file_path  $ bindir / mysqld_safe -- defaults - file =/ etc / mariadb / my . cnf -- datadir = /data/mariadb/data -- pid - file = /var/run/mysqld/mariadb.pid  parse_server_arguments `$ print_defaults $ extra_args -- mysqld mysql . server `  parse_server_arguments `$ print_defaults $ extra_args -- defaults - file =/ etc / mariadb / my . cnf mysqld `  # chown -R mariadb:mariadb /data/mariadb/  MariaDB : # /etc/init.d/mariadb start ：， / var / log / mariadb_error . log ，。  root  #/home/local/mariadb/bin/mysqladmin -u root password 123456  MariaDB  shell  [ root @ localhost mariadb ] # / data / mariadb / bin / mysql - u root - p Type help ; or \\h for help . Type \\c to clear the current input statement . MariaDB [( none )] show engines \\ G ; MariaDB [ mysql ] use mysql ; //mysql MariaDB [ mysql ] select Host , User , Password from user ; // MariaDB [ mysql ] delete from user where password = ; MariaDB [ mysql ] GRANT ALL PRIVILEGES ON * . * TO root @ % IDENTIFIED BY 123456 ; //root  MariaDB [ mysql ] flush privileges ; MariaDB [ mysql ] select Host , User , Password from user ; // MariaDB [ mysql ] exit ; ， vi / etc / sysconfig / iptables - A INPUT - m state -- state NEW - m tcp - p tcp -- dport 3309 - j ACCEPT / etc / init . d / iptables restart","title":"mariadb"},{"location":"mysql/#_5","text":"mount - t tmpfs - o size = 20 m tmpfs / mnt / ramdisk / etc / fstab tmpfs / mnt / ramdisk / tmpfs size = 20 m 0 0 SHOW GLOBAL VARIABLES LIKE tmpdir ; my . cnf [ mysqld ] max_heap_table_size = 1024 M # tmp_table_size = 1024 M # tmpdir =/ mnt / ramdisk","title":""},{"location":"mysql/#sqladvisor","text":" sql  https : // github . com / Meituan - Dianping / SQLAdvisor","title":"sqladvisor"},{"location":"mysql/#slow_killsh","text":"1 2 3 4 5 6 7 8 9 10 11 12 #!/usr/bin/env bash mysql --login-path = test -e show full processlist | grep -i select | awk {print $1,$6} /script/slow.txt while read line do time1 = $( echo $line | awk {print $2} ) if [ $time1 -gt 5 ] ; then 5s id = $( echo $line | awk {print $1} ) echo $id , $time1 mysql --login-path = test -e kill $id fi done /script/slow.txt","title":"slow_kill.sh"},{"location":"mysql/#_6","text":"， ， ： ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  1. ，， ： mysql flush tables with read lock ; ：， ， grant replication slave on * . * to repl @ 192.168.0 . % identified by 123456 ; flush privileges ; 2.  #all.sql mysqldump -- master - data = 2 -- single - transaction - R -- triggers - A all . sql  -- master - data = 2  master  Binlog  Position -- single - transaction  - R  -- triggres  - A 。 mysqldump -- help 。 ：， shell  python ，， 3.  binlog ， MASTER_LOG_FILE  MASTER_LOG_POS ： [ root @192.168.0.50 ~ ] # head - n 30 all . sql | grep CHANGE MASTER TO -- CHANGE MASTER TO MASTER_LOG_FILE = mysql - bin .000010 , MASTER_LOG_POS = 112 ; 4  [ root @ master ~ ] # mysql - uroot - p (  ) mysql unlock tables ; Query OK , 0 rows affected ( 0.00 sec ) 5 .  mysql ， #scp [ root @ server01 mysql ] # scp all . sql root @192.168.128.101 :/ tmp / ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~   server - id 5.  mysql stop slave ; 6.  mysql ， mysql source / tmp / mysql . bak . sql 7. ，， show master status  | File | Position  CHANGE MASTER TO MASTER_HOST = 192.168.0.50 , MASTER_USER = repl , MASTER_PASSWORD = 123456 , MASTER_LOG_FILE = mysql - bin .000010 , MASTER_LOG_POS = 112 ; 8.  mysql start slave ; 9.  mysql show slave status \\ G ： Slave_IO_Running : Yes Slave_SQL_Running : Yes Seconds_Behind_Master : 0  0  ，。","title":""},{"location":"mysql/#mysql","text":"ftp : // mirror . switch . ch / mirror / mysql / Downloads /  http : // mirrors . sohu . com / mysql / yum install rpm - build gperf ncurses - devel cmake libaio - devel rpm - ivh MySQL - 5 . 6 . 30 - 1 . el6 . src . rpm cd . / rpmbuild / SPECS / rpmbuild - bb mysql . spec --define= runselftest 0 cd .. / RPMS / x86_64 /  rpm   wget http : // mirrors . sohu . com / mysql / MySQL - 5 . 6 / mysql - 5 . 6 . 34 . tar . gz yum - y install make gcc - c ++ cmake bison - devel ncurses - devel groupadd mysql useradd - g mysql mysql cmake \\ - DCMAKE_INSTALL_PREFIX =/ data / mysql / \\ - DMYSQL_DATADIR =/ data / mysql / data \\ - DSYSCONFDIR =/ etc \\ - DWITH_MYISAM_STORAGE_ENGINE = 1 \\ - DWITH_INNOBASE_STORAGE_ENGINE = 1 \\ - DWITH_MEMORY_STORAGE_ENGINE = 1 \\ - DWITH_READLINE = 1 \\ - DMYSQL_UNIX_ADDR =/ var / lib / mysql / mysql . sock \\ - DMYSQL_TCP_PORT = 3306 \\ - DENABLED_LOCAL_INFILE = 1 \\ - DWITH_PARTITION_STORAGE_ENGINE = 1 \\ - DEXTRA_CHARSETS = all \\ - DDEFAULT_CHARSET = utf8 \\ - DDEFAULT_COLLATION = utf8_general_ci make make install cp cp support - files / my - default . cnf / etc / my . cnf ## config file edit vim / etc / my . cnf skip - name - resolve = 1 cp support - files / mysql . server / etc / init . d / mysql chmod 755 / etc / init . d / mysql chown mysql . mysql / data / mysql / - R ## init mysql datadir chmod 755 scripts / mysql_install_db scripts / mysql_install_db --user=mysql --basedir=/data/mysql/ --datadir=/data/mysql/data/ / etc / init . d / mysql start  sql / data / mysql / bin / mysql delete from mysql . user where user = ;  set password = PASSWORD ( pass );  FLUSH PRIVILEGES ;","title":"mysql"},{"location":"mysql/#last_sql_error","text":"， slave  insert 。 : 1 .  slave MySQL stop slave ; 2 .  slave  1  mysql set global sql_slave_skip_counter = 1 ; 3 . slave  mysql insert into ... 4 . slave mysql start slave ; 5 .， Seconds_Behind_Master  0  mysql pager grep - i - E Running|Seconds mysql show slave status \\ G Slave_IO_Running : Yes Slave_SQL_Running : Yes Seconds_Behind_Master : 0 Slave_SQL_Running_State : Slave has read all relay log ; waiting for the slave I/O thread to update it 1 row in set ( 0 . 00 sec ) 6 .， slave  master  mysql select count ( 1 ) from test ;  master  test 。  master  binlog ： # at 666 #141121 14 : 23 : 38 server id 150 end_log_pos 755 CRC32 0 x10a3f34c Query thread_id = 411 exec_time = 0 error_code = 0 SET TIMESTAMP = 1416551018 /*!*/ ; BEGIN /*!*/ ; # at 755 #141121 14 : 23 : 38 server id 150 end_log_pos 865 CRC32 0 xca82b435 Query thread_id = 411 exec_time = 0 error_code = 0 SET TIMESTAMP = 1416551018 /*!*/ ; insert into test values (  ) /*!*/ ; # at 865 #141121 14 : 23 : 38 server id 150 end_log_pos 975 CRC32 0 xd377f37e Query thread_id = 411 exec_time = 0 error_code = 0 SET TIMESTAMP = 1416551018 /*!*/ ; insert into test values ( ‘’ ) /*!*/ ; # at 975 #141121 14 : 23 : 38 server id 150 end_log_pos 1006 CRC32 0 x91c3fc01 Xid = 2745705 COMMIT /*!*/ ;  BEGIN / insert / COMMIT ， slave 。  master 。 slave ，。  event ， event 。  set global sql_slave_skip_counter = 1 ; ： 1 .  event  2 .  slave  event 。 3 .  master  binglog  evnet 。","title":"Last_SQL_error"},{"location":"mysql/#_7","text":"long_query_time = 10  SQL ， slow_query_log = 1  # 5 . 6  slow_query_log_file =/ data / mysql / data / mysql - master - slow . log # log_queries_not_using_indexes = 1 show variables like %slow% ; show variables like %index% ;  mysql . slow_log select @@ global . log_output ; set @@ global . log_output = TABLE ;","title":""},{"location":"mysql/#_8","text":"1 .，， where  order by 。 ，。，。 。： a .、 ( , , = , = )  order by 、 group by ， ; b .，，  c .，。 ， 。， 。 2 . where  null ，， Sql  : select id from t where num is null ;  num  0 , num  null ，： Sql  : select id from t where num = 0 ; 3 . where  !=  ，。 4 . where  or ，， Sql  : select id from t where num = 10 or num = 20 ; ： Sql  : select id from t where num = 10 union all select id from t where num = 20 ; 5 . in  not in ，，： Sql  : select id from t where num in ( 1 , 2 , 3 ) ; ， between  in ： Sql  : select id from t where num between 1 and 3 ; 6 .： Sql  : select id from t where name like %c% ; ，。 7 . where ，。 SQL ，   ;。 ， ，，。 ： Sql  : select id from t where num = @ num ; ： Sql  : select id from t with ( index (  )) where num = @ num ; 8 . where ， 。 Sql  : select id from t where num / 2 = 100 ; ： Sql  : select id from t where num = 100 * 2 ; 9 . where ，。： Sql  : select id from t where substring ( name , 1 , 3 ) = abc ;#name  abc  id ： Sql  : select id from t where name like abc% ; 10 . where “ = ”、， 。 11 .，， ，   ， 。 12 .，： Sql  : select col1 , col2 into # t from t where 1 = 0 ; ，，： Sql  : create table # t ( … ) ; 13 . exists  in ： Sql  : select num from a where num in ( select num from b ) ; ： Sql  : select num from a where exists ( select 1 from b where num = a . num ) ; 14 .， SQL ，， SQL ，  *** , male 、 female ， ***  。 15 .， select ， insert  update ， insert  update ，，。 6 ， 。 16 . clustered ，  clustered ， ，。 clustered ， clustered 。 17 .，，， 。 ， 。 18 . varchar / nvarchar  char / nchar , ， ， ， 。 19 . select * from t ,“ * ”,。 20 .。， (  ) 。 21 .，。 22 .，，， 。， ， 。 23 .，， select into  create table , log , ; ，， create table , insert . 24 .， ，  truncate table , drop table , 。 25 .，， 1 ，。 26 .，， 。 27 .，。 FAST_FORWARD ， 。“”。 ， ，。 28 . SET NOCOUNT ON , SET NOCOUNT OFF .  DONE_IN_PROC 。 29 .，。 30 .。 ： ANALYZE [ LOCAL | NO_WRITE_TO_BINLOG ] TABLE tb1_name [, tbl_name ]... ，， SQL 。  ，。，。 MyISAM ， DBD  InnoDB  。 ： analyze table table_name ： CHECK TABLE tb1_name [, tbl_name ]...[ option ]... option = { QUICK | FAST | MEDIUM | EXTENDED | CHANGED } ， CHECK TABLE  MyISAM  InnoDB ， MyISAM ， CHECK TABLE ，。 31 .。 ： OPTIMIZE [ LOCAL | NO_WRITE_TO_BINLOG ] TABLE tb1_name [, tbl_name ]... ， (  VARCHAR 、 BLOB  TEXT  ) ， OPTIMIZE TABLE 。，， OPTIMIZE TABLE  MyISAM 、 BDB  InnoDB 。 ： optimize table table_name ： analyze 、 check 、 optimize ， MySQL 。 32 . ， InnoDB ， ACID 。， MyISAM 。 MyISAM ，。 update ，， ， 。， MyISAM  SELECT COUNT ( * ) 。 InnoDB ，， MyISAM 。“” ，， 。，，：。 33 、 explain  SQL  34 、 EXPLAIN  SELECT   EXPLAIN  MySQL  SQL 。。 EXPLAIN ，……，。  SELECT （，）， EXPLAIN 。 phpmyadmin 。， 。， group_id ，：  group_id ： ， 7883 ， 9  16 。 rows 。 35 、  LIMIT 1 ，， fetch ，。 ， LIMIT 1 。， MySQL ， 。 ，“”，，。（， Select * ， Select 1 ）  // ： $ r = mysql_query ( SELECT * FROM user WHERE country = China ) ; if ( mysql_num_rows ( $ r ) 0 ) { // ...} // ： $ r = mysql_query ( SELECT 1 FROM user WHERE country = China LIMIT 1 ) ; if ( mysql_num_rows ( $ r ) 0 ) { // ... }  36 .  Join ，  JOIN ， Join 。， MySQL  Join  SQL 。 ， Join ，。： DECIMAL  INT  Join ， MySQL  。 STRING ，。（） //  state  company $ r = mysql_query ( SELECT company_name FROM users LEFT JOIN companies ON ( users . state = companies . state ) WHERE users . id = $ user_id );  state ，，。 37 、 ORDER BY RAND () ？？，。。  ， N 。。： MySQL  RAND () （ CPU ），，。 Limit 1 （）   // ： $ r = mysql_query ( SELECT username FROM user ORDER BY RAND() LIMIT 1 ) ; // ： $ r = mysql_query ( SELECT count(*) FROM user ) ; $d = mysql_fetch_row ( $ r ) ; $ rand = mt_rand ( 0 , $d [ 0 ] - 1 ) ; $ r = mysql_query ( SELECT username FROM user LIMIT $rand, 1 ) ;  38 .  ID  ID ， INT （ UNSIGNED ）， AUTO_INCREMENT 。  users  “ email ”，。 VARCHAR 。， ， ID 。 ， MySQL ，，，，，，……  ，，“”“”，，，。 “”。： “” ID ，“” ID ，，“”“”， ，， ID  ID  “”。 39 .  PROCEDURE ANALYSE ()  PROCEDURE ANALYSE ()  MySQL ，。， ，。  ， INT ，，， PROCEDURE ANALYSE ()   MEDIUMINT 。 VARCHAR ，， ENUM 。， ，。  phpmyadmin ，， “ Propose table structure ”  ，，，。，。 40 .  NOT NULL   NULL ， NOT NULL 。，。 ，“ Empty ”“ NULL ”（ INT ， 0  NULL ）？，  NULL 。（？ Oracle ， NULL  Empty ！ )  NULL ，，，，。 ，  NULL ，，， NULL 。  MySQL ： “ NULL columns require additional space in the row to record whether their values are NULL . For MyISAM tables , each NULL column takes one bit extra , rounded up to the nearest byte .”  NULL ,，。  0 、 NULL  41 . Prepared Statements Prepared Statements ， SQL ， prepared statements ， 。 Prepared Statements ，“ SQL ”。， ，，， 。 framework  ORM ，。 ，，。 Prepared Statements ，  MySQL 。  MySQL  Prepared Statements ，。 ，， Prepared Statements ，。 5 . 1 。 42 .  IP  UNSIGNED INT   VARCHAR ( 15 )  IP  IP 。， 4 ， 。，，  WHERE ： IP between ip1 and ip2 。  UNSIGNED INT ， IP  32 。 ， INET_ATON ()  IP ， INET_NTOA ()  IP 。 PHP ，  ip2long ()  long2ip () 。 1 $ r = UPDATE users SET ip = INET_ATON( {$_SERVER[ REMOTE_ADDR ]} ) WHERE user_id = $user_id ; 43 .   “”， “ static ”  “ fixed - length ”。 ，： VARCHAR ， TEXT ， BLOB 。，“”，， MySQL  。 ， MySQL ，， 。，，，。 ，。，，， ，。 “”（），，。 45 .  “”，，。（， ， 100 ，）  ： Users ，，，，  。，？ ，， ，， ID ，，，。 。 ：  “ last_login ” ，。，。 ，， ID ，，， 。 ，，， Join ，，，， 。 46 .  DELETE  INSERT   DELETE  INSERT ，， 。，，。 Apache 。，，，， ，。 ， 30 ，， 30  / ，， ， WEB  Crash ，。 ，，， LIMIT 。：  while ( 1 ) { //  1000  mysql_query ( DELETE FROM logs WHERE log_date = 2009-11-01 LIMIT 1000 ) ; if ( mysql_affected_rows () == 0 ) { // ，！ break ; } //  usleep ( 50000 ) ; }  47 .  ，。，，。  MySQL  Storage Requirements 。 （，），， INT ， MEDIUMINT , SMALLINT  TINYINT 。， DATE  DATETIME 。 ，，，，， Slashdot （ 2009  11  06 ）， ALTER TABLE  3 ，。 48 . （ Object Relational Mapper ）  ORM ( Object Relational Mapper ) ，。 ORM ，。， 。 ORM “ Lazy Loading ”，，。，  。 ORM  SQL ，。 49 . “” “ ” MySQL 。，，。，  Apache ——， HTTP  Apache ， MySQL 。 50 、 ( , , between and ) ，。，，  51 、，。 ： ALTER TABLE table_name ADD KEY ( column_name ( prefix_length )) ; 52 、 、，，，， IO , 。 53 、 MYSQL ，， DDL 。 （ TIPS :， ： 10 ，， 10 ， 20 ） 54 、，， IO 。（ a , b , c ）、（ a , b ），。， 。 55 、 WHERE  30 %  prefix_length ，：， ： 》、。 》、，、， 。 》、 IN 、 OR ，。，。 。 》、 CLOB 、 TEXT 、 BLOB  》、。 ENUM  ENUM 。， TINYINT ，。， 。 ，“”，“”，“”，“”“”，，， ENUM   VARCHAR 。 MySQL “”（）。 VARCHAR ， ENUM 。  PROCEDURE ANALYSE () 。 》、、。： Mysql 、 ，，：  ：  where  order by  ，， ，、 ( , , = , = )  order by 、 group by ， ，   6    where ：  where  null 、 !=  、 or 、 in  not in 、 like  % 、， where num = @ num 、 ， where num / 2 = 100 、 ( “ = ” ) ， substring ( name , 1 , 3 ) = abc ;#name、 exists  in  WHERE  30 % ：   varchar / nvarchar  char / nchar  NOT NULL  IP  UNSIGNED INT   ：     ，， select into  create table ， truncate table , drop table ：  select *   SET NOCOUNT ON , SET NOCOUNT OFF  ANALYZE 、 CHECK 、 OPTIMIZE  EXPLAIN  SELECT   LIMIT   Join ，  ORDER BY RAND ()   ID Prepared Statements “”   DELETE  INSERT  insert .. into .. select ..    orm ，，、 redis 、 memcace  、  ： mysql  truncate table mysql . slow_log ; select db , query_TIME , lock_time , rows_examined , sql_text from mysql . slow_log ： http : // blog . csdn . net / xyw591238 / article / details / 51965389","title":""},{"location":"mysql/#56","text":"mysql - uroot - pxxx - e show slave status\\G  Warning : Using a password on the command line interface can be insecure . 5 . 6  mysql_config_editor  login - path mysql_config_editor set -- login - path = test -- user = root -- password -- host = localhost Enter password : ，. mylogin . cnf ，，， mysql -- login - path = test  mysql -- login - path = test - e show slave status\\G  . mylogin . cnf  mysql_config_editor print -- all mysql_config_editor print -- login - path = test . mylogin . cnf ， mysql_config_editor remove -- login - path = test","title":"5.6"},{"location":"mysql/#_9","text":" mysqldump -- master - data = 2 -- single - transaction - R -- triggers - A all . sql  -- master - data = 2  master  Binlog  Position ， -- single - transaction ， - R ， -- triggres ， - A   binlog ， MASTER_LOG_FILE  MASTER_LOG_POS ： head - n 30 all . sql | grep CHANGE MASTER TO -- CHANGE MASTER TO MASTER_LOG_FILE = mysql - bin .000010 , MASTER_LOG_POS = 112 ; mysql / data / all . sql ============================================    mysql （ database is folder ）。  mysql ，（ / var / lib / mysql ），，  musql 。 myisam engine （ xt701 . frm  xt701 . myd  xt701 . myi ） innodb engine  innodb ，  mysql  mysqldump command  mysqldump - u root - p xxxx xt701 xt701 . bak . sql  xt701    xt701 mysql - u root - p xxx xt701 . bak . sql  mydumper soft mysqldump Usage : mysqldump [ OPTIONS ] database [ tables ] OR mysqldump [ OPTIONS ] -- databases [ OPTIONS ] DB1 [ DB2 DB3 ...] OR mysqldump [ OPTIONS ] -- all - databases [ OPTIONS ]  [ root @ convirt tmp ] # mysqldump - A - x quanbei . sql  [ root @ convirt tmp ] # mysqldump vfast vvv . sql [ root @ convirt tmp ] # mysqldump -- databases vfast / opt / 5. sql  vfast  T6  mysqldump - x vfast T6 / opt / t6 . sql vfast   1 ） 2 ） mysql create database vfast ; Query OK , 1 row affected ( 0.00 sec ) mysql exit Bye [ root @ convirt tmp ] # mysql vfast vvv . sql # vfast and test [ root @ instructor ~ ] # mysqldump -- database vfast test / opt / backup / vfast_no2 . sql  [ root @ convirt tmp ] # mysqldump -- lock - tables -- flush - logs -- master - data = 1 vfast test / opt / 1. sql or [ root @ convirt tmp ] # mysqldump -- lock - tables -- flush - logs -- master - data = 2 vfast test / opt / 3. sql mysql flush logs ;  binlog  binlog  mysqldump - h localhost - uroot - p123456 database table dump . sql mysqldump test H1 1. sql  test  H1   [ root @ convirt tmp ] # mysqldump -- no - data -- databases vfast bb . sql  [ root @ convirt tmp ] # mysql - u root - p [ database name ] [ backup file name ]  vim / etc / my . cnf log - bin = binlog  log - bin - index = binlog . index  sync - binlog = 1 ( 1 ， 0  ) expire_logs_days = 10 binlog 　 10  max_binlog_size = 2 G  binlog  binlog_do_db =   binlog  binlog mysql show master logs ;  binlog mysql purge binary logs to binlog .000004 ;  3     http : //www.jb51.net/article/45023.htm  binlog   binlog .000003 mysqlbinlog / var / lib / mysql / binlog .000003 | mysql  binlog  sql  mysqlbinlog / var / lib / mysql / binlog .000007 7. sql  binlog  mysqlbinlog / var / lib / mysql / binlog .[ 0 - 10 ] * 7. sql -- start - datatime  -- stop - datatime 。 - – start - position = #  position - – stop - position = # [ root @ convirt mysql ] # / usr / local / mysql / bin / mysqlbinlog -- start - position = 370 -- stop - position = 440 / var / lib / mysql / mysql - bin .000002 -- start - position = 370 -- stop - position = 440 ？ [ root @ convirt mysql ] # mysqlbinlog / usr / local / mysql / bin / mysqlbinlog # at 370 #100929 21:35:25 server id 1 end_log_pos 440 Query thread_id=1 exec_time=0 error_code=0 SET TIMESTAMP = 1285767325 /*!*/ ; 【】 mysqlbinlog binlog .[ 0 - 10 ] * -- start - datetime = 2014-03-02 10:30:00 | mysql  【，】 mysqlbinlog / var / lib / mysql / binlog .[ 0 - 7 ] * -- stop - datetime = 2014-02-26 11:38:58 | mysql","title":""},{"location":"mysql/#_10","text":"mysql  1 、 / etc / my . cnf ，  server - id = 1 log - bin = logbin 2 、，。 mysql grant replication slave , reload , super on * . * to slave @ 10.255.254.109 identified by 123456 ; mysql flush privileges ; 3 、。 mysql - u slave - p123456 - h 192.168.0.1  4 、， / etc / my . cnf ，： server - id = 2 master_host = 10.255.254.129 master_user = slave master_password = 123456 relay_log =/ var / lib / mysql / mysql - relay - bin relay_log_index =/ var / lib / mysql / mysql - relay - bin . index 5 、， / opt / mysql / share / mysql / mysql start / opt / mysql / bin / mysql - u root - p mysql load data from master ; ：。 6 、： ① mysql show databases ; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | test | +--------------------+ 3 rows in set ( 0.01 sec ) ② mysql show databases ; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | test | +--------------------+ 3 rows in set ( 0.01 sec )  ③， mysql create database xxx ; Query OK , 1 row affected ( 0.00 sec ) ，： mysql show databases ; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | test | | xxx | | +--------------------+ 4 rows in set ( 0.01 sec ) 。 7 、： slave stop ; slave start ; 。 show slave status \\ G ;  show master status \\ G ;  purge master logs to ’ binlog .000004 ’ ; ，。，。 change master ； ，， my . cnf ， MSQL  。， master . info  mysql 。 ： a 、 master . info  。 / var / lib / mysql 。 ，。 b 、 mysql  ， mysql 。 ，： mysql show master status \\ G ; +---------------+----------+--------------+------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | +---------------+----------+--------------+------------------+ | mysql - bin .003 | 73 | test | manual , mysql | +---------------+----------+--------------+------------------+  File  Position 。，： mysql slave stop ; mysql CHANGE MASTER TO - MASTER_HOST = master_host_name , //IP - MASTER_USER = replication_user_name , // - MASTER_PASSWORD = replication_password , // - MASTER_LOG_FILE = recorded_log_file_name , //(  ) - MASTER_LOG_POS = recorded_log_position ; //() mysql slave start ; AB ： 1.  slave  show slave status \\ G ;   I ／ O SQL  YES  2.   （）   1 ） sql  tailf / var / log / mysqld . log 140304 11 : 59 : 18 [ Note ] Slave I / O thread : connected to master slave @192.168.18.254 : 3306 , replication started in log binlog .000011 at position 294 ＃  / etc / my . cnf / var / lib / mysql / master . info 2 )  sql  140304 11 : 59 : 08 [ Note ] Slave SQL thread initialized , starting replication in log binlog .000011 at position 294 , relay log / var / lib / mysql / mysql - relay - bin .000001 position : 4  1 ） mysql slave stop ; 2 ) mysql CHANGE MASTER TO MASTER_HOST = 192.168.18.254 , MASTER_USER = slave , MASTER_PASSWORD = 123456 , MASTER_LOG_FILE = binlog .000011 ; 3 ) mysql slave start ;   AB      1 ， 2 ， 3   MySQL Replication ，，，。  mysql 。， master ， slave  server_id 。， 。。。 ，，。   sync_binlog ，。 I / O  。，， 。。。  pt - table - checksum 。 sync_binlog ， myisam 。 innodb ， innodb_flush_log_at_trx_commit  1 ，，。  sync_binlog = 1 innodb - flush - log - at - trx - commit = 1 MySQL 5.6  bug ，， InnoDB  group commit ， 。 group commit ？， sync_binlog = 1 , innodb - flush - log - at - trx - commit = 1 ？，。 ，， innodb - flush - log - at - trx - commit  2 ， master  crash safe ，。 innodb_flush_log_at_trx_commit  0 , 1 , 2 。， ， ^ _ ^ 0 ，，。， 1 。 1  2 ，： 1  commit ， fsync 。 2  ，。。 commit ，。  ACID ， innodb_flush_log_at_trx_commit  1 ，， 。，，。  0  2 ，。， 2 ， mysql  ，，。 ， RAID ， Write Back ， RAID （ BBU , Battery Backup Unit ），，。 ： ， master . info 。，， ， master . info 。， ，， 1062 。（），。 ， replication  SQL thread  IO thread 。 SQL thread ，： 1.  relay log  2.  relay - info . log   relay - info . log  relay log ， slave  relay log 。， ，，，。， MySQL   relay - info . log ，， SQL ， 。 MySQL 5.5  sync_relay_log_info ,  relay - info . log  fdatasync ， ，。 IO thread  master ， crash 。 IO thread  relay log ， log event ， log event  master - info . log 。 relay - info . log ， ， sync_master_info  fdatasync 。 IO thread  SQL thread  ，， log event  relay log 。  MySQL 5.5  relay_log_recovery ， crash  master ， master - info . log  ， relay - info  master  master （ master ，。。。） so ， mysql 5.5 ： sync_master_info = 1 sync_relay_log = 1 sync_relay_log_info = 1 read_only #， super  relay_log_recovery = 1 skip_slave_start # ， io  sql ， start slave   ，，，， ，，。 binlog ，。 。，，，，，。 。 ，， yayun  replicate_do_db = yayun ：  mysql select * from t1 ; +----+-------+ | id | name | +----+-------+ | 1 | yayun | | 2 | atlas | | 3 | mysql | +----+-------+ 3 rows in set ( 0.00 sec ) mysql  ：  mysql select * from t1 ; +----+-------+ | id | name | +----+-------+ | 1 | yayun | | 2 | atlas | | 3 | mysql | +----+-------+ 3 rows in set ( 0.00 sec ) mysql    mysql use test ; Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with - A Database changed mysql insert into yayun . t1 ( name ) values ( good yayun ); Query OK , 1 row affected ( 0.01 sec ) mysql select * from yayun . t1 ; +----+------------+ | id | name | +----+------------+ | 1 | yayun | | 2 | atlas | | 3 | mysql | | 5 | good yayun | +----+------------+ 4 rows in set ( 0.00 sec ) mysql  ：  mysql select * from t1 ; +----+-------+ | id | name | +----+-------+ | 1 | yayun | | 2 | atlas | | 3 | mysql | +----+-------+ 3 rows in set ( 0.00 sec ) mysql  ？？，： use test insert into yayun . t1 ( name ) values ( good yayun )  2 B ，， 2 B 。 2  replicate_wild_do_table replicate_wild_ignore_table ，， replicate_wild_do_table = yayun . %  yayun ，。   ROW ，？ MySQL  InnoDB   Seconds_Behind_Master  MySQL  。 ： ，，，，， 。","title":""},{"location":"mysql/#mha","text":" Mysql ，  MHA  ssh  ssh - keygen - t rsa ssh - copy - id - i . ssh / id_rsa . pub - p 27005 root @192.168.3.129 ssh - copy - id - i . ssh / id_rsa . pub - p 27005 root @192.168.3.128 ssh - copy - id - i . ssh / id_rsa . pub - p 27005 root @192.168.3.132 ssh   MHA node  yum install perl - DBD - MySQL - y rpm - ivh mha4mysql - node - 0.56 - 0. el6 . noarch . rpm  / usr / bin / apply_diff_relay_logs / usr / bin / filter_mysqlbinlog / usr / bin / purge_relay_logs / usr / bin / save_binary_logs  relay log   slave ： Sql set global relay_log_purge = 0 ; show variables like %relay_log_purge% ; ： MHA ， relay log ， relay log  OFF ，  relay log 。  relay （ slave ） cat purge_relay_log . sh #!/bin/bash user = root passwd = 1 port = 3306 log_dir = / var / log purge = / usr / bin / purge_relay_logs if [ ! - d $ log_dir ] then mkdir $ log_dir - p fi $ purge -- user = $ user -- password = $ passwd -- disable_relay_log_purge -- port = $ port -- workdir = $ work_dir $ log_dir / purge_relay_logs . log 2 1 crontab - l 0 4 * * * / bin / bash / root / purge_relay_log . sh  MHA Manager  : / etc / hosts  mha  192.168.3.129 server1 192.168.3.128 server2 192.168.3.132 server3  ssh  vim ~/ . ssh / config Port 27005 cd ~/ . ssh chmod 600 config  MHA Node ，  yum install perl - DBD - MySQL perl - Config - Tiny perl - Log - Dispatch perl - Parallel - ForkManager perl - Time - HiRes - y rpm - ivh mha4mysql - manager - 0.56 - 0. el6 . noarch . rpm mkdir - p / etc / masterha cat / etc / masterha / app1 . cnf [ server default ] manager_workdir =/ var / log / masterha / app1 manager_log =/ var / log / masterha / app1 / manager . log master_binlog_dir =/ data / mysql / data / # master  binlog  master_ip_failover_script = / usr / local / bin / master_ip_failover #master_ip_online_change_script= password = 123456 #， user = root ping_interval = 1 remote_workdir =/ tmp repl_password = 123456 # repl_user = slave report_script =/ usr / local / send_report # secondary_check_script =/ usr / bin / masterha_secondary_check - s server3 - s server2 #shutdown_script= #（,） ssh_user = root ssh_port = 27005 [ server1 ] hostname = 192.168.3.129 port = 3306 [ server2 ] hostname = 192.168.3.128 port = 3306 candidate_master = 1 # master ，，，  slave check_repl_delay = 0 # slave  master 100 M  relay logs ， MHA  slave  master ，  slave ， check_repl_delay = 0 , MHA  master ，  candidate_master = 1 ， master [ server3 ] hostname = 192.168.3.132 port = 3306 vim / usr / bin / masterha_secondary_check 72  ssh   : / usr / local / bin / master_ip_failover (  mysql  ifconfig eth0 : 1 192.168.3.130 / 24 ) masterha_check_ssh -- conf =/ etc / masterha / app1 . cnf  ssh masterha_check_repl -- conf =/ etc / masterha / app1 . cnf  mysql  masterha_check_status -- conf =/ etc / masterha / app1 . cnf  MHA Manager   MHA nohup masterha_manager -- conf =/ etc / masterha / app1 . cnf -- remove_dead_master_conf -- ignore_last_failover / dev / null / var / log / masterha / mha . log 2 1  MHA Manager  -- remove_dead_master_conf ， ip 。 -- manger_log  -- ignore_last_failover ， MHA ， 8 ， Failover ， ping - pong   MHA  mysql ， masterha_stop -- conf =/ etc / masterha / app1 . cnf  MHA Manage  ，， mha ，  sql ： set global relay_log_purge = 0 ;  yum install sysbench – y sysbench -- test = oltp -- oltp - table - size = 1000000 -- oltp - read - only = off -- init - rng = on -- num - threads = 16 -- max - requests = 0 -- oltp - dist - type = uniform -- max - time = 1800 -- mysql - user = root -- mysql - socket =/ var / lib / mysql / mysql . sock -- mysql - password = 1 -- db - driver = mysql -- mysql - table - engine = innodb -- oltp - test - mode = complex prepare  sysbench -- test = oltp -- oltp - table - size = 1000000 -- oltp - read - only = off -- init - rng = on -- num - threads = 16 -- max - requests = 0 -- oltp - dist - type = uniform -- max - time = 180 -- mysql - user = root -- mysql - socket =/ var / lib / mysql / mysql . sock -- mysql - password = 1 -- db - driver = mysql -- mysql - table - engine = innodb -- oltp - test - mode = complex run ","title":"mha"},{"location":"mysql/#mysql_1","text":"mysql  clint --- httpd --- php --- mysql ： tar fzxv mysqlreport - 3 . 5 . tgz ( ， ) cd mysqlreport - 3 . 5 cp mysqlreport / usr / bin mysqlreport -- user root -- password 123 (  ) # yum serach DBI - y # yum install perl - DBD - MySQL - y mysqlreport -- outfile / tmp / mysql  vim / tmp / mysql Myisam  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ Key ---- Mysam  Read hit ---- （）  key_buffer  1 ： show variables like %key% ; set global key_buffer_size = 16777216 ;  2 ： vim / etc / my . cnf key_buffer_size = 16777216 \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ Qusetion Total  DMS 、、、、 Slow 10 s  10 S ， vim / etc / my . cnf log - slow - queries =/ tmp / slow . log  long - query - time = 20  ： slow ，， IO Qc Hits   Query Cache show variables like %query% ; set global query_cache_size = 8384512 ; mysqlreport \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ SELECT and Sort Sort ， mysql ，， show variables like %sort% ; set global sort_buffer_size = 2097144 ; \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ Table locks Waited  show full processlist ; \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ Tables  open  opend  show variables like %table% ; table_cache set global table_cache = 128 ;  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ Connections Max used  show variables like %max% ; set global max_connections = 100 ; \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ Created Temp （、） show variables like %tmp% ; tmpdir / tmp /  tmp_table_size  32 M  Disk table  ： 1 、 2 、 \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ Threads ， show variables like %thread% ; thread_cache_size \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ Bytes  Sent  Recevied  ： B InnoDB  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ InnoDB Buffer Pool Usage  show variables like %innodb% ; set global innodb_buffer_pool_size = 8388608 ; ： 80 % Pages ： 16 K \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ InnoDB  back_log ，， tcp . max_syn_backlog somaxconn  show variables like %max_allowed_packet% ; default 1 M show variables like %timeout% ; connect_timeout  interactive_timeout  timeout ， wait_timeout net_read_timeout net_write_timeout  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ Innodb  IO  show variables like %innodb_flush_log% ; innodb_flush_log_at_trx_commit 0 ，，，， 1 ， 2 ，， mysql ，，， ，， vim / etc / my . cnf innodb_flush_medthod = O_DIRECT / etc / init . d / mysqld restart \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ InnoDB  cpu   taskset  select table_schema as DBname , sum ( data_length + index_length ) / 1024 / 1024 as DB size(MB) , sum ( data_free ) / 1024 / 1024 as free space (MB) from information_schema . tables group by table_schema ; mysql vm ey_buffer ( myisam ) query_cache_size sort_buffer_size table_cache tmp_table_size thread_cache_size innodb_buffer_pool_size ( innodb ) mysql net back_log max_connections / proc / sys / net / core / somaxconn / proc / sys / net / ipv4 / tcp_max_syn_backlog connect_timeout  interactive_timeout  timeout ， wait_timeout net_read_timeout net_write_timeout  max_allowed_packet ( 1 M ) mysql io innodb_flush_log_at_trx_commit 0 ，，，， 1 ， 2 ，， mysql ，，， innodb_flush_medthod = O_DIRECT mysql cpu","title":"mysql"},{"location":"mysql/#_11","text":" show variables like %char% ; SHOW VARIABLES LIKE character_set_% ; SHOW VARIABLES LIKE collation_% ; SET NAMES utf8 ; ： SET character_set_client = utf8 ; SET character_set_results = utf8 ; SET character_set_connection = utf8 ;  mysql create database name character set utf8 ;  CREATE TABLE ` type ` ( ` id ` int ( 10 ) unsigned NOT NULL auto_increment , ` flag_deleted ` enum ( Y , N ) character set utf8 NOT NULL default N , ` flag_type ` int ( 5 ) NOT NULL default 0 , ` type_name ` varchar ( 50 ) character set utf8 NOT NULL default , PRIMARY KEY ( ` id ` ) ) DEFAULT CHARSET = utf8 ;  utf8 . mysql alter database name character set utf8 ;  utf8 . mysql alter table type character set utf8 ;  utf8 mysql alter table type modify type_name varchar ( 50 ) CHARACTER SET utf8 ; / etc / my . cnf --  [ mysqld ]  character - set - server = utf8 ##### default - character - set = utf8 (  ) lower_case_table_names = 1 // （） --  [ mysql ]  default - character - set = utf8 --  [ mysql . server ] default - character - set = utf8 --  [ mysqld_safe ] default - character - set = utf8 --  [ client ] default - character - set = utf8  MySql ","title":""},{"location":"mysql2/","text":" delete from mysql . user where user = ;  set password = PASSWORD ( pass );  FLUSH PRIVILEGES ; create user sky ; select host , user , password from mysql . user ;  sky  drop user sky ; select host , user , password from mysql . user  sky  mysql ? create user  mysql create user sky identified by 123 ;  show grants for sky @ % ; USAGE  %  IP  mysql grant select on vfast . * to sky @ % ;  mysql revoke select on vfast . * from sky @ % lab ， IP ，，  revoke all privileges on * . * from rhce @ 192.168.18.234 ; drop user rhce @ 192.168.18.234 ;  192.168.18.234  mysql  VFAST （ select ） grant select on vfast . * to sky @ 192.168.18.234 identified by 123 ;  192.168.18.200  mysql  VFAST  select , insert , delete , update  grant select , insert , delete , update on vfast . * to sky @ 192.168.18.200 identified by 123 ; select host , password , user from user ;  192.168.18.234  mysql mysql - h 192.168.18.254 - u sky - p123 mysql use vfast ; mysql insert into H1 values ( 00 );    192.168.18.200  mysql mysql - h 192.168.18.254 - u sky - p123 mysql show databases ; mysql insert into H1 values ( 00 ); mysql delete from H1 where id = 00 ; mysql update H1 set id = 16 where id = 17 ;  ID = 17  16 mysql select * from H1 ;  mysql drop table H1 ;   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  GRANT ALL PRIVILEGES ON * . * TO kyo @ % identified by 123 ; flush privileges  ALL PRIVILEGES  * . *  kyo ， %  IP  ‘ 123 ’   select  ALL PRIVILEGES    　　 Alter 　　　　　　 　　 Create 　　　　  　　 Delete 　　　　  　　 Drop 　　 （） 　　 INDEX 　　　　  　　 Insert 　　　　  　　 REFERENCE 　　 　　 Select 　　　　  　　 Update 　　　　  　　 FILE 　　　　　　 　　 PROCESS 　　  　　 RELOAD 　　　　、。 　　 SHUTDOWN 　　  　　 ALL 　　　　　　； ALL PRIVILEGES  　　 USAGE 　　　　“”  mysql . user mysql . db mysql . tables_orive  revoke all privileges on * . * from kyo @ % ; show grants for kyo @ % ; USAGE    [ root @ convirt ~ ] # vim / etc / my . cnf skip - grant - tables #  mysql  mysql flush privileges ; mysql GRANT ALL PRIVILEGES ON * . * TO root @ localhost identified by ; password is null ## mysqld_safe -- skip - grant - tables （） -- skip - networking   update mysql . user set password = password ( 456 ) where user = “ kyo ” and host = “ localhost ” ; password ( 456 ) kyo @ localhost  456 password  456    show full processlist  ID   。，，。 kill $ ID  ID  explain explain  mysql  select 。。 ， select  explain ，： explain select * from statuses_status where id = 11 ; explain  table ： type ：，。 const 、 eq_reg 、 ref 、 range 、 indexhe  all possible_keys ：。，。 where  key ： 。 null ，。， mysql 。， select   use index （ indexname ） ignore index （ indexname ） mysql  key_len ：。， ref ：，， rows ： mysql  extra ： mysql 。 4 . 3 ， using temporary  using filesort ，  mysql ， extra  distinct : mysql ， not exists : mysql  left join ， left join ， range checked for each record （ index map :#）:，， mysql  ，。 using filesort : ，。 mysql 。  using index : ，  using temporary ，。， mysql ， order by ， group by  where used  where 。， all  index ， ，（） system ： system 。 const  const :（）。，， mysql   eq_ref :， mysql ，，，  ref :（，）。 ，。— range :，   index : （ all ，） all :，， gtid MySQL 5.6  GTID ( Global Transaction IDs ) 、，。  MySQL 5.6 ， [ mysqld ] ： binlog - format ：， row 、 statement  mixed ； ： READ - COMMITED  ROW ， MySQL  STATEMENT  ； mixed ，； log - slave - updates 、 gtid - mode 、 enforce - gtid - consistency 、 report - port  report - host ： GTID ； master - info - repository  relay - log - info - repository ：，； sync - master - info ：； slave - paralles - workers ： SQL ； 0 ； binlog - checksum 、 master - verify - checksum  slave - sql - verify - checksum ：； binlog - rows - query - log - events ：，； log - bin ：，； server - id ： id ； report - host ： The host name or IP address of the slave to be reported to the master during slave registration . This value appears in the output of SHOW SLAVE HOSTS on the master server . report - port : The TCP / IP port number for connecting to the slave , to be reported to the master during slave registration . master - info - repository : The setting of this variable determines whether the slave logs master status and connection information to a FILE ( master . info ), or to a TABLE ( mysql . slave_master_info ) relay - log - info - repository ： This option causes the server to log its relay log info to a file or a table . log_slave_updates ： Whether updates received by a slave server from a master server should be logged to the slave s own binary log . Binary logging must be enabled on the slave for this variable to have any effect . enforce_gtid_consistency ： 、 1 、 1.1 、 master ： [ mysqld ] binlog - format = ROW log - bin = master - bin log - slave - updates = true gtid - mode = on enforce - gtid - consistency = true master - info - repository = TABLE relay - log - info - repository = TABLE sync - master - info = 1 slave - parallel - workers = 2 binlog - checksum = CRC32 master - verify - checksum = 1 slave - sql - verify - checksum = 1 binlog - rows - query - log_events = 1 server - id = 1 report - port = 3306 port = 3306 datadir =/ mydata / data socket =/ tmp / mysql . sock report - host = master . magedu . com 1.2 、 slave ： [ mysqld ] binlog - format = ROW log - slave - updates = true gtid - mode = on enforce - gtid - consistency = true master - info - repository = TABLE relay - log - info - repository = TABLE sync - master - info = 1 slave - parallel - workers = 2 binlog - checksum = CRC32 master - verify - checksum = 1 slave - sql - verify - checksum = 1 binlog - rows - query - log_events = 1 server - id = 11 report - port = 3306 port = 3306 log - bin = mysql - bin . log datadir =/ mydata / data socket =/ tmp / mysql . sock report - host = slave . magedu . com 2 、 mysql GRANT REPLICATION SLAVE ON * . * TO repluser @172.16.100.7 IDENTIFIED BY replpass ; ： 172.16.100.7 ；，； 3 、 ，，； GTID ， master  show master status  ， slave 。 4 、  GTID ，： mysql CHANGE MASTER TO MASTER_HOST = master . magedu . com , MASTER_USER = repluser , MASTER_PASSWORD = replpass , MASTER_AUTO_POSITION = 1 ;  GTID ，： slave CHANGE MASTER TO MASTER_HOST = 172.16.100.6 , - MASTER_USER = repluser , - MASTER_PASSWORD = replpass , - MASTER_LOG_FILE = master - bin .000003 , - MASTER_LOG_POS = 1174 ; 、 1 、 master INSTALL PLUGIN rpl_semi_sync_master SONAME semisync_master . so ; slave INSTALL PLUGIN rpl_semi_sync_slave SONAME semisync_slave . so ; 2 、  master ， rpl_semi_sync_master_enabled = ON  slave  rpl_semi_sync_slave_enabled = ON  mysql 。 ， mysql ： master SET GLOBAL rpl_semi_sync_master_enabled = ON ; slave SET GLOBAL rpl_semi_sync_slave_enabled = ON ; slave STOP SLAVE IO_THREAD ; START SLAVE IO_THREAD ; 3 、 master CREATE DATABASE magedudb ; master SHOW STATUS LIKE Rpl_semi_sync_master_yes_tx ; slave SHOW DATABASES ; xtrabackup  Xtrabackup  MySQL ： 、 1 、 Xtrabackup  percona  mysql ，， innodb  xtradb  。： ( 1 ) 、； ( 2 ) ； ( 3 ) ； ( 4 ) ； ( 5 ) ； 2 、  http : // www . percona . com / software / percona - xtrabackup / 。 RHEL5 . 8 ，，  rpm ，。 wget https : // www . percona . com / downloads / XtraBackup / Percona - XtraBackup - 2 . 4 . 8 / binary / redhat / 6 / x86_64 / percona - xtrabackup - 24 - 2 . 4 . 8 - 1 . el6 . x86_64 . rpm yum install libev - y rpm - ivh percona - xtrabackup - 24 - 2 . 4 . 8 - 1 . el6 . x86_64 . rpm 、 1 、 # innobackupex -- user = DBUSER -- password = DBUSERPASS / path / to / BACKUP - DIR / ，： mysql CREATE USER ’ bkpuser ’@’ localhost ’ IDENTIFIED BY ’ s3cret ’ ; mysql REVOKE ALL PRIVILEGES , GRANT OPTION FROM ’ bkpuser ’ ; mysql GRANT RELOAD , LOCK TABLES , REPLICATION CLIENT ON * . * TO ’ bkpuser ’@’ localhost ’ ; mysql FLUSH PRIVILEGES ;  innobakupex ， xtrabackup  InnoDB ， ( . frm ) 、 MyISAM 、 MERGE 、 CSV  ARCHIVE ，。。 ， innobackupex ： ( 1 ) xtrabackup_checkpoints —— （）、（ prepared ） LSN (  ) ；  InnoDB  (  16 k  ) ， LSN 。 LSN ， LSN  。 ( 2 ) xtrabackup_binlog_info —— mysql 。 ( 3 ) xtrabackup_binlog_pos_innodb ——  InnoDB  XtraDB  position 。 ( 4 ) xtrabackup_binary ——  xtrabackup ； ( 5 ) backup - my . cnf —— ；  innobackupex ， -- no - timestamp ；， innobackupex  BACKUP - DIR 。 2 、 ( prepare )  ，，， 。，。“” 。 innobakupex  -- apply - log 。： # innobackupex -- apply - log / path / to / BACKUP - DIR ，： xtrabackup : starting shutdown with innodb_fast_shutdown = 1 120407 9 : 01 : 36 InnoDB : Starting shutdown ... 120407 9 : 01 : 40 InnoDB : Shutdown completed ; log sequence number 92036620 120407 09 : 01 : 40 innobackupex : completed OK ! “”， innobackupex  -- use - memory ， 100 M 。 ， prepare ，。 3 、 innobackupex  -- copy - back ， mysql  DATADIR  。 innobackupex  backup - my . cnf  DATADIR 。 # innobackupex -- copy - back / path / to / BACKUP - DIR ，： innobackupex : Starting to copy InnoDB log files innobackupex : in /backup/2012-04-07_08-17-03 innobackupex : back to original InnoDB log directory /mydata/data innobackupex : Finished copying back files . 120407 09 : 36 : 10 innobackupex : completed OK ! “ innobackupex : completed OK ! ”。  DATADIR ，， mysql ，， mysqld  。： # chown - R mysql : mysql / mydata / data / 4 、 innobackupex   InnoDB  LSN ，， LSN 。 InnoDB  ， innobackupex 。 ，： # innobackupex -- incremental / backup -- incremental - basedir = BASEDIR ， BASEDIR ，， innobackupex  / backup  。，， -- incremental - basedir 。 ， InnoDB  XtraDB ， MyISAM ，。 “” ( prepare ) ，： ( 1 )  (  ) ，“”。“”，。 ( 2 ) “”。 ，： # innobackupex -- apply - log -- redo - only BASE - DIR ： # innobackupex -- apply - log -- redo - only BASE - DIR -- incremental - dir = INCREMENTAL - DIR - 1 ： # innobackupex -- apply - log -- redo - only BASE - DIR -- incremental - dir = INCREMENTAL - DIR - 2  BASE - DIR ， INCREMENTAL - DIR - 1 ， INCREMENTAL - DIR - 2  ，，，； 5 、 Xtrabackup “”“” Xtrabackup “”， STDOUT  tar ， 。， -- stream 。： # innobackupex -- stream = tar / backup | gzip / backup / ` date +% F_ % H -% M -% S `. tar . gz ： # innobackupex -- stream = tar / backup | ssh user @ www . magedu . com cat - /backups/`date +%F_%H-%M-%S`.tar ，， -- parallel 。。， ， innodb_file_per_table  innodb_data_file_path   ibdata 。。： # innobackupex -- parallel / path / to / backup ， innobackupex ， -- remote - host ： # innobackupex -- remote - host = root @ www . magedu . com / path / IN / REMOTE / HOST / to / backup 6 、 ， InnoDB  mysql ， innodb_file_per_table 。  Xtrabackup ，，“” mysql  innodb_file_per_table （， “”， mysql  innodb_file_per_table ），“” innodb_file_per_table  innodb_expand_import 。 ( 1 ) “”  prepare ，，， prepare  -- export ： # innobackupex -- apply - log -- export / path / to / backup  innodb . exp ，. exp 。 ( 2 ) “”  mysql  innodb ，，： mysql CREATE TABLE mytable ( ... ) ENGINE = InnoDB ; ： mysql ALTER TABLE mydatabase . mytable DISCARD TABLESPACE ; ，“” mytable  mytable . ibd  mytable . exp ，“”： mysql ALTER TABLE mydatabase . mytable IMPORT TABLESPACE ; 7 、 Xtrabackup  Xtrabackup ，。， innodb_file_per_table ，。， -- stream ， 。 ，， prepared  -- copy - back  ，。，， -- copy - back ， ，，。 ( 1 )  ： ( -- include ) ,  ( -- tables - file )  ( -- databases ) 。 ( a )  -- include  -- include ，， databasename . tablename ，： # innobackupex -- include = ^mageedu[.]tb1 / path / to / backup ( b )  -- tables - file ，；： # echo - e mageedu.tb1 \\n mageedu.tb2 / tmp / tables . txt # innobackupex -- tables - file =/ tmp / tables . txt / path / to / backup ( c )  -- databases ，，；，，。， ，。： # innobackupex -- databases = mageedu testdb / path / to / backup ( 2 )  ( preparing )  prepare ， -- export ： # innobackupex -- apply - log -- export / pat / to / partial / backup ， innobackupex  xtrabackup ，，“”。 ，. exp 。 ( 3 )  。， prepared ， 。 MyISAM InnoDB MyISAM  InnoDB ：  MyISAM 。，。 . frm 。  . MYD ( MYData ) ， . MYI ( MYIndex ) 。  InnoDB ， InnoDB ， 2 GB  : MyISAM ， InnoDB ， InnoDB ， SELECT UPDATE , INSERT ， Delete   SELECT ， MyISAM  1 .  INSERT  UPDATE ，， InnoDB  2 . DELETE FROM table ， InnoDB ，。 3 . LOAD TABLE FROM MASTER  InnoDB ， InnoDB  MyISAM ， InnoDB ，  InnoDB （） MySQL  CPU 。 ，： cat / proc / cpuinfo ， CPU ： #cat /proc/cpuinfo processor : 5 model name : Intel ( R ) Xeon ( R ) CPU E5 - 2620 0 @2.00 GHz ... cpu MHz : 1200.000  Intel E5 - 2620  CPU ， 2.00 G * 24  CPU ，， 5  CPU  1.2 G 。 ？  CPU ：。 CPU ，，， CPU 。 ， MySQL ，。  MySQL  CPU ， CPU 。 BIOS ，， BIOS  ，。 BIOS ， CPU ，。 、 ，。 i )  numa  ( NUMA ： Non - Uniform Memory Access ) 。 ( SMP ： Symmetric Multi - Processor ) 。： ， NUMA 。： SMP ； NUMA ，  。，，。 ： -- interleave = nodes -- membind = nodes -- cpunodebind = nodes -- physcpubind = cpus -- localalloc -- preferred = node ，，， CPU 。  -- interleave = nodes ，  NUMA 。 NUMA  ， Linux ，  SWAP 。 DBA  SWAP  。 ，。 ，： BIOS ，，。 a )  BIOS ， NUMA ，。 b ) ， / etc / grub . conf  kernel  numa = off ，： kernel / vmlinuz - 2.6.32 - 220. el6 . x86_64 ro root =/ dev / mapper / VolGroup - root rd_NO_LUKS LANG = en_US . UTF - 8 rd_LVM_LV = VolGroup / root rd_NO_MD quiet SYSFONT = latarcyrheb - sun16 rhgb crashkernel = auto rd_LVM_LV = VolGroup / swap rhgb crashkernel = auto quiet KEYBOARDTYPE = pc KEYTABLE = us rd_NO_DM numa = off  vm . zone_reclaim_mode = 0 。 c )  MySQL ， NUMA ： numactl -- interleave = all mysqld ， BIOS 。 ii )  vm . swappiness 。 vm . swappiness 。， 0 ， 100 ， 60 。 vm . swappiness  0  swap ， 100  inactive 。 ：， inactive ， cache 。 cache ，， ； inactive ， ，“”。  vmstat  inactive ： #vmstat -an 1 procs ----------- memory ---------- --- swap -- ----- io ---- -- system -- ----- cpu ----- r b swpd free inact active si so bi bo in cs us sy id wa st 1 0 0 27522384 326928 1704644 0 0 0 153 11 10 0 0 100 0 0 0 0 0 27523300 326936 1704164 0 0 0 74 784 590 0 0 100 0 0 0 0 0 27523656 326936 1704692 0 0 8 8 439 1686 0 0 100 0 0 0 0 0 27524300 326916 1703412 0 0 4 52 198 262 0 0 100 0 0  / proc / meminfo ： #cat /proc/meminfo | grep -i inact Inactive : 326972 kB Inactive ( anon ) : 248 kB Inactive ( file ) : 326724 kB  inactive 。 Linux ，： free ， active  inactive 。， Linux Kernel  LRU ， LRU_INACTIVE_ANON , LRU_ACTIVE_ANON , LRU_INACTIVE_FILE , LRU_ACTIVE_FILE , LRU_UNEVICTABLE 。 LRU_INACTIVE_ANON , LRU_ACTIVE_ANON ， LRU_INACTIVE_FILE , LRU_ACTIVE_FILE  page caches 。， active  inactive ，  inactive   swap 。 ， MySQL ， InnoDB ，，， Linux ，   CPU  IO 。 InnoDB ， cache ， InnoDB 。 ， MySQL  vm . swappiness = 0 。  sysctl . conf ： echo vm.swappiness = 0 / etc / sysctl . conf  sysctl - p 。 、 ， i )  mount  noatime ， nobarrier 。  noatime mount ，， access time 。， Linux  ， change time , modify time  access time 。  stat ： stat libnids - 1.16 . tar . gz File : ` libnids - 1.16 . tar . gz Size : 72309 Blocks : 152 IO Block : 4096 regular file Device : 302 h / 770 d Inode : 4113144 Links : 1 Access : ( 0644 /- rw - r -- r -- ) Uid : ( 0 / root ) Gid : ( 0 / root ) Access : 2008 - 05 - 27 15 : 13 : 03.000000000 + 0800 Modify : 2004 - 03 - 10 12 : 25 : 09.000000000 + 0800 Change : 2008 - 05 - 27 14 : 18 : 18.000000000 + 0800  access time ， modify time ， change time  inode  ( 、、 ) 。，， 。 ， noatime ， access time ，。  cache ，， write barriers 。，  RAID ， RAID ； Flash ， ，。  nobarrier 。：  ext3 , ext4  reiserfs  mount  barrier = 0 ； xfs  nobarrier 。 ii )  IO ， deadline 。  Flash ，，，  IO ( IOPS ) ， ， IO ， Linux  IO  ，。 Linux  IO ： Deadline scheduler ， Anticipatory scheduler ， Completely Fair Queuing ( CFQ ) ， NOOP 。 ， CFQ  Deadline ， CFQ  Linux   2.6.18 ， IO ，。， 3  IO ， 10000  IO ，， 3  IO  10000  IO ， IO ，。，  IO  ， IO “”。 deadline ，  。 ， echo deadline / sys / block / sda / queue / scheduler  sda  deadline 。  / etc / grub . conf  kernel  elevator = deadline 。  CPU ：  ： vm . swappiness = 0  numa ：  noatime ， nobarrier  IO  deadline 。 ： http : //os.51cto.com/art/201407/446750.htm mycat http://www.mycat.org.cn/ https://github.com/MyCATApache/Mycat-download  ： 1.conf/server.xml mycat，mycatmysql，mycat。 ?xml version= 1.0 encoding= UTF-8 ? !DOCTYPE mycat:server SYSTEM server.dtd mycat:server xmlns:mycat= http://org.opencloudb/ system !-- property name= processors 32 /property property name= processorExecutor 32 /property property name= serverPort 8066 /property property name= managerPort 9066 /property -- /system user name= root property name= password root /property property name= schemas  /property /user /mycat:server 2.conf/schema.xml ，schematable，sql，mycat。 ?xml version= 1.0 ? !DOCTYPE mycat:schema SYSTEM schema.dtd mycat:schema xmlns:mycat= http://org.opencloudb/ schema name=  checkSQLschema= false dataNode= dn1 /schema dataNode name= dn1 dataHost= localhost1 database=  / dataHost name= localhost1 maxCon= 1000 minCon= 100 balance= 1 dbType= mysql dbDriver= native heartbeat select user() /heartbeat !-- can have multi write hosts -- writeHost host= 10.1.3.50 url= 10.1.3.50:3306 user=  password=  !-- can have multi read hosts -- readHost host= 10.1.3.5 url= 10.1.3.5:3306 user=  password=  / readHost host= 10.1.3.6 url= 10.1.3.6:3306 user=  password=  / /writeHost !--writeHost host= 10.1.3.34 url= 10.1.3.34:3306 user=  password=  -- !-- can have multi read hosts -- !--readHost host= 10.1.3.7 url= 10.1.3.7:3306 user=  password=  /-- !--readHost host= 10.1.3.8 url= 10.1.3.8:3306 user=  password=  /-- !--/writeHost-- /dataHost /mycat:schema  MyCAT： • SQL，，select/*balance*/ • select， • ，，，，，MYCAT select。 • ，，select， ，。 dataHostbalance： • 0， • 1，readHoststand by writeHostselect，，(M1- S1，M2- S2，M1 M2 )，，M2,S1,S2select。 • 2，readHostwriteHostselect，，，。 dataHost，，DBA。writeHost Master DB Server，readHostSlave DB Server。dataHostwriteHost， writeHost，Mycat ，writeHost。 MyCAT，，： • ，。 • （）， • ， ，，（），Mycat（）， MyCAT，。 sql yum install mysql mysql - server - y  （ / var / lib / mysql ）。 / etc / init . d / mysqld start  UPDATE tablename SET  = REPLACE ( , HTML , .YOUKU ) ;  create database vfast ; drop database vfast ; use vfast ; show databases ; flush tables with read lock ;  unlock tables ;  show tables ; create table rhce ( id int ) ; alter table rhce rename cbd ;  alter table cbd add sex enum ( Y , N ) ;  sex alter table cbd drop id ;  id alter table cbd modify name char ( 16 ) ; namechar（16） or alter table vfast_user change name name enum ( B , G ) ; alter table cbd change name mingzi char ( 26 ) ;　namemingzi char(26) show warnings \\ G ; mysql show create table cbd ; cbd desc cbd ; cbd drop table cbd ;   char   varchar （， CPU ， CPU ）  int  ， - 2147493648  2147493647 bigint  ， - 9223372036854775808  9223372036854775807 float （） 。 - 3 . 402823466 E + 38  - 1 . 175494351 E - 38 date  time  datetime  blob  text  enum  set  timestamp  select * from xt701 ; insert into xt701 ( name , ID , yuwen ) values ( lin , 1007 , 99 ) ; or insert into xt701 values ( zhang , 1001 , 80 , 70 , 90 ) , ( li , 1002 , 90 , 98 , 19 ) , ( zhao , 1003 , 68 , 67 , 90 ) ; select name , id from xt701 where shuxue = 80 ; ：！！ update xt701 set shuxue = 80 where id = 1007 and shuxue is NULL ;  update 3 m_recording_meeting m set m . play_url = REPLACE ( m . play_url , 127.0.0.1 , saas.3mang.com ) where m . play_url like %127.0.0.1% truncate  （）  delete delete  delete from xt701 ; truncate xt701 ; delete from xt701 where yingyu = 80 ; select * from T1 where YUWEN between 70 and 90 ;  awk - F : {print $1 , $3 , $4 , $NF} / etc / passwd / tmp / user create table H2 ( NAME char ( 15 ) , PASSWORD char ( 50 ) , UID int ( 5 ) , GID int ( 5 ) , MIAOSHU varchar ( 100 ) , HOME varchar ( 100 ) , SHELL varchar ( 100 )) ; load data infile /etc/passwd into table H2 fields terminated by : ; mysql  sum  max  min  avg  count   mysql  Atlas ， cobar ， TDDL ， mycat ， heisenberg , Oceanus , vitess , OneProxy ： http : // songwie . com / articlelist / 44 mysql - proxy  mysql ，， failover ，。  mysql ， Atlas ， cobar ， tddl ，。 Atlas Atlas  Qihoo 360 , Web  MySQL 。 mysql - proxy 0 . 8 . 2 ， ，。 360  Atlas  mysql ，。 Altas ： Atlas  MySQL ， MySQL ，， MySQL 。  DB ， MySQL ，。 ， LVS ， Altas  HA ,。 Altas ： 1 . ， Atlas ，，。， Atlas ，。  mysql  proxy ，。 2 .，， DB ，。  1 。  1 3 . （ 1 ）， Altas  SQL  /*master*/  。 （ 2 ） 2 ，，，，。  2 4 .（ 3 ） （ 1 ）。 （ 2 ） SELECT 、 INSERT 、 UPDATE 、 DELETE 、 REPLACE 。 （ 3 ）。  3  Atlas ，， DB  database ， Atlas 。 5 . lua ，， Atlas  C ， QPS ， latency 。 6 . （ 1 ） pwds  Atlas 。 （ 2 ） client - ips  Atlas  ip 。 （ 3 ） Altas  SQL ， IP 、 DB 、、 ，（ 4 ）。  4 7 .  lvs - ips ， Altas  SQL 。 lvs  ip ，  ip 。 Atlas  lvs 。 source ： https : // github . com / Qihoo360 / Atlas alibaba . cobar Cobar （ B2B ）， 。， cobar -- ？： 1 .，，。 2 .，。 3 . failover 。 4 .，，。  cobar ， cobar  proxy ， mysq l 。 SQL ，，。 Cobar  ： ： 1 . Cobar  test ， t1 , t2 。 3  MySQL  ( ip : port ) ，： A , B , C 。 2 . t1  A ， t2  B  C 。 t2  HA ， B  C  ，。 cabar ： 1 .： （ 1 ） Cobar  （ 2 ） Cobar  （ 3 ） ， ！： Cobar ， test  test_1 , test_2 , test_3 .....， 。 2 .。 3 .。 4 . failover , HA ： ( 1 ) Cobar ，， Cobar 。， ，，，， Cobar ，。 ( 2 ) Cobar  MySQL ，， Cobar  MySQL 。 cobar ：  mysql ，。 source ： http : // code . alibabatech . com / wiki / display / cobar / Home TDDL  TDDL （ Taobao Distributed Data Layer : © _Ob ）， ， jdbc datasource ，，，。 TDDL （ tddl ， jar ， SQL ）： ， ， DBRoute 。 DBRoute  、，。， ，，，， 2 、 4 、 8 、 16 、 32 …… 1024 、 2048 。，，，？，，， ，（）， TDDL 。  DAL （） 。 ： ： 1 . 2 . 3 . 4 . 5 . jboss  6 . mysql  oracle  7 . jdbc ， jdbc  8 . server , client - jar ， 9 .,， 10 .,， TDDL  diamond （ diamond ，，  diamond ， diamond ）。 TDDL ： http : // rdc . taobao . com / team / jm / archives / 1645 diamond ： http : // jm . taobao . org / tag / diamond % E4 % B8 % 93 % E9 % A2 % 98 / TDDL ： https : // github . com / alibaba / tb_tddl TDDL 。，，， diamond ，。 ，。，。 MyCAT http : // www . org . cn / https : // github . com / myCATApache  MyCAT ?， MyCAT ： ，“” 、 ACID 、 Mysql  ? “ Mysql ”， Oracle  ? 、 Nosql 、 HDFS  SQL Server ?  ? 。  “”，。  1 .  SQL 92   Mysql ， Proxy   JDBC  ORACLE 、 DB2 、 SQL Server ， MySQL Server   galera for mysql ， percona - cluster  mariadb cluster ，，， 。 2 . 。 3 .  Mysql ， 。 4 . 。 5 . ， 。 6 .  join ， E - R ，，。   Cobar ， Cobar 、、， MyCAT  ，，。， MyCAT ， MyCAT ，。 MyCAT ， 5 、、 DBA ， MyCAT 。 MyCAT ， ，，，。   Mysql ，， PosteSQL 、 FireBird ， JDBC  Oracle 、 DB2 、 SQL Server ， SQL ， ，， HDFS ， SQL ，  HDFS ，。 heisenberg  mysql , ： ，  db     Mysql   ， mysqlclient , c , java  Heisenberg ，，，，   velocity ， qq ： 150720285 : brucest0078 @ gmail . com https : // github . com / songwie / heisenberg ，  db     Mysql  ， mysqlclient , c , java  Heisenberg ，，，， Oceanus : Oceanus 、、、、，。， ，，，，。 Oceanus  datanode ：。，、 namenode ：。，、、 table ：。 sql  table ， table  name ， bean ：。， tracker ：。 IO ，，，   Oceanus  Oceanus ，，，。  ，， Oceanus ， HA 、、、 。 ， table ， Oceanus  sql 、 、 sql 。 ： select * from user ； ： select * from user0 ; select * from user1; select * from user2 ; select * from user3;  (  ) ，： github  “，”  Oceanus ， mybatis  hibernate ，， Oceanus  ，  DataSource  ConnectionProvider 。 ORM ， Oceanus  。   Oceanus ，， Cache 、 ID 、 ，，，。 vitess : ， ZooKeeper ， RPC ，， server ， command line ， gui  3 。 https : // github . com / youtube / vitess OneProxy OneProxy ，（@）。 MySQL - Proxy 0 . 8 . 4 ，，。 ，、。 OneProxy ： 1 .  2 .  3 . Proxy 【】 4 .  5 . （ master ） 6 . （ master ） 7 .  8 .  9 . SQL  10 . SQL 【】 11 . 【】 12 . 【】  http : // www . cnblogs . com / youge - OneSQL / articles / 4208583 . html  Server Group  OneProxy ， MySQL  Server Group 。. A ， Server Group A  Server Group B 。 A . A  OneProxy ， Server Group 。，。 A ） Server Group A  table X , table Y , table Z ， table X ， I / O ，  tableY , tableZ 。 B . B  1 . 0 ： table X ， Server Group B （ C ）， OneProxy  table X ，。 C . C B ） 1 . 0 ， I / O 。， Server Group B ， 。  2 . 0 :  Server Group B  table X ， X_00 , X_01  Server Group B ， X_02 ， X_03  Server Group C ， D  D atlas_keepalived   DB  360  Atlas ，， 2 。，， （ amoeba 、 cobar 、 MaxScale 、 MySQL - Proxy ），。  Atlas ，： ( 1 ) 、 mysql - proxy - 0.8.2 ，； ( 2 ) 、，； ( 3 ) 、 DB ； ( 4 ) 、 DB ， DB ； ( 5 ) 、 DB ； ( 6 ) 、（ IP 、）； ( 7 ) 、、、。 ， 360 Atlas ，。 Atlas ，， ： https : //github.com/Qihoo360/Atlas/blob/master/README_ZH.md 2 、 wKioL1Sw6iagbaHjAAJX6OZk - GM940 . jpg 3 、 CentOS 6.3 x86_64  ( 1 ) 、 glib ， yum ； ( 2 ) 、 LUA ， 5.1 . x ； ( 3 ) 、 glib ， glib - 2.32 . x ； ( 4 ) 、，。 yum install glib glib - devel ncurses readline lua libevent libevent - devel openssl openssl - devel - y https : //github.com/Qihoo360/Atlas/wiki/  https : //github.com/Qihoo360/Atlas/releases RPM，： sudo rpm – i Atlas - XX . el6 . x86_64 . rpm 。 Atlas （ test . cnf ）。 Atlas ，。 Atlas  / usr / local / mysql - proxy ，  conf ， test . cnf ，，。 1. ： [ mysql - proxy ] ( ， )  admin - username = user ( ， )  admin - password = pwd ( ， )  IP  proxy - backend - addresses = 192.168.0.12 : 3306 ( ， )  IP ， @ ，， 1 ，，。 ，。 proxy - read - only - backend - addresses = 192.168.0.13 : 3306 , 192.168.0.14 : 3306 ( ， )  MySQL ， PREFIX / bin  encrypt ， 。（）。 myuser ， mypwd ，  . / encrypt mypwd  HJBoxfRsjeI = 。。： pwds = myuser : HJBoxfRsjeI = , myuser2 : HJBoxfRsjeI = （， ) Atlas ， true ， false ， false ，  true daemon = true ( ， )  Atlas ， true  Atlas ， monitor ， worker ， monitor  worker  ， false  worker ， monitor ， false ， true keepalive = true ( ， ) ， CPU  2  4  event - threads = 4 ( ， ) ， message 、 warning 、 critical 、 error 、 debug  log - level = message ( ， )  log - path = / usr / local / mysql - proxy / log ( ， ) SQL ， OFF 、 ON 、 REALTIME ， OFF  SQL ， ON  SQL ， ，，。 REALTIME ， SQL ， OFF sql - log = OFF ( ，）。， sql - log - slow （： ms ) 。 。 sql - log - slow = 10 ( ，）。， Atlas  wait - timeout 。： wait - timeout = 10 ( ， ) Atlas  IP  proxy - address = 0.0.0.0 : 1234 ( ， ) Atlas  IP  admin - address = 0.0.0.0 : 2345 ( ， ) ， person ， mt ， id ， 3 ，，， ，， _ ， [ 0 ,  - 1 ] ，， mt_0 、 mt_1 、 mt_2 tables = person . mt . id .3 ( ， ) ，， latin1 charset = utf8 ( ， )  Atlas  IP ， IP ， IP ，， IP ，  IP  client - ips = 127.0.0.1 , 192.168.1 ( ， ) Atlas  LVS  IP (  IP ) ， LVS  client - ips ， lvs - ips = 192.168.1.1 2.  ，。 ( 1 )  event - threads ， CPU ，， CPU 。 ( 2 )  ( 2. x ， 1. x  ) min - idle - connections ，，， ，《》。 Atlas 2. X ，。 Atlas 1. X ， 。 3.  ，，。 ( 1 ) Atlas  proxy - address ， proxy - address = 0.0.0.0 : 1234  1234  Atlas  SQL 。 ( 2 ) Atlas  admin - address ， admin - address = 0.0.0.0 : 2345  DBA  2345  Atlas 。 ( 3 )  admin - username  admin - password ， Atlas ， MySQL ， ， MySQL 。 ( 4 )   log - level ， message 、 warning 、 critical 、 error 、 debug  ( 5 )   log - path ， log - path = / usr / local / mysql - proxy / log 。  / usr / local / mysql - proxy / bin ，、 Atlas 。 ( 1 ). sudo . / mysql - proxyd test start ， Atlas 。 ( 2 ). sudo . / mysql - proxyd test restart ， Atlas 。 ( 3 ). sudo . / mysql - proxyd test stop ， Atlas 。 ： ( 1 ). ： mysql - proxyd (  mysql - proxy ) 。 ( 2 ). test  conf ， instance ，。 ( 3 ).  ps - ef | grep mysql - proxy  Atlas 。 ： mysql - h127 .0.0.1 - P1234 - u  - p ， Atlas ， SQL  。  Atlas ： mysql - h127 .0.0.1 - P2345 - uuser - ppwd ， : select * from help ;  DB 。 Atlas 【 Keepalived 】 ( 1 ) 、 # vim /etc/keepalived/keepalived.conf global_defs { notification_email { lovezym5 @126. com } notification_email_from lovezym5 @126. com smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id dbproxy1 } vrrp_script chk_mysql_proxy_health { script /data/scripts/keepalived_check_mysql_proxy.sh interval 1 weight - 2 } vrrp_instance VI_1 { state MASTER interface eth1 virtual_router_id 51 priority 100 advert_int 1 smtp_alert authentication { auth_type PASS auth_pass 123456 } virtual_ipaddress { 10.209.6.115 } track_script { chk_mysql_proxy_health } notify_master /data/scripts/notify.sh master notify_bakcup /data/scripts/notify.sh backup notify_fault /data/scripts/notify.sh fault } ( 2 ) 、 # vim /etc/keepalived/keepalived.conf global_defs { notification_email { lovezym5 @126. com } notification_email_from lovezym5 @126. com smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id dbproxy2 } vrrp_script chk_mysql_proxy_health { script /data/scripts/keepalived_check_mysql_proxy.sh interval 1 weight - 2 } vrrp_instance VI_1 { state BACKUP interface eth1 virtual_router_id 51 priority 90 advert_int 1 smtp_alert authentication { auth_type PASS auth_pass 123456 } virtual_ipaddress { 10.209.6.115 } track_script { chk_mysql_proxy_health } notify_master /data/scripts/notify.sh master notify_bakcup /data/scripts/notify.sh backup notify_fault /data/scripts/notify.sh fault } ( 3 ) 、 VIP  # vim /data/scripts/notify.sh #!/bin/sh PATH =/ sbin : / bin : / usr / sbin : / usr / bin : / usr / local / bin : / usr / local / sbin KEEPALIVE_CONF = /etc/keepalived/keepalived.conf VIP = ` grep - A 1 virtual_ipaddress $ { KEEPALIVE_CONF } | tail - 1 | sed s / \\ t //g; s/ //g ` ETH1_ADDR = ` / sbin / ifconfig eth1 | awk / inet addr : / { print $ 2 } | awk - F : { print $ 2 } ` MONITOR = /usr/local/oms/agent/alarm/BusMonitorAgent TOKEN = ha_monitor function notify () { TITLE = $ETH1_ADDR to be $1: $VIP floating CONTENT = vrrp transition, $ETH1_ADDR changed to be $1 $ { MONITOR } - c 2 - f $ { TOKEN } - t ${TITLE} - i ${CONTENT} } case $1 in master ) notify master exit 0 ;; backup ) notify backup exit 0 ;; fault ) notify fault exit 0 ;; * ) echo Usage : ` basename $ 0 ` { master | backup | fault } exit 1 ;; esac ( 4 ) 、 DB  # vim /data/scripts/keepalived_check_mysql_proxy.sh #!/bin/sh PATH =/ sbin : / bin : / usr / sbin : / usr / bin : / usr / local / bin : / usr / local / sbin if [[ ` pgrep mysql - proxy | wc - l ` - eq 0 ]]; then / sbin / service mysql - proxy start sleep 5 [[ - z ` pgrep mysql - proxy ` ]] / sbin / service keepalived stop fi # chmod +x /data/scripts/*.sh # service keepalived start wKioL1Sw72OBWcdcAABQovflyow736 . jpg # ip addr show eth1 wKiom1Sw7r3S6v6_AACfXZvxonQ064 . jpg # ps aux | grep keepalive[d] wKiom1Sw7tnzsSOAAABqz91YIVo562 . jpg ========================================================================================== 、 ========================================================================================== 1 、 Atlas  # vim /usr/local/mysql-proxy/bin/check_service.sh #!/bin/sh PATH =/ sbin : / bin : / usr / sbin : / usr / bin : / usr / local / bin : / usr / local / sbin [[ $# - ne 3 ]] echo $0    exit 1 SRV_PORT = $ 1 ##  SRV_PROT = $ 2 ##  SRV_NAME = $ 3 ##  MONITOR = /usr/local/oms/agent/alarm/BusMonitorAgent TOKEN = ha_monitor TITLE = ${SRV_NAME} CONTENT = ${SRV_NAME}，！ ##  SCAN_FLAG = 0 function RESTART_SRV_AND_ALERT () { local CUR_SRV_NAME [[ $# - ne 1 ]] exit 1 CUR_SRV_NAME = $ 1 TMP_SRV_NAME = ` echo $ { CUR_SRV_NAME } | tr [ A - Z ] [ a - z ] ` [[ ! - f / etc / init . d / $ { TMP_SRV_NAME } ]] TMP_SRV_NAME = ${TMP_SRV_NAME}d killall - 9 $ { TMP_SRV_NAME } if [[ - z ` ps aux | grep $ { TMP_SRV_NAME } | grep - v grep ` ]]; then / sbin / service $ { TMP_SRV_NAME } start / dev / null 2 1 fi $ { MONITOR } - c 2 - f $ { TOKEN } - t ${TITLE} - i ${CONTENT} rm - f ` pwd ` / connect_error . log } ETH1_ADDR = ` / sbin / ifconfig eth1 | awk - F : / inet addr / { print $ 2 } | sed s / [ a - zA - Z ] //g ` TMP_SRV_PROT = ` echo $ { SRV_PROT } | tr [ A - Z ] [ a - z ] ` if [[ ${TMP_SRV_PROT} == tcp ]]; then PROT_OPT = S elif [[ ${TMP_SRV_PROT} == udp ]]; then PROT_OPT = U else echo ！ exit 1 fi ## 3，， for (( i = 0 ; i 3 ; i ++ )); do RETVAL = ` / usr / bin / nmap - n - s $ { PROT_OPT } - p $ { SRV_PORT } $ { ETH1_ADDR } | grep open ` [[ - n ${RETVAL} ]] SCAN_FLAG = 1 ; break || sleep 10 done ## 1、Atlas， [[ $ { SCAN_FLAG } - ne 1 ]] RESTART_SRV_AND_ALERT $ { SRV_NAME } ## 2、Atlas，，【DB】 mysqladmin - h $ { ETH1_ADDR } - uhealth_check1 - p123456 -- connect - timeout = 15 -- shutdown - timeout = 15 ping [[ $ ? - ne 0 ]] RESTART_SRV_AND_ALERT $ { SRV_NAME } ## 3、Atlas，，DB， ## DB【DB】 mysqladmin - h $ { ETH1_ADDR } - uhealth_check2 - p123456 -- connect - timeout = 15 -- shutdown - timeout = 15 ping [[ $ ? - ne 0 ]] RESTART_SRV_AND_ALERT $ { SRV_NAME } 2 、 Atlas  # vim /data/scripts/cut_and_clear_access_log.sh #!/bin/sh # Atlas，15 # PATH =/ sbin : / bin : / usr / sbin : / usr / bin : / usr / local / bin : / usr / local / sbin ## mysql-proxy LOGPATH = /usr/local/mysql-proxy/log [[ ` / sbin / ip addr show eth1 | grep inet | wc - l ` - eq 2 ]] || exit 1 cd $ { LOGPATH } ##  HISTORY_LOG_PATH = ` date - d - 1 hour + %Y-%m-%d/sql_mysql-proxy_%H.log ` [[ - d ` dirname $ { HISTORY_LOG_PATH } ` ]] || mkdir - p ` dirname $ { HISTORY_LOG_PATH } ` cp - a sql_mysql - proxy . log $ { HISTORY_LOG_PATH } echo sql_mysql - proxy . log ##  HISTORY_LOG_PATH = ` date - d 15 days ago + % Y -% m -% d ` [[ - d $ { HISTORY_LOG_PATH } ]] rm - rf $ { HISTORY_LOG_PATH } 3 、 crontab  # touch /var/lock/check_service.lock # echo touch /var/lock/check_service.lock /etc/rc.d/rc.local # crontab -uroot -e 1 2 * * * * * ( flock -- timeout = 0 / var / lock / check_service . lock / usr / local / mysql - proxy / bin / check_service . sh 3306 tcp mysql - proxy / dev / null 2 1 ) 00 * * * * / data / scripts / cut_and_clear_access_log . sh / dev / null 2 1 4 、 # mysql -h10.209.6.101 -P3307 -usysadmin -p admin2356!@() wKioL1Sw8S_gXZOuAALgQK7R39c195 . jpg my.cnf MySQL 。 MySQL 。 MySQL 。 MySQL 。 [ client ] password =[ your_password ] port = @MYSQL_TCP_PORT @ socket = @MYSQL_UNIX_ADDR @ ***  *** MySQL [ mysqld ]  port = @MYSQL_TCP_PORT @ socket = @MYSQL_UNIX_ADDR @ skip - name - resolve DNS ，  。  ， MySQLip back_log , MySQL .  ” connectionrefused ”  ,  .  . back_log ,  back_log = 300 TCP / IP . mysqld ,  mysqldUnixsockets . windows (  “ enable - named - pipe ”  ) mysql ! skip - networking MySQL SUPER .  . max_connections = 3000  ,  . MySQL ” FLUSHHOSTS ”   .  “ Aborted_connects ”  . max_connect_errors = 30  . mysqld  [ mysqld_safe ]  “ open - files - limit ” 4096 table_cache = 4096  .   (  ! ) MyISAM external - locking  ( BLOB )  .  max_allowed_packet = 32 M binlogSQLcache  ,  ,  . binlogbinlog  ,  .  binlog_cache_size = 4 M  .  . max_heap_table_size = 128 M ORDERBYGROUPBY  ,   “ Sort_merge_passes ”  .  sort_buffer_size = 16 M  ( fullJOINs ).  ,  .  “ Select_full_join ”   ,  join_buffer_size = 16 M cache  , cachethread_cache_size , cache .  (  ,  .) thread_cache_size = 16  . thread_concurrency ()  ( SunSolaris ).  [ CPU ]* ( 2..4 ) thread_concurrency thread_concurrency = 8 SELECT .  ,  .  “ Qcache_lowmem_prunes ”  .  :  ,  . query_cache_size = 128 M   ,  . query_cache_limit = 4 M  .  ,  .  , FULLTEXT ft_min_word_len = 8 memlock ()  , mysql ,  swappingout  memlock  ,  ,  default_table_type = MYISAM  .  . MySQL64K UDF  ,  . thread_stack = 512 K  .  : READ - UNCOMMITTED , READ - COMMITTED , REPEATABLE - READ , SERIALIZABLE transaction_isolation = REPEATABLE - READ  (  )   ,  .  ,  . tmp_table_size = 128 M  .  ( replication )  , MASTER  ,  . log - bin = mysql - bin  ( A - B - C ), B .  ,  . log_slave_updates  .  (  )  .  ,  . log log . MySQL log ,  . log_warnings  .  “ long_query_time ”  . log_long_format ,  .  .  , log_slow_queries  (  )  .  ” 1 ″ ,  ,  ( MySQL ). long_query_time = 6  .  .  log_long_format MySQL .  ,  ,  .  .  , swapfs / tmpfs  .  ” ; ”  roud - robin . tmpdir =/ tmp ***   , 12 ^ 32 - 1  . masterslave .  “ master - host ”  , 1 ,  , MySQLmaster . server - id = 1 Slave ( master ) slave ,  : 1 ) CHANGEMASTERTO (  ) -  : CHANGEMASTERTOMASTER_HOST = , MASTER_PORT = , MASTER_USER = , MASTER_PASSWORD = ;  ,, master ( 3306 ).  : CHANGEMASTERTOMASTER_HOST = ’ 125.564.12.1 ′ , MASTER_PORT = 3306 , MASTER_USER = ’ joe ’ , MASTER_PASSWORD = ’ secret ’ ;  2 )  .  ,  ,  (  , master - passwordslave ), slavemaster . info ,  master . info , slave , master . infoslave .  ,  (  ) CHANGEMASTERTO (  )  id22 ^ 32 – 1  ( master ) master - host . 2  ,  server - id = 2 master –  master - host = masterslave –  master - user = masterslave –  master - password = master .  – 3306 master - port = slave . SUPERslave . slavemaster read_only *** MyISAM  , MyISAM . 30 % , OS MyISAM , 8 - 64 M . key_buffer_size = 128 M MyISAM .  ,  . read_buffer_size = 8 M  ,  ,  .  , ORDERBY .  read_rnd_buffer_size = 64 M MyISAMcache (  , INSERT … SELECT , INSERT … VALUES ( … ),( … ), … , LOADDATA INFILE )  .  . 0 .  “ key_buffer_size ” .  . bulk_insert_buffer_size = 256 M MySQLREPAIR , OPTIMIZE , ALTERLOADDATAINFILE .  .  . myisam_sort_buffer_size = 256 M MySQL ( REPAIR , ALTERTABLELOADDATAINFILE ).  ,  (  ) myisam_max_sort_file_size = 10 G  ,  .  . myisam_max_extra_sort_file_size = 10 G  , MyISAM . CPU ,  . myisam_repair_threads = 1 MyISAM . myisam_recover Federated skip - federated *** BDB *** MySQLBDB .  . skip - bdb *** INNODB *** MySQLInnoDB ,  ,  skip - innodb InnoDBmetadata InnoDB , OS .  ,  . SHOWINNODBSTATUS . innodb_additional_mem_pool_size = 64 M InnoDB , MyISAM .  , I / O .  , 80 %  ,  ,  . 322 - 3.5 G ,  . innodb_buffer_pool_size = 6 G InnoDB .  ,  .  .  . InnoDB –  innodb_data_file_path = ibdata1 : 10 M : autoextend InnoDB . MySQLdatadir . innodb_data_home_dir = IOIO . Thisvalueis Unix4 , WindowsI / O . innodb_file_io_threads = 4 InnoDB ,  . 1 . innodb_force_recovery = 1 InnoDb .  ,  .  . innodb_thread_concurrency = 16 1 , InnoDB ( fsync )  , ACID .  ,  , 02I / O 0  . 2  ,  . innodb_flush_log_at_trx_commit = 2 （  ：  ， 2 ；  ， 1 ； 0 ，  ，  ！ 1 （ flush ）  ，  。   （ Batterybackedupcache ）  。 2 ， MyISAM ，   。 flush ， 1 - 2  。 0 ，  ， MySQL  。 2 。） InnoDB . InnoDB .  , InnoDB . innodb_fast_shutdown  .  , InnoDB .  ,  (  ) innodb_log_buffer_size = 16 M  . 25 %~ 100 %  .  ,  . innodb_log_file_size = 512 M  . 2 ~ 3  . innodb_log_files_in_group = 3 InnoDB . MySQLdatadir . RAID1 innodb_log_group_home_dir InnoDB .  , InnoDB .  ,  . innodb_max_dirty_pages_pct = 90 InnoDB .   “ fdatasync ” ,  “ O_DSYNC ” . innodb_flush_method = O_DSYNC  , InnoDB . InnoDB . LOCKTABLES , InnoDB InnoDB . timeout . innodb_lock_wait_timeout = 120 [ mysqldump ]  .  quick max_allowed_packet = 32 M [ mysql ] no - auto - rehash UPDATEsDELETEs . safe - updates [ isamchk ] key_buffer = 2048 M sort_buffer_size = 2048 M read_buffer = 32 M write_buffer = 32 M [ myisamchk ] key_buffer = 2048 M sort_buffer_size = 2048 M read_buffer = 32 M write_buffer = 32 M [ mysqlhotcopy ] interactive - timeout [ mysqld_safe ]  .  :  !  open - files - limit = 8192","title":"mysql2"},{"location":"mysql2/#_1","text":"delete from mysql . user where user = ;  set password = PASSWORD ( pass );  FLUSH PRIVILEGES ; create user sky ; select host , user , password from mysql . user ;  sky  drop user sky ; select host , user , password from mysql . user  sky  mysql ? create user  mysql create user sky identified by 123 ;  show grants for sky @ % ; USAGE  %  IP  mysql grant select on vfast . * to sky @ % ;  mysql revoke select on vfast . * from sky @ % lab ， IP ，，  revoke all privileges on * . * from rhce @ 192.168.18.234 ; drop user rhce @ 192.168.18.234 ;  192.168.18.234  mysql  VFAST （ select ） grant select on vfast . * to sky @ 192.168.18.234 identified by 123 ;  192.168.18.200  mysql  VFAST  select , insert , delete , update  grant select , insert , delete , update on vfast . * to sky @ 192.168.18.200 identified by 123 ; select host , password , user from user ;  192.168.18.234  mysql mysql - h 192.168.18.254 - u sky - p123 mysql use vfast ; mysql insert into H1 values ( 00 );    192.168.18.200  mysql mysql - h 192.168.18.254 - u sky - p123 mysql show databases ; mysql insert into H1 values ( 00 ); mysql delete from H1 where id = 00 ; mysql update H1 set id = 16 where id = 17 ;  ID = 17  16 mysql select * from H1 ;  mysql drop table H1 ;   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  GRANT ALL PRIVILEGES ON * . * TO kyo @ % identified by 123 ; flush privileges  ALL PRIVILEGES  * . *  kyo ， %  IP  ‘ 123 ’   select  ALL PRIVILEGES    　　 Alter 　　　　　　 　　 Create 　　　　  　　 Delete 　　　　  　　 Drop 　　 （） 　　 INDEX 　　　　  　　 Insert 　　　　  　　 REFERENCE 　　 　　 Select 　　　　  　　 Update 　　　　  　　 FILE 　　　　　　 　　 PROCESS 　　  　　 RELOAD 　　　　、。 　　 SHUTDOWN 　　  　　 ALL 　　　　　　； ALL PRIVILEGES  　　 USAGE 　　　　“”  mysql . user mysql . db mysql . tables_orive  revoke all privileges on * . * from kyo @ % ; show grants for kyo @ % ; USAGE    [ root @ convirt ~ ] # vim / etc / my . cnf skip - grant - tables #  mysql  mysql flush privileges ; mysql GRANT ALL PRIVILEGES ON * . * TO root @ localhost identified by ; password is null ## mysqld_safe -- skip - grant - tables （） -- skip - networking   update mysql . user set password = password ( 456 ) where user = “ kyo ” and host = “ localhost ” ; password ( 456 ) kyo @ localhost  456 password  456    show full processlist  ID   。，，。 kill $ ID  ID ","title":""},{"location":"mysql2/#explain","text":"explain  mysql  select 。。 ， select  explain ，： explain select * from statuses_status where id = 11 ; explain  table ： type ：，。 const 、 eq_reg 、 ref 、 range 、 indexhe  all possible_keys ：。，。 where  key ： 。 null ，。， mysql 。， select   use index （ indexname ） ignore index （ indexname ） mysql  key_len ：。， ref ：，， rows ： mysql  extra ： mysql 。 4 . 3 ， using temporary  using filesort ，  mysql ， extra  distinct : mysql ， not exists : mysql  left join ， left join ， range checked for each record （ index map :#）:，， mysql  ，。 using filesort : ，。 mysql 。  using index : ，  using temporary ，。， mysql ， order by ， group by  where used  where 。， all  index ， ，（） system ： system 。 const  const :（）。，， mysql   eq_ref :， mysql ，，，  ref :（，）。 ，。— range :，   index : （ all ，） all :，，","title":"explain"},{"location":"mysql2/#gtid","text":"MySQL 5.6  GTID ( Global Transaction IDs ) 、，。  MySQL 5.6 ， [ mysqld ] ： binlog - format ：， row 、 statement  mixed ； ： READ - COMMITED  ROW ， MySQL  STATEMENT  ； mixed ，； log - slave - updates 、 gtid - mode 、 enforce - gtid - consistency 、 report - port  report - host ： GTID ； master - info - repository  relay - log - info - repository ：，； sync - master - info ：； slave - paralles - workers ： SQL ； 0 ； binlog - checksum 、 master - verify - checksum  slave - sql - verify - checksum ：； binlog - rows - query - log - events ：，； log - bin ：，； server - id ： id ； report - host ： The host name or IP address of the slave to be reported to the master during slave registration . This value appears in the output of SHOW SLAVE HOSTS on the master server . report - port : The TCP / IP port number for connecting to the slave , to be reported to the master during slave registration . master - info - repository : The setting of this variable determines whether the slave logs master status and connection information to a FILE ( master . info ), or to a TABLE ( mysql . slave_master_info ) relay - log - info - repository ： This option causes the server to log its relay log info to a file or a table . log_slave_updates ： Whether updates received by a slave server from a master server should be logged to the slave s own binary log . Binary logging must be enabled on the slave for this variable to have any effect . enforce_gtid_consistency ： 、 1 、 1.1 、 master ： [ mysqld ] binlog - format = ROW log - bin = master - bin log - slave - updates = true gtid - mode = on enforce - gtid - consistency = true master - info - repository = TABLE relay - log - info - repository = TABLE sync - master - info = 1 slave - parallel - workers = 2 binlog - checksum = CRC32 master - verify - checksum = 1 slave - sql - verify - checksum = 1 binlog - rows - query - log_events = 1 server - id = 1 report - port = 3306 port = 3306 datadir =/ mydata / data socket =/ tmp / mysql . sock report - host = master . magedu . com 1.2 、 slave ： [ mysqld ] binlog - format = ROW log - slave - updates = true gtid - mode = on enforce - gtid - consistency = true master - info - repository = TABLE relay - log - info - repository = TABLE sync - master - info = 1 slave - parallel - workers = 2 binlog - checksum = CRC32 master - verify - checksum = 1 slave - sql - verify - checksum = 1 binlog - rows - query - log_events = 1 server - id = 11 report - port = 3306 port = 3306 log - bin = mysql - bin . log datadir =/ mydata / data socket =/ tmp / mysql . sock report - host = slave . magedu . com 2 、 mysql GRANT REPLICATION SLAVE ON * . * TO repluser @172.16.100.7 IDENTIFIED BY replpass ; ： 172.16.100.7 ；，； 3 、 ，，； GTID ， master  show master status  ， slave 。 4 、  GTID ，： mysql CHANGE MASTER TO MASTER_HOST = master . magedu . com , MASTER_USER = repluser , MASTER_PASSWORD = replpass , MASTER_AUTO_POSITION = 1 ;  GTID ，： slave CHANGE MASTER TO MASTER_HOST = 172.16.100.6 , - MASTER_USER = repluser , - MASTER_PASSWORD = replpass , - MASTER_LOG_FILE = master - bin .000003 , - MASTER_LOG_POS = 1174 ; 、 1 、 master INSTALL PLUGIN rpl_semi_sync_master SONAME semisync_master . so ; slave INSTALL PLUGIN rpl_semi_sync_slave SONAME semisync_slave . so ; 2 、  master ， rpl_semi_sync_master_enabled = ON  slave  rpl_semi_sync_slave_enabled = ON  mysql 。 ， mysql ： master SET GLOBAL rpl_semi_sync_master_enabled = ON ; slave SET GLOBAL rpl_semi_sync_slave_enabled = ON ; slave STOP SLAVE IO_THREAD ; START SLAVE IO_THREAD ; 3 、 master CREATE DATABASE magedudb ; master SHOW STATUS LIKE Rpl_semi_sync_master_yes_tx ; slave SHOW DATABASES ;","title":"gtid"},{"location":"mysql2/#xtrabackup","text":" Xtrabackup  MySQL ： 、 1 、 Xtrabackup  percona  mysql ，， innodb  xtradb  。： ( 1 ) 、； ( 2 ) ； ( 3 ) ； ( 4 ) ； ( 5 ) ； 2 、  http : // www . percona . com / software / percona - xtrabackup / 。 RHEL5 . 8 ，，  rpm ，。 wget https : // www . percona . com / downloads / XtraBackup / Percona - XtraBackup - 2 . 4 . 8 / binary / redhat / 6 / x86_64 / percona - xtrabackup - 24 - 2 . 4 . 8 - 1 . el6 . x86_64 . rpm yum install libev - y rpm - ivh percona - xtrabackup - 24 - 2 . 4 . 8 - 1 . el6 . x86_64 . rpm 、 1 、 # innobackupex -- user = DBUSER -- password = DBUSERPASS / path / to / BACKUP - DIR / ，： mysql CREATE USER ’ bkpuser ’@’ localhost ’ IDENTIFIED BY ’ s3cret ’ ; mysql REVOKE ALL PRIVILEGES , GRANT OPTION FROM ’ bkpuser ’ ; mysql GRANT RELOAD , LOCK TABLES , REPLICATION CLIENT ON * . * TO ’ bkpuser ’@’ localhost ’ ; mysql FLUSH PRIVILEGES ;  innobakupex ， xtrabackup  InnoDB ， ( . frm ) 、 MyISAM 、 MERGE 、 CSV  ARCHIVE ，。。 ， innobackupex ： ( 1 ) xtrabackup_checkpoints —— （）、（ prepared ） LSN (  ) ；  InnoDB  (  16 k  ) ， LSN 。 LSN ， LSN  。 ( 2 ) xtrabackup_binlog_info —— mysql 。 ( 3 ) xtrabackup_binlog_pos_innodb ——  InnoDB  XtraDB  position 。 ( 4 ) xtrabackup_binary ——  xtrabackup ； ( 5 ) backup - my . cnf —— ；  innobackupex ， -- no - timestamp ；， innobackupex  BACKUP - DIR 。 2 、 ( prepare )  ，，， 。，。“” 。 innobakupex  -- apply - log 。： # innobackupex -- apply - log / path / to / BACKUP - DIR ，： xtrabackup : starting shutdown with innodb_fast_shutdown = 1 120407 9 : 01 : 36 InnoDB : Starting shutdown ... 120407 9 : 01 : 40 InnoDB : Shutdown completed ; log sequence number 92036620 120407 09 : 01 : 40 innobackupex : completed OK ! “”， innobackupex  -- use - memory ， 100 M 。 ， prepare ，。 3 、 innobackupex  -- copy - back ， mysql  DATADIR  。 innobackupex  backup - my . cnf  DATADIR 。 # innobackupex -- copy - back / path / to / BACKUP - DIR ，： innobackupex : Starting to copy InnoDB log files innobackupex : in /backup/2012-04-07_08-17-03 innobackupex : back to original InnoDB log directory /mydata/data innobackupex : Finished copying back files . 120407 09 : 36 : 10 innobackupex : completed OK ! “ innobackupex : completed OK ! ”。  DATADIR ，， mysql ，， mysqld  。： # chown - R mysql : mysql / mydata / data / 4 、 innobackupex   InnoDB  LSN ，， LSN 。 InnoDB  ， innobackupex 。 ，： # innobackupex -- incremental / backup -- incremental - basedir = BASEDIR ， BASEDIR ，， innobackupex  / backup  。，， -- incremental - basedir 。 ， InnoDB  XtraDB ， MyISAM ，。 “” ( prepare ) ，： ( 1 )  (  ) ，“”。“”，。 ( 2 ) “”。 ，： # innobackupex -- apply - log -- redo - only BASE - DIR ： # innobackupex -- apply - log -- redo - only BASE - DIR -- incremental - dir = INCREMENTAL - DIR - 1 ： # innobackupex -- apply - log -- redo - only BASE - DIR -- incremental - dir = INCREMENTAL - DIR - 2  BASE - DIR ， INCREMENTAL - DIR - 1 ， INCREMENTAL - DIR - 2  ，，，； 5 、 Xtrabackup “”“” Xtrabackup “”， STDOUT  tar ， 。， -- stream 。： # innobackupex -- stream = tar / backup | gzip / backup / ` date +% F_ % H -% M -% S `. tar . gz ： # innobackupex -- stream = tar / backup | ssh user @ www . magedu . com cat - /backups/`date +%F_%H-%M-%S`.tar ，， -- parallel 。。， ， innodb_file_per_table  innodb_data_file_path   ibdata 。。： # innobackupex -- parallel / path / to / backup ， innobackupex ， -- remote - host ： # innobackupex -- remote - host = root @ www . magedu . com / path / IN / REMOTE / HOST / to / backup 6 、 ， InnoDB  mysql ， innodb_file_per_table 。  Xtrabackup ，，“” mysql  innodb_file_per_table （， “”， mysql  innodb_file_per_table ），“” innodb_file_per_table  innodb_expand_import 。 ( 1 ) “”  prepare ，，， prepare  -- export ： # innobackupex -- apply - log -- export / path / to / backup  innodb . exp ，. exp 。 ( 2 ) “”  mysql  innodb ，，： mysql CREATE TABLE mytable ( ... ) ENGINE = InnoDB ; ： mysql ALTER TABLE mydatabase . mytable DISCARD TABLESPACE ; ，“” mytable  mytable . ibd  mytable . exp ，“”： mysql ALTER TABLE mydatabase . mytable IMPORT TABLESPACE ; 7 、 Xtrabackup  Xtrabackup ，。， innodb_file_per_table ，。， -- stream ， 。 ，， prepared  -- copy - back  ，。，， -- copy - back ， ，，。 ( 1 )  ： ( -- include ) ,  ( -- tables - file )  ( -- databases ) 。 ( a )  -- include  -- include ，， databasename . tablename ，： # innobackupex -- include = ^mageedu[.]tb1 / path / to / backup ( b )  -- tables - file ，；： # echo - e mageedu.tb1 \\n mageedu.tb2 / tmp / tables . txt # innobackupex -- tables - file =/ tmp / tables . txt / path / to / backup ( c )  -- databases ，，；，，。， ，。： # innobackupex -- databases = mageedu testdb / path / to / backup ( 2 )  ( preparing )  prepare ， -- export ： # innobackupex -- apply - log -- export / pat / to / partial / backup ， innobackupex  xtrabackup ，，“”。 ，. exp 。 ( 3 )  。， prepared ， 。","title":"xtrabackup"},{"location":"mysql2/#myisam-innodb","text":"MyISAM  InnoDB ：  MyISAM 。，。 . frm 。  . MYD ( MYData ) ， . MYI ( MYIndex ) 。  InnoDB ， InnoDB ， 2 GB  : MyISAM ， InnoDB ， InnoDB ， SELECT UPDATE , INSERT ， Delete   SELECT ， MyISAM  1 .  INSERT  UPDATE ，， InnoDB  2 . DELETE FROM table ， InnoDB ，。 3 . LOAD TABLE FROM MASTER  InnoDB ， InnoDB  MyISAM ， InnoDB ，  InnoDB （）","title":"MyISAM InnoDB"},{"location":"mysql2/#mysql","text":" CPU 。 ，： cat / proc / cpuinfo ， CPU ： #cat /proc/cpuinfo processor : 5 model name : Intel ( R ) Xeon ( R ) CPU E5 - 2620 0 @2.00 GHz ... cpu MHz : 1200.000  Intel E5 - 2620  CPU ， 2.00 G * 24  CPU ，， 5  CPU  1.2 G 。 ？  CPU ：。 CPU ，，， CPU 。 ， MySQL ，。  MySQL  CPU ， CPU 。 BIOS ，， BIOS  ，。 BIOS ， CPU ，。 、 ，。 i )  numa  ( NUMA ： Non - Uniform Memory Access ) 。 ( SMP ： Symmetric Multi - Processor ) 。： ， NUMA 。： SMP ； NUMA ，  。，，。 ： -- interleave = nodes -- membind = nodes -- cpunodebind = nodes -- physcpubind = cpus -- localalloc -- preferred = node ，，， CPU 。  -- interleave = nodes ，  NUMA 。 NUMA  ， Linux ，  SWAP 。 DBA  SWAP  。 ，。 ，： BIOS ，，。 a )  BIOS ， NUMA ，。 b ) ， / etc / grub . conf  kernel  numa = off ，： kernel / vmlinuz - 2.6.32 - 220. el6 . x86_64 ro root =/ dev / mapper / VolGroup - root rd_NO_LUKS LANG = en_US . UTF - 8 rd_LVM_LV = VolGroup / root rd_NO_MD quiet SYSFONT = latarcyrheb - sun16 rhgb crashkernel = auto rd_LVM_LV = VolGroup / swap rhgb crashkernel = auto quiet KEYBOARDTYPE = pc KEYTABLE = us rd_NO_DM numa = off  vm . zone_reclaim_mode = 0 。 c )  MySQL ， NUMA ： numactl -- interleave = all mysqld ， BIOS 。 ii )  vm . swappiness 。 vm . swappiness 。， 0 ， 100 ， 60 。 vm . swappiness  0  swap ， 100  inactive 。 ：， inactive ， cache 。 cache ，， ； inactive ， ，“”。  vmstat  inactive ： #vmstat -an 1 procs ----------- memory ---------- --- swap -- ----- io ---- -- system -- ----- cpu ----- r b swpd free inact active si so bi bo in cs us sy id wa st 1 0 0 27522384 326928 1704644 0 0 0 153 11 10 0 0 100 0 0 0 0 0 27523300 326936 1704164 0 0 0 74 784 590 0 0 100 0 0 0 0 0 27523656 326936 1704692 0 0 8 8 439 1686 0 0 100 0 0 0 0 0 27524300 326916 1703412 0 0 4 52 198 262 0 0 100 0 0  / proc / meminfo ： #cat /proc/meminfo | grep -i inact Inactive : 326972 kB Inactive ( anon ) : 248 kB Inactive ( file ) : 326724 kB  inactive 。 Linux ，： free ， active  inactive 。， Linux Kernel  LRU ， LRU_INACTIVE_ANON , LRU_ACTIVE_ANON , LRU_INACTIVE_FILE , LRU_ACTIVE_FILE , LRU_UNEVICTABLE 。 LRU_INACTIVE_ANON , LRU_ACTIVE_ANON ， LRU_INACTIVE_FILE , LRU_ACTIVE_FILE  page caches 。， active  inactive ，  inactive   swap 。 ， MySQL ， InnoDB ，，， Linux ，   CPU  IO 。 InnoDB ， cache ， InnoDB 。 ， MySQL  vm . swappiness = 0 。  sysctl . conf ： echo vm.swappiness = 0 / etc / sysctl . conf  sysctl - p 。 、 ， i )  mount  noatime ， nobarrier 。  noatime mount ，， access time 。， Linux  ， change time , modify time  access time 。  stat ： stat libnids - 1.16 . tar . gz File : ` libnids - 1.16 . tar . gz Size : 72309 Blocks : 152 IO Block : 4096 regular file Device : 302 h / 770 d Inode : 4113144 Links : 1 Access : ( 0644 /- rw - r -- r -- ) Uid : ( 0 / root ) Gid : ( 0 / root ) Access : 2008 - 05 - 27 15 : 13 : 03.000000000 + 0800 Modify : 2004 - 03 - 10 12 : 25 : 09.000000000 + 0800 Change : 2008 - 05 - 27 14 : 18 : 18.000000000 + 0800  access time ， modify time ， change time  inode  ( 、、 ) 。，， 。 ， noatime ， access time ，。  cache ，， write barriers 。，  RAID ， RAID ； Flash ， ，。  nobarrier 。：  ext3 , ext4  reiserfs  mount  barrier = 0 ； xfs  nobarrier 。 ii )  IO ， deadline 。  Flash ，，，  IO ( IOPS ) ， ， IO ， Linux  IO  ，。 Linux  IO ： Deadline scheduler ， Anticipatory scheduler ， Completely Fair Queuing ( CFQ ) ， NOOP 。 ， CFQ  Deadline ， CFQ  Linux   2.6.18 ， IO ，。， 3  IO ， 10000  IO ，， 3  IO  10000  IO ， IO ，。，  IO  ， IO “”。 deadline ，  。 ， echo deadline / sys / block / sda / queue / scheduler  sda  deadline 。  / etc / grub . conf  kernel  elevator = deadline 。  CPU ：  ： vm . swappiness = 0  numa ：  noatime ， nobarrier  IO  deadline 。 ： http : //os.51cto.com/art/201407/446750.htm","title":"MySQL"},{"location":"mysql2/#mycat","text":"http://www.mycat.org.cn/ https://github.com/MyCATApache/Mycat-download  ： 1.conf/server.xml mycat，mycatmysql，mycat。 ?xml version= 1.0 encoding= UTF-8 ? !DOCTYPE mycat:server SYSTEM server.dtd mycat:server xmlns:mycat= http://org.opencloudb/ system !-- property name= processors 32 /property property name= processorExecutor 32 /property property name= serverPort 8066 /property property name= managerPort 9066 /property -- /system user name= root property name= password root /property property name= schemas  /property /user /mycat:server 2.conf/schema.xml ，schematable，sql，mycat。 ?xml version= 1.0 ? !DOCTYPE mycat:schema SYSTEM schema.dtd mycat:schema xmlns:mycat= http://org.opencloudb/ schema name=  checkSQLschema= false dataNode= dn1 /schema dataNode name= dn1 dataHost= localhost1 database=  / dataHost name= localhost1 maxCon= 1000 minCon= 100 balance= 1 dbType= mysql dbDriver= native heartbeat select user() /heartbeat !-- can have multi write hosts -- writeHost host= 10.1.3.50 url= 10.1.3.50:3306 user=  password=  !-- can have multi read hosts -- readHost host= 10.1.3.5 url= 10.1.3.5:3306 user=  password=  / readHost host= 10.1.3.6 url= 10.1.3.6:3306 user=  password=  / /writeHost !--writeHost host= 10.1.3.34 url= 10.1.3.34:3306 user=  password=  -- !-- can have multi read hosts -- !--readHost host= 10.1.3.7 url= 10.1.3.7:3306 user=  password=  /-- !--readHost host= 10.1.3.8 url= 10.1.3.8:3306 user=  password=  /-- !--/writeHost-- /dataHost /mycat:schema  MyCAT： • SQL，，select/*balance*/ • select， • ，，，，，MYCAT select。 • ，，select， ，。 dataHostbalance： • 0， • 1，readHoststand by writeHostselect，，(M1- S1，M2- S2，M1 M2 )，，M2,S1,S2select。 • 2，readHostwriteHostselect，，，。 dataHost，，DBA。writeHost Master DB Server，readHostSlave DB Server。dataHostwriteHost， writeHost，Mycat ，writeHost。 MyCAT，，： • ，。 • （）， • ， ，，（），Mycat（）， MyCAT，。","title":"mycat"},{"location":"mysql2/#sql","text":"yum install mysql mysql - server - y  （ / var / lib / mysql ）。 / etc / init . d / mysqld start  UPDATE tablename SET  = REPLACE ( , HTML , .YOUKU ) ;  create database vfast ; drop database vfast ; use vfast ; show databases ; flush tables with read lock ;  unlock tables ;  show tables ; create table rhce ( id int ) ; alter table rhce rename cbd ;  alter table cbd add sex enum ( Y , N ) ;  sex alter table cbd drop id ;  id alter table cbd modify name char ( 16 ) ; namechar（16） or alter table vfast_user change name name enum ( B , G ) ; alter table cbd change name mingzi char ( 26 ) ;　namemingzi char(26) show warnings \\ G ; mysql show create table cbd ; cbd desc cbd ; cbd drop table cbd ;   char   varchar （， CPU ， CPU ）  int  ， - 2147493648  2147493647 bigint  ， - 9223372036854775808  9223372036854775807 float （） 。 - 3 . 402823466 E + 38  - 1 . 175494351 E - 38 date  time  datetime  blob  text  enum  set  timestamp  select * from xt701 ; insert into xt701 ( name , ID , yuwen ) values ( lin , 1007 , 99 ) ; or insert into xt701 values ( zhang , 1001 , 80 , 70 , 90 ) , ( li , 1002 , 90 , 98 , 19 ) , ( zhao , 1003 , 68 , 67 , 90 ) ; select name , id from xt701 where shuxue = 80 ; ：！！ update xt701 set shuxue = 80 where id = 1007 and shuxue is NULL ;  update 3 m_recording_meeting m set m . play_url = REPLACE ( m . play_url , 127.0.0.1 , saas.3mang.com ) where m . play_url like %127.0.0.1% truncate  （）  delete delete  delete from xt701 ; truncate xt701 ; delete from xt701 where yingyu = 80 ; select * from T1 where YUWEN between 70 and 90 ;  awk - F : {print $1 , $3 , $4 , $NF} / etc / passwd / tmp / user create table H2 ( NAME char ( 15 ) , PASSWORD char ( 50 ) , UID int ( 5 ) , GID int ( 5 ) , MIAOSHU varchar ( 100 ) , HOME varchar ( 100 ) , SHELL varchar ( 100 )) ; load data infile /etc/passwd into table H2 fields terminated by : ; mysql  sum  max  min  avg  count ","title":"sql"},{"location":"mysql2/#_2","text":"mysql  Atlas ， cobar ， TDDL ， mycat ， heisenberg , Oceanus , vitess , OneProxy ： http : // songwie . com / articlelist / 44 mysql - proxy  mysql ，， failover ，。  mysql ， Atlas ， cobar ， tddl ，。 Atlas Atlas  Qihoo 360 , Web  MySQL 。 mysql - proxy 0 . 8 . 2 ， ，。 360  Atlas  mysql ，。 Altas ： Atlas  MySQL ， MySQL ，， MySQL 。  DB ， MySQL ，。 ， LVS ， Altas  HA ,。 Altas ： 1 . ， Atlas ，，。， Atlas ，。  mysql  proxy ，。 2 .，， DB ，。  1 。  1 3 . （ 1 ）， Altas  SQL  /*master*/  。 （ 2 ） 2 ，，，，。  2 4 .（ 3 ） （ 1 ）。 （ 2 ） SELECT 、 INSERT 、 UPDATE 、 DELETE 、 REPLACE 。 （ 3 ）。  3  Atlas ，， DB  database ， Atlas 。 5 . lua ，， Atlas  C ， QPS ， latency 。 6 . （ 1 ） pwds  Atlas 。 （ 2 ） client - ips  Atlas  ip 。 （ 3 ） Altas  SQL ， IP 、 DB 、、 ，（ 4 ）。  4 7 .  lvs - ips ， Altas  SQL 。 lvs  ip ，  ip 。 Atlas  lvs 。 source ： https : // github . com / Qihoo360 / Atlas alibaba . cobar Cobar （ B2B ）， 。， cobar -- ？： 1 .，，。 2 .，。 3 . failover 。 4 .，，。  cobar ， cobar  proxy ， mysq l 。 SQL ，，。 Cobar  ： ： 1 . Cobar  test ， t1 , t2 。 3  MySQL  ( ip : port ) ，： A , B , C 。 2 . t1  A ， t2  B  C 。 t2  HA ， B  C  ，。 cabar ： 1 .： （ 1 ） Cobar  （ 2 ） Cobar  （ 3 ） ， ！： Cobar ， test  test_1 , test_2 , test_3 .....， 。 2 .。 3 .。 4 . failover , HA ： ( 1 ) Cobar ，， Cobar 。， ，，，， Cobar ，。 ( 2 ) Cobar  MySQL ，， Cobar  MySQL 。 cobar ：  mysql ，。 source ： http : // code . alibabatech . com / wiki / display / cobar / Home TDDL  TDDL （ Taobao Distributed Data Layer : © _Ob ）， ， jdbc datasource ，，，。 TDDL （ tddl ， jar ， SQL ）： ， ， DBRoute 。 DBRoute  、，。， ，，，， 2 、 4 、 8 、 16 、 32 …… 1024 、 2048 。，，，？，，， ，（）， TDDL 。  DAL （） 。 ： ： 1 . 2 . 3 . 4 . 5 . jboss  6 . mysql  oracle  7 . jdbc ， jdbc  8 . server , client - jar ， 9 .,， 10 .,， TDDL  diamond （ diamond ，，  diamond ， diamond ）。 TDDL ： http : // rdc . taobao . com / team / jm / archives / 1645 diamond ： http : // jm . taobao . org / tag / diamond % E4 % B8 % 93 % E9 % A2 % 98 / TDDL ： https : // github . com / alibaba / tb_tddl TDDL 。，，， diamond ，。 ，。，。 MyCAT http : // www . org . cn / https : // github . com / myCATApache  MyCAT ?， MyCAT ： ，“” 、 ACID 、 Mysql  ? “ Mysql ”， Oracle  ? 、 Nosql 、 HDFS  SQL Server ?  ? 。  “”，。  1 .  SQL 92   Mysql ， Proxy   JDBC  ORACLE 、 DB2 、 SQL Server ， MySQL Server   galera for mysql ， percona - cluster  mariadb cluster ，，， 。 2 . 。 3 .  Mysql ， 。 4 . 。 5 . ， 。 6 .  join ， E - R ，，。   Cobar ， Cobar 、、， MyCAT  ，，。， MyCAT ， MyCAT ，。 MyCAT ， 5 、、 DBA ， MyCAT 。 MyCAT ， ，，，。   Mysql ，， PosteSQL 、 FireBird ， JDBC  Oracle 、 DB2 、 SQL Server ， SQL ， ，， HDFS ， SQL ，  HDFS ，。 heisenberg  mysql , ： ，  db     Mysql   ， mysqlclient , c , java  Heisenberg ，，，，   velocity ， qq ： 150720285 : brucest0078 @ gmail . com https : // github . com / songwie / heisenberg ，  db     Mysql  ， mysqlclient , c , java  Heisenberg ，，，， Oceanus : Oceanus 、、、、，。， ，，，，。 Oceanus  datanode ：。，、 namenode ：。，、、 table ：。 sql  table ， table  name ， bean ：。， tracker ：。 IO ，，，   Oceanus  Oceanus ，，，。  ，， Oceanus ， HA 、、、 。 ， table ， Oceanus  sql 、 、 sql 。 ： select * from user ； ： select * from user0 ; select * from user1; select * from user2 ; select * from user3;  (  ) ，： github  “，”  Oceanus ， mybatis  hibernate ，， Oceanus  ，  DataSource  ConnectionProvider 。 ORM ， Oceanus  。   Oceanus ，， Cache 、 ID 、 ，，，。 vitess : ， ZooKeeper ， RPC ，， server ， command line ， gui  3 。 https : // github . com / youtube / vitess OneProxy OneProxy ，（@）。 MySQL - Proxy 0 . 8 . 4 ，，。 ，、。 OneProxy ： 1 .  2 .  3 . Proxy 【】 4 .  5 . （ master ） 6 . （ master ） 7 .  8 .  9 . SQL  10 . SQL 【】 11 . 【】 12 . 【】  http : // www . cnblogs . com / youge - OneSQL / articles / 4208583 . html  Server Group  OneProxy ， MySQL  Server Group 。. A ， Server Group A  Server Group B 。 A . A  OneProxy ， Server Group 。，。 A ） Server Group A  table X , table Y , table Z ， table X ， I / O ，  tableY , tableZ 。 B . B  1 . 0 ： table X ， Server Group B （ C ）， OneProxy  table X ，。 C . C B ） 1 . 0 ， I / O 。， Server Group B ， 。  2 . 0 :  Server Group B  table X ， X_00 , X_01  Server Group B ， X_02 ， X_03  Server Group C ， D  D","title":""},{"location":"mysql2/#atlas_keepalived","text":"  DB  360  Atlas ，， 2 。，， （ amoeba 、 cobar 、 MaxScale 、 MySQL - Proxy ），。  Atlas ，： ( 1 ) 、 mysql - proxy - 0.8.2 ，； ( 2 ) 、，； ( 3 ) 、 DB ； ( 4 ) 、 DB ， DB ； ( 5 ) 、 DB ； ( 6 ) 、（ IP 、）； ( 7 ) 、、、。 ， 360 Atlas ，。 Atlas ，， ： https : //github.com/Qihoo360/Atlas/blob/master/README_ZH.md 2 、 wKioL1Sw6iagbaHjAAJX6OZk - GM940 . jpg 3 、 CentOS 6.3 x86_64  ( 1 ) 、 glib ， yum ； ( 2 ) 、 LUA ， 5.1 . x ； ( 3 ) 、 glib ， glib - 2.32 . x ； ( 4 ) 、，。 yum install glib glib - devel ncurses readline lua libevent libevent - devel openssl openssl - devel - y https : //github.com/Qihoo360/Atlas/wiki/  https : //github.com/Qihoo360/Atlas/releases RPM，： sudo rpm – i Atlas - XX . el6 . x86_64 . rpm 。 Atlas （ test . cnf ）。 Atlas ，。 Atlas  / usr / local / mysql - proxy ，  conf ， test . cnf ，，。 1. ： [ mysql - proxy ] ( ， )  admin - username = user ( ， )  admin - password = pwd ( ， )  IP  proxy - backend - addresses = 192.168.0.12 : 3306 ( ， )  IP ， @ ，， 1 ，，。 ，。 proxy - read - only - backend - addresses = 192.168.0.13 : 3306 , 192.168.0.14 : 3306 ( ， )  MySQL ， PREFIX / bin  encrypt ， 。（）。 myuser ， mypwd ，  . / encrypt mypwd  HJBoxfRsjeI = 。。： pwds = myuser : HJBoxfRsjeI = , myuser2 : HJBoxfRsjeI = （， ) Atlas ， true ， false ， false ，  true daemon = true ( ， )  Atlas ， true  Atlas ， monitor ， worker ， monitor  worker  ， false  worker ， monitor ， false ， true keepalive = true ( ， ) ， CPU  2  4  event - threads = 4 ( ， ) ， message 、 warning 、 critical 、 error 、 debug  log - level = message ( ， )  log - path = / usr / local / mysql - proxy / log ( ， ) SQL ， OFF 、 ON 、 REALTIME ， OFF  SQL ， ON  SQL ， ，，。 REALTIME ， SQL ， OFF sql - log = OFF ( ，）。， sql - log - slow （： ms ) 。 。 sql - log - slow = 10 ( ，）。， Atlas  wait - timeout 。： wait - timeout = 10 ( ， ) Atlas  IP  proxy - address = 0.0.0.0 : 1234 ( ， ) Atlas  IP  admin - address = 0.0.0.0 : 2345 ( ， ) ， person ， mt ， id ， 3 ，，， ，， _ ， [ 0 ,  - 1 ] ，， mt_0 、 mt_1 、 mt_2 tables = person . mt . id .3 ( ， ) ，， latin1 charset = utf8 ( ， )  Atlas  IP ， IP ， IP ，， IP ，  IP  client - ips = 127.0.0.1 , 192.168.1 ( ， ) Atlas  LVS  IP (  IP ) ， LVS  client - ips ， lvs - ips = 192.168.1.1 2.  ，。 ( 1 )  event - threads ， CPU ，， CPU 。 ( 2 )  ( 2. x ， 1. x  ) min - idle - connections ，，， ，《》。 Atlas 2. X ，。 Atlas 1. X ， 。 3.  ，，。 ( 1 ) Atlas  proxy - address ， proxy - address = 0.0.0.0 : 1234  1234  Atlas  SQL 。 ( 2 ) Atlas  admin - address ， admin - address = 0.0.0.0 : 2345  DBA  2345  Atlas 。 ( 3 )  admin - username  admin - password ， Atlas ， MySQL ， ， MySQL 。 ( 4 )   log - level ， message 、 warning 、 critical 、 error 、 debug  ( 5 )   log - path ， log - path = / usr / local / mysql - proxy / log 。  / usr / local / mysql - proxy / bin ，、 Atlas 。 ( 1 ). sudo . / mysql - proxyd test start ， Atlas 。 ( 2 ). sudo . / mysql - proxyd test restart ， Atlas 。 ( 3 ). sudo . / mysql - proxyd test stop ， Atlas 。 ： ( 1 ). ： mysql - proxyd (  mysql - proxy ) 。 ( 2 ). test  conf ， instance ，。 ( 3 ).  ps - ef | grep mysql - proxy  Atlas 。 ： mysql - h127 .0.0.1 - P1234 - u  - p ， Atlas ， SQL  。  Atlas ： mysql - h127 .0.0.1 - P2345 - uuser - ppwd ， : select * from help ;  DB 。 Atlas 【 Keepalived 】 ( 1 ) 、 # vim /etc/keepalived/keepalived.conf global_defs { notification_email { lovezym5 @126. com } notification_email_from lovezym5 @126. com smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id dbproxy1 } vrrp_script chk_mysql_proxy_health { script /data/scripts/keepalived_check_mysql_proxy.sh interval 1 weight - 2 } vrrp_instance VI_1 { state MASTER interface eth1 virtual_router_id 51 priority 100 advert_int 1 smtp_alert authentication { auth_type PASS auth_pass 123456 } virtual_ipaddress { 10.209.6.115 } track_script { chk_mysql_proxy_health } notify_master /data/scripts/notify.sh master notify_bakcup /data/scripts/notify.sh backup notify_fault /data/scripts/notify.sh fault } ( 2 ) 、 # vim /etc/keepalived/keepalived.conf global_defs { notification_email { lovezym5 @126. com } notification_email_from lovezym5 @126. com smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id dbproxy2 } vrrp_script chk_mysql_proxy_health { script /data/scripts/keepalived_check_mysql_proxy.sh interval 1 weight - 2 } vrrp_instance VI_1 { state BACKUP interface eth1 virtual_router_id 51 priority 90 advert_int 1 smtp_alert authentication { auth_type PASS auth_pass 123456 } virtual_ipaddress { 10.209.6.115 } track_script { chk_mysql_proxy_health } notify_master /data/scripts/notify.sh master notify_bakcup /data/scripts/notify.sh backup notify_fault /data/scripts/notify.sh fault } ( 3 ) 、 VIP  # vim /data/scripts/notify.sh #!/bin/sh PATH =/ sbin : / bin : / usr / sbin : / usr / bin : / usr / local / bin : / usr / local / sbin KEEPALIVE_CONF = /etc/keepalived/keepalived.conf VIP = ` grep - A 1 virtual_ipaddress $ { KEEPALIVE_CONF } | tail - 1 | sed s / \\ t //g; s/ //g ` ETH1_ADDR = ` / sbin / ifconfig eth1 | awk / inet addr : / { print $ 2 } | awk - F : { print $ 2 } ` MONITOR = /usr/local/oms/agent/alarm/BusMonitorAgent TOKEN = ha_monitor function notify () { TITLE = $ETH1_ADDR to be $1: $VIP floating CONTENT = vrrp transition, $ETH1_ADDR changed to be $1 $ { MONITOR } - c 2 - f $ { TOKEN } - t ${TITLE} - i ${CONTENT} } case $1 in master ) notify master exit 0 ;; backup ) notify backup exit 0 ;; fault ) notify fault exit 0 ;; * ) echo Usage : ` basename $ 0 ` { master | backup | fault } exit 1 ;; esac ( 4 ) 、 DB  # vim /data/scripts/keepalived_check_mysql_proxy.sh #!/bin/sh PATH =/ sbin : / bin : / usr / sbin : / usr / bin : / usr / local / bin : / usr / local / sbin if [[ ` pgrep mysql - proxy | wc - l ` - eq 0 ]]; then / sbin / service mysql - proxy start sleep 5 [[ - z ` pgrep mysql - proxy ` ]] / sbin / service keepalived stop fi # chmod +x /data/scripts/*.sh # service keepalived start wKioL1Sw72OBWcdcAABQovflyow736 . jpg # ip addr show eth1 wKiom1Sw7r3S6v6_AACfXZvxonQ064 . jpg # ps aux | grep keepalive[d] wKiom1Sw7tnzsSOAAABqz91YIVo562 . jpg ========================================================================================== 、 ========================================================================================== 1 、 Atlas  # vim /usr/local/mysql-proxy/bin/check_service.sh #!/bin/sh PATH =/ sbin : / bin : / usr / sbin : / usr / bin : / usr / local / bin : / usr / local / sbin [[ $# - ne 3 ]] echo $0    exit 1 SRV_PORT = $ 1 ##  SRV_PROT = $ 2 ##  SRV_NAME = $ 3 ##  MONITOR = /usr/local/oms/agent/alarm/BusMonitorAgent TOKEN = ha_monitor TITLE = ${SRV_NAME} CONTENT = ${SRV_NAME}，！ ##  SCAN_FLAG = 0 function RESTART_SRV_AND_ALERT () { local CUR_SRV_NAME [[ $# - ne 1 ]] exit 1 CUR_SRV_NAME = $ 1 TMP_SRV_NAME = ` echo $ { CUR_SRV_NAME } | tr [ A - Z ] [ a - z ] ` [[ ! - f / etc / init . d / $ { TMP_SRV_NAME } ]] TMP_SRV_NAME = ${TMP_SRV_NAME}d killall - 9 $ { TMP_SRV_NAME } if [[ - z ` ps aux | grep $ { TMP_SRV_NAME } | grep - v grep ` ]]; then / sbin / service $ { TMP_SRV_NAME } start / dev / null 2 1 fi $ { MONITOR } - c 2 - f $ { TOKEN } - t ${TITLE} - i ${CONTENT} rm - f ` pwd ` / connect_error . log } ETH1_ADDR = ` / sbin / ifconfig eth1 | awk - F : / inet addr / { print $ 2 } | sed s / [ a - zA - Z ] //g ` TMP_SRV_PROT = ` echo $ { SRV_PROT } | tr [ A - Z ] [ a - z ] ` if [[ ${TMP_SRV_PROT} == tcp ]]; then PROT_OPT = S elif [[ ${TMP_SRV_PROT} == udp ]]; then PROT_OPT = U else echo ！ exit 1 fi ## 3，， for (( i = 0 ; i 3 ; i ++ )); do RETVAL = ` / usr / bin / nmap - n - s $ { PROT_OPT } - p $ { SRV_PORT } $ { ETH1_ADDR } | grep open ` [[ - n ${RETVAL} ]] SCAN_FLAG = 1 ; break || sleep 10 done ## 1、Atlas， [[ $ { SCAN_FLAG } - ne 1 ]] RESTART_SRV_AND_ALERT $ { SRV_NAME } ## 2、Atlas，，【DB】 mysqladmin - h $ { ETH1_ADDR } - uhealth_check1 - p123456 -- connect - timeout = 15 -- shutdown - timeout = 15 ping [[ $ ? - ne 0 ]] RESTART_SRV_AND_ALERT $ { SRV_NAME } ## 3、Atlas，，DB， ## DB【DB】 mysqladmin - h $ { ETH1_ADDR } - uhealth_check2 - p123456 -- connect - timeout = 15 -- shutdown - timeout = 15 ping [[ $ ? - ne 0 ]] RESTART_SRV_AND_ALERT $ { SRV_NAME } 2 、 Atlas  # vim /data/scripts/cut_and_clear_access_log.sh #!/bin/sh # Atlas，15 # PATH =/ sbin : / bin : / usr / sbin : / usr / bin : / usr / local / bin : / usr / local / sbin ## mysql-proxy LOGPATH = /usr/local/mysql-proxy/log [[ ` / sbin / ip addr show eth1 | grep inet | wc - l ` - eq 2 ]] || exit 1 cd $ { LOGPATH } ##  HISTORY_LOG_PATH = ` date - d - 1 hour + %Y-%m-%d/sql_mysql-proxy_%H.log ` [[ - d ` dirname $ { HISTORY_LOG_PATH } ` ]] || mkdir - p ` dirname $ { HISTORY_LOG_PATH } ` cp - a sql_mysql - proxy . log $ { HISTORY_LOG_PATH } echo sql_mysql - proxy . log ##  HISTORY_LOG_PATH = ` date - d 15 days ago + % Y -% m -% d ` [[ - d $ { HISTORY_LOG_PATH } ]] rm - rf $ { HISTORY_LOG_PATH } 3 、 crontab  # touch /var/lock/check_service.lock # echo touch /var/lock/check_service.lock /etc/rc.d/rc.local # crontab -uroot -e 1 2 * * * * * ( flock -- timeout = 0 / var / lock / check_service . lock / usr / local / mysql - proxy / bin / check_service . sh 3306 tcp mysql - proxy / dev / null 2 1 ) 00 * * * * / data / scripts / cut_and_clear_access_log . sh / dev / null 2 1 4 、 # mysql -h10.209.6.101 -P3307 -usysadmin -p admin2356!@() wKioL1Sw8S_gXZOuAALgQK7R39c195 . jpg","title":"atlas_keepalived"},{"location":"mysql2/#mycnf","text":"MySQL 。 MySQL 。 MySQL 。 MySQL 。 [ client ] password =[ your_password ] port = @MYSQL_TCP_PORT @ socket = @MYSQL_UNIX_ADDR @ ***  *** MySQL [ mysqld ]  port = @MYSQL_TCP_PORT @ socket = @MYSQL_UNIX_ADDR @ skip - name - resolve DNS ，  。  ， MySQLip back_log , MySQL .  ” connectionrefused ”  ,  .  . back_log ,  back_log = 300 TCP / IP . mysqld ,  mysqldUnixsockets . windows (  “ enable - named - pipe ”  ) mysql ! skip - networking MySQL SUPER .  . max_connections = 3000  ,  . MySQL ” FLUSHHOSTS ”   .  “ Aborted_connects ”  . max_connect_errors = 30  . mysqld  [ mysqld_safe ]  “ open - files - limit ” 4096 table_cache = 4096  .   (  ! ) MyISAM external - locking  ( BLOB )  .  max_allowed_packet = 32 M binlogSQLcache  ,  ,  . binlogbinlog  ,  .  binlog_cache_size = 4 M  .  . max_heap_table_size = 128 M ORDERBYGROUPBY  ,   “ Sort_merge_passes ”  .  sort_buffer_size = 16 M  ( fullJOINs ).  ,  .  “ Select_full_join ”   ,  join_buffer_size = 16 M cache  , cachethread_cache_size , cache .  (  ,  .) thread_cache_size = 16  . thread_concurrency ()  ( SunSolaris ).  [ CPU ]* ( 2..4 ) thread_concurrency thread_concurrency = 8 SELECT .  ,  .  “ Qcache_lowmem_prunes ”  .  :  ,  . query_cache_size = 128 M   ,  . query_cache_limit = 4 M  .  ,  .  , FULLTEXT ft_min_word_len = 8 memlock ()  , mysql ,  swappingout  memlock  ,  ,  default_table_type = MYISAM  .  . MySQL64K UDF  ,  . thread_stack = 512 K  .  : READ - UNCOMMITTED , READ - COMMITTED , REPEATABLE - READ , SERIALIZABLE transaction_isolation = REPEATABLE - READ  (  )   ,  .  ,  . tmp_table_size = 128 M  .  ( replication )  , MASTER  ,  . log - bin = mysql - bin  ( A - B - C ), B .  ,  . log_slave_updates  .  (  )  .  ,  . log log . MySQL log ,  . log_warnings  .  “ long_query_time ”  . log_long_format ,  .  .  , log_slow_queries  (  )  .  ” 1 ″ ,  ,  ( MySQL ). long_query_time = 6  .  .  log_long_format MySQL .  ,  ,  .  .  , swapfs / tmpfs  .  ” ; ”  roud - robin . tmpdir =/ tmp ***   , 12 ^ 32 - 1  . masterslave .  “ master - host ”  , 1 ,  , MySQLmaster . server - id = 1 Slave ( master ) slave ,  : 1 ) CHANGEMASTERTO (  ) -  : CHANGEMASTERTOMASTER_HOST = , MASTER_PORT = , MASTER_USER = , MASTER_PASSWORD = ;  ,, master ( 3306 ).  : CHANGEMASTERTOMASTER_HOST = ’ 125.564.12.1 ′ , MASTER_PORT = 3306 , MASTER_USER = ’ joe ’ , MASTER_PASSWORD = ’ secret ’ ;  2 )  .  ,  ,  (  , master - passwordslave ), slavemaster . info ,  master . info , slave , master . infoslave .  ,  (  ) CHANGEMASTERTO (  )  id22 ^ 32 – 1  ( master ) master - host . 2  ,  server - id = 2 master –  master - host = masterslave –  master - user = masterslave –  master - password = master .  – 3306 master - port = slave . SUPERslave . slavemaster read_only *** MyISAM  , MyISAM . 30 % , OS MyISAM , 8 - 64 M . key_buffer_size = 128 M MyISAM .  ,  . read_buffer_size = 8 M  ,  ,  .  , ORDERBY .  read_rnd_buffer_size = 64 M MyISAMcache (  , INSERT … SELECT , INSERT … VALUES ( … ),( … ), … , LOADDATA INFILE )  .  . 0 .  “ key_buffer_size ” .  . bulk_insert_buffer_size = 256 M MySQLREPAIR , OPTIMIZE , ALTERLOADDATAINFILE .  .  . myisam_sort_buffer_size = 256 M MySQL ( REPAIR , ALTERTABLELOADDATAINFILE ).  ,  (  ) myisam_max_sort_file_size = 10 G  ,  .  . myisam_max_extra_sort_file_size = 10 G  , MyISAM . CPU ,  . myisam_repair_threads = 1 MyISAM . myisam_recover Federated skip - federated *** BDB *** MySQLBDB .  . skip - bdb *** INNODB *** MySQLInnoDB ,  ,  skip - innodb InnoDBmetadata InnoDB , OS .  ,  . SHOWINNODBSTATUS . innodb_additional_mem_pool_size = 64 M InnoDB , MyISAM .  , I / O .  , 80 %  ,  ,  . 322 - 3.5 G ,  . innodb_buffer_pool_size = 6 G InnoDB .  ,  .  .  . InnoDB –  innodb_data_file_path = ibdata1 : 10 M : autoextend InnoDB . MySQLdatadir . innodb_data_home_dir = IOIO . Thisvalueis Unix4 , WindowsI / O . innodb_file_io_threads = 4 InnoDB ,  . 1 . innodb_force_recovery = 1 InnoDb .  ,  .  . innodb_thread_concurrency = 16 1 , InnoDB ( fsync )  , ACID .  ,  , 02I / O 0  . 2  ,  . innodb_flush_log_at_trx_commit = 2 （  ：  ， 2 ；  ， 1 ； 0 ，  ，  ！ 1 （ flush ）  ，  。   （ Batterybackedupcache ）  。 2 ， MyISAM ，   。 flush ， 1 - 2  。 0 ，  ， MySQL  。 2 。） InnoDB . InnoDB .  , InnoDB . innodb_fast_shutdown  .  , InnoDB .  ,  (  ) innodb_log_buffer_size = 16 M  . 25 %~ 100 %  .  ,  . innodb_log_file_size = 512 M  . 2 ~ 3  . innodb_log_files_in_group = 3 InnoDB . MySQLdatadir . RAID1 innodb_log_group_home_dir InnoDB .  , InnoDB .  ,  . innodb_max_dirty_pages_pct = 90 InnoDB .   “ fdatasync ” ,  “ O_DSYNC ” . innodb_flush_method = O_DSYNC  , InnoDB . InnoDB . LOCKTABLES , InnoDB InnoDB . timeout . innodb_lock_wait_timeout = 120 [ mysqldump ]  .  quick max_allowed_packet = 32 M [ mysql ] no - auto - rehash UPDATEsDELETEs . safe - updates [ isamchk ] key_buffer = 2048 M sort_buffer_size = 2048 M read_buffer = 32 M write_buffer = 32 M [ myisamchk ] key_buffer = 2048 M sort_buffer_size = 2048 M read_buffer = 32 M write_buffer = 32 M [ mysqlhotcopy ] interactive - timeout [ mysqld_safe ]  .  :  !  open - files - limit = 8192","title":"my.cnf"},{"location":"netdata/","text":"netdata linux，，  https://my-netdata.io/ https://github.com/firehol/netdata rpm https://copr.fedorainfracloud.org/coprs/mosquito/netdata/ rpm -ivh https://copr-be.cloud.fedoraproject.org/results/mosquito/netdata/epel-7-x86_64/ systemctl start netdata.service open http://127.0.0.1:19999","title":"netdata"},{"location":"netdata/#netdata","text":"linux，，  https://my-netdata.io/ https://github.com/firehol/netdata rpm https://copr.fedorainfracloud.org/coprs/mosquito/netdata/ rpm -ivh https://copr-be.cloud.fedoraproject.org/results/mosquito/netdata/epel-7-x86_64/ systemctl start netdata.service open http://127.0.0.1:19999","title":"netdata"},{"location":"nginx/","text":"map map $ uri $ match { ~^/ common / file / dachui / (. * ) / dachui / ; } $ match  / dachui / $ uri nginx   $ uri  / common / file / dachui / 20170427160407 . jpg  $ 1  20170427160407 . jpg $ match $ 1  dachui / 20170427160407 . jpg ，$ 1  http : // www . ttlsa . com / nginx / using - nginx - map - method / session hash if ( $ http_cookie ~* JSESSIONID=(.*?); ) # ( . * ? ) ;(.*) { set $ wap_cookie $1 ; } upstream pool1 { hash $c ookie_jsessionid ; tomcatphpsession（cookie） server server1 : 80 ; server server2 : 80 ; server server3 : 80 ; hash_again 2 ;  } hash_again = 1 ， server2  server1 ， server3 。。  hash_again = 2 ， nginx  hash ，。  hash_again ，。 nginx rewrite $a rg_PARAMETER # GET ， PARAMETER   gRead . do ? imgurl =/ dachui / 20170427160407 . jpg $a rgs  imgurl =/ dachui / 20170427160407 . jpg $a rg_imgurl  / dachui / 20170427160407 . jpg $a rgs ,  ; $d ocument_root ,  ; $ host ,  Host ， Host ， ; $ limit_rate ,  ; $ request_method , ， GET 、 POST  ; $ remote_addr ,  ; $ remote_port ,  ; $ remote_user , ， ; $ request_filename ,  $ query_string ,  $a rgs  ; $ scheme , ， http  https $ server_protocol , ， HTTP/1.0  HTTP/1.1 ; $ server_addr , ， listen ，  (  ) ; $ server_name ,  ; $d ocument_uri $ uri ， URI  ; $ server_port ,  ; nginx rewrite ： 1 . server  rewrite  (  server {}， xx  ) 2 . location  3 . location  rewrite   URI ， 1 - 3 ，  10 ， 500 Internal Server Error  if ( $ hosts ~* ^ www . hah ) { set $ who who.html ; set ， rewrite ^/ ( . * ) $ http : // $ host / $1$2 / permanent ; } last  Apache [ L ]， rewrite break ，， redirect  302 ， URL  permanent  301 ， URL  rewrite ^/ test . php / new permanent ; // rewrite ^/ test . php / new ? permanent ; // rewrite ^/ test . php / new ? id = $a rg_id ? permanent ; // location / search { if ( $a rgs ~* ei= ) { rewrite ^/ / search ? newwindow = 1 q = $a rg_q start = $a rg_start ? permanent ; } proxy_pass https : // ipv6 . google . com / search ; proxy_hide_header Set-Cookie ; proxy_hide_header Cache-Control ; proxy_ignore_headers Expires Cache-Control Set-Cookie ; expires 30 d ; }  nginx . conf  rewrite  rewrite ^/ http : // staticwww . dachuizichan . com $ uri permanent ; add_header Access - Control - Allow - Origin * ; if ( $ request_method = OPTIONS ) { add_header Access - Control - Allow - Origin * ; add_header Access - Control - Allow - Credentials true ; add_header Access - Control - Allow - Methods GET, POST, OPTIONS ; add_header Access-Control-Allow-Headers Access-Control-Allow-Origin, x-requested-with, content-type ; return 200 ; } user nginx ; worker_processes 1 ; events { worker_connections 1024 ; } http { include mime . types ; default_type application / octet - stream ; log_format main $remote_addr - $remote_user [$time_local] $request $status $body_bytes_sent $http_referer $http_user_agent $http_x_forwarded_for ; # access_log logs / access . log main ; sendfile on ; keepalive_timeout 65 ; gzip on ; gzip_min_length 1 k ; gzip_buffers 4 16 k ; gzip_http_version 1 . 0 ; gzip_comp_level 2 ; 1-10，， gzip_types text / plain application / x - javascript text / css application / xml text / javascript application / x - httpd - php image / jpeg image / gif image / png ; gzip_vary off ; Squid，onHeader Vary: Accept-Encoding proxy_temp_path / tmp / temp_dir ; # proxy_cache_path / tmp / cache levels = 1 : 2 keys_zone = cache_one : 200 m inactive = 1 d max_size = 30 g ; server { listen 81 ; server_name localhost ; rewrite ^/ http : // $ host : 8081 / 3 m / index . do last ; } server { listen 8081 ; server_name localhost ; root / usr / local / tomcat / webapps ; location ~ ( \\. jsp | \\. do | imageServlet ) $ { proxy_pass http : // 127 . 0 . 0 . 1 : 8080 ; proxy_redirect off ; proxy_set_header Host $ host ; proxy_set_header X - Real - IP $ remote_addr ; proxy_set_header X - Forwarded - For $ proxy_add_x_forwarded_for ; client_max_body_size 10 m ; # client_body_buffer_size 128 k ; # proxy_connect_timeout 90 ; #nginx() proxy_read_timeout 90 ; #，() proxy_buffer_size 4 k ; #（nginx） proxy_buffers 6 32 k ; #proxy_buffers，32k， proxy_busy_buffers_size 64 k ;#（proxy_buffers*2） proxy_temp_file_write_size 64 k ; #，，upstream } location ~ . * \\. ( html | js | css | gif | jpg | png | bmp | swf | ico | txt ) ?$ { proxy_cache cache_one ; # ，keys_zone。 proxy_cache_valid 200 302 1 h ; expires 1 d ; root / usr / local / nginx / aaa / ;  } error_page 404 / 404 . html ; error_page 500 502 503 504 / 50 x . html ; location = / 50 x . html { root html ; } } } locationrewrite location / manage / { proxy_pass http : //dachui_servers/DaChui/manage/; uri sub_filter dachui_servers : 80 / DaChui / wwwtest . dachuizichan . com / ;  url #sub_filter http: //dachui_servers:80/DaChui/ http://wwwtest.dachuizichan.com/ ; sub_filter http : //dachui_servers/DaChui/ http://wwwtest.dachuizichan.com/ ; sub_filter_once off ; }  location  URI  proxy_pass ， nginx  location = / { #  / ， [ configuration A ] } location / { #  / ，#  [ configuration B ] } location / documents / { #  /documents/ ，，# ， [ configuration C ] } location ~ / documents / Abc { #  /documents/ ，，# ， [ configuration CC ] } location ^~ / images / { #  /images/ ，，，。 [ configuration D ] } location ~* \\ .( gif | jpg | jpeg ) $ { #  gif,jpgjpeg # ， /images/  config D ， ^~  [ configuration E ] } location / images / { #  /images/，， ^~  [ configuration F ] } location / images / abc { #  /images/abc，， ^~ # FG [ configuration G ] } location ~ / images / abc / { #  config D ： config G ，，， [ configuration H ] } location ~* / js / . */\\ . js  =   A ，。 ^~  uri ， ~  ; ~*  /  ,  ,   no ： ( location = ) ( location  ) ( location ^~  ) ( location ~ , ~*  ) ( location  ) ( / )   location ，： / - config A ， / index . html  / downloads / download . html - config B  B ，， B / images / 1. gif - configuration D  F ， D ， / images / abc / def - config D  G ， D ，   / images /  D ， FG ， H ， / documents / document . html - config C  C ，， C / documents / 1. jpg - configuration E  C ， E / documents / Abc . jpg - config CC  C ， CC ， E  ，，： #，，，。#， #  location = / { proxy_pass http : //tomcat:8080/index } # ，nginxhttp# ，, location ^~ / static / { root / webroot / static / ; } location ~* \\ .( gif | jpg | jpeg | png | css | js | ico ) $ { root / webroot / res / ; } #，#，# ， . php ,. jsp  location / { proxy_pass http : //tomcat:8080/ } http : //tengine.taobao.org/book/chapter_02.html http : //nginx.org/en/docs/http/ngx_http_rewrite_module.html Rewrite  rewrite ， nginx ， url 。 rewrite  server {}, location {}, if {} ，，  http : //seanlook.com/a/we/index.php?id=1 u=str /a/we/index.php。rewrite regex replacement [flag]; ，， proxy_pass 。  rewrite  location ，， rewrite ， location  ， proxy_pass 。 rewrite  location ，：  server  rewrite   location   location  rewrite   URI ， 1 - 3 ，； 10 ， 500 Internal Server Error 。 flag  last :  Apache  [ L ] ， rewrite break :  rewrite  redirect :  302 ， permanent :  301 ，  301  302 ， URL ， return  301 , 302 。 last  break ： last  server  if ， break  location  last  url ， url  server ， break  break  last  rewrite  if  if   if ( condition ){...} ， condition 。， rewrite ， if  ( conditon )  ： ， 0  false ， =  != ~ ， ~* ， !~  - f  !- f  - d  !- d  - e  !- e  - x  !- x  ： if ( $ http_user_agent ~ MSIE ) { rewrite ^ (. * ) $ / msie / $ 1 break ; } //UA MSIE ，rewrite/msid/ if ( $ http_cookie ~* id=([^;]+)(?:;|$) ) { set $ id $ 1 ; } //cookie，$id if ( $ request_method = POST ) { return 405 ; } //POST，405（Method not allowed）。return301,302if ($slow) { limit_rate 10 k ; } //，$slow set  if ( !- f $ request_filename ){ break ; proxy_pass http : //127.0.0.1; } //，localhost 。breakrewrite if ( $ args ~ post = 140 ){ rewrite ^ http : //example.com/ permanent; } //query string post=140 ，example.com location ~* \\ .( gif | jpg | png | swf | flv ) $ { valid_referers none blocked www . jefflei . com www . leizhenfang . com ; if ( $ invalid_referer ) { return 404 ; } // }   if  $ args ： #，$ query_string $ content_length ：  Content - length 。 $ content_type ：  Content - Type 。 $ document_root ：  root 。 $ host ： ，。 $ http_user_agent ：  agent  $ http_cookie ：  cookie  $ limit_rate ： 。 $ request_method ： ， GET  POST 。 $ remote_addr ：  IP 。 $ remote_port ： 。 $ remote_user ：  Auth Basic Module 。 $ request_filename ： ， root  alias  URI 。 $ scheme ： HTTP （ http ， https ）。 $ server_protocol ： ， HTTP / 1.0  HTTP / 1.1 。 $ server_addr ： ，。 $ server_name ： 。 $ server_port ： 。 $ request_uri ：  URI ，，：” / foo / bar . php ? arg = baz ”。 $ uri ：  URI ，$ uri ，” / foo / bar . html ”。 $ document_uri ： $ uri 。 ： http : //localhost:88/test1/test2/test.php $ host ： localhost $ server_port ： 88 $ request_uri ： http : //localhost:88/test1/test2/test.php $ document_uri ： / test1 / test2 / test . php $ document_root ： / var / www / html $ request_filename ： / var / www / html / test1 / test2 / test . php  . ：  ? ：  0  1  + ：  1  * ：  0  \\ d ： ^ ：  $ ：  { n } ：  n  { n ,} ：  n  [ c ] ：  c [ a - z ] ：  a - z   () ，$ 1 ，$ 2  () 。\\。 rewrite   1 ： rewrite ^ http : //staticwww.dachuizichan.com$request_uri? permanent;  http { # imagelog_format imagelog [$time_local] $image_file $image_type $body_bytes_sent $ status ; # rewrite_log on; server { root / home / www ; location / { # error_log logs/rewrite.log notice; # ‘’，{}rewrite ^/images/([a-z]{2})/([a-z0-9]{5})/(.*)\\.(png|jpg|gif)$ / data ? file = $ 3. $ 4 ; # “last”，setset $image_file $3; set $ image_type $ 4 ; } location / data { # ，access_log logs/images.log mian; root / data / images ; # 。，，urltry_files / $ arg_file / image404 . html ; } location = / image404 . html { # return 404 image not found\\n ; } }  / images / ef / uh7b3 / test . png ， / data ? file = test . png ， location / data ， / data / images / test . png ，， tryfiles  image404 location ， 404 。  2 ： rewrite ^/ images / (. * ) _ ( \\ d + ) x ( \\ d + ) \\ .( png | jpg | gif ) $ / resizer / $ 1. $ 4 ? width = $ 2 height = $ 3 ? last ;  / images / bla_500x400 . jpg ， / resizer / bla . jpg ? width = 500 height = 400 ， location 。 ，$ 1  () ，$ 2 ，。 nginx ：  http : // example . com / test . php ? para = xxx  http : // example . com / new ： rewrite ^/ test . php ( . * ) / new permanent ; ： http : // example . com / new ? para = xxx ： rewrite ^/ test . php ( . * ) / new ? permanent ; ： http : // example . com / new ，“？”。，？ Nginx  $a rg_PARAMETER 。 ：  http : // example . com / test . php ? para = xxx p = xx  http : // example . com / new ? p = xx ： rewrite ^/ test . php / new ? p = $a rg_p ? permanent ; rewrite ^/ test . php / new permanent ; // rewrite ^/ test . php / new ? permanent ; // rewrite ^/ test . php / new ? id = $a rg_id ? permanent ; // permanent ，，。 if ( $a rgs ) {  rewrite rewrite ^/ ( . * ) / $1 ? permanent ;  } cdn http {  http  # for pre - open closed test map $ http_x_forwarded_for $a llowed { default deny ; ~ \\ s * 111 . 222 . 333 . 444 $ allow ; ~ \\ s * 123 . 456 . 789 . * $ allow ; } } location / { if ( $a llowed = deny ) { return 403 ; } alias / path / to / document_root } =========================================== nginx http_realip_module  location = / getRealip . php { set_real_ip_from 192 . 168 . 50 . 0 / 24 ; set_real_ip_from 61 . 22 . 22 . 22 ; set_real_ip_from 121 . 207 . 33 . 33 ; set_real_ip_from 127 . 0 . 0 . 1 ; real_ip_header X - Forwarded - For ; real_ip_recursive on ; fastcgi_pass unix : / var / run / phpfpm . sock ; fastcgi_index index . php ; include fastcgi . conf ; } set_real_ip_from ： IP  IP , real_ip_header ： header  IP  real_ip_recursive ： IP , ip  set_real_ip_from  IP , ip  IP ，  IP  IP 。， IP ： 120 . 22 . 11 . 11 , 61 . 22 . 22 . 22 , 121 . 207 . 33 . 33 , 192 . 168 . 50 . 121  real_ip_recursive on  61 . 22 . 22 . 22 , 121 . 207 . 33 . 33 , 192 . 168 . 50 . 121  set_real_ip_from , 120 . 22 . 11 . 11 , ip ，  remote_addr   real_ip_recursive off  192 . 168 . 50 . 121  set_real_ip_from ,， ip  ip  ： set_real_ip_from 192 . 168 . 50 . 0 / 24 ; set_real_ip_from 127 . 0 . 0 . 1 ; real_ip_header X - Forwarded - For ; real_ip_recursive on ; ： 121 . 207 . 33 . 33  realip  ：， remote_addr  IP  ： ip ， CDN  ip  ip   set_real_ip_from 0 . 0 . 0 . 0 / 0 ;   http { … … client_max_body_size 300 m ; #， Content - Length 。 （） client_body_buffer_size 128 k ; #，： 8 k / 16 k 。  128 k ， Nginx 。，。 client_body_temp_path / dev / shm / client_body_temp ; #。 proxy_connect_timeout 600 ; #， proxy_read_timeout 600 ; #： proxy_read_timeout 60 。， nginx  。 established  ，。  proxy_connect_timeout ， ，，  。， nginx 。 proxy_send_timeout 600 ; #，， ， nginx 。 proxy_buffer_size 16 k ; #： proxy_buffer_size 4 k / 8 k 。， 。 proxy_buffers 4 32 k ; #（）， Nginx  Buffer ， proxy_busy_buffers_size 64 k ; # proxy_buffers ， * 2 proxy_temp_file_write_size 64 k ; # proxy_temp_path ， 。 proxy_temp_path / dev / shm / proxy_temp ; # http  client_body_temp_path ， 。 upstream server_pool { server 192 . 168 . 0 . 88 : 80 weight = 4 max_fails = 2 fail_timeout = 30 s ; server 192 . 168 . 0 . 89 : 80 weight = 2 max_fails = 2 fail_timeout = 30 s ; } # HTTP 。 upstream ， proxy_pass  fastcgi_pass ，，  TCP  Unix socket 。 ， 1 。 location / { proxy_pass http : // server_pool / ; # URL ， socket 。 proxy_redirect off ; # Location  Refresh ， 。 proxy_set_header X - Real - IP $ remote_addr ; #。  ，。 proxy_set_header X - Forwarded - For $ proxy_add_x_forwarded_for ; proxy_set_header Host $ host ; proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504 http_404 ; #： # error - ，，。 # timeout - ，。 # invalid_header - 。 # http_500 -  500 。 # http_502 -  502 。 # http_503 -  503 。 # http_504 -  504 。 # http_404 -  404 。 # off - 。 } Nginx  upstream  5  1 　（） ， down ， 。 2 　 weight ， weight ，。 ： upstream bakend { server 192 . 168 . 0 . 88 weight = 10 ; server 192 . 168 . 0 . 89 weight = 10 ; } 3 　 ip_hash  ip  hash ，，  session 。 ： upstream bakend { ip_hash ;  hash $ http_x_forwarded_for ; cdn server 192 . 168 . 0 . 88 : 80 ; server 192 . 168 . 0 . 89 : 80 ; } 4 　 fair （） ，。 ： upstream bakend { server 192 . 168 . 0 . 88 : 80 ; server 192 . 168 . 0 . 89 : 80 ; fair ; } 5 　 url_hash （）  url  hash ， url ， 。 ： upstream backend { server 192 . 168 . 0 . 88 : 3128 ; server 192 . 168 . 0 . 89 : 3128 ; hash $ request_uri ;  hash $ http_x_forwarded_for ; cdn # hash_method crc32 ; }  : 1 . down  server  2 . weight  1 . weight ，。 3 . max_fails ： 1 . ， proxy_next_upstream  4 . fail_timeout : max_fails ，。 5 . backup ：  backup  down ， backup 。 。 Nginx ， server 。 proxy_pass sub_filter www_servers:80/DaChui/ www.xxx.com/ ; sub_filter http://www_servers:80/DaChui/ http://www.xxx.com/ ; sub_filter http://www_servers/DaChui/ http://www.xxx.com/ ; sub_filter_once off ;  nginx  proxy_pass ， proxy_pass  url  / ，； / ，， 。  80   proxy_set_header Host $ host :$ server_port upstream falcon { server 172 . 31 . 20 . 205 : 8010 ; } location / { proxy_pass http : // falcon / ; proxy_set_header Host $ host :$ server_port ; proxy_set_header X - Real - IP $ remote_addr ; proxy_set_header X - Forwarded - For $ proxy_add_x_forwarded_for ; }  http : // 192 . 168 . 1 . 1 / proxy / test . html 。 ： location / proxy / { proxy_pass http : // 127 . 0 . 0 . 1 / ; }  URL ： http : // 127 . 0 . 0 . 1 / test . html （， / ） location / proxy / { proxy_pass http : // 127 . 0 . 0 . 1 ; }  URL ： http : // 127 . 0 . 0 . 1 / proxy / test . html ： location / proxy / { proxy_pass http : // 127 . 0 . 0 . 1 / aaa / ; }  URL ： http : // 127 . 0 . 0 . 1 / aaa / test . html （， / ） location / proxy / { proxy_pass http : // 127 . 0 . 0 . 1 / aaa ; }  URL ： http : // 127 . 0 . 0 . 1 / aaatest . html  / etc / nginx / conf . d / default . conf location / logio { proxy_pass http : // 192.168.1.2 : 28778 / ; auth_basic secret ; auth_basic_user_file /etc/nginx/passwd.db ; }  : auth_basic string | off ;  : auth_basic off ;  : http , server , location , limit_except ，，。  : auth_basic_user_file file ;  : —  : http , server , location , limit_except htpasswd -c / etc / nginx / passwd . db admin  chmod 400 / etc / nginx / passwd . db chown nginx . nginx / etc / nginx / passwd . db / etc / init . d / nginx reload rootalias location / img / { alias / var / www / image / ; } # ， / img / ， ningx  / var / www / image /  location / img / { root / var / www / image ; } # ， / img / ， nginx  / var / www / image / img /  alias ， root 。  alias “ / ”，  root  nginx  nginx . conf  http {}  # ip limit limit_conn_zone $ binary_remote_addr zone = perip : 10m ; limit_conn_zone $ server_name zone = perserver : 10m ;  location  location / { limit_conn perip 2 ; limit_conn perserver 20 ; limit_rate 100k ; } ： $ binary_remote_addr  ip ； $ server_name  server ； limit_conn ； limit_rate ； nginx 1 . 1 . 8  limit_conn_zone $ binary_remote_addr zone = NAME : 10m ; NAME  zone  http :// nginx . org / en / docs / http / ngx_http_limit_conn_module . html  : ，， http ： zone= ，， limit_conn  $ binary_remote_addr = ， 1m  32000  ...  N  http { limit_conn_zone $binary_remote_addr zone= addr : 10 m ; server（location），IP1， server { listen 80 ; server_name 192.168.11.128 ; index index.html index.htm index.php ; limit_conn addr 1 ; #IP1 （addr  limit_conn_zone ） limit_rate 100k ; # 100KB/ root html ; ： limit_rate 100k ; //100k。，IP！IP， IPlimit_rate * 2  nginx  api ， golang http 。。  “” ，，。 ， Golang http api  3 . 5 W ,  QPS ， go http api ，  nginx ， nginx  1 . 5 w 。  “”  nginx 。 ，，。  nginx  。 ，。 ，， ，， scp ， location ，。 ，， tmux  screen ， top  nginx  go api  cpu ， load ， run ， cpu ，。 dstat 。 ss + netstat 。  ， ab ，，，， ， ， python django ， webbench , ab , boom  http 。 ，。,  fd ， 。 ， 65535 - 1024 ， 1024  。  65535 - 1024 ， 64511 ， nginx ， nginx  golang http api 。 。  6 w ，， ，，。  nginx 。 ，， nginx worker ， backlog ， nginx worker 。 nginx  worker num * worker_connections ,  worker_connections  1024 ,  10 w 。 ，，。  lsof ， nginx  。  http1 . 1 ， tcpdump ， http1 . 0 ，  sysctl  tcp ， tcp 。  upstream  keepalive 。 COMMAND PID USER FD TYPE DEVICE SIZE / OFF NODE NAME python 538 ruifengyun 9 u IPv4 595559383 0 t0 TCP 58 . 215 . 141 . 194 : 46665 - 58 . 215 . 141 . 83 : 9001 ( ESTABLISHED ) test_dic4 7476 ruifengyun 5 u IPv6 660251515 0 t0 TCP * : 9001 ( LISTEN ) test_dic4 7476 ruifengyun 10 u IPv6 660870187 0 t0 TCP localhost : 9001 - localhost : 46679 ( ESTABLISHED ) test_dic4 7476 ruifengyun 13 u IPv6 660870138 0 t0 TCP localhost : 9001 - localhost : 46608 ( ESTABLISHED ) test_dic4 7476 ruifengyun 14 u IPv6 660870137 0 t0 TCP localhost : 9001 - localhost : 46607 ( ESTABLISHED ) test_dic4 7476 ruifengyun 22 u IPv6 660870153 0 t0 TCP localhost : 9001 - localhost : 46632 ( ESTABLISHED ) test_dic4 7476 ruifengyun 23 u IPv6 660870143 0 t0 TCP localhost : 9001 - localhost : 46618 ( ESTABLISHED ) test_dic4 7476 ruifengyun 27 u IPv6 660870166 0 t0 TCP localhost : 9001 - localhost : 46654 ( ESTABLISHED ) test_dic4 7476 ruifengyun 73 u IPv6 660870191 0 t0 TCP localhost : 9001 - localhost : 46685 ( ESTABLISHED ) test_dic4 7476 ruifengyun 85 u IPv6 660870154 0 t0 TCP localhost : 9001 - localhost : 46633 ( ESTABLISHED ) test_dic4 7476 ruifengyun 87 u IPv6 660870147 0 t0 TCP localhost : 9001 - localhost : 46625 ( ESTABLISHED ) .... 。， nginx worker ， ， nginx  keepalive 。 Activates cache of connections to upstream servers The connections parameter sets the maximum number of idle keepalive connections to upstream servers that are retained in the cache per one worker process . When this number is exceeded , the least recently used connections are closed Python # xiaorui . cc upstream http_backend { server 127 . 0 . 0 . 1 : 8080 ; keepalive 256 ; } server { ... location / http / { proxy_pass http : // http_backend ; proxy_http_version 1 . 1 ; proxy_set_header Connection ; ... } } ，，，，。 ，。  nginx error log 。  Nginx  keepalive ，，。 Python 2016 / 06 / 24 16 : 34 : 12 [ error ] 15419 #0 : * 9421660 connect () failed ( 111 : Connection refused ) while connecting to upstream , client : 10 . 1 . 1 . 58 , server : , request : GET / HTTP/1.0 , upstream : http://127.0.0.1:9001/ , host : 10.1.1.63 2016 / 06 / 24 16 : 34 : 12 [ error ] 15418 #0 : * 9423639 connect () failed ( 111 : Connection refused ) while connecting to upstream , client : 10 . 1 . 1 . 58 , server : , request : GET / HTTP/1.0 , upstream : http://127.0.0.1:9004/ , host : 10.1.1.63 2016 / 06 / 24 16 : 34 : 12 [ error ] 15418 #0 : * 9423639 no live upstreams while connecting to upstream , client : 10 . 1 . 1 . 58 , server : , request : GET / HTTP/1.0 , upstream : http://test_servers/ , host : 10.1.1.63 2016 / 06 / 24 16 : 34 : 12 [ error ] 15418 #0 : * 9393899 connect () failed ( 111 : Connection refused ) while connecting to upstream , client : 10 . 1 . 1 . 58 , server : , request : GET / HTTP/1.0 , upstream : http://127.0.0.1:9004/ , host : 10.1.1.63 2016 / 06 / 24 16 : 58 : 13 [ notice ] 26449 #26449 : signal process started 2016 / 06 / 24 16 : 58 : 13 [ emerg ] 27280 #0 : unknown directive keepalive in / etc / nginx / conf . d / test_multi . conf : 7 2016 / 06 / 24 17 : 02 : 18 [ notice ] 3141 #3141 : signal process started 2016 / 06 / 24 17 : 02 : 18 [ emerg ] 27280 #0 : unknown directive keepalive in / etc / nginx / conf . d / test_multi . conf : 7 2016 / 06 / 24 17 : 02 : 44 [ notice ] 4079 #4079 : signal process started 2016 / 06 / 24 17 : 02 : 44 [ emerg ] 27280 #0 : unknown directive keepalive in / etc / nginx / conf . d / test_multi . conf : 7  nginx upstream keepalive ?  Nginx  ( HTTP1 . 0 ) ，， Nginx ，。  http 1 . 1 ， Nginx ， keepalive ， Nginx  ，，。  nginx upstream keepalive .  connection pool ，，。 ， ， keepalive connection pool ， ，，，， socket  connect () 。， TCP  slow start 。 keepalive  。  nginx ， redis ， mysqldb ， 。 pop ， push ， O ( 1 ) 。  128 ，，，  nginx ， 1 . 8 ，，，， keepalive timeout 。 Golang  http  http spdy ，  tengine upstream spdy  Server 。  keepalive ，。 nginx_rtmp hls docker  https : // github . com / brocaar / nginx - rtmp - dockerfile ffmpeg ， ubuntu  apt   http : // johnvansickle . com / ffmpeg / wget http : // johnvansickle . com / ffmpeg / builds / ffmpeg - git - 64 bit - static . tar . xz  rpmforce  mkdir / data mkdir / static yum install ffmpeg wget pcre - devel zlib - devel openssl - devel wget http : // nginx . org / download / nginx - 1 . 6 . 2 . tar . gz tar zxf nginx - 1 . 6 . 2 . tar . gz wget https : // github . com / arut / nginx - rtmp - module / archive / v1 . 1 . 6 . tar . gz tar zxf v1 . 1 . 6 . tar . gz cd nginx - 1 . 6 . 2 . / configure -- add - module = .. / nginx - rtmp - module - 1 . 1 . 6 -- prefix =/ usr / local / nginx make make install nginx  daemon off ; events { worker_connections 1024 ; } rtmp { server { listen 1935 ; chunk_size 4000 ; application encoder { live on ; exec ffmpeg - i rtmp : // localhost : 1935 / encoder / $ name - c : a libfdk_aac - b : a 128 k - c : v libx264 - b : v 2500 k - f flv - g 30 - r 30 - s 1280 x720 - preset superfast - profile : v baseline rtmp : // localhost : 1935 / hls / $ name_720p2628kbs - c : a libfdk_aac - b : a 128 k - c : v libx264 - b : v 1000 k - f flv - g 30 - r 30 - s 854 x480 - preset superfast - profile : v baseline rtmp : // localhost : 1935 / hls / $ name_480p1128kbs - c : a libfdk_aac - b : a 128 k - c : v libx264 - b : v 750 k - f flv - g 30 - r 30 - s 640 x360 - preset superfast - profile : v baseline rtmp : // localhost : 1935 / hls / $ name_360p878kbs - c : a libfdk_aac - b : a 128 k - c : v libx264 - b : v 400 k - f flv - g 30 - r 30 - s 426 x240 - preset superfast - profile : v baseline rtmp : // localhost : 1935 / hls / $ name_240p528kbs - c : a libfdk_aac - b : a 64 k - c : v libx264 - b : v 200 k - f flv - g 15 - r 15 - s 426 x240 - preset superfast - profile : v baseline rtmp : // localhost : 1935 / hls / $ name_240p264kbs ; } application hls { live on ; hls on ; hls_fragment_naming system ; hls_fragment 5 s ; hls_path / data / hls ; hls_nested on ; hls_variant _720p2628kbs BANDWIDTH = 2628000 , RESOLUTION = 1280 x720 ; hls_variant _480p1128kbs BANDWIDTH = 1128000 , RESOLUTION = 854 x480 ; hls_variant _360p878kbs BANDWIDTH = 878000 , RESOLUTION = 640 x360 ; hls_variant _240p528kbs BANDWIDTH = 528000 , RESOLUTION = 426 x240 ; hls_variant _240p264kbs BANDWIDTH = 264000 , RESOLUTION = 426 x240 ; } } } http { server { listen 80 ; location / hls { types { application / vnd . apple . mpegurl m3u8 ; video / mp2t ts ; } root / data ; add_header Cache - Control no - cache ; add_header Access - Control - Allow - Origin * ; } location / stat { rtmp_stat all ; rtmp_stat_stylesheet static / stat . xsl ; } location / static { alias / static ; } location / crossdomain . xml { default_type text / xml ; return 200 ?xml version= 1.0 ? ! DOCTYPE cross - domain - policy SYSTEM http://www.adobe.com/xml/dtds/cross-domain-policy.dtd cross - domain - policy site - control permitted - cross - domain - policies = all / allow - access - from domain = * secure = false / allow - http - request - headers - from domain = * headers = * secure = false / / cross - domain - policy ; expires 24 h ; } } } ------------------------------ cat / static / stat . xsl ? xml version = 1.0 encoding = utf-8 ? !-- Copyright ( C ) Roman Arutyunyan -- xsl : stylesheet version = 1.0 xmlns : xsl = http://www.w3.org/1999/XSL/Transform xsl : template match = / html head title RTMP statistics / title / head body xsl : apply - templates select = rtmp / hr / Generated by a href = https://github.com/arut/nginx-rtmp-module nginx - rtmp - module / a #160 ; xsl:value-of select= /rtmp/nginx_rtmp_version / , a href = http://nginx.org nginx / a #160 ; xsl:value-of select= /rtmp/nginx_version / , pid xsl : value - of select = /rtmp/pid / , built xsl : value - of select = /rtmp/built / #160 ; xsl:value-of select= /rtmp/compiler / / body / html / xsl : template xsl : template match = rtmp table cellspacing = 1 cellpadding = 5 tr bgcolor = #999999 th RTMP / th th # clients / th th colspan = 4 Video / th th colspan = 4 Audio / th th In bytes / th th Out bytes / th th In bits / s / th th Out bits / s / th th State / th th Time / th / tr tr td colspan = 2 Accepted : xsl : value - of select = naccepted / / td th bgcolor = #999999 codec / th th bgcolor = #999999 bits / s / th th bgcolor = #999999 size / th th bgcolor = #999999 fps / th th bgcolor = #999999 codec / th th bgcolor = #999999 bits / s / th th bgcolor = #999999 freq / th th bgcolor = #999999 chan / th td xsl : call - template name = showsize xsl : with - param name = size select = bytes_in / / xsl : call - template / td td xsl : call - template name = showsize xsl : with - param name = size select = bytes_out / / xsl : call - template / td td xsl : call - template name = showsize xsl : with - param name = size select = bw_in / xsl : with - param name = bits select = 1 / xsl : with - param name = persec select = 1 / / xsl : call - template / td td xsl : call - template name = showsize xsl : with - param name = size select = bw_out / xsl : with - param name = bits select = 1 / xsl : with - param name = persec select = 1 / / xsl : call - template / td td / td xsl : call - template name = showtime xsl : with - param name = time select = /rtmp/uptime * 1000 / / xsl : call - template / td / tr xsl : apply - templates select = server / / table / xsl : template xsl : template match = server xsl : apply - templates select = application / / xsl : template xsl : template match = application tr bgcolor = #999999 td b xsl : value - of select = name / / b / td / tr xsl : apply - templates select = live / xsl : apply - templates select = play / / xsl : template xsl : template match = live tr bgcolor = #aaaaaa td i live streams / i / td td align = middle xsl : value - of select = nclients / / td / tr xsl : apply - templates select = stream / / xsl : template xsl : template match = play tr bgcolor = #aaaaaa td i vod streams / i / td td align = middle xsl : value - of select = nclients / / td / tr xsl : apply - templates select = stream / / xsl : template xsl : template match = stream tr valign = top xsl : attribute name = bgcolor xsl : choose xsl : when test = active # cccccc / xsl : when xsl : otherwise # dddddd / xsl : otherwise / xsl : choose / xsl : attribute td a href = xsl : attribute name = onclick var d = document . getElementById ( xsl:value-of select= ../../name / - xsl:value-of select= name / ) ; d . style . display = d . style . display == none ? : none ; return false / xsl : attribute xsl : value - of select = name / xsl : if test = string-length(name) = 0 [ EMPTY ] / xsl : if / a / td td align = middle xsl : value - of select = nclients / / td td xsl : value - of select = meta/video/codec / #160 ; xsl:value-of select= meta/video/profile / #160; xsl : value - of select = meta/video/level / / td td xsl : call - template name = showsize xsl : with - param name = size select = bw_video / xsl : with - param name = bits select = 1 / xsl : with - param name = persec select = 1 / / xsl : call - template / td td xsl : apply - templates select = meta/video/width / / td td xsl : value - of select = meta/video/frame_rate / / td td xsl : value - of select = meta/audio/codec / #160 ; xsl:value-of select= meta/audio/profile / / td td xsl : call - template name = showsize xsl : with - param name = size select = bw_audio / xsl : with - param name = bits select = 1 / xsl : with - param name = persec select = 1 / / xsl : call - template / td td xsl : apply - templates select = meta/audio/sample_rate / / td td xsl : value - of select = meta/audio/channels / / td td xsl : call - template name = showsize xsl : with - param name = size select = bytes_in / / xsl : call - template / td td xsl : call - template name = showsize xsl : with - param name = size select = bytes_out / / xsl : call - template / td td xsl : call - template name = showsize xsl : with - param name = size select = bw_in / xsl : with - param name = bits select = 1 / xsl : with - param name = persec select = 1 / / xsl : call - template / td td xsl : call - template name = showsize xsl : with - param name = size select = bw_out / xsl : with - param name = bits select = 1 / xsl : with - param name = persec select = 1 / / xsl : call - template / td td xsl : call - template name = streamstate / / td td xsl : call - template name = showtime xsl : with - param name = time select = time / / xsl : call - template / td / tr tr style = display:none xsl : attribute name = id xsl : value - of select = ../../name / - xsl : value - of select = name / / xsl : attribute td colspan = 16 ngcolor = #eeeeee table cellspacing = 1 cellpadding = 5 tr th Id / th th State / th th Address / th th Flash version / th th Page URL / th th SWF URL / th th Dropped / th th Timestamp / th th A - V / th th Time / th / tr xsl : apply - templates select = client / / table / td / tr / xsl : template xsl : template name = showtime xsl : param name = time / xsl : if test = $time gt; 0 xsl : variable name = sec xsl : value - of select = floor($time div 1000) / / xsl : variable xsl : if test = $sec gt;= 86400 xsl : value - of select = floor($sec div 86400) / d / xsl : if xsl : if test = $sec gt;= 3600 xsl : value - of select = (floor($sec div 3600)) mod 24 / h / xsl : if xsl : if test = $sec gt;= 60 xsl : value - of select = (floor($sec div 60)) mod 60 / m / xsl : if xsl : value - of select = $sec mod 60 / s / xsl : if / xsl : template xsl : template name = showsize xsl : param name = size / xsl : param name = bits select = 0 / xsl : param name = persec select = 0 / xsl : variable name = sizen xsl : value - of select = floor($size div 1024) / / xsl : variable xsl : choose xsl : when test = $sizen gt;= 1073741824 xsl : value - of select = format-number($sizen div 1073741824, #.### ) / T / xsl : when xsl : when test = $sizen gt;= 1048576 xsl : value - of select = format-number($sizen div 1048576, #.### ) / G / xsl : when xsl : when test = $sizen gt;= 1024 xsl : value - of select = format-number($sizen div 1024, #.## ) / M / xsl : when xsl : when test = $sizen gt;= 0 xsl : value - of select = $sizen / K / xsl : when / xsl : choose xsl : if test = string-length($size) gt; 0 xsl : choose xsl : when test = $bits = 1 b / xsl : when xsl : otherwise B / xsl : otherwise / xsl : choose xsl : if test = $persec = 1 / s / xsl : if / xsl : if / xsl : template xsl : template name = streamstate xsl : choose xsl : when test = active active / xsl : when xsl : otherwise idle / xsl : otherwise / xsl : choose / xsl : template xsl : template name = clientstate xsl : choose xsl : when test = publishing publishing / xsl : when xsl : otherwise playing / xsl : otherwise / xsl : choose / xsl : template xsl : template match = client tr xsl : attribute name = bgcolor xsl : choose xsl : when test = publishing # cccccc / xsl : when xsl : otherwise # eeeeee / xsl : otherwise / xsl : choose / xsl : attribute td xsl : value - of select = id / / td td xsl : call - template name = clientstate / / td td a target = _blank xsl : attribute name = href http : // apps . db . ripe . net / search / query . html #63 ;searchtext= xsl:value-of select= address / / xsl : attribute xsl : attribute name = title whois / xsl : attribute xsl : value - of select = address / / a / td td xsl : value - of select = flashver / / td td a target = _blank xsl : attribute name = href xsl : value - of select = pageurl / / xsl : attribute xsl : value - of select = pageurl / / a / td td xsl : value - of select = swfurl / / td td xsl : value - of select = dropped / / td td xsl : value - of select = timestamp / / td td xsl : value - of select = avsync / / td td xsl : call - template name = showtime xsl : with - param name = time select = time / / xsl : call - template / td / tr / xsl : template xsl : template match = publishing publishing / xsl : template xsl : template match = active active / xsl : template xsl : template match = width xsl : value - of select = . / x xsl : value - of select = ../height / / xsl : template / xsl : stylesheet","title":"nginx"},{"location":"nginx/#map","text":"map $ uri $ match { ~^/ common / file / dachui / (. * ) / dachui / ; } $ match  / dachui / $ uri nginx   $ uri  / common / file / dachui / 20170427160407 . jpg  $ 1  20170427160407 . jpg $ match $ 1  dachui / 20170427160407 . jpg ，$ 1  http : // www . ttlsa . com / nginx / using - nginx - map - method /","title":"map"},{"location":"nginx/#session-hash","text":"if ( $ http_cookie ~* JSESSIONID=(.*?); ) # ( . * ? ) ;(.*) { set $ wap_cookie $1 ; } upstream pool1 { hash $c ookie_jsessionid ; tomcatphpsession（cookie） server server1 : 80 ; server server2 : 80 ; server server3 : 80 ; hash_again 2 ;  } hash_again = 1 ， server2  server1 ， server3 。。  hash_again = 2 ， nginx  hash ，。  hash_again ，。","title":"session hash"},{"location":"nginx/#nginx-rewrite","text":"$a rg_PARAMETER # GET ， PARAMETER   gRead . do ? imgurl =/ dachui / 20170427160407 . jpg $a rgs  imgurl =/ dachui / 20170427160407 . jpg $a rg_imgurl  / dachui / 20170427160407 . jpg $a rgs ,  ; $d ocument_root ,  ; $ host ,  Host ， Host ， ; $ limit_rate ,  ; $ request_method , ， GET 、 POST  ; $ remote_addr ,  ; $ remote_port ,  ; $ remote_user , ， ; $ request_filename ,  $ query_string ,  $a rgs  ; $ scheme , ， http  https $ server_protocol , ， HTTP/1.0  HTTP/1.1 ; $ server_addr , ， listen ，  (  ) ; $ server_name ,  ; $d ocument_uri $ uri ， URI  ; $ server_port ,  ; nginx rewrite ： 1 . server  rewrite  (  server {}， xx  ) 2 . location  3 . location  rewrite   URI ， 1 - 3 ，  10 ， 500 Internal Server Error  if ( $ hosts ~* ^ www . hah ) { set $ who who.html ; set ， rewrite ^/ ( . * ) $ http : // $ host / $1$2 / permanent ; } last  Apache [ L ]， rewrite break ，， redirect  302 ， URL  permanent  301 ， URL  rewrite ^/ test . php / new permanent ; // rewrite ^/ test . php / new ? permanent ; // rewrite ^/ test . php / new ? id = $a rg_id ? permanent ; // location / search { if ( $a rgs ~* ei= ) { rewrite ^/ / search ? newwindow = 1 q = $a rg_q start = $a rg_start ? permanent ; } proxy_pass https : // ipv6 . google . com / search ; proxy_hide_header Set-Cookie ; proxy_hide_header Cache-Control ; proxy_ignore_headers Expires Cache-Control Set-Cookie ; expires 30 d ; }","title":"nginx rewrite"},{"location":"nginx/#_1","text":"nginx . conf  rewrite  rewrite ^/ http : // staticwww . dachuizichan . com $ uri permanent ; add_header Access - Control - Allow - Origin * ; if ( $ request_method = OPTIONS ) { add_header Access - Control - Allow - Origin * ; add_header Access - Control - Allow - Credentials true ; add_header Access - Control - Allow - Methods GET, POST, OPTIONS ; add_header Access-Control-Allow-Headers Access-Control-Allow-Origin, x-requested-with, content-type ; return 200 ; } user nginx ; worker_processes 1 ; events { worker_connections 1024 ; } http { include mime . types ; default_type application / octet - stream ; log_format main $remote_addr - $remote_user [$time_local] $request $status $body_bytes_sent $http_referer $http_user_agent $http_x_forwarded_for ; # access_log logs / access . log main ; sendfile on ; keepalive_timeout 65 ; gzip on ; gzip_min_length 1 k ; gzip_buffers 4 16 k ; gzip_http_version 1 . 0 ; gzip_comp_level 2 ; 1-10，， gzip_types text / plain application / x - javascript text / css application / xml text / javascript application / x - httpd - php image / jpeg image / gif image / png ; gzip_vary off ; Squid，onHeader Vary: Accept-Encoding proxy_temp_path / tmp / temp_dir ; # proxy_cache_path / tmp / cache levels = 1 : 2 keys_zone = cache_one : 200 m inactive = 1 d max_size = 30 g ; server { listen 81 ; server_name localhost ; rewrite ^/ http : // $ host : 8081 / 3 m / index . do last ; } server { listen 8081 ; server_name localhost ; root / usr / local / tomcat / webapps ; location ~ ( \\. jsp | \\. do | imageServlet ) $ { proxy_pass http : // 127 . 0 . 0 . 1 : 8080 ; proxy_redirect off ; proxy_set_header Host $ host ; proxy_set_header X - Real - IP $ remote_addr ; proxy_set_header X - Forwarded - For $ proxy_add_x_forwarded_for ; client_max_body_size 10 m ; # client_body_buffer_size 128 k ; # proxy_connect_timeout 90 ; #nginx() proxy_read_timeout 90 ; #，() proxy_buffer_size 4 k ; #（nginx） proxy_buffers 6 32 k ; #proxy_buffers，32k， proxy_busy_buffers_size 64 k ;#（proxy_buffers*2） proxy_temp_file_write_size 64 k ; #，，upstream } location ~ . * \\. ( html | js | css | gif | jpg | png | bmp | swf | ico | txt ) ?$ { proxy_cache cache_one ; # ，keys_zone。 proxy_cache_valid 200 302 1 h ; expires 1 d ; root / usr / local / nginx / aaa / ;  } error_page 404 / 404 . html ; error_page 500 502 503 504 / 50 x . html ; location = / 50 x . html { root html ; } } }","title":""},{"location":"nginx/#locationrewrite","text":"location / manage / { proxy_pass http : //dachui_servers/DaChui/manage/; uri sub_filter dachui_servers : 80 / DaChui / wwwtest . dachuizichan . com / ;  url #sub_filter http: //dachui_servers:80/DaChui/ http://wwwtest.dachuizichan.com/ ; sub_filter http : //dachui_servers/DaChui/ http://wwwtest.dachuizichan.com/ ; sub_filter_once off ; }  location  URI  proxy_pass ， nginx  location = / { #  / ， [ configuration A ] } location / { #  / ，#  [ configuration B ] } location / documents / { #  /documents/ ，，# ， [ configuration C ] } location ~ / documents / Abc { #  /documents/ ，，# ， [ configuration CC ] } location ^~ / images / { #  /images/ ，，，。 [ configuration D ] } location ~* \\ .( gif | jpg | jpeg ) $ { #  gif,jpgjpeg # ， /images/  config D ， ^~  [ configuration E ] } location / images / { #  /images/，， ^~  [ configuration F ] } location / images / abc { #  /images/abc，， ^~ # FG [ configuration G ] } location ~ / images / abc / { #  config D ： config G ，，， [ configuration H ] } location ~* / js / . */\\ . js  =   A ，。 ^~  uri ， ~  ; ~*  /  ,  ,   no ： ( location = ) ( location  ) ( location ^~  ) ( location ~ , ~*  ) ( location  ) ( / )   location ，： / - config A ， / index . html  / downloads / download . html - config B  B ，， B / images / 1. gif - configuration D  F ， D ， / images / abc / def - config D  G ， D ，   / images /  D ， FG ， H ， / documents / document . html - config C  C ，， C / documents / 1. jpg - configuration E  C ， E / documents / Abc . jpg - config CC  C ， CC ， E  ，，： #，，，。#， #  location = / { proxy_pass http : //tomcat:8080/index } # ，nginxhttp# ，, location ^~ / static / { root / webroot / static / ; } location ~* \\ .( gif | jpg | jpeg | png | css | js | ico ) $ { root / webroot / res / ; } #，#，# ， . php ,. jsp  location / { proxy_pass http : //tomcat:8080/ } http : //tengine.taobao.org/book/chapter_02.html http : //nginx.org/en/docs/http/ngx_http_rewrite_module.html Rewrite  rewrite ， nginx ， url 。 rewrite  server {}, location {}, if {} ，，  http : //seanlook.com/a/we/index.php?id=1 u=str /a/we/index.php。rewrite regex replacement [flag]; ，， proxy_pass 。  rewrite  location ，， rewrite ， location  ， proxy_pass 。 rewrite  location ，：  server  rewrite   location   location  rewrite   URI ， 1 - 3 ，； 10 ， 500 Internal Server Error 。 flag  last :  Apache  [ L ] ， rewrite break :  rewrite  redirect :  302 ， permanent :  301 ，  301  302 ， URL ， return  301 , 302 。 last  break ： last  server  if ， break  location  last  url ， url  server ， break  break  last  rewrite  if  if   if ( condition ){...} ， condition 。， rewrite ， if  ( conditon )  ： ， 0  false ， =  != ~ ， ~* ， !~  - f  !- f  - d  !- d  - e  !- e  - x  !- x  ： if ( $ http_user_agent ~ MSIE ) { rewrite ^ (. * ) $ / msie / $ 1 break ; } //UA MSIE ，rewrite/msid/ if ( $ http_cookie ~* id=([^;]+)(?:;|$) ) { set $ id $ 1 ; } //cookie，$id if ( $ request_method = POST ) { return 405 ; } //POST，405（Method not allowed）。return301,302if ($slow) { limit_rate 10 k ; } //，$slow set  if ( !- f $ request_filename ){ break ; proxy_pass http : //127.0.0.1; } //，localhost 。breakrewrite if ( $ args ~ post = 140 ){ rewrite ^ http : //example.com/ permanent; } //query string post=140 ，example.com location ~* \\ .( gif | jpg | png | swf | flv ) $ { valid_referers none blocked www . jefflei . com www . leizhenfang . com ; if ( $ invalid_referer ) { return 404 ; } // }   if  $ args ： #，$ query_string $ content_length ：  Content - length 。 $ content_type ：  Content - Type 。 $ document_root ：  root 。 $ host ： ，。 $ http_user_agent ：  agent  $ http_cookie ：  cookie  $ limit_rate ： 。 $ request_method ： ， GET  POST 。 $ remote_addr ：  IP 。 $ remote_port ： 。 $ remote_user ：  Auth Basic Module 。 $ request_filename ： ， root  alias  URI 。 $ scheme ： HTTP （ http ， https ）。 $ server_protocol ： ， HTTP / 1.0  HTTP / 1.1 。 $ server_addr ： ，。 $ server_name ： 。 $ server_port ： 。 $ request_uri ：  URI ，，：” / foo / bar . php ? arg = baz ”。 $ uri ：  URI ，$ uri ，” / foo / bar . html ”。 $ document_uri ： $ uri 。 ： http : //localhost:88/test1/test2/test.php $ host ： localhost $ server_port ： 88 $ request_uri ： http : //localhost:88/test1/test2/test.php $ document_uri ： / test1 / test2 / test . php $ document_root ： / var / www / html $ request_filename ： / var / www / html / test1 / test2 / test . php  . ：  ? ：  0  1  + ：  1  * ：  0  \\ d ： ^ ：  $ ：  { n } ：  n  { n ,} ：  n  [ c ] ：  c [ a - z ] ：  a - z   () ，$ 1 ，$ 2  () 。\\。 rewrite   1 ： rewrite ^ http : //staticwww.dachuizichan.com$request_uri? permanent;  http { # imagelog_format imagelog [$time_local] $image_file $image_type $body_bytes_sent $ status ; # rewrite_log on; server { root / home / www ; location / { # error_log logs/rewrite.log notice; # ‘’，{}rewrite ^/images/([a-z]{2})/([a-z0-9]{5})/(.*)\\.(png|jpg|gif)$ / data ? file = $ 3. $ 4 ; # “last”，setset $image_file $3; set $ image_type $ 4 ; } location / data { # ，access_log logs/images.log mian; root / data / images ; # 。，，urltry_files / $ arg_file / image404 . html ; } location = / image404 . html { # return 404 image not found\\n ; } }  / images / ef / uh7b3 / test . png ， / data ? file = test . png ， location / data ， / data / images / test . png ，， tryfiles  image404 location ， 404 。  2 ： rewrite ^/ images / (. * ) _ ( \\ d + ) x ( \\ d + ) \\ .( png | jpg | gif ) $ / resizer / $ 1. $ 4 ? width = $ 2 height = $ 3 ? last ;  / images / bla_500x400 . jpg ， / resizer / bla . jpg ? width = 500 height = 400 ， location 。 ，$ 1  () ，$ 2 ，。","title":"locationrewrite"},{"location":"nginx/#nginx","text":"：  http : // example . com / test . php ? para = xxx  http : // example . com / new ： rewrite ^/ test . php ( . * ) / new permanent ; ： http : // example . com / new ? para = xxx ： rewrite ^/ test . php ( . * ) / new ? permanent ; ： http : // example . com / new ，“？”。，？ Nginx  $a rg_PARAMETER 。 ：  http : // example . com / test . php ? para = xxx p = xx  http : // example . com / new ? p = xx ： rewrite ^/ test . php / new ? p = $a rg_p ? permanent ; rewrite ^/ test . php / new permanent ; // rewrite ^/ test . php / new ? permanent ; // rewrite ^/ test . php / new ? id = $a rg_id ? permanent ; // permanent ，，。 if ( $a rgs ) {  rewrite rewrite ^/ ( . * ) / $1 ? permanent ;  }","title":"nginx"},{"location":"nginx/#cdn","text":"http {  http  # for pre - open closed test map $ http_x_forwarded_for $a llowed { default deny ; ~ \\ s * 111 . 222 . 333 . 444 $ allow ; ~ \\ s * 123 . 456 . 789 . * $ allow ; } } location / { if ( $a llowed = deny ) { return 403 ; } alias / path / to / document_root } =========================================== nginx http_realip_module  location = / getRealip . php { set_real_ip_from 192 . 168 . 50 . 0 / 24 ; set_real_ip_from 61 . 22 . 22 . 22 ; set_real_ip_from 121 . 207 . 33 . 33 ; set_real_ip_from 127 . 0 . 0 . 1 ; real_ip_header X - Forwarded - For ; real_ip_recursive on ; fastcgi_pass unix : / var / run / phpfpm . sock ; fastcgi_index index . php ; include fastcgi . conf ; } set_real_ip_from ： IP  IP , real_ip_header ： header  IP  real_ip_recursive ： IP , ip  set_real_ip_from  IP , ip  IP ，  IP  IP 。， IP ： 120 . 22 . 11 . 11 , 61 . 22 . 22 . 22 , 121 . 207 . 33 . 33 , 192 . 168 . 50 . 121  real_ip_recursive on  61 . 22 . 22 . 22 , 121 . 207 . 33 . 33 , 192 . 168 . 50 . 121  set_real_ip_from , 120 . 22 . 11 . 11 , ip ，  remote_addr   real_ip_recursive off  192 . 168 . 50 . 121  set_real_ip_from ,， ip  ip  ： set_real_ip_from 192 . 168 . 50 . 0 / 24 ; set_real_ip_from 127 . 0 . 0 . 1 ; real_ip_header X - Forwarded - For ; real_ip_recursive on ; ： 121 . 207 . 33 . 33  realip  ：， remote_addr  IP  ： ip ， CDN  ip  ip   set_real_ip_from 0 . 0 . 0 . 0 / 0 ; ","title":"cdn"},{"location":"nginx/#_2","text":"http { … … client_max_body_size 300 m ; #， Content - Length 。 （） client_body_buffer_size 128 k ; #，： 8 k / 16 k 。  128 k ， Nginx 。，。 client_body_temp_path / dev / shm / client_body_temp ; #。 proxy_connect_timeout 600 ; #， proxy_read_timeout 600 ; #： proxy_read_timeout 60 。， nginx  。 established  ，。  proxy_connect_timeout ， ，，  。， nginx 。 proxy_send_timeout 600 ; #，， ， nginx 。 proxy_buffer_size 16 k ; #： proxy_buffer_size 4 k / 8 k 。， 。 proxy_buffers 4 32 k ; #（）， Nginx  Buffer ， proxy_busy_buffers_size 64 k ; # proxy_buffers ， * 2 proxy_temp_file_write_size 64 k ; # proxy_temp_path ， 。 proxy_temp_path / dev / shm / proxy_temp ; # http  client_body_temp_path ， 。 upstream server_pool { server 192 . 168 . 0 . 88 : 80 weight = 4 max_fails = 2 fail_timeout = 30 s ; server 192 . 168 . 0 . 89 : 80 weight = 2 max_fails = 2 fail_timeout = 30 s ; } # HTTP 。 upstream ， proxy_pass  fastcgi_pass ，，  TCP  Unix socket 。 ， 1 。 location / { proxy_pass http : // server_pool / ; # URL ， socket 。 proxy_redirect off ; # Location  Refresh ， 。 proxy_set_header X - Real - IP $ remote_addr ; #。  ，。 proxy_set_header X - Forwarded - For $ proxy_add_x_forwarded_for ; proxy_set_header Host $ host ; proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504 http_404 ; #： # error - ，，。 # timeout - ，。 # invalid_header - 。 # http_500 -  500 。 # http_502 -  502 。 # http_503 -  503 。 # http_504 -  504 。 # http_404 -  404 。 # off - 。 } Nginx  upstream  5  1 　（） ， down ， 。 2 　 weight ， weight ，。 ： upstream bakend { server 192 . 168 . 0 . 88 weight = 10 ; server 192 . 168 . 0 . 89 weight = 10 ; } 3 　 ip_hash  ip  hash ，，  session 。 ： upstream bakend { ip_hash ;  hash $ http_x_forwarded_for ; cdn server 192 . 168 . 0 . 88 : 80 ; server 192 . 168 . 0 . 89 : 80 ; } 4 　 fair （） ，。 ： upstream bakend { server 192 . 168 . 0 . 88 : 80 ; server 192 . 168 . 0 . 89 : 80 ; fair ; } 5 　 url_hash （）  url  hash ， url ， 。 ： upstream backend { server 192 . 168 . 0 . 88 : 3128 ; server 192 . 168 . 0 . 89 : 3128 ; hash $ request_uri ;  hash $ http_x_forwarded_for ; cdn # hash_method crc32 ; }  : 1 . down  server  2 . weight  1 . weight ，。 3 . max_fails ： 1 . ， proxy_next_upstream  4 . fail_timeout : max_fails ，。 5 . backup ：  backup  down ， backup 。 。 Nginx ， server 。","title":""},{"location":"nginx/#proxy_pass","text":"sub_filter www_servers:80/DaChui/ www.xxx.com/ ; sub_filter http://www_servers:80/DaChui/ http://www.xxx.com/ ; sub_filter http://www_servers/DaChui/ http://www.xxx.com/ ; sub_filter_once off ;  nginx  proxy_pass ， proxy_pass  url  / ，； / ，， 。  80   proxy_set_header Host $ host :$ server_port upstream falcon { server 172 . 31 . 20 . 205 : 8010 ; } location / { proxy_pass http : // falcon / ; proxy_set_header Host $ host :$ server_port ; proxy_set_header X - Real - IP $ remote_addr ; proxy_set_header X - Forwarded - For $ proxy_add_x_forwarded_for ; }  http : // 192 . 168 . 1 . 1 / proxy / test . html 。 ： location / proxy / { proxy_pass http : // 127 . 0 . 0 . 1 / ; }  URL ： http : // 127 . 0 . 0 . 1 / test . html （， / ） location / proxy / { proxy_pass http : // 127 . 0 . 0 . 1 ; }  URL ： http : // 127 . 0 . 0 . 1 / proxy / test . html ： location / proxy / { proxy_pass http : // 127 . 0 . 0 . 1 / aaa / ; }  URL ： http : // 127 . 0 . 0 . 1 / aaa / test . html （， / ） location / proxy / { proxy_pass http : // 127 . 0 . 0 . 1 / aaa ; }  URL ： http : // 127 . 0 . 0 . 1 / aaatest . html","title":"proxy_pass"},{"location":"nginx/#_3","text":"/ etc / nginx / conf . d / default . conf location / logio { proxy_pass http : // 192.168.1.2 : 28778 / ; auth_basic secret ; auth_basic_user_file /etc/nginx/passwd.db ; }  : auth_basic string | off ;  : auth_basic off ;  : http , server , location , limit_except ，，。  : auth_basic_user_file file ;  : —  : http , server , location , limit_except htpasswd -c / etc / nginx / passwd . db admin  chmod 400 / etc / nginx / passwd . db chown nginx . nginx / etc / nginx / passwd . db / etc / init . d / nginx reload","title":""},{"location":"nginx/#rootalias","text":"location / img / { alias / var / www / image / ; } # ， / img / ， ningx  / var / www / image /  location / img / { root / var / www / image ; } # ， / img / ， nginx  / var / www / image / img /  alias ， root 。  alias “ / ”，  root ","title":"rootalias"},{"location":"nginx/#nginx_1","text":" nginx . conf  http {}  # ip limit limit_conn_zone $ binary_remote_addr zone = perip : 10m ; limit_conn_zone $ server_name zone = perserver : 10m ;  location  location / { limit_conn perip 2 ; limit_conn perserver 20 ; limit_rate 100k ; } ： $ binary_remote_addr  ip ； $ server_name  server ； limit_conn ； limit_rate ； nginx 1 . 1 . 8  limit_conn_zone $ binary_remote_addr zone = NAME : 10m ; NAME  zone  http :// nginx . org / en / docs / http / ngx_http_limit_conn_module . html  : ，， http ： zone= ，， limit_conn  $ binary_remote_addr = ， 1m  32000  ...  N  http { limit_conn_zone $binary_remote_addr zone= addr : 10 m ; server（location），IP1， server { listen 80 ; server_name 192.168.11.128 ; index index.html index.htm index.php ; limit_conn addr 1 ; #IP1 （addr  limit_conn_zone ） limit_rate 100k ; # 100KB/ root html ; ： limit_rate 100k ; //100k。，IP！IP， IPlimit_rate * 2","title":"nginx"},{"location":"nginx/#nginx_2","text":" api ， golang http 。。  “” ，，。 ， Golang http api  3 . 5 W ,  QPS ， go http api ，  nginx ， nginx  1 . 5 w 。  “”  nginx 。 ，，。  nginx  。 ，。 ，， ，， scp ， location ，。 ，， tmux  screen ， top  nginx  go api  cpu ， load ， run ， cpu ，。 dstat 。 ss + netstat 。  ， ab ，，，， ， ， python django ， webbench , ab , boom  http 。 ，。,  fd ， 。 ， 65535 - 1024 ， 1024  。  65535 - 1024 ， 64511 ， nginx ， nginx  golang http api 。 。  6 w ，， ，，。  nginx 。 ，， nginx worker ， backlog ， nginx worker 。 nginx  worker num * worker_connections ,  worker_connections  1024 ,  10 w 。 ，，。  lsof ， nginx  。  http1 . 1 ， tcpdump ， http1 . 0 ，  sysctl  tcp ， tcp 。  upstream  keepalive 。 COMMAND PID USER FD TYPE DEVICE SIZE / OFF NODE NAME python 538 ruifengyun 9 u IPv4 595559383 0 t0 TCP 58 . 215 . 141 . 194 : 46665 - 58 . 215 . 141 . 83 : 9001 ( ESTABLISHED ) test_dic4 7476 ruifengyun 5 u IPv6 660251515 0 t0 TCP * : 9001 ( LISTEN ) test_dic4 7476 ruifengyun 10 u IPv6 660870187 0 t0 TCP localhost : 9001 - localhost : 46679 ( ESTABLISHED ) test_dic4 7476 ruifengyun 13 u IPv6 660870138 0 t0 TCP localhost : 9001 - localhost : 46608 ( ESTABLISHED ) test_dic4 7476 ruifengyun 14 u IPv6 660870137 0 t0 TCP localhost : 9001 - localhost : 46607 ( ESTABLISHED ) test_dic4 7476 ruifengyun 22 u IPv6 660870153 0 t0 TCP localhost : 9001 - localhost : 46632 ( ESTABLISHED ) test_dic4 7476 ruifengyun 23 u IPv6 660870143 0 t0 TCP localhost : 9001 - localhost : 46618 ( ESTABLISHED ) test_dic4 7476 ruifengyun 27 u IPv6 660870166 0 t0 TCP localhost : 9001 - localhost : 46654 ( ESTABLISHED ) test_dic4 7476 ruifengyun 73 u IPv6 660870191 0 t0 TCP localhost : 9001 - localhost : 46685 ( ESTABLISHED ) test_dic4 7476 ruifengyun 85 u IPv6 660870154 0 t0 TCP localhost : 9001 - localhost : 46633 ( ESTABLISHED ) test_dic4 7476 ruifengyun 87 u IPv6 660870147 0 t0 TCP localhost : 9001 - localhost : 46625 ( ESTABLISHED ) .... 。， nginx worker ， ， nginx  keepalive 。 Activates cache of connections to upstream servers The connections parameter sets the maximum number of idle keepalive connections to upstream servers that are retained in the cache per one worker process . When this number is exceeded , the least recently used connections are closed Python # xiaorui . cc upstream http_backend { server 127 . 0 . 0 . 1 : 8080 ; keepalive 256 ; } server { ... location / http / { proxy_pass http : // http_backend ; proxy_http_version 1 . 1 ; proxy_set_header Connection ; ... } } ，，，，。 ，。  nginx error log 。  Nginx  keepalive ，，。 Python 2016 / 06 / 24 16 : 34 : 12 [ error ] 15419 #0 : * 9421660 connect () failed ( 111 : Connection refused ) while connecting to upstream , client : 10 . 1 . 1 . 58 , server : , request : GET / HTTP/1.0 , upstream : http://127.0.0.1:9001/ , host : 10.1.1.63 2016 / 06 / 24 16 : 34 : 12 [ error ] 15418 #0 : * 9423639 connect () failed ( 111 : Connection refused ) while connecting to upstream , client : 10 . 1 . 1 . 58 , server : , request : GET / HTTP/1.0 , upstream : http://127.0.0.1:9004/ , host : 10.1.1.63 2016 / 06 / 24 16 : 34 : 12 [ error ] 15418 #0 : * 9423639 no live upstreams while connecting to upstream , client : 10 . 1 . 1 . 58 , server : , request : GET / HTTP/1.0 , upstream : http://test_servers/ , host : 10.1.1.63 2016 / 06 / 24 16 : 34 : 12 [ error ] 15418 #0 : * 9393899 connect () failed ( 111 : Connection refused ) while connecting to upstream , client : 10 . 1 . 1 . 58 , server : , request : GET / HTTP/1.0 , upstream : http://127.0.0.1:9004/ , host : 10.1.1.63 2016 / 06 / 24 16 : 58 : 13 [ notice ] 26449 #26449 : signal process started 2016 / 06 / 24 16 : 58 : 13 [ emerg ] 27280 #0 : unknown directive keepalive in / etc / nginx / conf . d / test_multi . conf : 7 2016 / 06 / 24 17 : 02 : 18 [ notice ] 3141 #3141 : signal process started 2016 / 06 / 24 17 : 02 : 18 [ emerg ] 27280 #0 : unknown directive keepalive in / etc / nginx / conf . d / test_multi . conf : 7 2016 / 06 / 24 17 : 02 : 44 [ notice ] 4079 #4079 : signal process started 2016 / 06 / 24 17 : 02 : 44 [ emerg ] 27280 #0 : unknown directive keepalive in / etc / nginx / conf . d / test_multi . conf : 7  nginx upstream keepalive ?  Nginx  ( HTTP1 . 0 ) ，， Nginx ，。  http 1 . 1 ， Nginx ， keepalive ， Nginx  ，，。  nginx upstream keepalive .  connection pool ，，。 ， ， keepalive connection pool ， ，，，， socket  connect () 。， TCP  slow start 。 keepalive  。  nginx ， redis ， mysqldb ， 。 pop ， push ， O ( 1 ) 。  128 ，，，  nginx ， 1 . 8 ，，，， keepalive timeout 。 Golang  http  http spdy ，  tengine upstream spdy  Server 。  keepalive ，。","title":" nginx"},{"location":"nginx/#nginx_rtmp-hls","text":"docker  https : // github . com / brocaar / nginx - rtmp - dockerfile ffmpeg ， ubuntu  apt   http : // johnvansickle . com / ffmpeg / wget http : // johnvansickle . com / ffmpeg / builds / ffmpeg - git - 64 bit - static . tar . xz  rpmforce  mkdir / data mkdir / static yum install ffmpeg wget pcre - devel zlib - devel openssl - devel wget http : // nginx . org / download / nginx - 1 . 6 . 2 . tar . gz tar zxf nginx - 1 . 6 . 2 . tar . gz wget https : // github . com / arut / nginx - rtmp - module / archive / v1 . 1 . 6 . tar . gz tar zxf v1 . 1 . 6 . tar . gz cd nginx - 1 . 6 . 2 . / configure -- add - module = .. / nginx - rtmp - module - 1 . 1 . 6 -- prefix =/ usr / local / nginx make make install nginx  daemon off ; events { worker_connections 1024 ; } rtmp { server { listen 1935 ; chunk_size 4000 ; application encoder { live on ; exec ffmpeg - i rtmp : // localhost : 1935 / encoder / $ name - c : a libfdk_aac - b : a 128 k - c : v libx264 - b : v 2500 k - f flv - g 30 - r 30 - s 1280 x720 - preset superfast - profile : v baseline rtmp : // localhost : 1935 / hls / $ name_720p2628kbs - c : a libfdk_aac - b : a 128 k - c : v libx264 - b : v 1000 k - f flv - g 30 - r 30 - s 854 x480 - preset superfast - profile : v baseline rtmp : // localhost : 1935 / hls / $ name_480p1128kbs - c : a libfdk_aac - b : a 128 k - c : v libx264 - b : v 750 k - f flv - g 30 - r 30 - s 640 x360 - preset superfast - profile : v baseline rtmp : // localhost : 1935 / hls / $ name_360p878kbs - c : a libfdk_aac - b : a 128 k - c : v libx264 - b : v 400 k - f flv - g 30 - r 30 - s 426 x240 - preset superfast - profile : v baseline rtmp : // localhost : 1935 / hls / $ name_240p528kbs - c : a libfdk_aac - b : a 64 k - c : v libx264 - b : v 200 k - f flv - g 15 - r 15 - s 426 x240 - preset superfast - profile : v baseline rtmp : // localhost : 1935 / hls / $ name_240p264kbs ; } application hls { live on ; hls on ; hls_fragment_naming system ; hls_fragment 5 s ; hls_path / data / hls ; hls_nested on ; hls_variant _720p2628kbs BANDWIDTH = 2628000 , RESOLUTION = 1280 x720 ; hls_variant _480p1128kbs BANDWIDTH = 1128000 , RESOLUTION = 854 x480 ; hls_variant _360p878kbs BANDWIDTH = 878000 , RESOLUTION = 640 x360 ; hls_variant _240p528kbs BANDWIDTH = 528000 , RESOLUTION = 426 x240 ; hls_variant _240p264kbs BANDWIDTH = 264000 , RESOLUTION = 426 x240 ; } } } http { server { listen 80 ; location / hls { types { application / vnd . apple . mpegurl m3u8 ; video / mp2t ts ; } root / data ; add_header Cache - Control no - cache ; add_header Access - Control - Allow - Origin * ; } location / stat { rtmp_stat all ; rtmp_stat_stylesheet static / stat . xsl ; } location / static { alias / static ; } location / crossdomain . xml { default_type text / xml ; return 200 ?xml version= 1.0 ? ! DOCTYPE cross - domain - policy SYSTEM http://www.adobe.com/xml/dtds/cross-domain-policy.dtd cross - domain - policy site - control permitted - cross - domain - policies = all / allow - access - from domain = * secure = false / allow - http - request - headers - from domain = * headers = * secure = false / / cross - domain - policy ; expires 24 h ; } } } ------------------------------ cat / static / stat . xsl ? xml version = 1.0 encoding = utf-8 ? !-- Copyright ( C ) Roman Arutyunyan -- xsl : stylesheet version = 1.0 xmlns : xsl = http://www.w3.org/1999/XSL/Transform xsl : template match = / html head title RTMP statistics / title / head body xsl : apply - templates select = rtmp / hr / Generated by a href = https://github.com/arut/nginx-rtmp-module nginx - rtmp - module / a #160 ; xsl:value-of select= /rtmp/nginx_rtmp_version / , a href = http://nginx.org nginx / a #160 ; xsl:value-of select= /rtmp/nginx_version / , pid xsl : value - of select = /rtmp/pid / , built xsl : value - of select = /rtmp/built / #160 ; xsl:value-of select= /rtmp/compiler / / body / html / xsl : template xsl : template match = rtmp table cellspacing = 1 cellpadding = 5 tr bgcolor = #999999 th RTMP / th th # clients / th th colspan = 4 Video / th th colspan = 4 Audio / th th In bytes / th th Out bytes / th th In bits / s / th th Out bits / s / th th State / th th Time / th / tr tr td colspan = 2 Accepted : xsl : value - of select = naccepted / / td th bgcolor = #999999 codec / th th bgcolor = #999999 bits / s / th th bgcolor = #999999 size / th th bgcolor = #999999 fps / th th bgcolor = #999999 codec / th th bgcolor = #999999 bits / s / th th bgcolor = #999999 freq / th th bgcolor = #999999 chan / th td xsl : call - template name = showsize xsl : with - param name = size select = bytes_in / / xsl : call - template / td td xsl : call - template name = showsize xsl : with - param name = size select = bytes_out / / xsl : call - template / td td xsl : call - template name = showsize xsl : with - param name = size select = bw_in / xsl : with - param name = bits select = 1 / xsl : with - param name = persec select = 1 / / xsl : call - template / td td xsl : call - template name = showsize xsl : with - param name = size select = bw_out / xsl : with - param name = bits select = 1 / xsl : with - param name = persec select = 1 / / xsl : call - template / td td / td xsl : call - template name = showtime xsl : with - param name = time select = /rtmp/uptime * 1000 / / xsl : call - template / td / tr xsl : apply - templates select = server / / table / xsl : template xsl : template match = server xsl : apply - templates select = application / / xsl : template xsl : template match = application tr bgcolor = #999999 td b xsl : value - of select = name / / b / td / tr xsl : apply - templates select = live / xsl : apply - templates select = play / / xsl : template xsl : template match = live tr bgcolor = #aaaaaa td i live streams / i / td td align = middle xsl : value - of select = nclients / / td / tr xsl : apply - templates select = stream / / xsl : template xsl : template match = play tr bgcolor = #aaaaaa td i vod streams / i / td td align = middle xsl : value - of select = nclients / / td / tr xsl : apply - templates select = stream / / xsl : template xsl : template match = stream tr valign = top xsl : attribute name = bgcolor xsl : choose xsl : when test = active # cccccc / xsl : when xsl : otherwise # dddddd / xsl : otherwise / xsl : choose / xsl : attribute td a href = xsl : attribute name = onclick var d = document . getElementById ( xsl:value-of select= ../../name / - xsl:value-of select= name / ) ; d . style . display = d . style . display == none ? : none ; return false / xsl : attribute xsl : value - of select = name / xsl : if test = string-length(name) = 0 [ EMPTY ] / xsl : if / a / td td align = middle xsl : value - of select = nclients / / td td xsl : value - of select = meta/video/codec / #160 ; xsl:value-of select= meta/video/profile / #160; xsl : value - of select = meta/video/level / / td td xsl : call - template name = showsize xsl : with - param name = size select = bw_video / xsl : with - param name = bits select = 1 / xsl : with - param name = persec select = 1 / / xsl : call - template / td td xsl : apply - templates select = meta/video/width / / td td xsl : value - of select = meta/video/frame_rate / / td td xsl : value - of select = meta/audio/codec / #160 ; xsl:value-of select= meta/audio/profile / / td td xsl : call - template name = showsize xsl : with - param name = size select = bw_audio / xsl : with - param name = bits select = 1 / xsl : with - param name = persec select = 1 / / xsl : call - template / td td xsl : apply - templates select = meta/audio/sample_rate / / td td xsl : value - of select = meta/audio/channels / / td td xsl : call - template name = showsize xsl : with - param name = size select = bytes_in / / xsl : call - template / td td xsl : call - template name = showsize xsl : with - param name = size select = bytes_out / / xsl : call - template / td td xsl : call - template name = showsize xsl : with - param name = size select = bw_in / xsl : with - param name = bits select = 1 / xsl : with - param name = persec select = 1 / / xsl : call - template / td td xsl : call - template name = showsize xsl : with - param name = size select = bw_out / xsl : with - param name = bits select = 1 / xsl : with - param name = persec select = 1 / / xsl : call - template / td td xsl : call - template name = streamstate / / td td xsl : call - template name = showtime xsl : with - param name = time select = time / / xsl : call - template / td / tr tr style = display:none xsl : attribute name = id xsl : value - of select = ../../name / - xsl : value - of select = name / / xsl : attribute td colspan = 16 ngcolor = #eeeeee table cellspacing = 1 cellpadding = 5 tr th Id / th th State / th th Address / th th Flash version / th th Page URL / th th SWF URL / th th Dropped / th th Timestamp / th th A - V / th th Time / th / tr xsl : apply - templates select = client / / table / td / tr / xsl : template xsl : template name = showtime xsl : param name = time / xsl : if test = $time gt; 0 xsl : variable name = sec xsl : value - of select = floor($time div 1000) / / xsl : variable xsl : if test = $sec gt;= 86400 xsl : value - of select = floor($sec div 86400) / d / xsl : if xsl : if test = $sec gt;= 3600 xsl : value - of select = (floor($sec div 3600)) mod 24 / h / xsl : if xsl : if test = $sec gt;= 60 xsl : value - of select = (floor($sec div 60)) mod 60 / m / xsl : if xsl : value - of select = $sec mod 60 / s / xsl : if / xsl : template xsl : template name = showsize xsl : param name = size / xsl : param name = bits select = 0 / xsl : param name = persec select = 0 / xsl : variable name = sizen xsl : value - of select = floor($size div 1024) / / xsl : variable xsl : choose xsl : when test = $sizen gt;= 1073741824 xsl : value - of select = format-number($sizen div 1073741824, #.### ) / T / xsl : when xsl : when test = $sizen gt;= 1048576 xsl : value - of select = format-number($sizen div 1048576, #.### ) / G / xsl : when xsl : when test = $sizen gt;= 1024 xsl : value - of select = format-number($sizen div 1024, #.## ) / M / xsl : when xsl : when test = $sizen gt;= 0 xsl : value - of select = $sizen / K / xsl : when / xsl : choose xsl : if test = string-length($size) gt; 0 xsl : choose xsl : when test = $bits = 1 b / xsl : when xsl : otherwise B / xsl : otherwise / xsl : choose xsl : if test = $persec = 1 / s / xsl : if / xsl : if / xsl : template xsl : template name = streamstate xsl : choose xsl : when test = active active / xsl : when xsl : otherwise idle / xsl : otherwise / xsl : choose / xsl : template xsl : template name = clientstate xsl : choose xsl : when test = publishing publishing / xsl : when xsl : otherwise playing / xsl : otherwise / xsl : choose / xsl : template xsl : template match = client tr xsl : attribute name = bgcolor xsl : choose xsl : when test = publishing # cccccc / xsl : when xsl : otherwise # eeeeee / xsl : otherwise / xsl : choose / xsl : attribute td xsl : value - of select = id / / td td xsl : call - template name = clientstate / / td td a target = _blank xsl : attribute name = href http : // apps . db . ripe . net / search / query . html #63 ;searchtext= xsl:value-of select= address / / xsl : attribute xsl : attribute name = title whois / xsl : attribute xsl : value - of select = address / / a / td td xsl : value - of select = flashver / / td td a target = _blank xsl : attribute name = href xsl : value - of select = pageurl / / xsl : attribute xsl : value - of select = pageurl / / a / td td xsl : value - of select = swfurl / / td td xsl : value - of select = dropped / / td td xsl : value - of select = timestamp / / td td xsl : value - of select = avsync / / td td xsl : call - template name = showtime xsl : with - param name = time select = time / / xsl : call - template / td / tr / xsl : template xsl : template match = publishing publishing / xsl : template xsl : template match = active active / xsl : template xsl : template match = width xsl : value - of select = . / x xsl : value - of select = ../height / / xsl : template / xsl : stylesheet","title":"nginx_rtmp hls"},{"location":"nginx2/","text":"nginx 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 #!/bin/bash NGINX = /usr/local/nginx/sbin/nginx PID = /usr/local/nginx/logs/nginx.pid ##fun START () { pstree -p | grep nginx /dev/null 2 1 if [ -f $PID ] [ $? -eq 0 ] then echo Warnning: nginx already running else if [ -f $PID ] ; then rm -rf $PID fi $NGINX ##stdin OK if [ $? -eq 0 ] ; then echo -e nginx start\\t\\t\\t\\t [\\033[32m OK \\033[0m] else echo -e nginx start\\t\\t\\t\\t [\\033[31m Fail \\033[0m] fi fi } STOP () { pstree -p | grep nginx /dev/null 2 1 if [ -f $PID ] [ $? -eq 0 ] then killall -s QUIT nginx #check if [ $? -eq 0 ] ; then echo -e nginx stop\\t\\t\\t\\t [\\033[32m OK \\033[0m] fi else rm -rf /usr/local/nginx/logs/nginx.pid /dev/null 2 1 echo -e nginx stop\\t\\t\\t\\t [\\033[31m Fail \\033[0m] fi } RESTART () { STOP ; sleep 1 ; START } RELOAD () { if [ -f $PID ] [ $? -eq 0 ] then killall -s HUP $NGINX #reload check if [ $? -eq 0 ] ; then echo -e nginx reload\\t\\t\\t\\t [\\033[32m OK \\033[0m] fi else echo Warnning: nginx stop,please start nginx fi } STATUS () { elinks http://localhost -dump /dev/null 2 1 if [ $? -eq 0 ] ; then echo nginx running... else echo nging stop fi } #main case $1 in start ) START ;; stop ) STOP ;; restart ) RESTART ;; reload ) RELOAD ;; status ) STATUS ;; * ) echo USAGE: AVGE is start|stop|restart|reload|status ;; esac Nginx Nginx (  engine x ) 、，， Apache   Web 。 Nginx 。 Nginx ， ，， Nginx ，； ，。 Nginx ，，。 .  ( 1 )  Nginx ，。， rpm 、 deb  ，。。，， ，；，、，  Nginx  yum 、 deb  (  ) 。 ，，、 uwsgi 、 memcache ，，， 。， Web 。， ，。。， PHP  fastcgi ，： . / configure \\ --prefix=/App/nginx \\ --with-http_stub_status_module \\ --without-http_auth_basic_module \\ --without-http_autoindex_module \\ --without-http_browser_module \\ --without-http_empty_gif_module \\ --without-http_geo_module \\ --without-http_limit_conn_module \\ --without-http_limit_req_module \\ --without-http_map_module \\ --without-http_memcached_module \\ --without-http_proxy_module \\ --without-http_referer_module \\ --without-http_scgi_module \\ --without-http_split_clients_module \\ --without-http_ssi_module \\ --without-http_upstream_ip_hash_module \\ --without-http_upstream_keepalive_module \\ --without-http_upstream_least_conn_module \\ --without-http_userid_module \\ --without-http_uwsgi_module \\ --without-mail_imap_module \\ --without-mail_pop3_module \\ --without-mail_smtp_module \\ --without-poll_module \\ --without-select_module \\ --with-cc-opt= -O2 ， ssi , shtml ， 17 ，  Nginx 。 ./configure --help ，。 ( 2 ) GCC  [】 GCC  5 ： - O0 : 。 - O  - O1 : 。。 - O2 :  - O1 。。 。 - Os :  - O2 . 5 ，， - O2 ，。 。，，。 - O3 :  - O2  - finline - functions 、 - funswitch - loops 、 - fgcse - after - reload 。 - O2  ，，，， (  ) ， ，。  GCC ，， GCC ， Nginx 。 - O2 ， 。 Nginx  auto / cc / gcc ， NGX_GCC_OPT ， GCC  - O ， NGX_GCC_OPT = -O2   . / configure  -- with - cc - opt = -O2 。 .   CPU 、、 IO  IO ， Nginx  nginx . conf ： ( 1 )  ： worker_processes  Nginx  web 。，（） CPU 、。 ， CPU （“ auto ”）。 Shell  ps ax | grep nginx: worker process | grep - v grep  Nginx ， ， Shell  cat / proc / cpuinfo | grep processor | wc - l  ， auto ， Nginx 。 ( 2 )  CPU ： worker_cpu_affinity  CPU ， Nginx  CPU 。 CPU ，， CPU  ， CPU ， CPU ， CPU 。 top 、 htop  CPU 。： 1 2 worker_processes 4 ; worker_cpu_affinity 0001 0010 0100 1000 ; ( 3 )  ： worker_rlimit_nofile  Nginx ，，。  Shell  Nginx 。 Nginx ，  Shell 。 Shell  ulimit - n  Shell  。 Linux  1024 ，，“ too many open files 。 Shell ： echo * - nofile 65536 / etc / security / limits . conf  / etc / profile ， Shell  Shell ： 1 echo ulimit -n 65536 / etc / profile Shell  Shell ： 1 ulimit - n 65536 ( 4 )  ： accept_mutex  accept_mutex  on ，，；  off ，， use  IO ， ，“”。 Web  Apache ， ，“”。 Nginx ， on 。 Off  ，。 ( 5 )  IO  ： use  Nginx  (  IO  ) 。， Linux 2 . 6 +   epoll ， FreeBSD  kqueue ， Nginx 。 ( 6 )  ： worker_connections  Nginx ，，。  worker_rlimit_nofile ， worker_rlimit_nofile 。 ( 7 )  ： open_file_cache ， off ，，，。  max = ，。， LRU (  ) ； inactive =  ，，。： open_file_cache max = 65536 inactive = 60 s 。 ： open_file_cache_valid  open_file_cache 。 ： open_file_cache_min_uses  open_file_cache  inactive ， 。， ，。 ( 8 )  ： access_log  error_log ， Nginx ， Nginx 。， IO 。 ， tmpfs ，， IO 。 access_log off 。，， IO ， ，，。 error  crit 。，，。 ( 9 )  Nginx  ： server_tokens “ Server ” Nginx 。 off ，，， ，，。 ( 10 )  ： gzip Nginx  gzip 。， gzip  CPU 。， gzip  Nginx  CPU ，，， js  css 、 xml 、 j son 、 html ，。 gzip on ，  75 % ，，。。 ， PDF 、，。 gzip ，， ，。 CPU  ，。 Web ，， HttpWatch 、 Firebug 。 ： gzip_comp_level ， 1  9 ，，， CPU ，。 9 ，，  CPU ，，，。 1 - 4 ，。 2 。 ： gzip_min_length ， bytes ，，。 1 k ，，  CPU ，。 ： gzip_types ， Nginx  conf  mime . types  Nginx ， text / html ， html htm shtml 。： gzip_types text / plain text / css application / json application / x - javascript text / xml application / xml application / xml + rss text / javascript 。 ( 11 )  ： expires  HTTP “ Expires ”“ Cache - Control ”。 Expires  Last-Modified 。 expires ，  Web ，。 URL  If-Modified-Since ，，，  http 304 ，；，。 ，，，，。，； - 1 ，。 expires ，。 Nginx ： location ~ . + \\. ( gif | jpg | jpeg | png | bmp | swf ) $ { expires 30 d ; } location ~ . + \\. ( js | css | xml | javascript | txt | csv ) $ { expires 30 d ; }  location  expires ，： location / static / { expires 30 d ; } ( 12 )  ： keepalive_timeout  Http  Keepalive ， TCP 、， TCP 。 ，；，，。 。， 0 。 ( 13 )  HTTP  、、、 Flash ， 。。 Web ， Web  ，。 Nginx  Concat  Google  PageSpeed  。，，。 Concat  ： https : // github . com / alibaba / nginx - http - concat / ， PageSpeed ： https : // github . com / pagespeed / ngx_pagespeed 。 ( 14 ) PHP  Nginx  PHP ， FastCGI  PHP ， Nginx 。 PHP 。 Nginx  FastCGI ，。 ： fastcgi_temp_path  FastCGI 。 ： fastcgi_cache_path  FastCGI 。， key  URL  MD5 。 fastcgi_temp_path ， fastcgi_cache_path  。 levels , 16 ； keys_zone ， key ； inactive ，，； max_size ， 。 fastcgi_temp_path  fastcgi_cache_path ，。： fastcgi_temp_path / tmp / fastcgi_temp ; fastcgi_cache_path / tmp / fastcgi_cache levels = 1 : 2 keys_zone = cache_fastcgi : 16 m inactive = 30 m max_size = 1 g ;  / tmp / fastcgi_temp  FastCGI ； / tmp / fastcgi_cache  FastCGI ； 16  16 ， 16  2  256 ； cache_fastcgi ， 128 MB ； 30 ；  1 GB 。 ： fastcgi_cache_key  FastCGI 。 FastCGI ， PHP  PHP  URL 。 ： fastcgi_cache_valid  Http 。 ： fastcgi_cache_min_uses  URL 。 ： fastcgi_cache_use_stale  FastCGI ，。 ： fastcgi_cache 。  nginx . conf ，： user nginx nginx ; worker_processes auto ; error_log logs / error . log error ; pid logs / nginx . pid ; worker_rlimit_nofile 65536 ; events { use epoll ; accept_mutex off ; worker_connections 65536 ; } http { include mime . types ; default_type text / html ; charset UTF - 8 ; server_names_hash_bucket_size 128 ; client_header_buffer_size 4 k ; large_client_header_buffers 4 32 k ; client_max_body_size 8 m ; open_file_cache max = 65536 inactive = 60 s ; open_file_cache_valid 80 s ; open_file_cache_min_uses 1 ; log_format main $remote_addr - $remote_user [$time_local] $request $status $body_bytes_sent $http_referer $http_user_agent $http_x_forwarded_for ; access_log logs / access . log main ; sendfile on ; server_tokens off ; fastcgi_temp_path / tmp / fastcgi_temp ; fastcgi_cache_path / tmp / fastcgi_cache levels = 1 : 2 keys_zone = cache_fastcgi : 128 m inactive = 30 m max_size = 1 g ; fastcgi_cache_key $ request_method : // $ host $ request_uri ; fastcgi_cache_valid 200 302 1 h ; fastcgi_cache_valid 301 1 d ; fastcgi_cache_valid any 1 m ; fastcgi_cache_min_uses 1 ; fastcgi_cache_use_stale error timeout http_500 http_503 invalid_header ; keepalive_timeout 60 ; gzip on ; gzip_min_length 1 k ; gzip_buffers 4 64 k ; gzip_http_version 1 . 1 ; gzip_comp_level 2 ; gzip_types text / plain text / css application / json application / x - javascript text / xml application / xml application / xml + rss text / javascript ; server { listen 80 ; server_name localhost ; index index . html ; root / App / web ; location ~ . + \\. ( php | php5 ) $ { fastcgi_pass unix : / tmp / php . sock ; fastcgi_index index . php ; include fastcgi . conf ; fastcgi_cache cache_fastcgi ; } location ~ . + \\. ( gif | jpg | jpeg | png | bmp | swf | txt | csv | doc | docx | xls | xlsx | ppt | pptx | flv ) $ { expires 30 d ; } location ~ . + \\. ( js | css | html | xml ) $ { expires 30 d ; } location / nginx - status { stub_status on ; allow 192 . 168 . 1 . 0 / 24 ; allow 127 . 0 . 0 . 1 ; deny all ; } } } .  Linux ， / Proc ， / etc / sysctl . conf 。  / Proc ，，。 Linux ，、， ： grep - q net.ipv4.tcp_max_tw_buckets / etc / sysctl . conf || cat / etc / sysctl . conf EOF ######################################## net . core . rmem_default = 262144 net . core . rmem_max = 16777216 net . core . wmem_default = 262144 net . core . wmem_max = 16777216 net . core . somaxconn = 262144 net . core . netdev_max_backlog = 262144 net . ipv4 . tcp_max_orphans = 262144 net . ipv4 . tcp_max_syn_backlog = 262144 net . ipv4 . tcp_max_tw_buckets = 10000 net . ipv4 . ip_local_port_range = 1024 65500 net . ipv4 . tcp_tw_recycle = 1 net . ipv4 . tcp_tw_reuse = 1 net . ipv4 . tcp_syncookies = 1 net . ipv4 . tcp_synack_retries = 1 net . ipv4 . tcp_syn_retries = 1 net . ipv4 . tcp_fin_timeout = 30 net . ipv4 . tcp_keepalive_time = 600 net . ipv4 . tcp_keepalive_intvl = 30 net . ipv4 . tcp_keepalive_probes = 3 net . ipv4 . tcp_mem = 786432 1048576 1572864 fs . aio - max - nr = 1048576 fs . file - max = 6815744 kernel . sem = 250 32000 100 128 vm . swappiness = 10 EOF sysctl - p  Linux ： http : // dongsong . blog . 51 cto . com / 916653 / 1631085 。 .  Nginx ， 7 。 。 ，，， CDN 。 Nginx ，  Nginx  LVS ， F5 （，）， Nginx 。  Varnish  Squid  CDN 。 Nginx  Memcache ， ， PHP  JPS ，，。 ： http : // www . ttlsa . com / nginx / web - server - nginx - optimization / keepalived Keepalived  keepalived  layer3 , 4 , 5 ， 3 、 4  5 。 Keepalived   web ， web ，， Keepalived ， web ，  web  Keepalived  web ，，，  web  ： http : // www . keepalived . org keepalved ：  ： CentOS6 . 6 64  2  Nginx - Master 10 . 0 . 0 . 60 Nginx - Backup 10 . 0 . 0 . 61 VIP 10 . 0 . 0 . 62 ：， (  )   Nginx 《 OneinStack 》 Nginx  y ， n  Keepalived  Nginx - Master 、 Nginx - Backup ： cd ~/ oneinstack / src wget http : // www . keepalived . org / software / keepalived - 1 . 2 . 22 . tar . gz tar xzf keepalived - 1 . 2 . 22 . tar . gz cd keepalived - 1 . 2 . 22 . / configure -- prefix =/ usr / local / keepalived make make install  Keepalived  Nginx - Master 、 Nginx - Backup ： ln - s / usr / local / keepalived / etc / keepalived / etc / keepalived ln - s / usr / local / keepalived / etc / rc . d / init . d / keepalived / etc / rc . d / init . d / keepalived ln - s / usr / local / keepalived / etc / sysconfig / keepalived / etc / sysconfig / keepalived ln - s / usr / local / keepalived / sbin / keepalived / usr / bin / keepalived chkconfig keepalived on  Nginx - Master ， vi / etc / keepalived / keepalived . conf ! Configuration File for keepalived global_defs { notification_email { admin @ linuxeye . com #，，。  sendmail  } notification_email_from no - reply @ linuxeye . com # smtp_server 127 . 0 . 0 . 1 # smtp server  smtp_connect_timeout 30 # smtp server  router_id LVS_DEVEL # keepalived 。 } vrrp_script chk_nginx { script /usr/local/keepalived/sbin/check_nginx.sh # ngnix ， nginx   ngnix ， keepalived ，。 interval 2 # 2 s ， check_nginx . sh ， weight 2 #（ 0 ） 2 } vrrp_instance VI_1 { state MASTER # keepalived ， MASTER ， BACKUP  interface eth0 # HA  virtual_router_id 55 #，， vrrp 。 vrrp_instance  ， MASTER  BACKUP  priority 100 #，，， vrrp_instance ， MASTER   BACKUP  advert_int 1 # MASTER  BACKUP ， authentication { # auth_type PASS #， PASS  AH  auth_pass linuxeye #， vrrp_instance ， MASTER  BACKUP  } virtual_ipaddress { # IP ， IP ， 10 . 0 . 0 . 62 } track_script { chk_nginx # VRRP ， vrrp_script 。，。 } }  Nginx - Backup ， vi / etc / keepalived / keepalived . conf ! Configuration File for keepalived global_defs { notification_email { admin @ linuxeye . com #，，。  sendmail  } notification_email_from no - reply @ linuxeye . com # smtp_server 127 . 0 . 0 . 1 # smtp server  smtp_connect_timeout 30 # smtp server  router_id LVS_DEVEL # keepalived 。 } vrrp_script chk_nginx { script /usr/local/keepalived/sbin/check_nginx.sh # ngnix ， nginx   ngnix ， keepalived ，。 interval 2 # 2 s  weight 2 #（ 0 ） 2 } vrrp_instance VI_1 { state BACKUP # keepalived ， MASTER ， BACKUP  interface eth0 # HA  virtual_router_id 55 #，， vrrp 。 vrrp_instance ， MASTER  BACKUP  priority 50 #，，， vrrp_instance ， MASTER  BACKUP  advert_int 1 # MASTER  BACKUP ， nopreempt # nopreempt ， BACKUP  authentication { # auth_type PASS #， PASS  AH  auth_pass linuxeye #， vrrp_instance ， MASTER  BACKUP  } virtual_ipaddress { # IP ， IP ， 10 . 0 . 0 . 62 } track_script { chk_nginx # VRRP ， vrrp_script 。，。 } } ， vi / usr / local / keepalived / sbin / check_nginx . sh # !/ bin / bash if [ $(ps -ef | grep nginx : master process | grep -v grep ) == ] ;then # echo 1 / etc / init . d / nginx start sleep 5 if [ $(ps -ef | grep nginx : master process | grep -v grep ) == ] ;then / etc / init . d / keepalived stop # echo 2 fi fi  chmod + x / usr / local / keepalived / sbin / check_nginx . sh  service keepalived start # Nginx - Master service keepalived start # Nginx - Backup ip addr #2 ， IP  Nginx - Master service keepalived stop # Nginx - Backup ip addr #2 ， IP  Nginx - Backup service keepalived start # Nginx - Backup ip addr #2 ， IP  Nginx - Master  master  backup   master  backup  master ， master  master  VIP ， 。 nopreempt ， state  BACKUP ， HA  MASTER  backup  state  BACKUP  priority 。   2 ，， backup ， master ， vip  backup ， master ，  vip  2 ，？ ： master ， iptables  backup ， master keepalived iptables - F iptables - t nat - I PREROUTING - i eth0 - j DNAT -- to - destination 10 . 0 . 0 . 61 iptables - t nat - I POSTROUTING - o eth0 - j MASQUERADE nginx_upstream_check_module  。  nginx  nginx_upstream_check_module ，  realserver  。  realserver  ，  。  tengine  ， tenginenginx ，  ： http : // tengine . taobao . org / 。  nginx_upstream_check_module [ root@localhost ~ ] # cd / usr / local / src wget https : // codeload . github . com / yaoweibin / nginx_upstream_check_module / zip / master unzip master [ root@localhost /usr/local/src ] # ll - d nginx_upstream_check_module - master drwxr - xr - x . 6 root root 4096 Dec 1 02 : 28 nginx_upstream_check_module - master 2 、 nginx [ root@localhost /usr/local/src ] # cd nginx - 1.6.0 # nginx [ root@localhost nginx-1.6.0 ] # patch - p1 .. / nginx_upstream_check_module - master / check_1 .5.12 + . patch [ root@localhost nginx-1.6.0 ] # . / configure --user=nginx --group=nginx --prefix=/usr/local/nginx-1.6.0 --with-http_ssl_module --with-openssl=/usr/local/src/openssl-0.9.8q --with-pcre=/usr/local/src/pcre-8.32 --add-module=/usr/local/src/nginx_concat_module/ --add-module=../nginx_upstream_check_module-master/ make (  ： make ，  ) [ root@localhost nginx-1.6.0 ] # mv / usr / local / nginx / sbin / nginx / usr / local / nginx / sbin / nginx - 1.6.0 . bak [ root@localhost nginx-1.6.0 ] # cp . / objs / nginx / usr / local / nginx / sbin / [ root@localhost nginx-1.6.0 ] # / usr / local / nginx / sbin / nginx - t #  [ root@localhost nginx-1.6.0 ] # kill - USR2 ` cat / usr / local / nginx / logs / nginx . pid ` 3 、 nginx . confupstream ，  ： upstream name { server 192.168.0.21 : 80 ; server 192.168.0.22 : 80 ; check interval = 3000 rise = 2 fall = 5 timeout = 1000 type = http ; }   ， name ， 3 ， 2 realserverup ，  5  ，  realserverdown ， 1 。  nginx_upstream_check_module  ： Syntax : check interval = milliseconds [ fall=count ] [ rise=count ] [ timeout=milliseconds ] [ default_down=true|false ] [ type=tcp|http|ssl_hello|mysql|ajp ] [ port=check_port ] Default :  ，  ： interval = 30000 fall = 5 rise = 2 timeout = 1000 default_down = true type = tcpContext : upstream  。  ： - interval ：  。 - fall ( fall_count ) : fall_count ， down 。 - rise ( rise_count ) : rise_count ， up 。 - timeout :  。 - default_down :  ， true ， down ， false ， up 。 true ，   ，  。 - type ：  ，  - tcp ： tcp ，  ，  。 - ssl_hello ： SSL helloSSL hello 。 - http ： HTTP ，  。 - mysql : mysql ， greeting 。 - ajp ： AJPCping ， Cpong 。 - port :  。  ， 443 ，  80  。 0 ， server 。 Tengine - 1.4.0 。 Syntax : check_keepalive_requests request_numDefault : 1 Context : upstream  ， 1 ， Tengine1 。 Syntax : check_http_send http_packetDefault : GET / HTTP/1.0\\r\\n\\r\\n Context : upstream http 。  ，  HEAD  。  ， keep - alive ，  ： HEAD / HTTP/1.1\\r\\nConnection: keep-alive\\r\\n\\r\\n 。  ，  GET  ， urisize ， 1interval ，   。 Syntax : check_http_expect_alive [ http_2xx | http_3xx | http_4xx | http_5xx ] Default : http_2xx | http_3xxContext : upstream HTTP ， 2XX3XX 。 Syntax : check_shm_size sizeDefault : 1 MContext : http  ，  。 1M ， 1  ，  。 Syntax : check_status [ html|csv|json ] Default : check_status htmlContext : location  。 http 。 Tengine - 1.4.0  ，  。  : html 、 csv 、 json 。 html 。  ，  ‘ / status ’ URL ， format ，  ： / status ? format = html / status ? format = csv / status ? format = json status ，  ： / status ? format = html status = down / status ? format = csv status = up  ： http { server { location / nstatus { check_status ; access_log off ; #allow IP ; #deny all ; } } }  ， nginx 。  ，  realserver  。  ： realserver  ： wKiom1SZZXKQcPJTAAFnMqUEfBo238 . jpg  realserver  ： wKioL1SZZivDAzdWAAGTyIK9cS8558 . jpgOK ， nginx_upstream_check_module ，  tenginegithub ，  ： http : // tengine . taobao . org / document_cn / http_upstream_check_cn . html https : // github . com / yaoweibin / nginx_upstream_check_module  ，  2  ： 1 、 type 。 typetcp ，  ，  ，  ，   ，  。 2 、 check_http_send 。  GET / HTTP/1.0\\r\\n\\r\\n 。 http : // ip / name ，   check_http_send GET /name HTTP/1.0\\r\\n\\r\\n  。  ， keep - alive   ，  HEAD /name HTTP/1.1\\r\\nConnection: keep-alive\\r\\n\\r\\n 。 tomcat ，   check_http_sendhost ，  ，  ： check_http_send GET /mobileapi HTTP/1.0\\r\\n HOST www.redhat.sx \\r\\n\\r\\n ;  、 ngx_http_healthcheck_module  ， nginxngx_http_healthcheck_module  nginx 。 nginx_upstream_check_module  ，  。  ， ngx_http_healthcheck_module nginx1 .0.0  ， 1.1.0  ！  ，   ，  ，  ！  ，  ： http : // wiki . nginx . org / HttpHealthcheckModule https : // github . com / cep21 / healthcheck_nginx_upstreams / blob / master / README OK ！  ， 51 ！  ： http : // www . tuicool . com / articles / vuiQry   server { listen 80 ; server_name www.example.com ; ... } server { listen 80 ; server_name www.test.com ; ... }  ip  server { listen 10.0.0.88:80 ; root 88.com ; index index.html ; } server { listen 10.0.0.87:80 ; root 87.com ; index index.html ; }  server { listen 8093 ; location / { resolver 218 . 85 . 157 . 99 218 . 85 . 152 . 99 ; #dns resolver_timeout 30 s ; proxy_pass http : // $ host $ request_uri ; } access_log / var / log / proxy - aceess . log ; }  Nginx  CONNECT ， Https  ( ：， Gmail )  squid  CONNECT curl http : // www . baidu . com / - x 172 . 29 . 0 . 70 : 8093 curl https : // www . baidu . com - x 10 . 191 . 174 . 31 : 3128 squid rsync  export RSYNC_PROXY = 192.168.0.123:8080 http / ftp  export http_proxy = 192.168.0.123:8080 export FTP_PROXY = 192.168.0.123:8080 export HTTP_PROXY = 192.168.0.123:8080 export ftp_proxy = 192.168.0.123:8080  wget . wgetrc http - proxy = 192.168.0.123:8080 ftp - proxy = 192.168.0.123:8080 ， / etc / profile  ~/ . bash_profile  unset ======================= yum  export http_proxy = http : // 172 . 29 . 0 . 70 : 8093 yum install unset http_proxy (  ) ======================== pip  pip -- proxy http : // 172 . 29 . 0 . 70 : 8093 install - r pip_requirements . txt - i http : // pypi . douban . com / simple rsync  squid yum install squid vim / etc / squid / squid . conf acl localnet src 10 . 191 . 173 . 0 / 24 acl SSL_ports port 443 563 873 acl Safe_ports port 873 / etc / init . d / squid start  dns export RSYNC_PROXY = 192.168.0.123:3128 404 nginx+php ，。 nginx ？ ，：  /a/b/c ， /a/b/index.php，/c  PATH_INFO； ， /a/index.php，/b/c  PATH_INFO； ， /index.php，/a/b/c  PATH_INFO； ， 404. ， 🙂 server ，： index index.php index.html index.htm; location / { set $ path $ request_uri ; set $ path_info ; try_files $ uri $ uri / @404 ; } location @404 { if ( $ path ~ ^ (. * )( / . + ) $ ) { set $ path $ 1 / index . php ; set $ path_info $ 2 ; rewrite . * $ path last ; } return 404 ; } location ~ . + . php ( $ |/ ) { fastcgi_split_path_info ^ (. + . php )( / . + ) $ ; if ( $ path_info !~ . * ) { set $ path_info $ fastcgi_path_info ; } try_files $ fastcgi_script_name @404 php ; fastcgi_param PATH_INFO $ path_info ; fastcgi_index index . php ; include fastcgi . conf ; fastcgi_pass unix : / usr / local / var / run / php - fpm . sock ; fastcgi_connect_timeout 60 ; fastcgi_send_timeout 300 ; fastcgi_read_timeout 300 ; } location @404 php { if ( $ path = / index . php ) { return 404 ; } if ( $ path ~ ^ (. * )( / . + ) / index . php $ ) { set $ path_info $ 2 ; set $ path $ 1 / index . php ; rewrite . * $ path last ; } return 404 ; } yum # nginx . conf log_format  $upstream_cache_status  proxy_cache_path / data / cache levels = 1 : 2 keys_zone = rpm - cache : 50 m max_size = 20 g inactive = 365 d use_temp_path = off ; proxy_cache_path / data / repo levels = 1 : 2 keys_zone = repo - cache : 50 m max_size = 1 g inactive = 1 d use_temp_path = off ; proxy_redirect off ; proxy_connect_timeout 30 ; proxy_cache_valid 200 304 302 24 h ; proxy_cache_use_stale error timeout updating http_500 http_502 http_503 http_504 ; # add_header X - Cache - Status $ upstream_cache_status ; server_tokens off ; server { listen 80 ; root html ; index index . html index . htm index . php ; location / { return 404 ; } location ~ ( \\. iso | \\. filez | \\. dirtree | \\. png | \\. gif ) $ { return 403 ; } location / itv / { alias / data / itv / ; } location / base / { set $ key rpm - cache ; if ( $ uri ~* repodata ) { set $ key repo - cache ; } proxy_pass http : // mirrors . aliyun . com / centos / ; proxy_cache $ key ; } location / epel / { set $ key rpm - cache ; if ( $ uri ~* repodata ) { set $ key repo - cache ; } proxy_pass http : // mirrors . aliyun . com / epel / ; proxy_cache $ key ; } } repo  [ iTV ] name = iTV baseurl = http : // 192 . 168 . 41 . 21 / itv / $ releasever / $ba search / enabled = 1 gpgcheck = 0 [ iTV - base ] name = iTV - base baseurl = http : // 192 . 168 . 41 . 21 / base / $ releasever / os / $ba search / enabled = 1 gpgcheck = 0 [ iTV - updates ] name = iTV - updates baseurl = http : // 192 . 168 . 41 . 21 / base / $ releasever / updates / $ba search / enabled = 1 gpgcheck = 0 [ iTV - extras ] name = iTV - extras baseurl = http : // 192 . 168 . 41 . 21 / base / $ releasever / extras / $ba search / enabled = 1 gpgcheck = 0 [ iTV - epel ] name = iTV - epel baseurl = http : // 192 . 168 . 41 . 21 / epel / $ releasever / $ba search / enabled = 1 gpgcheck = 0 sslh2 # rpm - ivh https : // nginx . org / packages / rhel / 7 / x86_64 / RPMS / nginx - 1 . 14 . 0 - 1 . el7_4 . ngx . x86_64 . rpm # wget https : // raw . githubusercontent . com / Neilpang / acme . sh / master / acme . sh # sh acme . sh -- issue - d * . zxdr . tk - d zxdr . tk -- dns -- yes - I - know - dns - manual - mode - enough - go - ahead - please # add dns record # sh acme . sh -- issue - d * . zxdr . tk - d zxdr . tk -- dns -- yes - I - know - dns - manual - mode - enough - go - ahead - please -- renew user nobody ; worker_processes auto ; events { use epoll ; accept_mutex off ; worker_connections 65536 ; } http { include mime . types ; default_type application / octet - stream ; sendfile on ; keepalive_timeout 65 ; gzip on ; server_tokens off ; map $ http_upgrade $c onnection_upgrade { default upgrade ; close ; } # server { listen 80 default ; location / { root html; } } server { listen 0 . 0 . 0 . 0 : 443 ssl http2 default ; ssl on ; ssl_certificate / root / . acme . sh /*.zxdr.tk/fullchain.cer; ssl_certificate_key /root/.acme.sh/*.zxdr.tk/*.zxdr.tk.key; ssl_session_timeout 1d; ssl_session_cache shared:SSL:50m; ssl_session_tickets off; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256 ; ssl_prefer_server_ciphers on; add_header Strict-Transport-Security max-age=15768000; ssl_stapling on; ssl_stapling_verify on; resolver 8.8.8.8; location / { alias /tmp/down/; autoindex on; charset utf-8; autoindex_localtime on; autoindex_exact_size off; add_before_body /.nginx/header.html; add_after_body /.nginx/footer.html; } location /co/ { proxy_pass http://127.0.0.1:9090; proxy_http_version 1.1; proxy_buffering off; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $remote_addr; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $connection_upgrade; proxy_set_header Origin http://$host; #gzip off; } location /test/ { proxy_redirect off; proxy_pass http://127.0.0.1:7923; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection upgrade ; proxy_set_header Host $http_host; proxy_intercept_errors on; } location /stat { stub_status on; } error_page 400 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; } } }  add_header Access - Control - Allow - Origin * ; location / { if ( $ request_method = OPTIONS ) { add_header Access - Control - Allow - Origin * ; add_header Access - Control - Allow - Methods GET , POST , PUT , DELETE , OPTIONS ; return 204 ; } index index . php ; try_files $ uri @ rewriteapp ; } openresty https://openresty.org/package/centos/openresty.repo [openresty] name = Official OpenResty Open Source Repository for CentOS baseurl = https://openresty.org/package/centos/$releasever/$basearch skip_if_unavailable = False gpgcheck = 1 repo_gpgcheck = 1 gpgkey = https://openresty.org/package/pubkey.gpg enabled = 1 enabled_metadata = 1 proxyip upstream www . 264 . cn { ip_hash ; server serving - server1 . com : 80 ; server serving - server2 . com : 80 ; } server { listen www . 264 . cn : 80 ; server_name www . 264 . cn ; location / { proxy_pass http : // www . 264 . cn ; } proxy_set_header Host $ host ; proxy_set_header X - Real - IP $ remote_addr ; proxy_set_header X - Forwarded - For $ proxy_add_x_forwarded_for ; }  nginx ， php $ _SERVER [ HTTP_X_REAL_IP ] ip 。 proxy_set_header Host $ host ; proxy_set_header X - Real - IP $ remote_addr ; proxy_set_header X - Forwarded - For $ proxy_add_x_forwarded_for ; $ _SERVER [ REMOTE_ADDR ]，， REMOTE_ADDR 。  $ http_x_forwared_for  ip ， ip  ip ， REMOTE_ADDR  ip ，  $ http_x_forwarded_for  ip  REMOTE_ADDR : set $ realip $ remote_addr ; if ( $ http_x_forwarded_for ~ ^(\\d+\\.\\d+\\.\\d+\\.\\d+) ) { set $ realip $1 ; } fastcgi_param REMOTE_ADDR $ realip ; php-fpm yum install php - fpm systemctl start php - fpm root / var / www ; location / { index index . php ; } location ~ \\. php $ { fastcgi_pass 127 . 0 . 0 . 1 : 9000 ; fastcgi_index index . php ; fastcgi_param SCRIPT_FILENAME $d ocument_root $fa stcgi_script_name ; include fastcgi_params ; }","title":"nginx2"},{"location":"nginx2/#nginx","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 #!/bin/bash NGINX = /usr/local/nginx/sbin/nginx PID = /usr/local/nginx/logs/nginx.pid ##fun START () { pstree -p | grep nginx /dev/null 2 1 if [ -f $PID ] [ $? -eq 0 ] then echo Warnning: nginx already running else if [ -f $PID ] ; then rm -rf $PID fi $NGINX ##stdin OK if [ $? -eq 0 ] ; then echo -e nginx start\\t\\t\\t\\t [\\033[32m OK \\033[0m] else echo -e nginx start\\t\\t\\t\\t [\\033[31m Fail \\033[0m] fi fi } STOP () { pstree -p | grep nginx /dev/null 2 1 if [ -f $PID ] [ $? -eq 0 ] then killall -s QUIT nginx #check if [ $? -eq 0 ] ; then echo -e nginx stop\\t\\t\\t\\t [\\033[32m OK \\033[0m] fi else rm -rf /usr/local/nginx/logs/nginx.pid /dev/null 2 1 echo -e nginx stop\\t\\t\\t\\t [\\033[31m Fail \\033[0m] fi } RESTART () { STOP ; sleep 1 ; START } RELOAD () { if [ -f $PID ] [ $? -eq 0 ] then killall -s HUP $NGINX #reload check if [ $? -eq 0 ] ; then echo -e nginx reload\\t\\t\\t\\t [\\033[32m OK \\033[0m] fi else echo Warnning: nginx stop,please start nginx fi } STATUS () { elinks http://localhost -dump /dev/null 2 1 if [ $? -eq 0 ] ; then echo nginx running... else echo nging stop fi } #main case $1 in start ) START ;; stop ) STOP ;; restart ) RESTART ;; reload ) RELOAD ;; status ) STATUS ;; * ) echo USAGE: AVGE is start|stop|restart|reload|status ;; esac","title":"nginx"},{"location":"nginx2/#nginx_1","text":"Nginx (  engine x ) 、，， Apache   Web 。 Nginx 。 Nginx ， ，， Nginx ，； ，。 Nginx ，，。 .  ( 1 )  Nginx ，。， rpm 、 deb  ，。。，， ，；，、，  Nginx  yum 、 deb  (  ) 。 ，，、 uwsgi 、 memcache ，，， 。， Web 。， ，。。， PHP  fastcgi ，： . / configure \\ --prefix=/App/nginx \\ --with-http_stub_status_module \\ --without-http_auth_basic_module \\ --without-http_autoindex_module \\ --without-http_browser_module \\ --without-http_empty_gif_module \\ --without-http_geo_module \\ --without-http_limit_conn_module \\ --without-http_limit_req_module \\ --without-http_map_module \\ --without-http_memcached_module \\ --without-http_proxy_module \\ --without-http_referer_module \\ --without-http_scgi_module \\ --without-http_split_clients_module \\ --without-http_ssi_module \\ --without-http_upstream_ip_hash_module \\ --without-http_upstream_keepalive_module \\ --without-http_upstream_least_conn_module \\ --without-http_userid_module \\ --without-http_uwsgi_module \\ --without-mail_imap_module \\ --without-mail_pop3_module \\ --without-mail_smtp_module \\ --without-poll_module \\ --without-select_module \\ --with-cc-opt= -O2 ， ssi , shtml ， 17 ，  Nginx 。 ./configure --help ，。 ( 2 ) GCC  [】 GCC  5 ： - O0 : 。 - O  - O1 : 。。 - O2 :  - O1 。。 。 - Os :  - O2 . 5 ，， - O2 ，。 。，，。 - O3 :  - O2  - finline - functions 、 - funswitch - loops 、 - fgcse - after - reload 。 - O2  ，，，， (  ) ， ，。  GCC ，， GCC ， Nginx 。 - O2 ， 。 Nginx  auto / cc / gcc ， NGX_GCC_OPT ， GCC  - O ， NGX_GCC_OPT = -O2   . / configure  -- with - cc - opt = -O2 。 .   CPU 、、 IO  IO ， Nginx  nginx . conf ： ( 1 )  ： worker_processes  Nginx  web 。，（） CPU 、。 ， CPU （“ auto ”）。 Shell  ps ax | grep nginx: worker process | grep - v grep  Nginx ， ， Shell  cat / proc / cpuinfo | grep processor | wc - l  ， auto ， Nginx 。 ( 2 )  CPU ： worker_cpu_affinity  CPU ， Nginx  CPU 。 CPU ，， CPU  ， CPU ， CPU ， CPU 。 top 、 htop  CPU 。： 1 2 worker_processes 4 ; worker_cpu_affinity 0001 0010 0100 1000 ; ( 3 )  ： worker_rlimit_nofile  Nginx ，，。  Shell  Nginx 。 Nginx ，  Shell 。 Shell  ulimit - n  Shell  。 Linux  1024 ，，“ too many open files 。 Shell ： echo * - nofile 65536 / etc / security / limits . conf  / etc / profile ， Shell  Shell ： 1 echo ulimit -n 65536 / etc / profile Shell  Shell ： 1 ulimit - n 65536 ( 4 )  ： accept_mutex  accept_mutex  on ，，；  off ，， use  IO ， ，“”。 Web  Apache ， ，“”。 Nginx ， on 。 Off  ，。 ( 5 )  IO  ： use  Nginx  (  IO  ) 。， Linux 2 . 6 +   epoll ， FreeBSD  kqueue ， Nginx 。 ( 6 )  ： worker_connections  Nginx ，，。  worker_rlimit_nofile ， worker_rlimit_nofile 。 ( 7 )  ： open_file_cache ， off ，，，。  max = ，。， LRU (  ) ； inactive =  ，，。： open_file_cache max = 65536 inactive = 60 s 。 ： open_file_cache_valid  open_file_cache 。 ： open_file_cache_min_uses  open_file_cache  inactive ， 。， ，。 ( 8 )  ： access_log  error_log ， Nginx ， Nginx 。， IO 。 ， tmpfs ，， IO 。 access_log off 。，， IO ， ，，。 error  crit 。，，。 ( 9 )  Nginx  ： server_tokens “ Server ” Nginx 。 off ，，， ，，。 ( 10 )  ： gzip Nginx  gzip 。， gzip  CPU 。， gzip  Nginx  CPU ，，， js  css 、 xml 、 j son 、 html ，。 gzip on ，  75 % ，，。。 ， PDF 、，。 gzip ，， ，。 CPU  ，。 Web ，， HttpWatch 、 Firebug 。 ： gzip_comp_level ， 1  9 ，，， CPU ，。 9 ，，  CPU ，，，。 1 - 4 ，。 2 。 ： gzip_min_length ， bytes ，，。 1 k ，，  CPU ，。 ： gzip_types ， Nginx  conf  mime . types  Nginx ， text / html ， html htm shtml 。： gzip_types text / plain text / css application / json application / x - javascript text / xml application / xml application / xml + rss text / javascript 。 ( 11 )  ： expires  HTTP “ Expires ”“ Cache - Control ”。 Expires  Last-Modified 。 expires ，  Web ，。 URL  If-Modified-Since ，，，  http 304 ，；，。 ，，，，。，； - 1 ，。 expires ，。 Nginx ： location ~ . + \\. ( gif | jpg | jpeg | png | bmp | swf ) $ { expires 30 d ; } location ~ . + \\. ( js | css | xml | javascript | txt | csv ) $ { expires 30 d ; }  location  expires ，： location / static / { expires 30 d ; } ( 12 )  ： keepalive_timeout  Http  Keepalive ， TCP 、， TCP 。 ，；，，。 。， 0 。 ( 13 )  HTTP  、、、 Flash ， 。。 Web ， Web  ，。 Nginx  Concat  Google  PageSpeed  。，，。 Concat  ： https : // github . com / alibaba / nginx - http - concat / ， PageSpeed ： https : // github . com / pagespeed / ngx_pagespeed 。 ( 14 ) PHP  Nginx  PHP ， FastCGI  PHP ， Nginx 。 PHP 。 Nginx  FastCGI ，。 ： fastcgi_temp_path  FastCGI 。 ： fastcgi_cache_path  FastCGI 。， key  URL  MD5 。 fastcgi_temp_path ， fastcgi_cache_path  。 levels , 16 ； keys_zone ， key ； inactive ，，； max_size ， 。 fastcgi_temp_path  fastcgi_cache_path ，。： fastcgi_temp_path / tmp / fastcgi_temp ; fastcgi_cache_path / tmp / fastcgi_cache levels = 1 : 2 keys_zone = cache_fastcgi : 16 m inactive = 30 m max_size = 1 g ;  / tmp / fastcgi_temp  FastCGI ； / tmp / fastcgi_cache  FastCGI ； 16  16 ， 16  2  256 ； cache_fastcgi ， 128 MB ； 30 ；  1 GB 。 ： fastcgi_cache_key  FastCGI 。 FastCGI ， PHP  PHP  URL 。 ： fastcgi_cache_valid  Http 。 ： fastcgi_cache_min_uses  URL 。 ： fastcgi_cache_use_stale  FastCGI ，。 ： fastcgi_cache 。  nginx . conf ，： user nginx nginx ; worker_processes auto ; error_log logs / error . log error ; pid logs / nginx . pid ; worker_rlimit_nofile 65536 ; events { use epoll ; accept_mutex off ; worker_connections 65536 ; } http { include mime . types ; default_type text / html ; charset UTF - 8 ; server_names_hash_bucket_size 128 ; client_header_buffer_size 4 k ; large_client_header_buffers 4 32 k ; client_max_body_size 8 m ; open_file_cache max = 65536 inactive = 60 s ; open_file_cache_valid 80 s ; open_file_cache_min_uses 1 ; log_format main $remote_addr - $remote_user [$time_local] $request $status $body_bytes_sent $http_referer $http_user_agent $http_x_forwarded_for ; access_log logs / access . log main ; sendfile on ; server_tokens off ; fastcgi_temp_path / tmp / fastcgi_temp ; fastcgi_cache_path / tmp / fastcgi_cache levels = 1 : 2 keys_zone = cache_fastcgi : 128 m inactive = 30 m max_size = 1 g ; fastcgi_cache_key $ request_method : // $ host $ request_uri ; fastcgi_cache_valid 200 302 1 h ; fastcgi_cache_valid 301 1 d ; fastcgi_cache_valid any 1 m ; fastcgi_cache_min_uses 1 ; fastcgi_cache_use_stale error timeout http_500 http_503 invalid_header ; keepalive_timeout 60 ; gzip on ; gzip_min_length 1 k ; gzip_buffers 4 64 k ; gzip_http_version 1 . 1 ; gzip_comp_level 2 ; gzip_types text / plain text / css application / json application / x - javascript text / xml application / xml application / xml + rss text / javascript ; server { listen 80 ; server_name localhost ; index index . html ; root / App / web ; location ~ . + \\. ( php | php5 ) $ { fastcgi_pass unix : / tmp / php . sock ; fastcgi_index index . php ; include fastcgi . conf ; fastcgi_cache cache_fastcgi ; } location ~ . + \\. ( gif | jpg | jpeg | png | bmp | swf | txt | csv | doc | docx | xls | xlsx | ppt | pptx | flv ) $ { expires 30 d ; } location ~ . + \\. ( js | css | html | xml ) $ { expires 30 d ; } location / nginx - status { stub_status on ; allow 192 . 168 . 1 . 0 / 24 ; allow 127 . 0 . 0 . 1 ; deny all ; } } } .  Linux ， / Proc ， / etc / sysctl . conf 。  / Proc ，，。 Linux ，、， ： grep - q net.ipv4.tcp_max_tw_buckets / etc / sysctl . conf || cat / etc / sysctl . conf EOF ######################################## net . core . rmem_default = 262144 net . core . rmem_max = 16777216 net . core . wmem_default = 262144 net . core . wmem_max = 16777216 net . core . somaxconn = 262144 net . core . netdev_max_backlog = 262144 net . ipv4 . tcp_max_orphans = 262144 net . ipv4 . tcp_max_syn_backlog = 262144 net . ipv4 . tcp_max_tw_buckets = 10000 net . ipv4 . ip_local_port_range = 1024 65500 net . ipv4 . tcp_tw_recycle = 1 net . ipv4 . tcp_tw_reuse = 1 net . ipv4 . tcp_syncookies = 1 net . ipv4 . tcp_synack_retries = 1 net . ipv4 . tcp_syn_retries = 1 net . ipv4 . tcp_fin_timeout = 30 net . ipv4 . tcp_keepalive_time = 600 net . ipv4 . tcp_keepalive_intvl = 30 net . ipv4 . tcp_keepalive_probes = 3 net . ipv4 . tcp_mem = 786432 1048576 1572864 fs . aio - max - nr = 1048576 fs . file - max = 6815744 kernel . sem = 250 32000 100 128 vm . swappiness = 10 EOF sysctl - p  Linux ： http : // dongsong . blog . 51 cto . com / 916653 / 1631085 。 .  Nginx ， 7 。 。 ，，， CDN 。 Nginx ，  Nginx  LVS ， F5 （，）， Nginx 。  Varnish  Squid  CDN 。 Nginx  Memcache ， ， PHP  JPS ，，。 ： http : // www . ttlsa . com / nginx / web - server - nginx - optimization /","title":"Nginx"},{"location":"nginx2/#keepalived","text":"Keepalived  keepalived  layer3 , 4 , 5 ， 3 、 4  5 。 Keepalived   web ， web ，， Keepalived ， web ，  web  Keepalived  web ，，，  web  ： http : // www . keepalived . org keepalved ：  ： CentOS6 . 6 64  2  Nginx - Master 10 . 0 . 0 . 60 Nginx - Backup 10 . 0 . 0 . 61 VIP 10 . 0 . 0 . 62 ：， (  )   Nginx 《 OneinStack 》 Nginx  y ， n  Keepalived  Nginx - Master 、 Nginx - Backup ： cd ~/ oneinstack / src wget http : // www . keepalived . org / software / keepalived - 1 . 2 . 22 . tar . gz tar xzf keepalived - 1 . 2 . 22 . tar . gz cd keepalived - 1 . 2 . 22 . / configure -- prefix =/ usr / local / keepalived make make install  Keepalived  Nginx - Master 、 Nginx - Backup ： ln - s / usr / local / keepalived / etc / keepalived / etc / keepalived ln - s / usr / local / keepalived / etc / rc . d / init . d / keepalived / etc / rc . d / init . d / keepalived ln - s / usr / local / keepalived / etc / sysconfig / keepalived / etc / sysconfig / keepalived ln - s / usr / local / keepalived / sbin / keepalived / usr / bin / keepalived chkconfig keepalived on  Nginx - Master ， vi / etc / keepalived / keepalived . conf ! Configuration File for keepalived global_defs { notification_email { admin @ linuxeye . com #，，。  sendmail  } notification_email_from no - reply @ linuxeye . com # smtp_server 127 . 0 . 0 . 1 # smtp server  smtp_connect_timeout 30 # smtp server  router_id LVS_DEVEL # keepalived 。 } vrrp_script chk_nginx { script /usr/local/keepalived/sbin/check_nginx.sh # ngnix ， nginx   ngnix ， keepalived ，。 interval 2 # 2 s ， check_nginx . sh ， weight 2 #（ 0 ） 2 } vrrp_instance VI_1 { state MASTER # keepalived ， MASTER ， BACKUP  interface eth0 # HA  virtual_router_id 55 #，， vrrp 。 vrrp_instance  ， MASTER  BACKUP  priority 100 #，，， vrrp_instance ， MASTER   BACKUP  advert_int 1 # MASTER  BACKUP ， authentication { # auth_type PASS #， PASS  AH  auth_pass linuxeye #， vrrp_instance ， MASTER  BACKUP  } virtual_ipaddress { # IP ， IP ， 10 . 0 . 0 . 62 } track_script { chk_nginx # VRRP ， vrrp_script 。，。 } }  Nginx - Backup ， vi / etc / keepalived / keepalived . conf ! Configuration File for keepalived global_defs { notification_email { admin @ linuxeye . com #，，。  sendmail  } notification_email_from no - reply @ linuxeye . com # smtp_server 127 . 0 . 0 . 1 # smtp server  smtp_connect_timeout 30 # smtp server  router_id LVS_DEVEL # keepalived 。 } vrrp_script chk_nginx { script /usr/local/keepalived/sbin/check_nginx.sh # ngnix ， nginx   ngnix ， keepalived ，。 interval 2 # 2 s  weight 2 #（ 0 ） 2 } vrrp_instance VI_1 { state BACKUP # keepalived ， MASTER ， BACKUP  interface eth0 # HA  virtual_router_id 55 #，， vrrp 。 vrrp_instance ， MASTER  BACKUP  priority 50 #，，， vrrp_instance ， MASTER  BACKUP  advert_int 1 # MASTER  BACKUP ， nopreempt # nopreempt ， BACKUP  authentication { # auth_type PASS #， PASS  AH  auth_pass linuxeye #， vrrp_instance ， MASTER  BACKUP  } virtual_ipaddress { # IP ， IP ， 10 . 0 . 0 . 62 } track_script { chk_nginx # VRRP ， vrrp_script 。，。 } } ， vi / usr / local / keepalived / sbin / check_nginx . sh # !/ bin / bash if [ $(ps -ef | grep nginx : master process | grep -v grep ) == ] ;then # echo 1 / etc / init . d / nginx start sleep 5 if [ $(ps -ef | grep nginx : master process | grep -v grep ) == ] ;then / etc / init . d / keepalived stop # echo 2 fi fi  chmod + x / usr / local / keepalived / sbin / check_nginx . sh  service keepalived start # Nginx - Master service keepalived start # Nginx - Backup ip addr #2 ， IP  Nginx - Master service keepalived stop # Nginx - Backup ip addr #2 ， IP  Nginx - Backup service keepalived start # Nginx - Backup ip addr #2 ， IP  Nginx - Master  master  backup   master  backup  master ， master  master  VIP ， 。 nopreempt ， state  BACKUP ， HA  MASTER  backup  state  BACKUP  priority 。   2 ，， backup ， master ， vip  backup ， master ，  vip  2 ，？ ： master ， iptables  backup ， master keepalived iptables - F iptables - t nat - I PREROUTING - i eth0 - j DNAT -- to - destination 10 . 0 . 0 . 61 iptables - t nat - I POSTROUTING - o eth0 - j MASQUERADE","title":"keepalived"},{"location":"nginx2/#nginx_upstream_check_module","text":" 。  nginx  nginx_upstream_check_module ，  realserver  。  realserver  ，  。  tengine  ， tenginenginx ，  ： http : // tengine . taobao . org / 。  nginx_upstream_check_module [ root@localhost ~ ] # cd / usr / local / src wget https : // codeload . github . com / yaoweibin / nginx_upstream_check_module / zip / master unzip master [ root@localhost /usr/local/src ] # ll - d nginx_upstream_check_module - master drwxr - xr - x . 6 root root 4096 Dec 1 02 : 28 nginx_upstream_check_module - master 2 、 nginx [ root@localhost /usr/local/src ] # cd nginx - 1.6.0 # nginx [ root@localhost nginx-1.6.0 ] # patch - p1 .. / nginx_upstream_check_module - master / check_1 .5.12 + . patch [ root@localhost nginx-1.6.0 ] # . / configure --user=nginx --group=nginx --prefix=/usr/local/nginx-1.6.0 --with-http_ssl_module --with-openssl=/usr/local/src/openssl-0.9.8q --with-pcre=/usr/local/src/pcre-8.32 --add-module=/usr/local/src/nginx_concat_module/ --add-module=../nginx_upstream_check_module-master/ make (  ： make ，  ) [ root@localhost nginx-1.6.0 ] # mv / usr / local / nginx / sbin / nginx / usr / local / nginx / sbin / nginx - 1.6.0 . bak [ root@localhost nginx-1.6.0 ] # cp . / objs / nginx / usr / local / nginx / sbin / [ root@localhost nginx-1.6.0 ] # / usr / local / nginx / sbin / nginx - t #  [ root@localhost nginx-1.6.0 ] # kill - USR2 ` cat / usr / local / nginx / logs / nginx . pid ` 3 、 nginx . confupstream ，  ： upstream name { server 192.168.0.21 : 80 ; server 192.168.0.22 : 80 ; check interval = 3000 rise = 2 fall = 5 timeout = 1000 type = http ; }   ， name ， 3 ， 2 realserverup ，  5  ，  realserverdown ， 1 。  nginx_upstream_check_module  ： Syntax : check interval = milliseconds [ fall=count ] [ rise=count ] [ timeout=milliseconds ] [ default_down=true|false ] [ type=tcp|http|ssl_hello|mysql|ajp ] [ port=check_port ] Default :  ，  ： interval = 30000 fall = 5 rise = 2 timeout = 1000 default_down = true type = tcpContext : upstream  。  ： - interval ：  。 - fall ( fall_count ) : fall_count ， down 。 - rise ( rise_count ) : rise_count ， up 。 - timeout :  。 - default_down :  ， true ， down ， false ， up 。 true ，   ，  。 - type ：  ，  - tcp ： tcp ，  ，  。 - ssl_hello ： SSL helloSSL hello 。 - http ： HTTP ，  。 - mysql : mysql ， greeting 。 - ajp ： AJPCping ， Cpong 。 - port :  。  ， 443 ，  80  。 0 ， server 。 Tengine - 1.4.0 。 Syntax : check_keepalive_requests request_numDefault : 1 Context : upstream  ， 1 ， Tengine1 。 Syntax : check_http_send http_packetDefault : GET / HTTP/1.0\\r\\n\\r\\n Context : upstream http 。  ，  HEAD  。  ， keep - alive ，  ： HEAD / HTTP/1.1\\r\\nConnection: keep-alive\\r\\n\\r\\n 。  ，  GET  ， urisize ， 1interval ，   。 Syntax : check_http_expect_alive [ http_2xx | http_3xx | http_4xx | http_5xx ] Default : http_2xx | http_3xxContext : upstream HTTP ， 2XX3XX 。 Syntax : check_shm_size sizeDefault : 1 MContext : http  ，  。 1M ， 1  ，  。 Syntax : check_status [ html|csv|json ] Default : check_status htmlContext : location  。 http 。 Tengine - 1.4.0  ，  。  : html 、 csv 、 json 。 html 。  ，  ‘ / status ’ URL ， format ，  ： / status ? format = html / status ? format = csv / status ? format = json status ，  ： / status ? format = html status = down / status ? format = csv status = up  ： http { server { location / nstatus { check_status ; access_log off ; #allow IP ; #deny all ; } } }  ， nginx 。  ，  realserver  。  ： realserver  ： wKiom1SZZXKQcPJTAAFnMqUEfBo238 . jpg  realserver  ： wKioL1SZZivDAzdWAAGTyIK9cS8558 . jpgOK ， nginx_upstream_check_module ，  tenginegithub ，  ： http : // tengine . taobao . org / document_cn / http_upstream_check_cn . html https : // github . com / yaoweibin / nginx_upstream_check_module  ，  2  ： 1 、 type 。 typetcp ，  ，  ，  ，   ，  。 2 、 check_http_send 。  GET / HTTP/1.0\\r\\n\\r\\n 。 http : // ip / name ，   check_http_send GET /name HTTP/1.0\\r\\n\\r\\n  。  ， keep - alive   ，  HEAD /name HTTP/1.1\\r\\nConnection: keep-alive\\r\\n\\r\\n 。 tomcat ，   check_http_sendhost ，  ，  ： check_http_send GET /mobileapi HTTP/1.0\\r\\n HOST www.redhat.sx \\r\\n\\r\\n ;  、 ngx_http_healthcheck_module  ， nginxngx_http_healthcheck_module  nginx 。 nginx_upstream_check_module  ，  。  ， ngx_http_healthcheck_module nginx1 .0.0  ， 1.1.0  ！  ，   ，  ，  ！  ，  ： http : // wiki . nginx . org / HttpHealthcheckModule https : // github . com / cep21 / healthcheck_nginx_upstreams / blob / master / README OK ！  ， 51 ！  ： http : // www . tuicool . com / articles / vuiQry","title":"nginx_upstream_check_module"},{"location":"nginx2/#_1","text":" server { listen 80 ; server_name www.example.com ; ... } server { listen 80 ; server_name www.test.com ; ... }  ip  server { listen 10.0.0.88:80 ; root 88.com ; index index.html ; } server { listen 10.0.0.87:80 ; root 87.com ; index index.html ; }","title":""},{"location":"nginx2/#_2","text":"server { listen 8093 ; location / { resolver 218 . 85 . 157 . 99 218 . 85 . 152 . 99 ; #dns resolver_timeout 30 s ; proxy_pass http : // $ host $ request_uri ; } access_log / var / log / proxy - aceess . log ; }  Nginx  CONNECT ， Https  ( ：， Gmail )  squid  CONNECT curl http : // www . baidu . com / - x 172 . 29 . 0 . 70 : 8093 curl https : // www . baidu . com - x 10 . 191 . 174 . 31 : 3128 squid rsync  export RSYNC_PROXY = 192.168.0.123:8080 http / ftp  export http_proxy = 192.168.0.123:8080 export FTP_PROXY = 192.168.0.123:8080 export HTTP_PROXY = 192.168.0.123:8080 export ftp_proxy = 192.168.0.123:8080  wget . wgetrc http - proxy = 192.168.0.123:8080 ftp - proxy = 192.168.0.123:8080 ， / etc / profile  ~/ . bash_profile  unset ======================= yum  export http_proxy = http : // 172 . 29 . 0 . 70 : 8093 yum install unset http_proxy (  ) ======================== pip  pip -- proxy http : // 172 . 29 . 0 . 70 : 8093 install - r pip_requirements . txt - i http : // pypi . douban . com / simple rsync  squid yum install squid vim / etc / squid / squid . conf acl localnet src 10 . 191 . 173 . 0 / 24 acl SSL_ports port 443 563 873 acl Safe_ports port 873 / etc / init . d / squid start  dns export RSYNC_PROXY = 192.168.0.123:3128","title":""},{"location":"nginx2/#404","text":"nginx+php ，。 nginx ？ ，：  /a/b/c ， /a/b/index.php，/c  PATH_INFO； ， /a/index.php，/b/c  PATH_INFO； ， /index.php，/a/b/c  PATH_INFO； ， 404. ， 🙂 server ，： index index.php index.html index.htm; location / { set $ path $ request_uri ; set $ path_info ; try_files $ uri $ uri / @404 ; } location @404 { if ( $ path ~ ^ (. * )( / . + ) $ ) { set $ path $ 1 / index . php ; set $ path_info $ 2 ; rewrite . * $ path last ; } return 404 ; } location ~ . + . php ( $ |/ ) { fastcgi_split_path_info ^ (. + . php )( / . + ) $ ; if ( $ path_info !~ . * ) { set $ path_info $ fastcgi_path_info ; } try_files $ fastcgi_script_name @404 php ; fastcgi_param PATH_INFO $ path_info ; fastcgi_index index . php ; include fastcgi . conf ; fastcgi_pass unix : / usr / local / var / run / php - fpm . sock ; fastcgi_connect_timeout 60 ; fastcgi_send_timeout 300 ; fastcgi_read_timeout 300 ; } location @404 php { if ( $ path = / index . php ) { return 404 ; } if ( $ path ~ ^ (. * )( / . + ) / index . php $ ) { set $ path_info $ 2 ; set $ path $ 1 / index . php ; rewrite . * $ path last ; } return 404 ; }","title":"404"},{"location":"nginx2/#yum","text":"# nginx . conf log_format  $upstream_cache_status  proxy_cache_path / data / cache levels = 1 : 2 keys_zone = rpm - cache : 50 m max_size = 20 g inactive = 365 d use_temp_path = off ; proxy_cache_path / data / repo levels = 1 : 2 keys_zone = repo - cache : 50 m max_size = 1 g inactive = 1 d use_temp_path = off ; proxy_redirect off ; proxy_connect_timeout 30 ; proxy_cache_valid 200 304 302 24 h ; proxy_cache_use_stale error timeout updating http_500 http_502 http_503 http_504 ; # add_header X - Cache - Status $ upstream_cache_status ; server_tokens off ; server { listen 80 ; root html ; index index . html index . htm index . php ; location / { return 404 ; } location ~ ( \\. iso | \\. filez | \\. dirtree | \\. png | \\. gif ) $ { return 403 ; } location / itv / { alias / data / itv / ; } location / base / { set $ key rpm - cache ; if ( $ uri ~* repodata ) { set $ key repo - cache ; } proxy_pass http : // mirrors . aliyun . com / centos / ; proxy_cache $ key ; } location / epel / { set $ key rpm - cache ; if ( $ uri ~* repodata ) { set $ key repo - cache ; } proxy_pass http : // mirrors . aliyun . com / epel / ; proxy_cache $ key ; } } repo  [ iTV ] name = iTV baseurl = http : // 192 . 168 . 41 . 21 / itv / $ releasever / $ba search / enabled = 1 gpgcheck = 0 [ iTV - base ] name = iTV - base baseurl = http : // 192 . 168 . 41 . 21 / base / $ releasever / os / $ba search / enabled = 1 gpgcheck = 0 [ iTV - updates ] name = iTV - updates baseurl = http : // 192 . 168 . 41 . 21 / base / $ releasever / updates / $ba search / enabled = 1 gpgcheck = 0 [ iTV - extras ] name = iTV - extras baseurl = http : // 192 . 168 . 41 . 21 / base / $ releasever / extras / $ba search / enabled = 1 gpgcheck = 0 [ iTV - epel ] name = iTV - epel baseurl = http : // 192 . 168 . 41 . 21 / epel / $ releasever / $ba search / enabled = 1 gpgcheck = 0","title":"yum"},{"location":"nginx2/#sslh2","text":"# rpm - ivh https : // nginx . org / packages / rhel / 7 / x86_64 / RPMS / nginx - 1 . 14 . 0 - 1 . el7_4 . ngx . x86_64 . rpm # wget https : // raw . githubusercontent . com / Neilpang / acme . sh / master / acme . sh # sh acme . sh -- issue - d * . zxdr . tk - d zxdr . tk -- dns -- yes - I - know - dns - manual - mode - enough - go - ahead - please # add dns record # sh acme . sh -- issue - d * . zxdr . tk - d zxdr . tk -- dns -- yes - I - know - dns - manual - mode - enough - go - ahead - please -- renew user nobody ; worker_processes auto ; events { use epoll ; accept_mutex off ; worker_connections 65536 ; } http { include mime . types ; default_type application / octet - stream ; sendfile on ; keepalive_timeout 65 ; gzip on ; server_tokens off ; map $ http_upgrade $c onnection_upgrade { default upgrade ; close ; } # server { listen 80 default ; location / { root html; } } server { listen 0 . 0 . 0 . 0 : 443 ssl http2 default ; ssl on ; ssl_certificate / root / . acme . sh /*.zxdr.tk/fullchain.cer; ssl_certificate_key /root/.acme.sh/*.zxdr.tk/*.zxdr.tk.key; ssl_session_timeout 1d; ssl_session_cache shared:SSL:50m; ssl_session_tickets off; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256 ; ssl_prefer_server_ciphers on; add_header Strict-Transport-Security max-age=15768000; ssl_stapling on; ssl_stapling_verify on; resolver 8.8.8.8; location / { alias /tmp/down/; autoindex on; charset utf-8; autoindex_localtime on; autoindex_exact_size off; add_before_body /.nginx/header.html; add_after_body /.nginx/footer.html; } location /co/ { proxy_pass http://127.0.0.1:9090; proxy_http_version 1.1; proxy_buffering off; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $remote_addr; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $connection_upgrade; proxy_set_header Origin http://$host; #gzip off; } location /test/ { proxy_redirect off; proxy_pass http://127.0.0.1:7923; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection upgrade ; proxy_set_header Host $http_host; proxy_intercept_errors on; } location /stat { stub_status on; } error_page 400 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; } } }","title":"sslh2"},{"location":"nginx2/#_3","text":"add_header Access - Control - Allow - Origin * ; location / { if ( $ request_method = OPTIONS ) { add_header Access - Control - Allow - Origin * ; add_header Access - Control - Allow - Methods GET , POST , PUT , DELETE , OPTIONS ; return 204 ; } index index . php ; try_files $ uri @ rewriteapp ; }","title":""},{"location":"nginx2/#openresty","text":"https://openresty.org/package/centos/openresty.repo [openresty] name = Official OpenResty Open Source Repository for CentOS baseurl = https://openresty.org/package/centos/$releasever/$basearch skip_if_unavailable = False gpgcheck = 1 repo_gpgcheck = 1 gpgkey = https://openresty.org/package/pubkey.gpg enabled = 1 enabled_metadata = 1","title":"openresty"},{"location":"nginx2/#proxyip","text":"upstream www . 264 . cn { ip_hash ; server serving - server1 . com : 80 ; server serving - server2 . com : 80 ; } server { listen www . 264 . cn : 80 ; server_name www . 264 . cn ; location / { proxy_pass http : // www . 264 . cn ; } proxy_set_header Host $ host ; proxy_set_header X - Real - IP $ remote_addr ; proxy_set_header X - Forwarded - For $ proxy_add_x_forwarded_for ; }  nginx ， php $ _SERVER [ HTTP_X_REAL_IP ] ip 。 proxy_set_header Host $ host ; proxy_set_header X - Real - IP $ remote_addr ; proxy_set_header X - Forwarded - For $ proxy_add_x_forwarded_for ; $ _SERVER [ REMOTE_ADDR ]，， REMOTE_ADDR 。  $ http_x_forwared_for  ip ， ip  ip ， REMOTE_ADDR  ip ，  $ http_x_forwarded_for  ip  REMOTE_ADDR : set $ realip $ remote_addr ; if ( $ http_x_forwarded_for ~ ^(\\d+\\.\\d+\\.\\d+\\.\\d+) ) { set $ realip $1 ; } fastcgi_param REMOTE_ADDR $ realip ;","title":"proxyip"},{"location":"nginx2/#php-fpm","text":"yum install php - fpm systemctl start php - fpm root / var / www ; location / { index index . php ; } location ~ \\. php $ { fastcgi_pass 127 . 0 . 0 . 1 : 9000 ; fastcgi_index index . php ; fastcgi_param SCRIPT_FILENAME $d ocument_root $fa stcgi_script_name ; include fastcgi_params ; }","title":"php-fpm"},{"location":"open-falcon/","text":"install doc http : // book . open - falcon . org / zh_0_2 / intro / github https : // github . com / open - falcon / 、 yum install - y redis mysql - server yum install - y python - virtualenv yum install - y python - devel python - pip yum install - y openldap - devel yum install - y mysql - devel yum groupinstall Development tools / etc / init . d / redis start / etc / init . d / mysqld start chkconfig redis on chkconfig mysqld on 、 #  https : // github . com / open - falcon / falcon - plus / releases mkdir / usr / local / open - falcon / cd / usr / local / open - falcon / tar - zxf open - falcon - v0 . 2 . 1 . tar . gz #  mysql  grep - Ilr 3306 . / | xargs - n1 -- sed -i s/root:password/real_user:real_password/g ) 、 #  http : // 192 . 168 . 41 . 90 : 3000 / lianggy / falcon - dashboard #  / usr / local / open - falcon / dashboard  mkdir / usr / local / open - falcon / dashboard cd / usr / local / open - falcon / dashboard unzip falcon - dashboard - master . zip mv falcon - dashboard /* /usr/local/open-falcon/dashboard/ # mysql -h 127.0.0.1 -u root -p mysql-falcon.sql # python virtualenv ./env ./env/bin/pip install -r pip_requirements.txt -i http://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com --------------------- dashboard： rrd/config.py ， ## API_ADDR api API_ADDR = http://127.0.0.1:8080/api/v1 ## ，PORTAL_DB_*, root， ## ，ALARM_DB_*, root， #  cd /usr/local/open-falcon/ ./open-falcon start #  ./open-falcon check #  cd /usr/local/open-falcon/dashboard ./control start|stop 、 #  https://github.com/gaochao1/swcollector/releases /usr/local/open-falcon/switch cfg.example.json，cfg.json ipRange :[ #IP，IP，Ping，IPSNMP 192.168.56.101/32 , 192.168.56.102-192.168.56.120 ,#，ipping，ipsnmp。 172.16.114.233 ], hosts.json host { hosts : { 192.168.160 : test1 , 192.168.88.161 : test2 , 192.168.33.2 : test3 , 192.168.31.51 : test4 } } ./control start|stop 、 mkdir /usr/local/open-falcon/mail/ cd /usr/local/open-falcon/mail/ mv /usr/local/open-falcon/dashboard/mailapi.py . chmod 777 mailapi.py pip install flask -i http://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com vim mailapi.py mailfrom = test  mailserver = ip   nohup python mailapi.py 、 cd /usr/local/open-falcon/dashboard mv ipmi.sh ../ mv curl_time.py ../ cd ../ chmod 777 ipmi.sh curl_time.py vim ipmi.cfg   ip #  * * * * * /usr/local/open-falcon/dashboard/flow_alert.py # ipmi */ 10 * * * * / usr / local / open - falcon / ipmi . sh # curl  * * * * * / usr / local / open - falcon / curl_time . py #  0 1 * * * / usr / local / open - falcon / dashboard / backup . sh / dev / null 2 1  http : // ip : 8010 user : root pass : 123456 . test  open - falcon 。 report 、 #  / usr / local / open-falcon / dashboard2  mkdir / usr / local / open-falcon / dashboard2 cd / usr / local / open-falcon / dashboard2 unzip falcon-dashboard2-master . zip cp -r ../ dashboard / env . cp ../ dashboard / rrd / config . py ./ rrd / config . py  # ./ control start # http :// phantomjs . org / download . html  / usr / local / open-falcon / dashboard2 / phantomjs chmod 777 / usr / local / open-falcon / dashboard2 / phantomjs vim url . txt     Hh511 http :// 127 . 0 . 0 . 1 : 8011 / chart / big ? id = 1643 start = -86400 cf = start = -86400 graph_type = a  url  #  yum install tengine mkdir -pv / var / www / html / chmod 777 / var / www / html / server { listen 0.0.0.0:82 default ; location / { # /usr/share/nginx/ root /var/www/html/ ; index index.html index.htm ; } } # vim flow_report . sh HTTPURL = http://10.21.30.95:82/img/$DIR  echo ， / usr / local / bin / sendEmail -f test ， # chmod 777 flow_report . sh ./ flow_report . sh  30 7 , 19 * * * / usr / local / open-falcon / dashboard2 / flow_report . sh / dev / null 2 1 mailapi 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 #!/usr/bin/env python # coding:utf-8 import os from flask import Flask , request import logging import sys reload ( sys ) sys . setdefaultencoding ( utf8 ) mailfrom = test mailserver = 172.29.0.68 logging . basicConfig ( level = logging . INFO , format = %(levelname)s : %(message)s , filename = mailapi.log ) app = Flask ( __name__ ) @app.route ( / , methods = [ GET , POST ]) def index (): if request . method == POST : try : content = request . form . get ( content ) tos = request . form . get ( tos ) sub = request . form . get ( subject ) . replace ( [ , ) . replace ( ] , ) . split () ipcom = mysql -uroot -p123456.test falcon_portal -e select ip from host where hostname= %s | sed 1d % ( sub [ 2 ]) ip = os . popen ( ipcom ) . read () . strip () subject = sub [ 2 ] + ( + ip + ) + + sub [ 3 ] + + sub [ 1 ] logging . info ( subject ) except Exception , e : content = request . form . get ( content ) tos = request . form . get ( tos ) subject = request . form . get ( subject ) try : #mail = /usr/local/bin/sendEmail -f %s -t %s -u %s -m %s -s %s -o message-charset=GB2312 % (mailfrom, tos, subject.encode( gb2312 ), content.encode( gb2312 ), mailserver) mail = /usr/local/bin/sendEmail -f %s -t %s -u $(echo %s | iconv -f utf-8 -t GB2312) -m $(echo %s | iconv -f utf-8 -t GB2312) -s %s -o message-charset=GB2312 % ( mailfrom , tos , subject , content , mailserver ) result = os . popen ( mail ) . read () #logging.info(mail) logging . info ( result ) return result except Exception , e : return str ( e ) return OK if __name__ == __main__ : logging . info ( app . run ( host = 127.0.0.1 , threaded = True , port = 8900 , debug = False )) #app.run(host= 0.0.0.0 , threaded=True,port=8900, debug=True) plugin 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 #!/usr/bin/env bash api = http://127.0.0.1:1988/v1/push ts = $( date +%s ) endpoint = $( hostname ) curll = $( ps aux | grep curl | wc -l ) [ $curll -ge 5 ] exit stat = $( curl http://127.0.0.1:1988 -o /dev/null -s -w % { http_code } ) if [ $stat -ne 404 ] ; then exit fi netdev = ` sudo ifconfig -a | grep HWaddr | grep -v bond | awk {print $1} ` for each in $netdev do Link_detected = ` sudo ethtool $each | grep detected | awk -F: {print $2} | tr -d ` if [ $Link_detected = yes ] ; then speed = ` ethtool $each | grep Speed | awk -F: {print $2} | awk -FM {print $1} ` curl -s -X POST -d [{\\ metric\\ : \\ net.if.speed\\ , \\ endpoint\\ : \\ $endpoint \\ , \\ timestamp\\ : $ts ,\\ step\\ : 60,\\ value\\ : $speed ,\\ counterType\\ : \\ GAUGE\\ ,\\ tags\\ : \\ iface= $each \\ }] $api /dev/null fi done proce = $( ps -ef | wc -l ) curl -s -X POST -d [{\\ metric\\ : \\ proce.num\\ , \\ endpoint\\ : \\ $endpoint \\ , \\ timestamp\\ : $ts ,\\ step\\ : 60,\\ value\\ : $proce ,\\ counterType\\ : \\ GAUGE\\ ,\\ tags\\ : \\ \\ }] $api /dev/null proce_Z = $( ps -eo stat | egrep z|Z | wc -l ) curl -s -X POST -d [{\\ metric\\ : \\ proce.num\\ , \\ endpoint\\ : \\ $endpoint \\ , \\ timestamp\\ : $ts ,\\ step\\ : 60,\\ value\\ : $proce_Z ,\\ counterType\\ : \\ GAUGE\\ ,\\ tags\\ : \\ type=zombie\\ }] $api /dev/null user = $( w | awk /user/ {print $6} ) curl -s -X POST -d [{\\ metric\\ : \\ login.user\\ , \\ endpoint\\ : \\ $endpoint \\ , \\ timestamp\\ : $ts ,\\ step\\ : 60,\\ value\\ : $user ,\\ counterType\\ : \\ GAUGE\\ ,\\ tags\\ : \\ \\ }] $api /dev/null","title":"open-falcon"},{"location":"open-falcon/#install","text":"doc http : // book . open - falcon . org / zh_0_2 / intro / github https : // github . com / open - falcon / 、 yum install - y redis mysql - server yum install - y python - virtualenv yum install - y python - devel python - pip yum install - y openldap - devel yum install - y mysql - devel yum groupinstall Development tools / etc / init . d / redis start / etc / init . d / mysqld start chkconfig redis on chkconfig mysqld on 、 #  https : // github . com / open - falcon / falcon - plus / releases mkdir / usr / local / open - falcon / cd / usr / local / open - falcon / tar - zxf open - falcon - v0 . 2 . 1 . tar . gz #  mysql  grep - Ilr 3306 . / | xargs - n1 -- sed -i s/root:password/real_user:real_password/g ) 、 #  http : // 192 . 168 . 41 . 90 : 3000 / lianggy / falcon - dashboard #  / usr / local / open - falcon / dashboard  mkdir / usr / local / open - falcon / dashboard cd / usr / local / open - falcon / dashboard unzip falcon - dashboard - master . zip mv falcon - dashboard /* /usr/local/open-falcon/dashboard/ # mysql -h 127.0.0.1 -u root -p mysql-falcon.sql # python virtualenv ./env ./env/bin/pip install -r pip_requirements.txt -i http://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com --------------------- dashboard： rrd/config.py ， ## API_ADDR api API_ADDR = http://127.0.0.1:8080/api/v1 ## ，PORTAL_DB_*, root， ## ，ALARM_DB_*, root， #  cd /usr/local/open-falcon/ ./open-falcon start #  ./open-falcon check #  cd /usr/local/open-falcon/dashboard ./control start|stop 、 #  https://github.com/gaochao1/swcollector/releases /usr/local/open-falcon/switch cfg.example.json，cfg.json ipRange :[ #IP，IP，Ping，IPSNMP 192.168.56.101/32 , 192.168.56.102-192.168.56.120 ,#，ipping，ipsnmp。 172.16.114.233 ], hosts.json host { hosts : { 192.168.160 : test1 , 192.168.88.161 : test2 , 192.168.33.2 : test3 , 192.168.31.51 : test4 } } ./control start|stop 、 mkdir /usr/local/open-falcon/mail/ cd /usr/local/open-falcon/mail/ mv /usr/local/open-falcon/dashboard/mailapi.py . chmod 777 mailapi.py pip install flask -i http://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com vim mailapi.py mailfrom = test  mailserver = ip   nohup python mailapi.py 、 cd /usr/local/open-falcon/dashboard mv ipmi.sh ../ mv curl_time.py ../ cd ../ chmod 777 ipmi.sh curl_time.py vim ipmi.cfg   ip #  * * * * * /usr/local/open-falcon/dashboard/flow_alert.py # ipmi */ 10 * * * * / usr / local / open - falcon / ipmi . sh # curl  * * * * * / usr / local / open - falcon / curl_time . py #  0 1 * * * / usr / local / open - falcon / dashboard / backup . sh / dev / null 2 1  http : // ip : 8010 user : root pass : 123456 . test  open - falcon 。","title":"install"},{"location":"open-falcon/#report","text":"、 #  / usr / local / open-falcon / dashboard2  mkdir / usr / local / open-falcon / dashboard2 cd / usr / local / open-falcon / dashboard2 unzip falcon-dashboard2-master . zip cp -r ../ dashboard / env . cp ../ dashboard / rrd / config . py ./ rrd / config . py  # ./ control start # http :// phantomjs . org / download . html  / usr / local / open-falcon / dashboard2 / phantomjs chmod 777 / usr / local / open-falcon / dashboard2 / phantomjs vim url . txt     Hh511 http :// 127 . 0 . 0 . 1 : 8011 / chart / big ? id = 1643 start = -86400 cf = start = -86400 graph_type = a  url  #  yum install tengine mkdir -pv / var / www / html / chmod 777 / var / www / html / server { listen 0.0.0.0:82 default ; location / { # /usr/share/nginx/ root /var/www/html/ ; index index.html index.htm ; } } # vim flow_report . sh HTTPURL = http://10.21.30.95:82/img/$DIR  echo ， / usr / local / bin / sendEmail -f test ， # chmod 777 flow_report . sh ./ flow_report . sh  30 7 , 19 * * * / usr / local / open-falcon / dashboard2 / flow_report . sh / dev / null 2 1","title":"report"},{"location":"open-falcon/#mailapi","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 #!/usr/bin/env python # coding:utf-8 import os from flask import Flask , request import logging import sys reload ( sys ) sys . setdefaultencoding ( utf8 ) mailfrom = test mailserver = 172.29.0.68 logging . basicConfig ( level = logging . INFO , format = %(levelname)s : %(message)s , filename = mailapi.log ) app = Flask ( __name__ ) @app.route ( / , methods = [ GET , POST ]) def index (): if request . method == POST : try : content = request . form . get ( content ) tos = request . form . get ( tos ) sub = request . form . get ( subject ) . replace ( [ , ) . replace ( ] , ) . split () ipcom = mysql -uroot -p123456.test falcon_portal -e select ip from host where hostname= %s | sed 1d % ( sub [ 2 ]) ip = os . popen ( ipcom ) . read () . strip () subject = sub [ 2 ] + ( + ip + ) + + sub [ 3 ] + + sub [ 1 ] logging . info ( subject ) except Exception , e : content = request . form . get ( content ) tos = request . form . get ( tos ) subject = request . form . get ( subject ) try : #mail = /usr/local/bin/sendEmail -f %s -t %s -u %s -m %s -s %s -o message-charset=GB2312 % (mailfrom, tos, subject.encode( gb2312 ), content.encode( gb2312 ), mailserver) mail = /usr/local/bin/sendEmail -f %s -t %s -u $(echo %s | iconv -f utf-8 -t GB2312) -m $(echo %s | iconv -f utf-8 -t GB2312) -s %s -o message-charset=GB2312 % ( mailfrom , tos , subject , content , mailserver ) result = os . popen ( mail ) . read () #logging.info(mail) logging . info ( result ) return result except Exception , e : return str ( e ) return OK if __name__ == __main__ : logging . info ( app . run ( host = 127.0.0.1 , threaded = True , port = 8900 , debug = False )) #app.run(host= 0.0.0.0 , threaded=True,port=8900, debug=True)","title":"mailapi"},{"location":"open-falcon/#plugin","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 #!/usr/bin/env bash api = http://127.0.0.1:1988/v1/push ts = $( date +%s ) endpoint = $( hostname ) curll = $( ps aux | grep curl | wc -l ) [ $curll -ge 5 ] exit stat = $( curl http://127.0.0.1:1988 -o /dev/null -s -w % { http_code } ) if [ $stat -ne 404 ] ; then exit fi netdev = ` sudo ifconfig -a | grep HWaddr | grep -v bond | awk {print $1} ` for each in $netdev do Link_detected = ` sudo ethtool $each | grep detected | awk -F: {print $2} | tr -d ` if [ $Link_detected = yes ] ; then speed = ` ethtool $each | grep Speed | awk -F: {print $2} | awk -FM {print $1} ` curl -s -X POST -d [{\\ metric\\ : \\ net.if.speed\\ , \\ endpoint\\ : \\ $endpoint \\ , \\ timestamp\\ : $ts ,\\ step\\ : 60,\\ value\\ : $speed ,\\ counterType\\ : \\ GAUGE\\ ,\\ tags\\ : \\ iface= $each \\ }] $api /dev/null fi done proce = $( ps -ef | wc -l ) curl -s -X POST -d [{\\ metric\\ : \\ proce.num\\ , \\ endpoint\\ : \\ $endpoint \\ , \\ timestamp\\ : $ts ,\\ step\\ : 60,\\ value\\ : $proce ,\\ counterType\\ : \\ GAUGE\\ ,\\ tags\\ : \\ \\ }] $api /dev/null proce_Z = $( ps -eo stat | egrep z|Z | wc -l ) curl -s -X POST -d [{\\ metric\\ : \\ proce.num\\ , \\ endpoint\\ : \\ $endpoint \\ , \\ timestamp\\ : $ts ,\\ step\\ : 60,\\ value\\ : $proce_Z ,\\ counterType\\ : \\ GAUGE\\ ,\\ tags\\ : \\ type=zombie\\ }] $api /dev/null user = $( w | awk /user/ {print $6} ) curl -s -X POST -d [{\\ metric\\ : \\ login.user\\ , \\ endpoint\\ : \\ $endpoint \\ , \\ timestamp\\ : $ts ,\\ step\\ : 60,\\ value\\ : $user ,\\ counterType\\ : \\ GAUGE\\ ,\\ tags\\ : \\ \\ }] $api /dev/null","title":"plugin"},{"location":"other/","text":" “”。，， 。 ，、、、。， 。 ！“”，： ：“” ，，，、 ，  webserver ， DB ， cache ， cdn ， computing ， ， 、、。，  bug 。，，， ，，，， !?   ? ：“”  DBA  DB ， DBA ，“”，。， ，  DBA 。，， ，，！ ，，。 ：“” ？，，，， ？ ？？，， 。，， ，“”。 ，，，“”，“”，“ ”，， “”，“”，“”，“”。， ；，， ，。 ，，，，“” ，， ，，， 。 360 360   ---console [... document . getElementsByTagName ( * )]. forEach ( x = x . oncopy = function () {} ) teredo @ echo off net start ip helper netsh int ipv6 reset netsh int teredo set state default netsh int 6 to4 set state disable netsh int isatap set state disable :: netsh int teredo set state server = teredo . remlab . net netsh int teredo set state server = teredo . trex . fi netsh int ipv6 set teredo enterpriseclient netsh int ter set state enterpriseclient route DELETE :: / 0 netsh int ipv6 add route :: / 0 Teredo Tunneling Pseudo-Interface netsh int ipv6 set prefix 2002 :: / 16 30 1 netsh int ipv6 set prefix 2001 :: / 32 5 1 ipconfig / flushdns route print netsh int ipv6 show int netsh int ipv6 show teredo cmd win10  netsh interface Teredo set state disable netsh interface Teredo set state type = default netsh interface teredo set state enterpriseclient server = teredo . remlab . net ping - 6 ipv6 . test - ipv6 . com ping - 6 [ 2001 : 470 : 1 : 18 :: 125 ]  # coding=utf-8 # pip install baidu-aip from aip import AipSpeech APP_ID = 9953283 API_KEY = p3grxzGIU55uApjDO56vXVNE SECRET_KEY = sEFXAWrwPDackWSqo4tCsTtNNZlRlBiB # AipSpeech aipSpeech = AipSpeech ( APP_ID , API_KEY , SECRET_KEY ) def hecheng ( txt ): # result = aipSpeech . synthesis ( txt , zh , 1 , { vol : 5 , }) #  dict  if not isinstance ( result , dict ): with open ( audio.wav , wb ) as f : f . write ( result ) else : print result def shibie ( filePath , types = amr , rate = 16000 ): # with open ( filePath , rb ) as fp : file = fp . read () asr_result = aipSpeech . asr ( file , types , rate , { lan : zh , }) if asr_result [ err_msg ] == success. : # for i in asr_result[ result ]: # print i print asr_result [ result ][ 0 ] else : print asr_result hecheng (  ) miui https : // xiaomi . eu / community /  ROMS DOWNLOAD https : // xiaomi . eu / community / threads / 8 - 3 - 22 . 43708 / https : // dl . google . com / android / repository / platform - tools - latest - windows . zip https : // jaist . dl . sourceforge . net / project / xiaomi - eu - multilang - miui - roms / xiaomi . eu /  http : // sourceforge . mirrorservice . org / x / xi / xiaomi - eu - multilang - miui - roms / xiaomi . eu / ， md5 twrp MD5 1 a12d541c2a3d1e95448e62f6a20f4c8  MD5 77 e597db85858df9eef057c4fc6f202e  fastboot flash recovery twrp . img fastboot boot twrp . img  recovery ，“”， data ，， “”， data （ data ， rom ）， ，。，， recovery ，  bbr bbr https : // www . elrepo . org / rpm -- import https : // www . elrepo . org / RPM - GPG - KEY - elrepo . org rpm - Uvh http : // www . elrepo . org / elrepo - release - 7.0 - 3. el7 . elrepo . noarch . rpm yum -- enablerepo = elrepo - kernel install kernel - ml - y  rpm - qa | grep kernel  kernel - ml - 4. xx egrep ^ menuentry / etc / grub2 . cfg | cut - f 2 - d \\ CentOS Linux ( 4.16 . 2 - 1. el7 . elrepo . x86_64 ) 7 ( Core ) ，  grub2 - set - default 1 CentOS Linux ( 3.10 . 0 - 693.11 . 6. el7 . x86_64 ) 7 ( Core ) CentOS Linux ( 3.10 . 0 - 693. el7 . x86_64 ) 7 ( Core ) CentOS Linux ( 0 - rescue - c73a5ccf3b8145c3a675b64c4c3ab1d4 ) 7 ( Core )   4.16 echo net.core.default_qdisc = fq / etc / sysctl . conf echo net.ipv4.tcp_congestion_control = bbr / etc / sysctl . conf sysctl - p ， bbr sysctl - n net . ipv4 . tcp_available_congestion_control sysctl - n net . ipv4 . tcp_congestion_control lsmod | grep bbr  bbr  selinux aws  bbr yum remove amazon - ssm - agent postfix rpcbind update - motd irqbalance sysstat - y echo - e ListenAddress 0.0.0.0 \\n Port 17006 \\n PermitRootLogin yes / etc / ssh / sshd_config echo PS1= [\\e[31m\\u@\\e[36m\\d \\w] \\\\ $\\e[m / etc / profile systemctl restart sshd \\ cp - f / home / ec2 - user /. ssh / authorized_keys . ssh / \\ cp - f / usr / share / zoneinfo / Asia / Shanghai / etc / localtime userdel - r ec2 - user echo nohup /root/v2ray/v2ray / etc / rc . local chmod + x / etc / rc . d / rc . local crontab - l 0 0 * * * / root / v2ray / access . log ; find / var / log / - type f - mtime 1 - exec rm {} \\ ; chrome Windows 32 ： Canary  ： http : // www . google . com / chrome / eula . html ? platform = win extra = canarychannel standalone = 1 Dev ： http : // www . google . com / chrome / eula . html ? platform = win extra = devchannel standalone = 1 Beta ： http : // www . google . com / chrome / eula . html ? platform = win extra = betachannel standalone = 1 Stable ： http : // www . google . com / chrome / eula . html ? platform = win extra = stablechannel standalone = 1 crx https : // chrome - extension - downloader . com / how - does - it - work . php URL ： https : // clients2 . google . com / service / update2 / crx ? response = redirect prodversion = 49.0 x = id % 3 D ~~~~% 26 installsource % 3 Dondemand % 26 uc 4 （ ~~~~ ） ID 。  ， Google ， https : // chrome . google . com / webstore / detail / google - maps / lneaknkopdijkpnocmklfnjbeapigfbh 。 GoogleIDlneaknkopdijkpnocmklfnjbeapigfbh 。 Googlehttps : // clients2 . google . com / service / update2 / crx ? response = redirect prodversion = 49.0 x = id % 3 Dlneaknkopdijkpnocmklfnjbeapigfbh % 26 installsource % 3 Dondemand % 26 uc 。 extension_ [ version ] . crx 。 Googleextension_5_2_7 . crx ， Google5 .2.7 。  ， Linux ，。  Linux 。 ： CentOS （ 5 . 8 / 6 . 4 ）。 5 . 8  6 . 4 ，。 ：  ip 、、、 DNS   selinux ， iptables  sudo   yum     / var / spool / clientmqueue / ， inode   ssh ， root    ，   1 、 ip 、、、 DNS   IP ： [ root @ localhost ~ ]# vi / etc / sysconfig / network - scripts / ifcfg - eth0 DEVICE = eth0 # BOOTPROTO = static # IP  ： DHCP  IP  IPADDR = 192 . 168 . 1 . 113 # IP  NETMASK = 255 . 255 . 255 . 0 # ONBOOT = yes # GATEWAY = 192 . 168 . 1 . 1 [ root @ localhost ~ ]# cat / etc / sysconfig / network - scripts / ifcfg - eth0 DEVICE = eth0 BOOTPROTO = static IPADDR = 192 . 168 . 1 . 113 NETMASK = 255 . 255 . 255 . 0 ONBOOT = yes GATEWAY = 192 . 168 . 1 . 1 ： [ root @ localhost ~ ]# vi / etc / sysconfig / network HOSTNAME = c64 #， GATEWAY = 192 . 168 . 1 . 1 #, eth0 ，。 [ root @ localhost ~ ]# cat / etc / sysconfig / network HOSTNAME = c64 GATEWAY = 192 . 168 . 1 . 1  hostname c64 ，  DNS [ root @ localhost ~ ]# vi / etc / resolv . conf # DNS  nameserver 114 . 114 . 114 . 114 nameserver 8 . 8 . 8 . 8 [ root @ localhost ~ ]# cat / etc / resolv . conf # DNS  nameserver 114 . 114 . 114 . 114 nameserver 8 . 8 . 8 . 8 [ root @ localhost ~ ]# service network restart #， ， [ root @ localhost ~ ]# / etc / init . d / network restart 2 、 selinux ， iptables  selinux [ root @ c64 ~ ]# sed – i s/SELINUX=enforcing/SELINUX=disabled/g / etc / selinux / config #， 。 [ root @ c64 ~ ]# grep SELINUX = disabled / etc / selinux / config SELINUX = disabled # [ root @ c64 ~ ]# setenforce 0 # [ root @ c64 ~ ]# getenforce # selinux  Permissive  iptables [ root @ c64 ~ ]# iptables – F # [ root @ c64 ~ ]# iptables – L # Chain INPUT ( policy ACCEPT ) target prot opt source destination Chain FORWARD ( policy ACCEPT ) target prot opt source destination Chain OUTPUT ( policy ACCEPT ) target prot opt source destination [ root @ c64 ~ ]# / etc / init . d / iptables save # 3 、 sudo  [ root @ c64 ~ ]# useradd sunsky [ root @ c64 ~ ]# echo 123456 | passwd -- stdin sunsky history – c [ root @ c64 ~ ]# visudo  root ALL = ( ALL ) ALL ， sunsky ALL = ( ALL ) ALL 4 、 yum  yum ， rpm ，。 ：、  1 ：， linux 。  2 ： yum  [ root @ c64 ~ ]# cd / etc / yum . repos . d / [ root @ c64 yum . repos . d ]# / bin / mv CentOS - Base . repo CentOS - Base . repo . bak [ root @ c64 yum . repos . d ]# wget http : // mirrors . 163 . com / . help / CentOS6 - Base - 163 . repo ， yum  [ root @ c64 yum . repos . d ]# yum clean all # yum  [ root @ c64 yum . repos . d ]# yum makecache # yum   [ root @ c64 yum . repos . d ]# rpm -- import / etc / pki / rpm - gpg / RPM - GPG - KEY * # KEY  RPM [ root @ c64 yum . repos . d ]# yum upgrade - y #  [ root @ c64 yum . repos . d ]# yum install lrzsz ntpdate sysstat - y lrzsz ： ntpdate ： sysstat ： 5 、 [ root @ c64 ~ ]# echo */5 * * * * /usr/sbin/ntpdate time.windows.com /dev/null 2 1 / var / spool / cron / root [ root @ c64 ~ ]# echo */10 * * * * /usr/sbin/ntpdate time.nist.gov /dev/null 2 1 / var / spool / cron / root ： CentOS 6 . 4  6  / usr / sbin / ntpdate 5  / sbin / ntpdate ：，。， NTP Server 。 ，。 6 、  crond ， network ， syslog ， sshd 。（ Centos6 . 4  rsyslog ） [ root @ c64 ~ ]# for sun in ` chkconfig -- list | grep 3 : on | awk {print $1} ` ;do chkconfig --level 3 $sun off;done [ root @ c64 ~ ]# for sun in crond rsyslog sshd network ;do chkconfig --level 3 $sun on;done [ root @ c64 ~ ]# chkconfig -- list | grep 3 : on crond 0 : off 1 : off 2 : on 3 : on 4 : on 5 : on 6 : off network 0 : off 1 : off 2 : on 3 : on 4 : on 5 : on 6 : off rsyslog 0 : off 1 : off 2 : on 3 : on 4 : on 5 : on 6 : off sshd 0 : off 1 : off 2 : on 3 : on 4 : on 5 : on 6 : off 7 、 / var / spool / clientmqueue / ， inode  ， 6 . 4 ！ [ root @ c64 ~ ]# mkdir / server / scripts - p [ root @ c64 ~ ]# vi / server / scripts / spool_clean . sh # !/ bin / sh find / var / spool / clientmqueue / - type f - mtime + 30 | xargs rm - f  crontab  [ root @ c64 ~ ]# echo */30 * * * * /bin/sh /server/scripts/spool_clean.sh /dev/null 2 1 / var / spool / cron / root 8 、 ssh ， root  [ root @ c64 ~ ]# cp / etc / ssh / sshd_config / etc / ssh / sshd_config . bak [ root @ c64 ~ ]# vim / etc / ssh / sshd_config Port 52113 # ssh  PermitRootLogin no # root ， PermitEmptyPasswords no # UseDNS no # DNS [ root @ c64 ~ ]# / etc / init . d / sshd reload # [ root @ c64 ~ ]# netstat - lnt # [ root @ c64 ~ ]# lsof - i tcp : 52113 9 、 [ root @ c64 ~ ]# chattr + i / etc / passwd [ root @ c64 ~ ]# chattr + i / etc / inittab [ root @ c64 ~ ]# chattr + i / etc / group [ root @ c64 ~ ]# chattr + i / etc / shadow [ root @ c64 ~ ]# chattr + i / etc / gshadow  chattr ， [ root @ c64 ~ ]# / bin / mv / usr / bin / chattr / usr / bin /  10 、 [ root @ localhost ~ ]# ulimit – n # 1024 [ root @ localhost ~ ]# echo * - nofile 65535 / etc / security / limits . conf ，。 ： ulimit - SHn 65535  / etc / rc . local ， [ root @ c64 ~ ]# cat / etc / rc . local EOF # open files ulimit - HSn 65535 # stack size ulimit - s 65535 EOF ： 。，，。 ，。， 。 Unix 、 Linux 。 ，（ standard input ） 0 ，（ standard output ） 1 ，（ standard error ） 2 。 Unix ， shell ，，， 。 11 、， sed - i s#LANG= en_US.UTF-8 #LANG= zh_CN.GB18030 # / etc / sysconfig / i18n source / etc / sysconfig / i18n ：？ 。： GBK ， UTF - 8  1 - 4 ， MYSQL  UTF - 8 12 、 [ root @ c64 ~ ]# / etc / redhat - release [ root @ c64 ~ ]# / etc / issue 13 、 ： apache ， nginx ， squid  web ，。 [ root @ c64 ~ ]# vi / etc / sysctl . conf # by sun in 20131001 net . ipv4 . tcp_fin_timeout = 2 net . ipv4 . tcp_tw_reuse = 1 net . ipv4 . tcp_tw_recycle = 1 net . ipv4 . tcp_syncookies = 1 net . ipv4 . tcp_keepalive_time = 600 net . ipv4 . ip_local_port_range = 4000 65000 net . ipv4 . tcp_max_syn_backlog = 16384 net . ipv4 . tcp_max_tw_buckets = 36000 net . ipv4 . route . gc_timeout = 100 net . ipv4 . tcp_syn_retries = 1 net . ipv4 . tcp_synack_retries = 1 net . core . somaxconn = 16384 net . core . netdev_max_backlog = 16384 net . ipv4 . tcp_max_orphans = 16384 # iptables ，，。 net . ipv4 . ip_conntrack_max = 25000000 net . ipv4 . netfilter . ip_conntrack_max = 25000000 net . ipv4 . netfilter . ip_conntrack_tcp_timeout_established = 180 net . ipv4 . netfilter . ip_conntrack_tcp_timeout_time_wait = 120 net . ipv4 . netfilter . ip_conntrack_tcp_timeout_close_wait = 60 net . ipv4 . netfilter . ip_conntrack_tcp_timeout_fin_wait = 120 [ root @ localhost ~ ]# sysctl – p # ： CentOS6 . X  ip_conntrack ， nf_conntrack ， / etc / sysctl . conf ，  net . ipv4 . netfilter . ip_conntrack_max ， net . netfilter . nf_conntrack_max 。 ， 5 . 8 : net . ipv4 . ip_conntrack_max = 25000000 net . ipv4 . netfilter . ip_conntrack_max = 25000000 net . ipv4 . netfilter . ip_conntrack_tcp_timeout_established = 180 net . ipv4 . netfilter . ip_conntrack_tcp_timeout_time_wait = 120 net . ipv4 . netfilter . ip_conntrack_tcp_timeout_close_wait = 60 net . ipv4 . netfilter . ip_conntrack_tcp_timeout_fin_wait = 120  6 . 4 : net . nf_conntrack_max = 25000000 net . netfilter . nf_conntrack_max = 25000000 net . netfilter . nf_conntrack_tcp_timeout_established = 180 net . netfilter . nf_conntrack_tcp_timeout_time_wait = 120 net . netfilter . nf_conntrack_tcp_timeout_close_wait = 60 net . netfilter . nf_conntrack_tcp_timeout_fin_wait = 120 ，： 1 、 5 . 8  error : net.ipv4.ip_conntrack_max is an unknown key error : net.ipv4.netfilter.ip_conntrack_max is an unknown key error : net.ipv4.netfilter.ip_conntrack_tcp_timeout_established is an unknown key error : net.ipv4.netfilter.ip_conntrack_tcp_timeout_time_wait is an unknown key error : net.ipv4.netfilter.ip_conntrack_tcp_timeout_close_wait is an unknown key error : net.ipv4.netfilter.ip_conntrack_tcp_timeout_fin_wait is an unknown key  ip_conntrack ，，，  ip_conntrack modprobe ip_conntrack echo modprobe ip_conntrack / etc / rc . local 2 、 6 . 4  error : net.nf_conntrack_max is an unknown key error : net.netfilter.nf_conntrack_max is an unknown key error : net.netfilter.nf_conntrack_tcp_timeout_established is an unknown key error : net.netfilter.nf_conntrack_tcp_timeout_time_wait is an unknown key error : net.netfilter.nf_conntrack_tcp_timeout_close_wait is an unknown key error : net.netfilter.nf_conntrack_tcp_timeout_fin_wait is an unknown key  ip_conntrack ，，，  ip_conntrack modprobe nf_conntrack echo modprobe nf_conntrack / etc / rc . local 3 、 6 . 4  error : net.bridge.bridge-nf-call-ip6tables is an unknown key error : net.bridge.bridge-nf-call-iptables is an unknown key error : net.bridge.bridge-nf-call-arptables is an unknown key  bridge ， ip_conntrack modprobe bridge echo modprobe bridge / etc / rc . local ， Linux ， 13 。 io socket ， ： huangguisu 1 .  ， ( Sync ) /  ( Async ) ， ( Block ) /  ( Unblock ) ： ： ，，，。,。  B / S （）： -  -   ： 。，。，、 。  ajax （）:  - （） -   ，（，， cpu ，）。 。 ，。，， 。 ， socket  recv ，，，。， 。  ，，，。  ，。， API  ，，。，。 select  。 1 . ，，，。 2 . ，，，（） 3 . ， （），（），。 4 . ， （），（）， select   IO  IO ：！  IO  IO ：！  c / s ： ： -  -  ： - （） -   SOCKET 。 ,,,,。 ,,, ; , I / O , ( ,  ) ,, I / O ,,。 (   ) 1 . Linux  I / O  1 )  I / O （ blocking I / O ） 2 )  I / O （ nonblocking I / O ） 3 ) I / O  ( select  poll ) （ I / O multiplexing ） 4 )  I / O （ signal driven I / O ( SIGIO ) ） 5 )  I / O （ asynchronous I / O ( the POSIX aio_functions ) ） ， IO 。  I / O ： ：，  IO ，，。 ，….，, IO 。  I / O ： recv () / recvfrom （），。  recv () ，。，。， ，。， recv () ，， recv () 。  socket ()  WSASocket () ，。 Windows Sockets API ， ，。  Windows Sockets API 。， bind () 、 listen () ， 。 Windows Sockets API : 1 ．： recv () 、 recvfrom () 、 WSARecv ()  WSARecvfrom () 。。 ，。 2 ．： send () 、 sendto () 、 WSASend ()  WSASendto () 。。 ，，。 3 ．： accept ()  WSAAcept () 。，。， 。 4 ．： connect ()  WSAConnect () 。 TCP ，，。 ，。 TCP 。 　　，，。，， 。 ，。“ - ”， 、，。 ，，  IO  ： IO  IO （，）；，；  SOCKET ， I / O ，，。 I / O ，，，。，  CPU 。  SOCKET ，： Windows Sockets API ，，。， 。， recv () 。 recv () ，。 ， WSAEWOULDBLOCK 。 recv () ，，， recv ()  ，。  socket ()  WSASocket () ，。， ioctlsocket () ， 。 Linux : fcntl () . ， Windows Sockets API ，。，“”，  WSAEWOULDBLOCK 。。，，。  Windows Sockets API ， WSAEWOULDBLOCK 。，  bind () ，。， WSAStartup () ，， 。 ， ioctlsocket () ， WSAAsyncselect ()  WSAEventselect () 。 ，。 　　， WSAEWOULDBLOCK 。，“”。 ，。， While  recv () ， 1024  。。 ， MSG_PEEK  recv () 。，。 ， recv () ，。，“ I / O ” 。 ，。，， Windows Sockets API  ， WSAEWOULDBLOCK 。，。 ，，，，。， ，。，“ I / O ”，， 。 IO ： ： select  epoll ； IO ，，， IO ； IO  ； I / O  select 、 poll 、 epoll ，， I / O ， I / O 。， I / O ，， I / O 。  IO ：，；  I / O ,，。， SIGIO ，  I / O 。  IO  ：。 ，。，、   IO ， IO 。  IO 。 IO  select 。 5  I / O ： 1 . select 、 poll 、 epoll  epoll  select  I / O 。 Linux ， epoll  Linux ， select  POSIX ， select ： select  fd 。： 1 、  fd ，。 ， cat / proc / sys / fs / file - max 。 32  1024 。 64  2048 . 2 、  socket ，，： ， select ()  FD_SETSIZE  Socket , Socket ,。  CPU 。，，，， epoll  kqueue 。 3 、 fd ， poll ： poll  select ，， fd ， ， fd ，，， fd 。 。 ，，： 1 、 fd ，。 2 、 poll “”， fd ，， poll  fd 。 epoll : epoll ，， fd ，。， epoll “”， epoll_ctl  fd ， fd ， callback  fd ， epoll_wait  epoll ： 1 、， FD  1024 （ 1 G  10 ）； 2 、，， FD 。 FD  callback ；  Epoll “”，，， Epoll  select  poll 。 3 、 ， mmap () ； epoll  mmap 。 select 、 poll 、 epoll ： 1 、 select  FD_SETSIZE ， 32 （ 32 ， 32 * 32 ， 64  FD_SETSIZE  32 * 64 ），，，，。 poll poll  select ，， epoll ，， 1 G  10 ， 2 G  20  2 、 FD  IO  select ， FD “”。 poll  epoll  epoll  fd  callback ， socket  callback ， socket ，  epoll ， socket ，。 3 、  select ， poll  epoll epoll 。 ： ， select ， poll ， epoll 。 1 、 epoll ，， select  poll  epoll ， epoll  。 2 、 select 。，， ： http : // blog . csdn . net / jay900323 / article / details / 18141217 network Network 1 、 NIC  （ 1 ）、 socket  ，   ： 1 、 sock ls – l / tmp / mysql . sock  ，  。 2 、 sock （  ） （ 1 ）、 IP   IP  （ 2 ）、 IP （ 3 ）、 mysqltcp （ 4 ）、 socket buffer  （ 5 ）、 core  ， IPV4tcp （ 6 ）、 tcp ，  （ 7 ）、 tcp_mem sk_buffer ，  ： 4 KB ， 32  ： 900 M （ 8 ）、  ， tcp_mem ，  ，  （ 9 ）、  =  *  * 1024 * 1024 （  ） （ 10 ）、  ，  2 、 TCP （ 1 ）、  ， established （ 2 ）、  ， syn （ 3 ）、 Time_wait ， Close_wait （ 4 ）、 established =  + somaxconn （  ） （ 5 ）、  ，  ，  （ apachenginx . php hash ） 3 、  ： yum install iptraf  iptraf mtr IP  ----cacti cactiez ：  ，  ，  ，  。 cactiez （  ） net - snmp - utils net - snmp snmp ：  port ： 161 cactiez ： cd / var / www / html / rra cactiez ： cd / var / www / html / scripts log : / var / www / html / log  ： snmp ： vim / etc / snmp / snmpd . conf rocommunity public 192.168.18.0 / 24 # （ IP ） syslocation China . beijing # syscontact Root haha @vfast . com #   snmp : service snmpd start cactiezip  snmpwalk - v 2 c - c public 192.168.18.96 .1.3.6.1.4.1.2021.4.4.0 4 、  linuxTCP ，  ， linux ，  ，  。 （ 1 ）、 linuxtcp ，  cat / proc / sys / net / ipv4 / tcp_mem （ 2 ）、  （  ） cat / proc / sys / net / core / rmem_default cat / proc / sys / net / core / rmem_max （ 3 ）、  （  ） cat / proc / sys / net / core / wmem_default cat / proc / sys / net / core / wmem_max （ 4 ）、 socket buffer  cat / proc / sys / net / core / optmem_max 1 12MB ，  ， tcp   ： rmem_maxwmem_max128KB ，  ， webdns ，   ，  （ 1 ）、  echo ‘ net . core . wmem_max = 12582912 ’ / etc / sysctl . conf echo ‘ net . core . rmem_max = 12582912 ’ / etc / sysctl . conf （ 2 ）、 tcp echo ‘ net . ipv4 . tcp_rmem = 10240 87380 12582912 ’ / etc / sysctl . conf echo ‘ net . ipv4 . tcp_wmem = 10240 87380 12582912 ’ / etc / sysctl . conf （ 3 ）、 window scaling echo ‘ net . ipv4 . tcp_window_scaling = 1 ’ / etc / sysctl . conf （ 4 ）、  （ RFC 1323 ） tcp12 echo ‘ net . ipv4 . tcp_timestamps = 1 ’ / etc / sysctl . conf （ 5 ）、  echo ‘ net . ipv4 . tcp_sock = 1 ’ / etc / sysctl . conf （ 6 ）、 tcp ， snd_sthresh ， snd_cwnd ， srtt dst_entry ， dst_rntey ，  ，  echo ‘ net . ipv4 . tcp_no_metrics_save = 1 ’ / etc / sysctl . conf （ 7 ）、  ，  echo ‘ net . core . netdev_max_backlog = 5000 ’ / etc / sysctl . conf （ 8 ）、  sysctl – p tcpdump tcpdump - ni eth0 2  ， linux （ 2.6 kernel ）  ，  ，  （ 1 ）、 / proc / sys / net / core / wmem_max socketbuffer ，  ： 873200 （ 2 ）、 / proc / sys / net / core / rmem_max socketbuffer ，  ： 873200 （ 3 ）、 / proc / sys / net / ipv4 / tcp_wmem Tcpbuffer ，  ： 8192 436600 873200 （ 4 ）、 / proc / sys / net / ipv4 / tcp_rmem Tcpbuffer ，  ： 32768 436600 873200 （ 5 ）、 / proc / sys / net / ipv4 / tcp_mem 3 ，  ： net . ipv4 . tcp_mem [ 0 ] ：  ， tcp net . ipv4 . tcp_mem [ 1 ] ：  ，  net . ipv4 . tcp_mem [ 2 ] ：  ， tcpsocket  ，  ： 4 KB  ： 786432 1048576 1572864 （ 6 ）、 / proc / sys / net / core / netdev_max_backlog  ， 300 ，  ，  ， 1000 （ 7 ）、 / proc / sys / net / core / somaxconn Listen ()  ，  ， 128 ，  ，  ， 256 （ 8 ）、 / proc / sys / net / core / optmem_max socket buffer  ， 10K （ 9 ）、 / proc / sys / net / ipv4 / tcp_max_syn_backlog syn ， 1024 ，  ，  ， 2048 （ 10 ）、 / proc / sys / net / ipv4 / tcp_retrises2 tcp ， 15 ， 15 ， 5 ，  （ 11 ）、 / proc / sys / net / ipv4 / tcp_keepalive_time / proc / sys / net / ipv4 / tcp_keepalive_intvl / proc / sys / net / ipv4 / tcp_keepalive_probes 3tcp keepalive ，  ： tcp_keepalive_time = 7200 seconds ( 2 hours ) tcp_keepalive_probes = 9 tcp_keepalive_intvl = 75 seconds tcpidle 2  ， probe probe 9  （ 75 ）  ，  ，   ，  ，  ： tcp_keepalive_time = 1800 seconds tcp_keepalive_probes = 3 tcp_keepalive_intvl = 30 seconds （ 12 ）、 / proc / sys / net / ipv4 / ip_local_range  ， 32768 61000  io_mem ：  ： ulimit - SHn 65535 ： vim / etc / security / limits . conf * soft nofile 65535 * hard nofile 65535 io  noop ssd ， cpu anticipatory ， deadline ， cfg ， cat / sys / block / sda / queue / scheduler noop anticipatory deadline [ cfq ]  echo deadline / sys / block / sda / queue / scheduler ： vim / boot / grub / menu . lst kernel / boot / vmlinuz - 2 . 6 . 18 - 8 . el5 ro root = LABEL =/ elevator = deadline rhgb quiet ：  sync echo 3 / proc / sys / vm / drop_caches ： vim / etc / sysctl . conf net . ipv4 . tcp_keepalive_intvl = 75 ，， 75 。 net . ipv4 . tcp_keepalive_probes = 9 ， TCP  keepalive ， 9 . tcp_keepalive_intvl  keepalive 。 net . ipv4 . tcp_keepalive_time = 7200  keepalive ， TCP  keepalive ， 2 。 net . ipv4 . tcp_syn_retries = 5  SYN 。 net . ipv4 . tcp_synack_retries = 5 ， SYN  SYN  ACK 。。  SYN + ACK 。 net . ipv4 . tcp_syncookies = 1  SYN cookies 。 SYN ， cookies ， SYN ， 0 ，； net . ipv4 . tcp_tw_reuse = 1 。 TIME - WAIT sockets  TCP ， 0 ，； net . ipv4 . tcp_tw_recycle = 1  TCP  TIME - WAIT sockets ， 0 ，。 net . ipv4 . tcp_fin_timeout = 30  TIMEOUT  sysctl - p ","title":"other"},{"location":"other/#_1","text":"“”。，， 。 ，、、、。， 。 ！“”，： ：“” ，，，、 ，  webserver ， DB ， cache ， cdn ， computing ， ， 、、。，  bug 。，，， ，，，， !?   ? ：“”  DBA  DB ， DBA ，“”，。， ，  DBA 。，， ，，！ ，，。 ：“” ？，，，， ？ ？？，， 。，， ，“”。 ，，，“”，“”，“ ”，， “”，“”，“”，“”。， ；，， ，。 ，，，，“” ，， ，，， 。","title":""},{"location":"other/#360","text":"360   ---console [... document . getElementsByTagName ( * )]. forEach ( x = x . oncopy = function () {} )","title":"360"},{"location":"other/#teredo","text":"@ echo off net start ip helper netsh int ipv6 reset netsh int teredo set state default netsh int 6 to4 set state disable netsh int isatap set state disable :: netsh int teredo set state server = teredo . remlab . net netsh int teredo set state server = teredo . trex . fi netsh int ipv6 set teredo enterpriseclient netsh int ter set state enterpriseclient route DELETE :: / 0 netsh int ipv6 add route :: / 0 Teredo Tunneling Pseudo-Interface netsh int ipv6 set prefix 2002 :: / 16 30 1 netsh int ipv6 set prefix 2001 :: / 32 5 1 ipconfig / flushdns route print netsh int ipv6 show int netsh int ipv6 show teredo cmd win10  netsh interface Teredo set state disable netsh interface Teredo set state type = default netsh interface teredo set state enterpriseclient server = teredo . remlab . net ping - 6 ipv6 . test - ipv6 . com ping - 6 [ 2001 : 470 : 1 : 18 :: 125 ]","title":"teredo"},{"location":"other/#_2","text":"# coding=utf-8 # pip install baidu-aip from aip import AipSpeech APP_ID = 9953283 API_KEY = p3grxzGIU55uApjDO56vXVNE SECRET_KEY = sEFXAWrwPDackWSqo4tCsTtNNZlRlBiB # AipSpeech aipSpeech = AipSpeech ( APP_ID , API_KEY , SECRET_KEY ) def hecheng ( txt ): # result = aipSpeech . synthesis ( txt , zh , 1 , { vol : 5 , }) #  dict  if not isinstance ( result , dict ): with open ( audio.wav , wb ) as f : f . write ( result ) else : print result def shibie ( filePath , types = amr , rate = 16000 ): # with open ( filePath , rb ) as fp : file = fp . read () asr_result = aipSpeech . asr ( file , types , rate , { lan : zh , }) if asr_result [ err_msg ] == success. : # for i in asr_result[ result ]: # print i print asr_result [ result ][ 0 ] else : print asr_result hecheng (  )","title":""},{"location":"other/#miui","text":"https : // xiaomi . eu / community /  ROMS DOWNLOAD https : // xiaomi . eu / community / threads / 8 - 3 - 22 . 43708 / https : // dl . google . com / android / repository / platform - tools - latest - windows . zip https : // jaist . dl . sourceforge . net / project / xiaomi - eu - multilang - miui - roms / xiaomi . eu /  http : // sourceforge . mirrorservice . org / x / xi / xiaomi - eu - multilang - miui - roms / xiaomi . eu / ， md5 twrp MD5 1 a12d541c2a3d1e95448e62f6a20f4c8  MD5 77 e597db85858df9eef057c4fc6f202e  fastboot flash recovery twrp . img fastboot boot twrp . img  recovery ，“”， data ，， “”， data （ data ， rom ）， ，。，， recovery ， ","title":"miui"},{"location":"other/#bbr","text":"bbr https : // www . elrepo . org / rpm -- import https : // www . elrepo . org / RPM - GPG - KEY - elrepo . org rpm - Uvh http : // www . elrepo . org / elrepo - release - 7.0 - 3. el7 . elrepo . noarch . rpm yum -- enablerepo = elrepo - kernel install kernel - ml - y  rpm - qa | grep kernel  kernel - ml - 4. xx egrep ^ menuentry / etc / grub2 . cfg | cut - f 2 - d \\ CentOS Linux ( 4.16 . 2 - 1. el7 . elrepo . x86_64 ) 7 ( Core ) ，  grub2 - set - default 1 CentOS Linux ( 3.10 . 0 - 693.11 . 6. el7 . x86_64 ) 7 ( Core ) CentOS Linux ( 3.10 . 0 - 693. el7 . x86_64 ) 7 ( Core ) CentOS Linux ( 0 - rescue - c73a5ccf3b8145c3a675b64c4c3ab1d4 ) 7 ( Core )   4.16 echo net.core.default_qdisc = fq / etc / sysctl . conf echo net.ipv4.tcp_congestion_control = bbr / etc / sysctl . conf sysctl - p ， bbr sysctl - n net . ipv4 . tcp_available_congestion_control sysctl - n net . ipv4 . tcp_congestion_control lsmod | grep bbr  bbr  selinux aws  bbr yum remove amazon - ssm - agent postfix rpcbind update - motd irqbalance sysstat - y echo - e ListenAddress 0.0.0.0 \\n Port 17006 \\n PermitRootLogin yes / etc / ssh / sshd_config echo PS1= [\\e[31m\\u@\\e[36m\\d \\w] \\\\ $\\e[m / etc / profile systemctl restart sshd \\ cp - f / home / ec2 - user /. ssh / authorized_keys . ssh / \\ cp - f / usr / share / zoneinfo / Asia / Shanghai / etc / localtime userdel - r ec2 - user echo nohup /root/v2ray/v2ray / etc / rc . local chmod + x / etc / rc . d / rc . local crontab - l 0 0 * * * / root / v2ray / access . log ; find / var / log / - type f - mtime 1 - exec rm {} \\ ;","title":"bbr"},{"location":"other/#chrome","text":"Windows 32 ： Canary  ： http : // www . google . com / chrome / eula . html ? platform = win extra = canarychannel standalone = 1 Dev ： http : // www . google . com / chrome / eula . html ? platform = win extra = devchannel standalone = 1 Beta ： http : // www . google . com / chrome / eula . html ? platform = win extra = betachannel standalone = 1 Stable ： http : // www . google . com / chrome / eula . html ? platform = win extra = stablechannel standalone = 1 crx https : // chrome - extension - downloader . com / how - does - it - work . php URL ： https : // clients2 . google . com / service / update2 / crx ? response = redirect prodversion = 49.0 x = id % 3 D ~~~~% 26 installsource % 3 Dondemand % 26 uc 4 （ ~~~~ ） ID 。  ， Google ， https : // chrome . google . com / webstore / detail / google - maps / lneaknkopdijkpnocmklfnjbeapigfbh 。 GoogleIDlneaknkopdijkpnocmklfnjbeapigfbh 。 Googlehttps : // clients2 . google . com / service / update2 / crx ? response = redirect prodversion = 49.0 x = id % 3 Dlneaknkopdijkpnocmklfnjbeapigfbh % 26 installsource % 3 Dondemand % 26 uc 。 extension_ [ version ] . crx 。 Googleextension_5_2_7 . crx ， Google5 .2.7 。","title":"chrome"},{"location":"other/#_3","text":"， Linux ，。  Linux 。 ： CentOS （ 5 . 8 / 6 . 4 ）。 5 . 8  6 . 4 ，。 ：  ip 、、、 DNS   selinux ， iptables  sudo   yum     / var / spool / clientmqueue / ， inode   ssh ， root    ，   1 、 ip 、、、 DNS   IP ： [ root @ localhost ~ ]# vi / etc / sysconfig / network - scripts / ifcfg - eth0 DEVICE = eth0 # BOOTPROTO = static # IP  ： DHCP  IP  IPADDR = 192 . 168 . 1 . 113 # IP  NETMASK = 255 . 255 . 255 . 0 # ONBOOT = yes # GATEWAY = 192 . 168 . 1 . 1 [ root @ localhost ~ ]# cat / etc / sysconfig / network - scripts / ifcfg - eth0 DEVICE = eth0 BOOTPROTO = static IPADDR = 192 . 168 . 1 . 113 NETMASK = 255 . 255 . 255 . 0 ONBOOT = yes GATEWAY = 192 . 168 . 1 . 1 ： [ root @ localhost ~ ]# vi / etc / sysconfig / network HOSTNAME = c64 #， GATEWAY = 192 . 168 . 1 . 1 #, eth0 ，。 [ root @ localhost ~ ]# cat / etc / sysconfig / network HOSTNAME = c64 GATEWAY = 192 . 168 . 1 . 1  hostname c64 ，  DNS [ root @ localhost ~ ]# vi / etc / resolv . conf # DNS  nameserver 114 . 114 . 114 . 114 nameserver 8 . 8 . 8 . 8 [ root @ localhost ~ ]# cat / etc / resolv . conf # DNS  nameserver 114 . 114 . 114 . 114 nameserver 8 . 8 . 8 . 8 [ root @ localhost ~ ]# service network restart #， ， [ root @ localhost ~ ]# / etc / init . d / network restart 2 、 selinux ， iptables  selinux [ root @ c64 ~ ]# sed – i s/SELINUX=enforcing/SELINUX=disabled/g / etc / selinux / config #， 。 [ root @ c64 ~ ]# grep SELINUX = disabled / etc / selinux / config SELINUX = disabled # [ root @ c64 ~ ]# setenforce 0 # [ root @ c64 ~ ]# getenforce # selinux  Permissive  iptables [ root @ c64 ~ ]# iptables – F # [ root @ c64 ~ ]# iptables – L # Chain INPUT ( policy ACCEPT ) target prot opt source destination Chain FORWARD ( policy ACCEPT ) target prot opt source destination Chain OUTPUT ( policy ACCEPT ) target prot opt source destination [ root @ c64 ~ ]# / etc / init . d / iptables save # 3 、 sudo  [ root @ c64 ~ ]# useradd sunsky [ root @ c64 ~ ]# echo 123456 | passwd -- stdin sunsky history – c [ root @ c64 ~ ]# visudo  root ALL = ( ALL ) ALL ， sunsky ALL = ( ALL ) ALL 4 、 yum  yum ， rpm ，。 ：、  1 ：， linux 。  2 ： yum  [ root @ c64 ~ ]# cd / etc / yum . repos . d / [ root @ c64 yum . repos . d ]# / bin / mv CentOS - Base . repo CentOS - Base . repo . bak [ root @ c64 yum . repos . d ]# wget http : // mirrors . 163 . com / . help / CentOS6 - Base - 163 . repo ， yum  [ root @ c64 yum . repos . d ]# yum clean all # yum  [ root @ c64 yum . repos . d ]# yum makecache # yum   [ root @ c64 yum . repos . d ]# rpm -- import / etc / pki / rpm - gpg / RPM - GPG - KEY * # KEY  RPM [ root @ c64 yum . repos . d ]# yum upgrade - y #  [ root @ c64 yum . repos . d ]# yum install lrzsz ntpdate sysstat - y lrzsz ： ntpdate ： sysstat ： 5 、 [ root @ c64 ~ ]# echo */5 * * * * /usr/sbin/ntpdate time.windows.com /dev/null 2 1 / var / spool / cron / root [ root @ c64 ~ ]# echo */10 * * * * /usr/sbin/ntpdate time.nist.gov /dev/null 2 1 / var / spool / cron / root ： CentOS 6 . 4  6  / usr / sbin / ntpdate 5  / sbin / ntpdate ：，。， NTP Server 。 ，。 6 、  crond ， network ， syslog ， sshd 。（ Centos6 . 4  rsyslog ） [ root @ c64 ~ ]# for sun in ` chkconfig -- list | grep 3 : on | awk {print $1} ` ;do chkconfig --level 3 $sun off;done [ root @ c64 ~ ]# for sun in crond rsyslog sshd network ;do chkconfig --level 3 $sun on;done [ root @ c64 ~ ]# chkconfig -- list | grep 3 : on crond 0 : off 1 : off 2 : on 3 : on 4 : on 5 : on 6 : off network 0 : off 1 : off 2 : on 3 : on 4 : on 5 : on 6 : off rsyslog 0 : off 1 : off 2 : on 3 : on 4 : on 5 : on 6 : off sshd 0 : off 1 : off 2 : on 3 : on 4 : on 5 : on 6 : off 7 、 / var / spool / clientmqueue / ， inode  ， 6 . 4 ！ [ root @ c64 ~ ]# mkdir / server / scripts - p [ root @ c64 ~ ]# vi / server / scripts / spool_clean . sh # !/ bin / sh find / var / spool / clientmqueue / - type f - mtime + 30 | xargs rm - f  crontab  [ root @ c64 ~ ]# echo */30 * * * * /bin/sh /server/scripts/spool_clean.sh /dev/null 2 1 / var / spool / cron / root 8 、 ssh ， root  [ root @ c64 ~ ]# cp / etc / ssh / sshd_config / etc / ssh / sshd_config . bak [ root @ c64 ~ ]# vim / etc / ssh / sshd_config Port 52113 # ssh  PermitRootLogin no # root ， PermitEmptyPasswords no # UseDNS no # DNS [ root @ c64 ~ ]# / etc / init . d / sshd reload # [ root @ c64 ~ ]# netstat - lnt # [ root @ c64 ~ ]# lsof - i tcp : 52113 9 、 [ root @ c64 ~ ]# chattr + i / etc / passwd [ root @ c64 ~ ]# chattr + i / etc / inittab [ root @ c64 ~ ]# chattr + i / etc / group [ root @ c64 ~ ]# chattr + i / etc / shadow [ root @ c64 ~ ]# chattr + i / etc / gshadow  chattr ， [ root @ c64 ~ ]# / bin / mv / usr / bin / chattr / usr / bin /  10 、 [ root @ localhost ~ ]# ulimit – n # 1024 [ root @ localhost ~ ]# echo * - nofile 65535 / etc / security / limits . conf ，。 ： ulimit - SHn 65535  / etc / rc . local ， [ root @ c64 ~ ]# cat / etc / rc . local EOF # open files ulimit - HSn 65535 # stack size ulimit - s 65535 EOF ： 。，，。 ，。， 。 Unix 、 Linux 。 ，（ standard input ） 0 ，（ standard output ） 1 ，（ standard error ） 2 。 Unix ， shell ，，， 。 11 、， sed - i s#LANG= en_US.UTF-8 #LANG= zh_CN.GB18030 # / etc / sysconfig / i18n source / etc / sysconfig / i18n ：？ 。： GBK ， UTF - 8  1 - 4 ， MYSQL  UTF - 8 12 、 [ root @ c64 ~ ]# / etc / redhat - release [ root @ c64 ~ ]# / etc / issue 13 、 ： apache ， nginx ， squid  web ，。 [ root @ c64 ~ ]# vi / etc / sysctl . conf # by sun in 20131001 net . ipv4 . tcp_fin_timeout = 2 net . ipv4 . tcp_tw_reuse = 1 net . ipv4 . tcp_tw_recycle = 1 net . ipv4 . tcp_syncookies = 1 net . ipv4 . tcp_keepalive_time = 600 net . ipv4 . ip_local_port_range = 4000 65000 net . ipv4 . tcp_max_syn_backlog = 16384 net . ipv4 . tcp_max_tw_buckets = 36000 net . ipv4 . route . gc_timeout = 100 net . ipv4 . tcp_syn_retries = 1 net . ipv4 . tcp_synack_retries = 1 net . core . somaxconn = 16384 net . core . netdev_max_backlog = 16384 net . ipv4 . tcp_max_orphans = 16384 # iptables ，，。 net . ipv4 . ip_conntrack_max = 25000000 net . ipv4 . netfilter . ip_conntrack_max = 25000000 net . ipv4 . netfilter . ip_conntrack_tcp_timeout_established = 180 net . ipv4 . netfilter . ip_conntrack_tcp_timeout_time_wait = 120 net . ipv4 . netfilter . ip_conntrack_tcp_timeout_close_wait = 60 net . ipv4 . netfilter . ip_conntrack_tcp_timeout_fin_wait = 120 [ root @ localhost ~ ]# sysctl – p # ： CentOS6 . X  ip_conntrack ， nf_conntrack ， / etc / sysctl . conf ，  net . ipv4 . netfilter . ip_conntrack_max ， net . netfilter . nf_conntrack_max 。 ， 5 . 8 : net . ipv4 . ip_conntrack_max = 25000000 net . ipv4 . netfilter . ip_conntrack_max = 25000000 net . ipv4 . netfilter . ip_conntrack_tcp_timeout_established = 180 net . ipv4 . netfilter . ip_conntrack_tcp_timeout_time_wait = 120 net . ipv4 . netfilter . ip_conntrack_tcp_timeout_close_wait = 60 net . ipv4 . netfilter . ip_conntrack_tcp_timeout_fin_wait = 120  6 . 4 : net . nf_conntrack_max = 25000000 net . netfilter . nf_conntrack_max = 25000000 net . netfilter . nf_conntrack_tcp_timeout_established = 180 net . netfilter . nf_conntrack_tcp_timeout_time_wait = 120 net . netfilter . nf_conntrack_tcp_timeout_close_wait = 60 net . netfilter . nf_conntrack_tcp_timeout_fin_wait = 120 ，： 1 、 5 . 8  error : net.ipv4.ip_conntrack_max is an unknown key error : net.ipv4.netfilter.ip_conntrack_max is an unknown key error : net.ipv4.netfilter.ip_conntrack_tcp_timeout_established is an unknown key error : net.ipv4.netfilter.ip_conntrack_tcp_timeout_time_wait is an unknown key error : net.ipv4.netfilter.ip_conntrack_tcp_timeout_close_wait is an unknown key error : net.ipv4.netfilter.ip_conntrack_tcp_timeout_fin_wait is an unknown key  ip_conntrack ，，，  ip_conntrack modprobe ip_conntrack echo modprobe ip_conntrack / etc / rc . local 2 、 6 . 4  error : net.nf_conntrack_max is an unknown key error : net.netfilter.nf_conntrack_max is an unknown key error : net.netfilter.nf_conntrack_tcp_timeout_established is an unknown key error : net.netfilter.nf_conntrack_tcp_timeout_time_wait is an unknown key error : net.netfilter.nf_conntrack_tcp_timeout_close_wait is an unknown key error : net.netfilter.nf_conntrack_tcp_timeout_fin_wait is an unknown key  ip_conntrack ，，，  ip_conntrack modprobe nf_conntrack echo modprobe nf_conntrack / etc / rc . local 3 、 6 . 4  error : net.bridge.bridge-nf-call-ip6tables is an unknown key error : net.bridge.bridge-nf-call-iptables is an unknown key error : net.bridge.bridge-nf-call-arptables is an unknown key  bridge ， ip_conntrack modprobe bridge echo modprobe bridge / etc / rc . local ， Linux ， 13 。","title":""},{"location":"other/#io","text":"socket ， ： huangguisu 1 .  ， ( Sync ) /  ( Async ) ， ( Block ) /  ( Unblock ) ： ： ，，，。,。  B / S （）： -  -   ： 。，。，、 。  ajax （）:  - （） -   ，（，， cpu ，）。 。 ，。，， 。 ， socket  recv ，，，。， 。  ，，，。  ，。， API  ，，。，。 select  。 1 . ，，，。 2 . ，，，（） 3 . ， （），（），。 4 . ， （），（）， select   IO  IO ：！  IO  IO ：！  c / s ： ： -  -  ： - （） -   SOCKET 。 ,,,,。 ,,, ; , I / O , ( ,  ) ,, I / O ,,。 (   ) 1 . Linux  I / O  1 )  I / O （ blocking I / O ） 2 )  I / O （ nonblocking I / O ） 3 ) I / O  ( select  poll ) （ I / O multiplexing ） 4 )  I / O （ signal driven I / O ( SIGIO ) ） 5 )  I / O （ asynchronous I / O ( the POSIX aio_functions ) ） ， IO 。  I / O ： ：，  IO ，，。 ，….，, IO 。  I / O ： recv () / recvfrom （），。  recv () ，。，。， ，。， recv () ，， recv () 。  socket ()  WSASocket () ，。 Windows Sockets API ， ，。  Windows Sockets API 。， bind () 、 listen () ， 。 Windows Sockets API : 1 ．： recv () 、 recvfrom () 、 WSARecv ()  WSARecvfrom () 。。 ，。 2 ．： send () 、 sendto () 、 WSASend ()  WSASendto () 。。 ，，。 3 ．： accept ()  WSAAcept () 。，。， 。 4 ．： connect ()  WSAConnect () 。 TCP ，，。 ，。 TCP 。 　　，，。，， 。 ，。“ - ”， 、，。 ，，  IO  ： IO  IO （，）；，；  SOCKET ， I / O ，，。 I / O ，，，。，  CPU 。  SOCKET ，： Windows Sockets API ，，。， 。， recv () 。 recv () ，。 ， WSAEWOULDBLOCK 。 recv () ，，， recv ()  ，。  socket ()  WSASocket () ，。， ioctlsocket () ， 。 Linux : fcntl () . ， Windows Sockets API ，。，“”，  WSAEWOULDBLOCK 。。，，。  Windows Sockets API ， WSAEWOULDBLOCK 。，  bind () ，。， WSAStartup () ，， 。 ， ioctlsocket () ， WSAAsyncselect ()  WSAEventselect () 。 ，。 　　， WSAEWOULDBLOCK 。，“”。 ，。， While  recv () ， 1024  。。 ， MSG_PEEK  recv () 。，。 ， recv () ，。，“ I / O ” 。 ，。，， Windows Sockets API  ， WSAEWOULDBLOCK 。，。 ，，，，。， ，。，“ I / O ”，， 。 IO ： ： select  epoll ； IO ，，， IO ； IO  ； I / O  select 、 poll 、 epoll ，， I / O ， I / O 。， I / O ，， I / O 。  IO ：，；  I / O ,，。， SIGIO ，  I / O 。  IO  ：。 ，。，、   IO ， IO 。  IO 。 IO  select 。 5  I / O ： 1 . select 、 poll 、 epoll  epoll  select  I / O 。 Linux ， epoll  Linux ， select  POSIX ， select ： select  fd 。： 1 、  fd ，。 ， cat / proc / sys / fs / file - max 。 32  1024 。 64  2048 . 2 、  socket ，，： ， select ()  FD_SETSIZE  Socket , Socket ,。  CPU 。，，，， epoll  kqueue 。 3 、 fd ， poll ： poll  select ，， fd ， ， fd ，，， fd 。 。 ，，： 1 、 fd ，。 2 、 poll “”， fd ，， poll  fd 。 epoll : epoll ，， fd ，。， epoll “”， epoll_ctl  fd ， fd ， callback  fd ， epoll_wait  epoll ： 1 、， FD  1024 （ 1 G  10 ）； 2 、，， FD 。 FD  callback ；  Epoll “”，，， Epoll  select  poll 。 3 、 ， mmap () ； epoll  mmap 。 select 、 poll 、 epoll ： 1 、 select  FD_SETSIZE ， 32 （ 32 ， 32 * 32 ， 64  FD_SETSIZE  32 * 64 ），，，，。 poll poll  select ，， epoll ，， 1 G  10 ， 2 G  20  2 、 FD  IO  select ， FD “”。 poll  epoll  epoll  fd  callback ， socket  callback ， socket ，  epoll ， socket ，。 3 、  select ， poll  epoll epoll 。 ： ， select ， poll ， epoll 。 1 、 epoll ，， select  poll  epoll ， epoll  。 2 、 select 。，， ： http : // blog . csdn . net / jay900323 / article / details / 18141217","title":"io"},{"location":"other/#network","text":"Network 1 、 NIC  （ 1 ）、 socket  ，   ： 1 、 sock ls – l / tmp / mysql . sock  ，  。 2 、 sock （  ） （ 1 ）、 IP   IP  （ 2 ）、 IP （ 3 ）、 mysqltcp （ 4 ）、 socket buffer  （ 5 ）、 core  ， IPV4tcp （ 6 ）、 tcp ，  （ 7 ）、 tcp_mem sk_buffer ，  ： 4 KB ， 32  ： 900 M （ 8 ）、  ， tcp_mem ，  ，  （ 9 ）、  =  *  * 1024 * 1024 （  ） （ 10 ）、  ，  2 、 TCP （ 1 ）、  ， established （ 2 ）、  ， syn （ 3 ）、 Time_wait ， Close_wait （ 4 ）、 established =  + somaxconn （  ） （ 5 ）、  ，  ，  （ apachenginx . php hash ） 3 、  ： yum install iptraf  iptraf mtr IP  ----cacti cactiez ：  ，  ，  ，  。 cactiez （  ） net - snmp - utils net - snmp snmp ：  port ： 161 cactiez ： cd / var / www / html / rra cactiez ： cd / var / www / html / scripts log : / var / www / html / log  ： snmp ： vim / etc / snmp / snmpd . conf rocommunity public 192.168.18.0 / 24 # （ IP ） syslocation China . beijing # syscontact Root haha @vfast . com #   snmp : service snmpd start cactiezip  snmpwalk - v 2 c - c public 192.168.18.96 .1.3.6.1.4.1.2021.4.4.0 4 、  linuxTCP ，  ， linux ，  ，  。 （ 1 ）、 linuxtcp ，  cat / proc / sys / net / ipv4 / tcp_mem （ 2 ）、  （  ） cat / proc / sys / net / core / rmem_default cat / proc / sys / net / core / rmem_max （ 3 ）、  （  ） cat / proc / sys / net / core / wmem_default cat / proc / sys / net / core / wmem_max （ 4 ）、 socket buffer  cat / proc / sys / net / core / optmem_max 1 12MB ，  ， tcp   ： rmem_maxwmem_max128KB ，  ， webdns ，   ，  （ 1 ）、  echo ‘ net . core . wmem_max = 12582912 ’ / etc / sysctl . conf echo ‘ net . core . rmem_max = 12582912 ’ / etc / sysctl . conf （ 2 ）、 tcp echo ‘ net . ipv4 . tcp_rmem = 10240 87380 12582912 ’ / etc / sysctl . conf echo ‘ net . ipv4 . tcp_wmem = 10240 87380 12582912 ’ / etc / sysctl . conf （ 3 ）、 window scaling echo ‘ net . ipv4 . tcp_window_scaling = 1 ’ / etc / sysctl . conf （ 4 ）、  （ RFC 1323 ） tcp12 echo ‘ net . ipv4 . tcp_timestamps = 1 ’ / etc / sysctl . conf （ 5 ）、  echo ‘ net . ipv4 . tcp_sock = 1 ’ / etc / sysctl . conf （ 6 ）、 tcp ， snd_sthresh ， snd_cwnd ， srtt dst_entry ， dst_rntey ，  ，  echo ‘ net . ipv4 . tcp_no_metrics_save = 1 ’ / etc / sysctl . conf （ 7 ）、  ，  echo ‘ net . core . netdev_max_backlog = 5000 ’ / etc / sysctl . conf （ 8 ）、  sysctl – p tcpdump tcpdump - ni eth0 2  ， linux （ 2.6 kernel ）  ，  ，  （ 1 ）、 / proc / sys / net / core / wmem_max socketbuffer ，  ： 873200 （ 2 ）、 / proc / sys / net / core / rmem_max socketbuffer ，  ： 873200 （ 3 ）、 / proc / sys / net / ipv4 / tcp_wmem Tcpbuffer ，  ： 8192 436600 873200 （ 4 ）、 / proc / sys / net / ipv4 / tcp_rmem Tcpbuffer ，  ： 32768 436600 873200 （ 5 ）、 / proc / sys / net / ipv4 / tcp_mem 3 ，  ： net . ipv4 . tcp_mem [ 0 ] ：  ， tcp net . ipv4 . tcp_mem [ 1 ] ：  ，  net . ipv4 . tcp_mem [ 2 ] ：  ， tcpsocket  ，  ： 4 KB  ： 786432 1048576 1572864 （ 6 ）、 / proc / sys / net / core / netdev_max_backlog  ， 300 ，  ，  ， 1000 （ 7 ）、 / proc / sys / net / core / somaxconn Listen ()  ，  ， 128 ，  ，  ， 256 （ 8 ）、 / proc / sys / net / core / optmem_max socket buffer  ， 10K （ 9 ）、 / proc / sys / net / ipv4 / tcp_max_syn_backlog syn ， 1024 ，  ，  ， 2048 （ 10 ）、 / proc / sys / net / ipv4 / tcp_retrises2 tcp ， 15 ， 15 ， 5 ，  （ 11 ）、 / proc / sys / net / ipv4 / tcp_keepalive_time / proc / sys / net / ipv4 / tcp_keepalive_intvl / proc / sys / net / ipv4 / tcp_keepalive_probes 3tcp keepalive ，  ： tcp_keepalive_time = 7200 seconds ( 2 hours ) tcp_keepalive_probes = 9 tcp_keepalive_intvl = 75 seconds tcpidle 2  ， probe probe 9  （ 75 ）  ，  ，   ，  ，  ： tcp_keepalive_time = 1800 seconds tcp_keepalive_probes = 3 tcp_keepalive_intvl = 30 seconds （ 12 ）、 / proc / sys / net / ipv4 / ip_local_range  ， 32768 61000 ","title":"network"},{"location":"other/#io_mem","text":"：  ： ulimit - SHn 65535 ： vim / etc / security / limits . conf * soft nofile 65535 * hard nofile 65535 io  noop ssd ， cpu anticipatory ， deadline ， cfg ， cat / sys / block / sda / queue / scheduler noop anticipatory deadline [ cfq ]  echo deadline / sys / block / sda / queue / scheduler ： vim / boot / grub / menu . lst kernel / boot / vmlinuz - 2 . 6 . 18 - 8 . el5 ro root = LABEL =/ elevator = deadline rhgb quiet ：  sync echo 3 / proc / sys / vm / drop_caches ： vim / etc / sysctl . conf net . ipv4 . tcp_keepalive_intvl = 75 ，， 75 。 net . ipv4 . tcp_keepalive_probes = 9 ， TCP  keepalive ， 9 . tcp_keepalive_intvl  keepalive 。 net . ipv4 . tcp_keepalive_time = 7200  keepalive ， TCP  keepalive ， 2 。 net . ipv4 . tcp_syn_retries = 5  SYN 。 net . ipv4 . tcp_synack_retries = 5 ， SYN  SYN  ACK 。。  SYN + ACK 。 net . ipv4 . tcp_syncookies = 1  SYN cookies 。 SYN ， cookies ， SYN ， 0 ，； net . ipv4 . tcp_tw_reuse = 1 。 TIME - WAIT sockets  TCP ， 0 ，； net . ipv4 . tcp_tw_recycle = 1  TCP  TIME - WAIT sockets ， 0 ，。 net . ipv4 . tcp_fin_timeout = 30  TIMEOUT  sysctl - p ","title":"io_mem"},{"location":"postgresql/","text":" PostgreSQL ，。： cd / opt / PostgreSQL / 9 . 3 . 5 / data / mkdir pgdata1 mkdir pgdata2 chown postgres pgdata1 chown postgres pgdata2 ： su postgres initdb - D / opt / PostgreSQL / 9 . 3 . 5 / data / pgdata1 --locale=zh_CN.UTF8 initdb - D / opt / PostgreSQL / 9 . 3 . 5 / data / pgdata2 --locale=zh_CN.UTF8  pgdata1  pgdata2  postgresql . conf  port ， 5433  5434 ，，： pg_ctl - D / opt / PostgreSQL / 9 . 3 . 5 / data / pgdata1 start pg_ctl - D / opt / PostgreSQL / 9 . 3 . 5 / data / pgdata2 start ： psql - p 5433 psql - p 5434 ： https : // mos . meituan . com / library / 33 / postgresql - source - based - installation / pg  +  ，。   root postgresql   A ： ssh - keygen - t rsa ，， passphrase 。 Generating public / private rsa key pair . Enter file in which to save the key ( / root / . ssh / id_rsa ) : Enter passphrase ( empty for no passphrase ) : Enter same passphrase again : Your identification has been saved in / root / . ssh / id_rsa . Your public key has been saved in / root / . ssh / id_rsa . pub . The key fingerprint is : ff : 8 e : 85 : 68 : 85 : 94 : 7 c : 2 c : 46 : b1 : e5 : 2 d : 41 : 5 c : e8 : 9 b root @ localhost . domain  . ssh  id_rsa . pub   B  ~/ . ssh / ， authorized_keys 。 scp . ssh / id_rsa . pub 192.168.2.91 :/ root / . ssh / authorized_keys ： scp id_rsa . pub postgres @192.168.2.92 :/ home / postgres / . ssh / authorized_keys  A  scp  B 。 ， B  A ， B  id_rsa . pub  A  . ssh 。 ， . ssh ， id_rsa . pub  authorized_keys 。 cat id_rsa . pub  / authorized_keys ： ： vim / usr / local / pgsql / data / pg_hba . conf ： local all all trust host all all 127.0.0.1 / 32 trust # IPv6 local connections: host all all 192.168.2.0 / 24 trust # Allow replication connections from localhost, by a user with the # replication privilege. host replication postgres 192.168.2.0 / 24 trust host replication postgres :: 1 / 128 trust  vim / usr / local / pgsql / data / postgresql . conf max_wal_senders = 5 wal_keep_segments = 1000 wal_sender_timeout = 60 s hot_standby = on log_destination = stderr logging_collector = on log_directory = pg_log log_filename = postgresql -% Y -% m -% d_ % H % M % S . log log_file_mode = 0600 log_rotation_age = 1 d log_rotation_size = 20 MB client_min_messages = notice log_min_messages = warning log_min_error_statement = error log_min_duration_statement = 60 shared_preload_libraries = pg_stat_statements pg_stat_statements . max = 1000 pg_stat_statements . track = top pg_stat_statements . track_utility = true pg_stat_statements . save = true log_checkpoints = on log_connections = on log_lock_waits = on log_statement = ddl log_timezone = PRC  / data  mkdir archivedir chown postgres . postgres archivedir  / data mkidr pgbackup chown postgres . postgres pgbackup ， postgresql 。 / etc / init . d / postgresql restart / usr / local / pgsql / bin / pg_ctl restart - D / usr / local / pgsql / data / ：  postgresql ： su - l postgres [ postgres @ AY131021150028549089Z ~ ] $ psql postgres = # SELECT pg_start_backup ( basebak20151209 ); pg_start_backup ----------------- 0 / 8000028 ( 1 row ) postgres = # \\ q [ postgres @ AY131021150028549089Z ~ ] $ exit [ root @ AY131021150028549089Z data ] # cd pgbackup / [ root @ AY131021150028549089Z pgbackup ] # tar zvcf base201510_data . tar . gz / data  [ root @ AY131021150028549089Z data ] # su - l postgres [ postgres @ AY131021150028549089Z ~ ] $ psql postgres = # SELECT pg_stop_backup (); NOTICE : pg_stop_backup complete , all required WAL segments have been archived pg_stop_backup ---------------- 0 / 8000230 ( 1 row ) postgres = # \\ q [ root @ AY131021150028549089Z data ] # cd pgbackup / [ root @ AY131021150028549089Z pgbackup ] # chown postgres . postgres base20131112_data . tar . gz ：  / data  pgbackup  mkdir archivedir chown postgres . postgres archivedir  mkdir pgbackup chown postgres . postgres pgbackup ， postgresql 。 / etc / init . d / postgresql stop  su su - l postgres cd / data / pgbackup scp 192.168.2.91 :/ data / pgbackup / base20131112_data . tar . gz . /  [ postgres @ AY131021150027813b05Z pgbackup ] $ tar zvxf base20131112_data . tar . gz - C .. /  cd / data / data / pg_xlog [ postgres @ AY131021150027813b05Z pg_xlog ] $ rm - f 0 * [ postgres @ AY131021150027813b05Z archive_status ] $ rm - f 0 * cd / data / data rm postmaster . pid cp / usr / local / pgsql / share / recovery . conf . sample . / recovery . conf  recover . conf  restore_command = scp 10.161.166.25 :/ data / archivedir /% f %p 2 / dev / null recovery_target_timeline = latest standby_mode = on primary_conninfo = host = 172.31.2.150 port = 5432 user = postgres trigger_file = / tmp / trigger_file0 chown postgres . postgres recovery . conf  ， / etc / rc . d / init . d / postgres start pg yum install postgresql - server postgresql - y / etc / init . d / postgresql initdb / etc / init . d / postgresql restart / var / lib / pgsql / data / postgresql . conf  vim / var / lib / pgsql / data / pg_hba . conf ， host all all 0 . 0 . 0 . 0 / 0 md5 su - postgres psql  \\ password ， postgres 。 \\ password postgres  dbuser （ Linux ），。 CREATE USER dbuser WITH PASSWORD password ; ， exampledb ， dbuser 。 CREATE DATABASE exampledb OWNER dbuser ;  exampledb  dbuser ， dbuser ，。 GRANT ALL PRIVILEGES ON DATABASE exampledb to dbuser ; ，\\ q （ ctrl + D ）。 \\ q ， shell 。 ， PostgreSQL ， shell 。 PostgreSQL   createuser  createdb 。 dbuser  exampledb 。 ， dbuser ，。 sudo - u postgres createuser -- superuser dbuser ，， dbuser ，。 sudo - u postgres psql \\ password dbuser \\ q ， shell ， exampledb ， dbuser 。 sudo - u postgres createdb - O dbuser exampledb 、 ，， psql 。 psql - U dbuser - d exampledb - h 127 . 0 . 0 . 1 - p 5432 ： - U ， - d ， - h ， - p 。 ， dbuser 。，。 psql 。 Linux ， PostgreSQL ，（ - U ）。 ， Linux  ruanyf ， PostgreSQL ， ruanyf  Linux ， ，。 psql exampledb ， PostgreSQL ，。， ruanyf ， psql 。 psql ，，。 psql exampledb exampledb . sql 、 \\ password （）\\ q （），。 \\ h ： SQL ，\\ h select 。 \\?： psql 。 \\ l ：。 \\ c [ database_name ]：。 \\ d ：。 \\ d [ table_name ]：。 \\ du ：。 \\ e ：。 \\ conninfo ：。 、 ， SQL 。 #  CREATE TABLE user_tbl ( name VARCHAR ( 20 ) , signup_date DATE ) ; #  INSERT INTO user_tbl ( name , signup_date ) VALUES (  , 2013-12-22 ) ; #  SELECT * FROM user_tbl ; #  UPDATE user_tbl set name =  WHERE name =  ; #  DELETE FROM user_tbl WHERE name =  ; #  ALTER TABLE user_tbl ADD email VARCHAR ( 40 ) ; #  ALTER TABLE user_tbl ALTER COLUMN signup_date SET NOT NULL ; #  ALTER TABLE user_tbl RENAME COLUMN signup_date TO signup ; #  ALTER TABLE user_tbl DROP COLUMN email ; #  ALTER TABLE user_tbl RENAME TO backup_tbl ; #  DROP TABLE IF EXISTS backup_tbl ;","title":"postgresql"},{"location":"postgresql/#_1","text":"PostgreSQL ，。： cd / opt / PostgreSQL / 9 . 3 . 5 / data / mkdir pgdata1 mkdir pgdata2 chown postgres pgdata1 chown postgres pgdata2 ： su postgres initdb - D / opt / PostgreSQL / 9 . 3 . 5 / data / pgdata1 --locale=zh_CN.UTF8 initdb - D / opt / PostgreSQL / 9 . 3 . 5 / data / pgdata2 --locale=zh_CN.UTF8  pgdata1  pgdata2  postgresql . conf  port ， 5433  5434 ，，： pg_ctl - D / opt / PostgreSQL / 9 . 3 . 5 / data / pgdata1 start pg_ctl - D / opt / PostgreSQL / 9 . 3 . 5 / data / pgdata2 start ： psql - p 5433 psql - p 5434 ： https : // mos . meituan . com / library / 33 / postgresql - source - based - installation /","title":""},{"location":"postgresql/#pg","text":" +  ，。   root postgresql   A ： ssh - keygen - t rsa ，， passphrase 。 Generating public / private rsa key pair . Enter file in which to save the key ( / root / . ssh / id_rsa ) : Enter passphrase ( empty for no passphrase ) : Enter same passphrase again : Your identification has been saved in / root / . ssh / id_rsa . Your public key has been saved in / root / . ssh / id_rsa . pub . The key fingerprint is : ff : 8 e : 85 : 68 : 85 : 94 : 7 c : 2 c : 46 : b1 : e5 : 2 d : 41 : 5 c : e8 : 9 b root @ localhost . domain  . ssh  id_rsa . pub   B  ~/ . ssh / ， authorized_keys 。 scp . ssh / id_rsa . pub 192.168.2.91 :/ root / . ssh / authorized_keys ： scp id_rsa . pub postgres @192.168.2.92 :/ home / postgres / . ssh / authorized_keys  A  scp  B 。 ， B  A ， B  id_rsa . pub  A  . ssh 。 ， . ssh ， id_rsa . pub  authorized_keys 。 cat id_rsa . pub  / authorized_keys ： ： vim / usr / local / pgsql / data / pg_hba . conf ： local all all trust host all all 127.0.0.1 / 32 trust # IPv6 local connections: host all all 192.168.2.0 / 24 trust # Allow replication connections from localhost, by a user with the # replication privilege. host replication postgres 192.168.2.0 / 24 trust host replication postgres :: 1 / 128 trust  vim / usr / local / pgsql / data / postgresql . conf max_wal_senders = 5 wal_keep_segments = 1000 wal_sender_timeout = 60 s hot_standby = on log_destination = stderr logging_collector = on log_directory = pg_log log_filename = postgresql -% Y -% m -% d_ % H % M % S . log log_file_mode = 0600 log_rotation_age = 1 d log_rotation_size = 20 MB client_min_messages = notice log_min_messages = warning log_min_error_statement = error log_min_duration_statement = 60 shared_preload_libraries = pg_stat_statements pg_stat_statements . max = 1000 pg_stat_statements . track = top pg_stat_statements . track_utility = true pg_stat_statements . save = true log_checkpoints = on log_connections = on log_lock_waits = on log_statement = ddl log_timezone = PRC  / data  mkdir archivedir chown postgres . postgres archivedir  / data mkidr pgbackup chown postgres . postgres pgbackup ， postgresql 。 / etc / init . d / postgresql restart / usr / local / pgsql / bin / pg_ctl restart - D / usr / local / pgsql / data / ：  postgresql ： su - l postgres [ postgres @ AY131021150028549089Z ~ ] $ psql postgres = # SELECT pg_start_backup ( basebak20151209 ); pg_start_backup ----------------- 0 / 8000028 ( 1 row ) postgres = # \\ q [ postgres @ AY131021150028549089Z ~ ] $ exit [ root @ AY131021150028549089Z data ] # cd pgbackup / [ root @ AY131021150028549089Z pgbackup ] # tar zvcf base201510_data . tar . gz / data  [ root @ AY131021150028549089Z data ] # su - l postgres [ postgres @ AY131021150028549089Z ~ ] $ psql postgres = # SELECT pg_stop_backup (); NOTICE : pg_stop_backup complete , all required WAL segments have been archived pg_stop_backup ---------------- 0 / 8000230 ( 1 row ) postgres = # \\ q [ root @ AY131021150028549089Z data ] # cd pgbackup / [ root @ AY131021150028549089Z pgbackup ] # chown postgres . postgres base20131112_data . tar . gz ：  / data  pgbackup  mkdir archivedir chown postgres . postgres archivedir  mkdir pgbackup chown postgres . postgres pgbackup ， postgresql 。 / etc / init . d / postgresql stop  su su - l postgres cd / data / pgbackup scp 192.168.2.91 :/ data / pgbackup / base20131112_data . tar . gz . /  [ postgres @ AY131021150027813b05Z pgbackup ] $ tar zvxf base20131112_data . tar . gz - C .. /  cd / data / data / pg_xlog [ postgres @ AY131021150027813b05Z pg_xlog ] $ rm - f 0 * [ postgres @ AY131021150027813b05Z archive_status ] $ rm - f 0 * cd / data / data rm postmaster . pid cp / usr / local / pgsql / share / recovery . conf . sample . / recovery . conf  recover . conf  restore_command = scp 10.161.166.25 :/ data / archivedir /% f %p 2 / dev / null recovery_target_timeline = latest standby_mode = on primary_conninfo = host = 172.31.2.150 port = 5432 user = postgres trigger_file = / tmp / trigger_file0 chown postgres . postgres recovery . conf  ， / etc / rc . d / init . d / postgres start","title":"pg"},{"location":"postgresql/#pg_1","text":"yum install postgresql - server postgresql - y / etc / init . d / postgresql initdb / etc / init . d / postgresql restart / var / lib / pgsql / data / postgresql . conf  vim / var / lib / pgsql / data / pg_hba . conf ， host all all 0 . 0 . 0 . 0 / 0 md5 su - postgres psql  \\ password ， postgres 。 \\ password postgres  dbuser （ Linux ），。 CREATE USER dbuser WITH PASSWORD password ; ， exampledb ， dbuser 。 CREATE DATABASE exampledb OWNER dbuser ;  exampledb  dbuser ， dbuser ，。 GRANT ALL PRIVILEGES ON DATABASE exampledb to dbuser ; ，\\ q （ ctrl + D ）。 \\ q ， shell 。 ， PostgreSQL ， shell 。 PostgreSQL   createuser  createdb 。 dbuser  exampledb 。 ， dbuser ，。 sudo - u postgres createuser -- superuser dbuser ，， dbuser ，。 sudo - u postgres psql \\ password dbuser \\ q ， shell ， exampledb ， dbuser 。 sudo - u postgres createdb - O dbuser exampledb 、 ，， psql 。 psql - U dbuser - d exampledb - h 127 . 0 . 0 . 1 - p 5432 ： - U ， - d ， - h ， - p 。 ， dbuser 。，。 psql 。 Linux ， PostgreSQL ，（ - U ）。 ， Linux  ruanyf ， PostgreSQL ， ruanyf  Linux ， ，。 psql exampledb ， PostgreSQL ，。， ruanyf ， psql 。 psql ，，。 psql exampledb exampledb . sql 、 \\ password （）\\ q （），。 \\ h ： SQL ，\\ h select 。 \\?： psql 。 \\ l ：。 \\ c [ database_name ]：。 \\ d ：。 \\ d [ table_name ]：。 \\ du ：。 \\ e ：。 \\ conninfo ：。 、 ， SQL 。 #  CREATE TABLE user_tbl ( name VARCHAR ( 20 ) , signup_date DATE ) ; #  INSERT INTO user_tbl ( name , signup_date ) VALUES (  , 2013-12-22 ) ; #  SELECT * FROM user_tbl ; #  UPDATE user_tbl set name =  WHERE name =  ; #  DELETE FROM user_tbl WHERE name =  ; #  ALTER TABLE user_tbl ADD email VARCHAR ( 40 ) ; #  ALTER TABLE user_tbl ALTER COLUMN signup_date SET NOT NULL ; #  ALTER TABLE user_tbl RENAME COLUMN signup_date TO signup ; #  ALTER TABLE user_tbl DROP COLUMN email ; #  ALTER TABLE user_tbl RENAME TO backup_tbl ; #  DROP TABLE IF EXISTS backup_tbl ;","title":"pg"},{"location":"python-base/","text":"  from collections import Counter Counter ( list ) . most_common  [ a for a in range ( 10 )]  ( a for a in range ( 10 ))  { a for a in range ( 10 )}  { a : a * 2 for a in range ( 3 )}  { a for a in range ( 10 ) if a == 2 } set ([ 2 ]) list . apped ( obj )  obj a = [ 1 , 2 , 3 ] a . append ( 4 ) ，，，， a . append ({ ‘ age ’ : 34 })  None list . extend ( seq )  seq  a = [ 1 , 2 , 3 ] 、 key b = [ 3 , 4 , 5 ] a . extend ( b )  None list . insert ( n , object )  n  obj a = [ 1 , 2 , 3 ] ，，，， a . insert ( 0 , ’ du ’ )  None list . pop ([ index ]) ， a = [ 1 , 2 , 3 , 4 , 5 ]  a . pop ( 0 )  list . reverse ()  a = [ 1 , 2 , 3 , 4 ]  a . reverse ()  None list . count ( obj )  obj  a = [ 1 , 2 , 3 , 3 , 3 , 4 ] 、、 a . count ( 1 )  list . index ( obj , i = 0 , j = len ( list ))  list [ k ] == obj  k  ,  k  [ i , j ) a = [ 1 , 2 , 3 , 4 , 5 , 6 , 2 ]  list （） a . index ( 2 )  obj  list  list . remove ( value )  obj a = [ 1 , 2 , 3 , 4 , 2 ]  list  a . remove ( 2 )  None list . sort ( func = None , key = None , reverse = False ) ， func  key  ， ,  reverse = True  a = [ 1 , 4 , 2 , 3 , 5 ] a . sort () a = [ 1 , 2 , 3 , 4 , 5 ] 、 key 、 reverse  a = [ ‘ du ’ , ’ dumc ’ , ’ d ’ , ’ dddddd ’ ]  None a . sort ( key = len ) a = [ ‘ d ’ , ’ du ’ , ’ dumc ’ , ’ dddddd ’ ] https : // wiki . python . org / moin / HowTo / Sorting student_tuples = [ ( john , A , 15 ), ( jane , B , 12 ), ( dave , B , 10 ), ] sorted ( student_tuples , key = lambda student : student [ 2 ]) # sort by age [( dave , B , 10 ), ( jane , B , 12 ), ( john , A , 15 )] a = [ 2 , 2 , 3 , 4 , 5 ] list ( set ( a )   list  #: a = [ 2 , 3 , 4 , 5 ] b = [ 2 , 5 , 8 ] tmp = [ val for val in a if val in b ] print tmp #[2, 5] # print list ( set ( a ) . intersection ( set ( b )))  list  print list ( set ( a ) . union ( set ( b )))  list  print list ( set ( b ) . difference ( set ( a ))) # ba  UnicodeEncodeError : ascii codec can ’ t encode characters in position 0 - 15 : ordinal not in range ( 128 ) # coding=utf-8  import sys reload ( sys ) sys . setdefaultencoding ( utf8 )  # coding=utf-8 # pip install pygeoip # wget http://geolite.maxmind.com/download/geoip/database/GeoLiteCity.dat.gz import pytz import time , os import pygeoip from datetime import datetime gi = pygeoip . GeoIP ( GeoLiteCity.dat , pygeoip . MEMORY_CACHE ) def ZoneTrans ( ip , timedate ): zone = gi . record_by_addr ( ip )[ time_zone ] tz = pytz . timezone ( zone ) utc = pytz . timezone ( Asia/Shanghai ) dateobj = datetime . strptime ( timedate , %Y-%m- %d %H:%M:%S ) print dateobj . replace ( tzinfo = tz ) . astimezone ( utc ) print dateobj . replace ( tzinfo = tz ) . astimezone ( utc ) . strptime ( %Y-%m- %d %H:%M:%S )) ZoneTrans ( 50.186.14.252 , 2016-10-31 04:59:35 )  bisect bisect   (sorted)  。 import bisect b = [ 20 , 34 , 35 , 65 , 78 ] bisect . bisect ( b , 25 ) #  25 。 1 bisect . bisect ( b , 40 ) #  40 。 3 bisect . bisect_left ( b , 35 ) # ，。 2 bisect . bisect_right ( b , 35 ) # ，。 3  insort_left () 。 bisect . insort_left ( b , 25 ) b [ 20 , 25 , 34 , 35 , 65 , 78 ] bisect . insort_left ( b , 40 ) b [ 20 , 25 , 34 , 35 , 40 , 65 , 78 ]  bisect  SortedList 。 def SortedList ( list , * elements ): ... for e in elements : ... bisect . insort_right ( list , e ) ... ... return list SortedList ([], 3 , 7 , 4 , 1 ) [ 1 , 3 , 4 , 7 ] o = SortedList ([], 3 , 7 , 4 , 1 ) o [ 1 , 3 , 4 , 7 ] SortedList ( o , 8 , 2 , 6 , 0 ) [ 0 , 1 , 2 , 3 , 4 , 6 , 7 , 8 ]  bisect  Consistent Hashing ， Key  Ring ， 。 heapq  : ，。 ： / 。 (  )  O ( logN ) ， O ( N ) 。 。，； ，。 from heapq import * from random import * rand = sample ( xrange ( 1000 ), 10 ) # 。 rand [ 572 , 758 , 737 , 738 , 412 , 755 , 507 , 734 , 479 , 374 ] heap = [] for x in rand : heappush ( heap , x ) # 。 heap # ，。 [ 374 , 412 , 507 , 572 , 479 , 755 , 737 , 758 , 734 , 738 ] while heap : print heappop ( heap ) # 。 374 412 479 507 572 734 737 738 755 758 。 d = sample ( xrange ( 10 ), 10 ) d [ 9 , 7 , 3 , 4 , 0 , 2 , 5 , 1 , 8 , 6 ] heapify ( d ) # 。 d [ 0 , 1 , 2 , 4 , 6 , 3 , 5 , 9 , 8 , 7 ] heappushpop ( d , - 1 ) #  push(item)， pop。 item。 - 1 heapreplace ( d , - 1 ) #  pop， push(item)。 item。 0 ... ... a = range ( 1 , 10 , 2 ) b = range ( 2 , 10 , 2 ) [ x for x in merge ( a , b )] # 。 [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 ] ... ... d = sample ( range ( 10 ), 10 ) d [ 9 , 0 , 3 , 4 , 5 , 6 , 1 , 2 , 8 , 7 ] nlargest ( 5 , list ) # () n 。 [ 9 , 8 , 7 , 6 , 5 ] nsmallest ( 5 , list ) #  n 。 [ 0 , 1 , 2 , 3 , 4 ]  cmp ，，。 from string import * data = map ( None , sample ( xrange ( 100 ), 10 ), sample ( letters , 10 )) data [( 31 , Z ), ( 71 , S ), ( 94 , r ), ( 65 , s ), ( 98 , B ), ( 10 , U ), ( 8 , u ), ( 25 , p ), ( 11 , v ), ( 29 , i )] for item in data : heappush ( heap , item ) heap [( 8 , u ), ( 11 , v ), ( 10 , U ), ( 25 , p ), ( 29 , i ), ( 94 , r ), ( 31 , Z ), ( 71 , S ), ( 65 , s ), ( 98 , B )] while heap : print heappop ( heap ) ( 8 , u ) ( 10 , U ) ( 11 , v ) ( 25 , p ) ( 29 , i ) ( 31 , Z ) ( 65 , s ) ( 71 , S ) ( 94 , r ) ( 98 , B ) re  、。 ，，。 ，。 ： ^ 。。 $ 。。 . ， alternate  ( re . DOTALL ) 。 A  Z  b 。 w  W 。 B ； [ ^ b ]。 d 。 D 。 s ； [ tnrfv ]。 S ； [ ^ tnrfv ]。 w ； [ a - zA - Z0 - 9 _ ]。 W ； [ ^ a - zA - Z0 - 9 _ ]。 x ?  x 。 0  1  x 。 x *  0  x 。 x +  1  x 。 x { n , m }  n  m  x ， n ， m 。 ( a | b | c )  a  b  c 。 ( x ) ，，。  re . search ()  groups () 。 1 ，；， 2  3 。 。 ( ? iLmsux ) iLmsux  re . I ( re . IGNORECASE ) :  re . M ( re . MULTILINE ) :  re . S ( re . DOTALL ) :  re . L ( re . LOCALE ) :  w W b B s S ， re . U ( re . UNICODE ) :  w W b B s S d D  unicode  re . X ( re . VERBOSE ) : ，。 ( ?: ) 。，。 ( ? P name  ) 。，。 ( ? P = name ) 。 ( ?#... ) “#”。：“ ab ( ?# comment ) cd ”“ abcd ” ( ? = ... ) 。。 ：“ a ( ? = d ) ”“ a12 ”“ a ” ( ? ! ... ) 。。 ：“ a ( ? ! d ) ”“ abc ”“ a ” ( ? = ... ) 。。 ：“ ( ? = d ) a ”“ 2 a ”“ a ” ( ? ! ... ) 。。 ：“ ( ? ! d ) a ”“ sa ”“ a ” ： 4 ，。 ( ? ( id / name ) yes - pattern | no - pattern )  id  name ， yes - pattern ，  no - pattern 。 “ | no - pattern ”。：“ ( d ) ab ( ? ( 1 ) d | c ) ”“ 1 ab2 ”“ abc ”   str2 = 12345@itv.cn print re . findall ( r (? = 12).+(?=@itv.cn ) , str2 ) ： [ 345 ] : [  ] 。，“ - ” 。 ，[ abc ]  a , b ,  c ；[ a - c ]， 。 。，[ a $] a  $ ； $  。 。 ^ ； ^   ^ 。 ，[ ^ 5 ]  5 。 。，[ s ,.] ,  . 。  。  Python ，。 ，。 ， [  ，： [  。 : 。： r bROAD$ ,  bROAD$ ， (  ) 。 : ，。“ ( ? :... ) ”。 ，；、，  (  ) 。 ，。 。 : ，。，。 ( ? P name ... ) ， ( ? P = name ) 。 MatchObject ，。  。 : ，，： 1 , 。、 ( tab ) 。，“”。 2 , 。“#”， python 。 ， re . VERBOSE  。。 re ： match () : 。 search () : ，。 findall () : ，。 finditer () : ，。 match  search ， None 。 import re s = 12abc345ab m = re . match ( r d+ , s ) m . group () , m . span () ( 12 , ( 0 , 2 )) m = re . match ( r d{3,} , s ) m is None True m = re . search ( r d{3,} , s ) m . group () , m . span () ( 345 , ( 5 , 8 )) m = re . search ( r d+ , s ) m . group () , m . span () ( 12 , ( 0 , 2 )) findall  (  ) ， finditer  match 、 search  MatchObject 。 ms = re . findall ( r d+ , s ) ms [ 12 , 345 ] ms = re . findall ( r d{5} , s ) ms [] for m in re . finditer ( r d+ , s ) : print m . group () , m . span () ... 12 ( 0 , 2 ) 345 ( 5 , 8 ) for m in re . finditer ( r d{5} , s ) : print m . group () , m . span () #  ... MatchObject match 、 search 、 finditer  —— MatchObject 。 group () : 。 start () : 。 end () : 。 span () : 、。 groups () : 。 groupdict () : 。 m = re . match ( r (d+)(P letter [abc]+) , s ) m . group () 12abc m . start () 0 m . end () 5 m . span () ( 0 , 5 ) m . groups () ( 12 , abc ) m . groupdict () { letter : abc } group () ，。 m . group ( 0 ) 12abc m . group ( 1 ) 12 m . group ( 2 ) abc m . group ( 1 , 2 ) ( 12 , abc ) m . group ( 0 , 1 , 2 ) ( 12abc , 12 , abc ) start () 、 end ()  span () 。 group () ， 0 。 m . start ( 0 ) , m . end ( 0 ) ( 0 , 5 ) m . start ( 1 ) , m . end ( 1 ) ( 0 , 2 ) m . start ( 2 ) , m . end ( 2 ) ( 2 , 5 ) m . span ( 0 ) ( 0 , 5 ) m . span ( 1 ) ( 0 , 2 ) m . span ( 2 ) ( 2 , 5 )   re . I 、 re . M ， (iLmsux) 。 s : 。 . 。 i : 。 L :  w ，。 m : 。 x : ，。 u : Unicode 。 。 re . findall ( r [a-z]+ , %123Abc%45xyz ) [ bc , xyz ] re . findall ( r [a-z]+ , %123Abc%45xyz , re . I ) [ Abc , xyz ] re . findall ( r (i)[a-z]+ , %123Abc%45xyz ) [ Abc , xyz ] ？ pattern = r ... ( d + ) # number ... ( [ a - z ] + ) # letter ... re . findall ( pattern , %123Abcn%45xyz , re . I | re . S | re . X ) [ ( 123 , Abc ) , ( 45 , xyz ) ]  ： ( P ... ) for m in re . finditer ( r (P number d+)(P letter [a-z]+) , %123Abc%45xyz , re . I ) : ... print m . groupdict () ... { number : 123 , letter : Abc } { number : 45 , letter : xyz } ： ( :... ) ，，。 for m in re . finditer ( r (:d+)([a-z]+) , %123Abc%45xyz , re . I ) : ... print m . groups () ... ( Abc , ) ( xyz , ) ：  ( P = name ) ，。 for m in re . finditer ( r a w+ /a , % a 123Abc /a % b 45xyz /b ) : ... print m . group () ... a 123 Abc / a for m in re . finditer ( r (w) w+ /(1) , % a 123Abc /a % b 45xyz /b ) : ... print m . group () ... a 123 Abc / a b 45 xyz / b for m in re . finditer ( r (P tag w) w+ /(P=tag) , % a 123Abc /a % b 45xyz / b ): ... print m . group () ... a 123 Abc / a b 45 xyz / b  ( = ... ) ：，。  ( ... ) ：，。  ( = ) ： ，。  ( ) ：，。 for m in re . finditer ( r d+(=[ab]) , %123Abc%45xyz%780b , re . I ) : ... print m . group () ... 123 780 for m in re . finditer ( r ( d)[a-z]{3,} , %123Abc%45xyz%byse , re . I ) : ... print m . group () ... byse 。  split :  pattern 。 (pattern) ，。 re . split ( r W , abc,123,x ) [ abc , 123 , x ] re . split ( r (W) , abc,123,x ) [ abc , , , 123 , , , x ] sub : 。。 re . sub ( r [a-z]+ , * , abc,123,x ) *,123,* re . sub ( r [a-z]+ , * , abc,123,x , 1 ) *,123,x subn ()  sub () ， (，) 。 re . subn ( r [a-z]+ , * , abc,123,x ) ( *,123,* , 2 ) ，。 def repl ( m ) : ... print m . group () ... return * * len ( m . group ()) ... re . subn ( r [a-z]+ , repl , abc,123,x ) abc x ( ***,123,* , 2 ) StringIO ， cStringIO 。 from contextlib import closing from cStringIO import StringIO with closing ( StringIO ( ab )) as f : ... print f , cd ... f . write ( 1234 ) ... print f . getvalue () abcd 1234  with  close () 。 getvalue () ， ( closed = False ) 。 struct struct  format ，。，、、 (  ) 、。 from struct import * hexstr = lambda s : map ( lambda c : hex ( ord ( c )) , s ) s = pack ( i , 0 x1234 ) hexstr ( s ) # 4  [ 0x34 , 0x12 , 0x0 , 0x0 ] unpack ( i , s ) # 。 4660 = 0 x1234 ( 4660 , ) s = pack ( i , 0 x1234 ) #  hexstr ( s ) [ 0x0 , 0x0 , 0x12 , 0x34 ] s = pack ( 2i2s , 0 x12 , 0 x34 , ab ) # 。。 hexstr ( s ) [ 0x12 , 0x0 , 0x0 , 0x0 , 0x34 , 0x0 , 0x0 , 0x0 , 0x61 , 0x62 ] unpack ( 2i2s , s ) ( 18 , 52 , ab )  bytearray 、 array 、 ctypes . create_str_buffer () 。 fmt = 3bi2s size = calcsize ( fmt ) # 。 buffer = bytearray ( size ) pack_into ( fmt , buffer , 0 , 0 x1 , 0 x2 , 0 x3 , 0 x1FFFFF , ab ) buffer bytearray ( b x01x02x03x00xffxffx1fx00ab ) unpack_from ( fmt , str ( buffer ) , 0 ) ( 1 , 2 , 3 , 2097151 , ab )  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 #!/usr/bin/env python import os , sys # global definition # base = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, A, B, C, D, E, F] base = [ str ( x ) for x in range ( 10 )] + [ chr ( x ) for x in range ( ord ( A ), ord ( A ) + 6 )] # bin2dec #  to : int(str,n=10) def bin2dec ( string_num ): return str ( int ( string_num , 2 )) # hex2dec #  to  def hex2dec ( string_num ): return str ( int ( string_num . upper (), 16 )) # dec2bin #  to : bin() def dec2bin ( string_num ): num = int ( string_num ) mid = [] while True : if num == 0 : break num , rem = divmod ( num , 2 ) mid . append ( base [ rem ]) return . join ([ str ( x ) for x in mid [:: - 1 ]]) # dec2hex #  to : oct() #  to : hex() def dec2hex ( string_num ): num = int ( string_num ) mid = [] while True : if num == 0 : break num , rem = divmod ( num , 16 ) mid . append ( base [ rem ]) return . join ([ str ( x ) for x in mid [:: - 1 ]]) # hex2tobin #  to : bin(int(str,16)) def hex2bin ( string_num ): return dec2bin ( hex2dec ( string_num . upper ())) # bin2hex #  to : hex(int(str,2)) def bin2hex ( string_num ): return dec2hex ( bin2dec ( string_num )) lambda reduce map filter zip  lambda lambda ，，，，。 def f ( x , y ) : return x + y print f ( 2 , 3 ) # 5 g = lambda x , y : x + y print g ( 2 , 3 ) # 5 reduce ，， def add ( x , y ) : return x + y print reduce ( add , xrange ( 1 , 10 )) # 45 print reduce ( lambda x , y : x + y , xrange ( 1 , 10 )) # 45 map  map 。 print map ( lambda x : x ** 2 , xrange ( 1 , 6 ))  # [ 1 , 4 , 9 , 16 , 25 ] print map ( lambda x , y : x + y , [ 1 , 3 , 5 , 7 , 9 ], [ 2 , 4 , 6 , 8 , 10 ] ) # [ 3 , 7 , 11 , 15 , 19 ] print map ( None ,[ 1 , 3 , 5 , 7 , 9 ], [ 2 , 4 , 6 , 8 , 10 ] )  None ， zip  # [ ( 1 , 2 ) , ( 3 , 4 ) , ( 5 , 6 ) , ( 7 , 8 ) , ( 9 , 10 ) ] filter  filter  sequence  function ， True 。 def is_even ( x ) : if x % 2 == 0 : return True return False print filter ( is_even , xrange ( 1 , 11 )) # # [ 2 , 4 , 6 , 8 , 10 ] print filter ( lambda x : x % 2 , xrange ( 1 , 11 )) # # [ 1 , 3 , 5 , 7 , 9 ]  function  None ， sequence 。 zip  ， x = [ 1 , 2 , 3 ] y = [ 4 , 5 , 6 ] z = [ 7 , 8 , 9 ] xyz = zip ( x , y , z ) print xyz # [ ( 1 , 4 , 7 ) , ( 2 , 5 , 8 ) , ( 3 , 6 , 9 ) ] print zip ( * xyz ) #  zip  # [ ( 1 , 2 , 3 ) , ( 4 , 5 , 6 ) , ( 7 , 8 , 9 ) ]   Python ， cpu ， io （，） ，，， ， setDaemon ( True ) import threading def worker ( a_tid , a_account ): print a_tid , a_account for i in range ( 20 ): th = threading . Thread ( name = name , target = worker , args = ( ‘ key ’ ,), kwargs = { a_tid : a , a_account : 2 } )  #name，, target , args (，，), kwargs  th . start ()  # +： import socket import threading from Queue import Queue def scan ( port ): s = socket . socket () s . settimeout ( 0.1 ) if s . connect_ex (( localhost , port )) == 0 : print port , open s . close () def worker (): while not q . empty (): port = q . get ()  try : scan ( port ) finally : q . task_done () if __name__ == __main__ : q = Queue () map ( q . put , xrange ( 1 , 65535 ))  threads = [ threading . Thread ( target = worker ) for i in xrange ( 500 )]  500  map ( lambda x : x . start (), threads )  # q.join()  threading . Thread ： 1 ， __init__  threading . Thread . __init__ ( self , name = threadname ) # threadname  2 ， run () ，，。 3 ， getName () ， 4 ， setName () ， 5 ， start () ， 6 ， join ( timeout = None ) ，。 timeout ， timeout  7 ， setDaemon ( bool ) ，， start () 。 False 8 ， isDaemon () ， 9 ， isAlive () ，。  threading ，。  https : // docs . python . org / 2 / library / threading . html ? highlight = threading #module-threading。  import threading lock = threading . Lock ()  share = [ 0 , 1 ] num = 2 def AddNum (): global num lock . acquire ()  share . append ( num ) print share add: , num print now: , share num += 1 lock . release ()  Condition (  ) •，。 •， condition  wait () 。 • wait () ， lock （， wait ）。 • notify ，。 •  acquire  lock ， release 。 • condition  notify () ，，。 • notify ()  lock ， notify () ， lock 。 • condition . release ()  lock 。 •，， IndexError 。 from threading import Condition , Thread import time import random queue = [] condition = Condition () class ConsumerThread ( Thread ): def run ( self ): global queue while True : condition . acquire () if not queue : print Nothing in queue, consumer is waiting condition . wait ()  queue ， wait , ， print Producer added something to queue and notified the consumer num = queue . pop ( 0 ) print Consumed , num condition . release () time . sleep ( random . random ()) class ProducerThread ( Thread ): def run ( self ): nums = range ( 5 ) global queue while True : condition . acquire ()  num = random . choice ( nums ) queue . append ( num ) print Produced , num condition . notify ()  wait condition . release ()  time . sleep ( random . random ()) ProducerThread () . start () ConsumerThread () . start () （ Queue ）  • list ， Queue （）。 • condition ， lock 。 Queue ， condition  lock 。 • put 。 • put ( — )  lock 。 •， put () 。， wait () ，。 •  get 。 • get ()  lock 。 • get () ，，。 • get ()  put ()  notify () 。 Queue 。 from threading import Thread import time import random from Queue import Queue queue = Queue ( 10 ) class ProducerThread ( Thread ): def run ( self ): nums = range ( 5 ) global queue while True : num = random . choice ( nums ) queue . put ( num ) print Produced , num time . sleep ( random . random ()) class ConsumerThread ( Thread ): def run ( self ): global queue while True : num = queue . get () #queue.task_done() print Consumed , num time . sleep ( random . random ()) ProducerThread () . start () ConsumerThread () . start ()    try : s = input ( Enter something -- ) # Python 2  raw_input () except EOFError as e :  EOFError ， e  print ( nWhy did you do an EOF on me? ) except :  print ( nWhy did you do an Exception on me? ) else :  print ( No exception was raised. ) finally : # , print ( finally ..... )  (  ) :   KeyError 。   ValueError 。   AttributeError 。   NameError 。   TypeError 。  ImportError 。 raise   raise  (  ) 。 / 。  Error  Exception 。  Python 3 ，。 Python 2 Python 3 ① raise MyException MyException ② raise MyException , error message raise MyException ( error message ) ③ raise MyException , error message , a_traceback raise MyException ( error message ) . with_traceback ( a_traceback ) ④ raise error message unsupported (  ) : ① ，，。 ② : Python 2 ； Python 3 。 ③  ( stack trace , ) 。 Python 2  3 。 ④  Python 2 ，。 Python 3 ，。 2 to3 。 ： raise RuntimeError (  ) #   def func (  ): ““” func “”“ print ( func ) # return #return，，， print ( ‘ func ’ ) # ”“”“”“ func () # ， func #，  return  ，，， () ， return ， return ， None ， print ， print 。 def func ( first , second ): return first + second a1 = func ( 4 , 5 ) print a1 a2 = func print func print a2 print a2 ( 3 , 4 ) ： 9 function func at 0x7f38bca44c80 function func at 0x7f38bca44c80 7  ， def func ( arg1 , * args , ** kw ): #*，；** print ( arg1: %s % arg1 ) print args print kw func ( A , B , C , D = 1 , E = 2 ) ： arg1 : A ( B , C ) { E : 2 , D : 1 } def func ( name , age = 10 ): # pass  Lambda ，，，。 lambda ，，，，。 Reduce Reduce ，，。  closures  import time def hl ( func ): def wrap (): begin = int ( time . time ()) print begin func () end = int ( time . time ()) print end print cost: , end - begin return end - begin return wrap def t (): time . sleep ( 1 ) hl ( t )()  、 import time def hl ( func ): def wrap (): begin = int ( time . time ()) print begin func () end = int ( time . time ()) print end print cost: , end - begin return end - begin return wrap @hl def t (): time . sleep ( 1 ) t () ############################## def mb ( func ): def wrap (): return b + func () + /b return wrap def mi ( func ): def wrap (): return i + func () + /i return wrap @mb @mi def hello (): return ( hello ) print ( hello ())  dict . clear ()  a = dict ( x = 1 , y = 2 )  a . clear ()  None dict . get ( key )  dict  key , value ， ，  None a = dict ( x = 1 , y = 2 ) a . get ( ‘ x ’ ) 、， values  None dict . keys ()  a = dict ( x = 1 , y = 2 )  a . keys ()  key  dict . values ()  a = {‘ x ’: 1 ,’ y ’: 2 }  a . values ()  value  dict . items ()  ( ,  )  a = {‘ x ’: 1 ,’ y ’: 2 }  a . items () [ ( y , 2 ) , ( x , 1 ) ] （ key ， value ） dict . copy () （） a = {‘ x ’: 1 ,’ y ’: 2 }  b = a . copy ()  dict . has_key ( key )  dict  key a . has_key ( ‘ x ’ ) 、（ key ，） return boole （ True or False ） dict . iteritems () （ key , value ）， for  a = { a : 1 , b : 2 } for k , v in a . iteritems () : for  ... print k , v ... a 1 b 2 s = a . iteritems () s . next () next  ( a , 1 ) s . next () ( b , 2 ) dict . iterkeys ()  key  dict . itervalues ()  value  dict . pop ( key [, default ] )  key ， dict [ key ]， key ，  default ， KeyError  a = {‘ x ’: 1 ,’ y ’: 2 ,’ z ’: 3 } a . pop ( ‘ x ’ ) 1  key a . pop ( ‘ abc ’,’ sky ’ ) sky  value dict . popitem ()  a = {‘ x ’: 1 ,’ y ’: 2 ,’ z ’: 3 } a . popitem ()  ( ‘ x ’, 1 ) （ key ， value ） dict . setdefault ( key , default = None )  key ， dict [ key ] = default 。 a = {‘ x ’: 1 } a . setdefalut ( ‘ y ’ )  key a . setdefault ( ‘ z ’, 3 )  value  None { x : 1 , y : None , z : 3 } dict . update ( dict2 )  dict2  -  dict a = { a : 1 } b = { b : 2 } a . update ( b )  a  None { a : 1 , b : 2 } dict . fromkeys ( seq , val = None ) ，  seq ， val   ( ， None ) a . fromkeys ( ‘ d ’, 3 )  key  value （）， { d : 3 }  a = { a : 1 , b : 2 } a . viewitems () dict_items ( [ ( a , 1 ) , ( b , 2 ) ] ) a . viewkeys () dict_keys ( [ a , b ] ) a . viewvalues () dict_values ( [ 1 , 2 ] )  sorted ( dic1 . iteritems () , key = lambda key : key [ 0 ], reverse = True )  key ， reverse = True ， sorted ( dic1 . iteritems () , key = lambda key : key [ 1 ], reverse = True )  value   class （ oop ） web flask  salt zabbix cobbler  hadoop   ，     ，  def __init__ ( self ) :  def __del__ ( self ) :  f1 = Friut ( app , 33 ) self        ，  class Friut ( object ) :  count = 0  def __init__ ( self , name , weight ) :  self . name = name self . weight = weight Friut . count += 1 def info ( self ) :  print self . name , self . weight , Friut . count  @staticmethod def func_name ()  . func_name () @classmethod def func_name ( self )  . func_name ()   . func_name () dir (  )  __doc__ __name__ __module__  __main__ __base__ __dict__  、  class Parent ( object ) : # define parent class def myMethod ( self ) : print Calling parent method def setAttr ( self , attr ) : Parent . parentAttr = attr class Child ( Parent ) : # define child class Parent def myMethod ( self ) : print Calling child method myMethod  class JustCounter ( object ) : __secretCount = 0 def count ( self ) : self . __secretCount += 1 print self . __secretCount counter = JustCounter () counter . count () print counter . __secretCount  ， class super class A ( object ) : def __init__ ( self ) : print enter A class B ( A ) : # def __init__ ( self ) : print enter B super ( B , self ). __init__ () print leave B  B build in ：  ，  G  global E  L  local  import py  import sys print sys . path    1 . for - in  Iterator (  )  2 . yield  Generator (  ) ， 3 . yield , for - in  ，， 1 . next  (  ) 2 . __iter__ （） type ( iter ( range ( 10 ))) Out [ 5 ]: listiterator  iter () 。: iter ( obj )  iter () ，，，:  0 。， __iter__ ()  next () . iter ( func ， sentinel )  iter () ， func ， sentinel 。 it = iter ( [ 1 , 2 , 3 , 4 , 5 ] ) while True : try : x = next ( it )  except StopIteration :  StopIteration （） break  ，  str . rstrip ()  str  str . lstrip ()  str  str . strip ()  str  lstrip ()  rstrip () ，， str . center ( width ) , width  str . ljust ( width ) , width  str . rjust ( width ) , width  string . zfill ( width )  width ， string ， 0 str . expandtabs ( tabsize = 8 )  str  tab ， 8   a = ‘ t123abc23t ’ a . strip () ‘ 123 abc123 ’ a . srtip ( ‘ 123 ’ ) ‘ t123abc23t ’ a . rstrip () ‘ t123abc23 ’ a . lsrtip ( ‘ 123 ’ ) ‘ t123abc23t ’ s . expandtabs ( 4 ) 123abc23 s = hello s . center ( 20 ) hello  string . title ()    string ,，  str . lower ()  string  str . upper ()  string  str . swapcase ()  string  str . capitalize ()  ，，  ， str . isalnum ()  str  True , False str . isalpha ()  str  True , False str . isdigit ()  str  True  False str . isdecimal ()  string  True  False str . isspace ()  str ， True ， False str . istitle ()  str  (  title ())  True ， False str . isupper ()  str ， (  )  ， True ， False str . islower ()  str ， (  )  ， True ， False ################################################# ，（ True or False ） str . startswith ( obj , beg = 0 , end = len ( string ))  obj ， True ， False 。 beg  end ， str . endswith ( obj , beg = 0 , end = len ( string ))  obj ， beg  end   obj ，， True , False ，，， str . join ( sqp )  string ， seq  (  )   l = [ I , am , tom ] 、、， -- . join ( l ) I--am--tom 、、 key  str  str . split ( str = , num = string . count ( str ))  str  string ， num ， num  astr = ‘ I | am | tom ! ’ （） astr . split ( ‘ | ’ ) [ I , am , tom! ]  string . find ( str , beg = 0 , end = len ( string ))  str  string ，  beg  end ， ，， - 1 string . index ( str , beg = 0 , end = len ( string ))  find () ， str  string  ValueError . string . rfind ( str , beg = 0 , end = len ( string ) )  find () ，. string . rindex ( str , beg = 0 , end = len ( string ))  index () ， a = ‘ i am a student ’ （） a . find ( ‘ am ’ ) 2  - 1 str . replace ( str1 , str2 , num = string . count ( str1 ))  str  str1  str2 , num ， num  a = ‘ du , hello , du bye ’ ，（） a . replace ( ‘ du ’,’ minchao ’, 1 ) minchao,hello,du bye ， string . count ( str , beg = 0 , end = len ( string ))  str  string ， beg  end  str  a = ‘ du , hello , du bye ’ （） a . count ( ‘ du ’, 3 ) return 1  str  string . partition ( str )  find ()  split () , str ,    string     3      ( string_pre_str , str , string_post_str ) , string  str  string_pre_str == string . s = a b c d e ， s . partition ( c ) ( a b , c , d e ) s . partition ( f ) ( a b c d e , , ) string . rpartition ( str )  partition () ,. string . splitlines ( num = string . count ( n )) ，， num  num . s = 332 ， 2432 4343 s . splitlines () [ 332 , 2432 , 4343 ]   string . decode ( encoding = UTF-8 , errors = strict )  encoding  string ， ValueError    ，   errors     ignore   replace s =  s xc4xe3xbaxc3 s . decode ( encoding = GBK ) u u4f60u597d string . encode ( encoding = UTF-8 , errors = strict )  encoding  string ， ValueError ， errors   ignore  replace  tuple . index ( obj , i = 0 , j = len ( list ))  tuple [ k ]== obj  k  ,  k  [ i , j ) a = ( 1 , 2 , 3 , 4 , 5 , 6 , 2 )  tuple  （  ） a . index ( 2 )  obj  tuple  tuple . count ( obj )  obj  tuple  a = ( 1 , 2 , 3 , 3 , 3 , 4 )  、  、  a . count ( 1 )  tuple  eval ： str 。 ： eval ( source [, globals [, locals ]]) ： source ： Python  compile ()  globals ：。 dictionary locals ：。 map   list , tuple , dict  string 。 eval ，， ast  ast . literal_eval ()   a = [[1,2], [3,4], [5,6], [7,8], [9,0]] type ( a ) type str b = eval ( a ) print b [[ 1 , 2 ], [ 3 , 4 ], [ 5 , 6 ], [ 7 , 8 ], [ 9 , 0 ]] type ( b ) type list  a = {1: a , 2: b } type ( a ) type str b = eval ( a ) print b { 1 : a , 2 : b } type ( b ) type dict","title":"python-base"},{"location":"python-base/#_1","text":" from collections import Counter Counter ( list ) . most_common  [ a for a in range ( 10 )]  ( a for a in range ( 10 ))  { a for a in range ( 10 )}  { a : a * 2 for a in range ( 3 )}  { a for a in range ( 10 ) if a == 2 } set ([ 2 ]) list . apped ( obj )  obj a = [ 1 , 2 , 3 ] a . append ( 4 ) ，，，， a . append ({ ‘ age ’ : 34 })  None list . extend ( seq )  seq  a = [ 1 , 2 , 3 ] 、 key b = [ 3 , 4 , 5 ] a . extend ( b )  None list . insert ( n , object )  n  obj a = [ 1 , 2 , 3 ] ，，，， a . insert ( 0 , ’ du ’ )  None list . pop ([ index ]) ， a = [ 1 , 2 , 3 , 4 , 5 ]  a . pop ( 0 )  list . reverse ()  a = [ 1 , 2 , 3 , 4 ]  a . reverse ()  None list . count ( obj )  obj  a = [ 1 , 2 , 3 , 3 , 3 , 4 ] 、、 a . count ( 1 )  list . index ( obj , i = 0 , j = len ( list ))  list [ k ] == obj  k  ,  k  [ i , j ) a = [ 1 , 2 , 3 , 4 , 5 , 6 , 2 ]  list （） a . index ( 2 )  obj  list  list . remove ( value )  obj a = [ 1 , 2 , 3 , 4 , 2 ]  list  a . remove ( 2 )  None list . sort ( func = None , key = None , reverse = False ) ， func  key  ， ,  reverse = True  a = [ 1 , 4 , 2 , 3 , 5 ] a . sort () a = [ 1 , 2 , 3 , 4 , 5 ] 、 key 、 reverse  a = [ ‘ du ’ , ’ dumc ’ , ’ d ’ , ’ dddddd ’ ]  None a . sort ( key = len ) a = [ ‘ d ’ , ’ du ’ , ’ dumc ’ , ’ dddddd ’ ] https : // wiki . python . org / moin / HowTo / Sorting student_tuples = [ ( john , A , 15 ), ( jane , B , 12 ), ( dave , B , 10 ), ] sorted ( student_tuples , key = lambda student : student [ 2 ]) # sort by age [( dave , B , 10 ), ( jane , B , 12 ), ( john , A , 15 )] a = [ 2 , 2 , 3 , 4 , 5 ] list ( set ( a )   list  #: a = [ 2 , 3 , 4 , 5 ] b = [ 2 , 5 , 8 ] tmp = [ val for val in a if val in b ] print tmp #[2, 5] # print list ( set ( a ) . intersection ( set ( b )))  list  print list ( set ( a ) . union ( set ( b )))  list  print list ( set ( b ) . difference ( set ( a ))) # ba","title":""},{"location":"python-base/#_2","text":"UnicodeEncodeError : ascii codec can ’ t encode characters in position 0 - 15 : ordinal not in range ( 128 ) # coding=utf-8  import sys reload ( sys ) sys . setdefaultencoding ( utf8 )","title":""},{"location":"python-base/#_3","text":"# coding=utf-8 # pip install pygeoip # wget http://geolite.maxmind.com/download/geoip/database/GeoLiteCity.dat.gz import pytz import time , os import pygeoip from datetime import datetime gi = pygeoip . GeoIP ( GeoLiteCity.dat , pygeoip . MEMORY_CACHE ) def ZoneTrans ( ip , timedate ): zone = gi . record_by_addr ( ip )[ time_zone ] tz = pytz . timezone ( zone ) utc = pytz . timezone ( Asia/Shanghai ) dateobj = datetime . strptime ( timedate , %Y-%m- %d %H:%M:%S ) print dateobj . replace ( tzinfo = tz ) . astimezone ( utc ) print dateobj . replace ( tzinfo = tz ) . astimezone ( utc ) . strptime ( %Y-%m- %d %H:%M:%S )) ZoneTrans ( 50.186.14.252 , 2016-10-31 04:59:35 )","title":""},{"location":"python-base/#_4","text":"bisect bisect   (sorted)  。 import bisect b = [ 20 , 34 , 35 , 65 , 78 ] bisect . bisect ( b , 25 ) #  25 。 1 bisect . bisect ( b , 40 ) #  40 。 3 bisect . bisect_left ( b , 35 ) # ，。 2 bisect . bisect_right ( b , 35 ) # ，。 3  insort_left () 。 bisect . insort_left ( b , 25 ) b [ 20 , 25 , 34 , 35 , 65 , 78 ] bisect . insort_left ( b , 40 ) b [ 20 , 25 , 34 , 35 , 40 , 65 , 78 ]  bisect  SortedList 。 def SortedList ( list , * elements ): ... for e in elements : ... bisect . insort_right ( list , e ) ... ... return list SortedList ([], 3 , 7 , 4 , 1 ) [ 1 , 3 , 4 , 7 ] o = SortedList ([], 3 , 7 , 4 , 1 ) o [ 1 , 3 , 4 , 7 ] SortedList ( o , 8 , 2 , 6 , 0 ) [ 0 , 1 , 2 , 3 , 4 , 6 , 7 , 8 ]  bisect  Consistent Hashing ， Key  Ring ， 。 heapq  : ，。 ： / 。 (  )  O ( logN ) ， O ( N ) 。 。，； ，。 from heapq import * from random import * rand = sample ( xrange ( 1000 ), 10 ) # 。 rand [ 572 , 758 , 737 , 738 , 412 , 755 , 507 , 734 , 479 , 374 ] heap = [] for x in rand : heappush ( heap , x ) # 。 heap # ，。 [ 374 , 412 , 507 , 572 , 479 , 755 , 737 , 758 , 734 , 738 ] while heap : print heappop ( heap ) # 。 374 412 479 507 572 734 737 738 755 758 。 d = sample ( xrange ( 10 ), 10 ) d [ 9 , 7 , 3 , 4 , 0 , 2 , 5 , 1 , 8 , 6 ] heapify ( d ) # 。 d [ 0 , 1 , 2 , 4 , 6 , 3 , 5 , 9 , 8 , 7 ] heappushpop ( d , - 1 ) #  push(item)， pop。 item。 - 1 heapreplace ( d , - 1 ) #  pop， push(item)。 item。 0 ... ... a = range ( 1 , 10 , 2 ) b = range ( 2 , 10 , 2 ) [ x for x in merge ( a , b )] # 。 [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 ] ... ... d = sample ( range ( 10 ), 10 ) d [ 9 , 0 , 3 , 4 , 5 , 6 , 1 , 2 , 8 , 7 ] nlargest ( 5 , list ) # () n 。 [ 9 , 8 , 7 , 6 , 5 ] nsmallest ( 5 , list ) #  n 。 [ 0 , 1 , 2 , 3 , 4 ]  cmp ，，。 from string import * data = map ( None , sample ( xrange ( 100 ), 10 ), sample ( letters , 10 )) data [( 31 , Z ), ( 71 , S ), ( 94 , r ), ( 65 , s ), ( 98 , B ), ( 10 , U ), ( 8 , u ), ( 25 , p ), ( 11 , v ), ( 29 , i )] for item in data : heappush ( heap , item ) heap [( 8 , u ), ( 11 , v ), ( 10 , U ), ( 25 , p ), ( 29 , i ), ( 94 , r ), ( 31 , Z ), ( 71 , S ), ( 65 , s ), ( 98 , B )] while heap : print heappop ( heap ) ( 8 , u ) ( 10 , U ) ( 11 , v ) ( 25 , p ) ( 29 , i ) ( 31 , Z ) ( 65 , s ) ( 71 , S ) ( 94 , r ) ( 98 , B )","title":""},{"location":"python-base/#re","text":" 、。 ，，。 ，。 ： ^ 。。 $ 。。 . ， alternate  ( re . DOTALL ) 。 A  Z  b 。 w  W 。 B ； [ ^ b ]。 d 。 D 。 s ； [ tnrfv ]。 S ； [ ^ tnrfv ]。 w ； [ a - zA - Z0 - 9 _ ]。 W ； [ ^ a - zA - Z0 - 9 _ ]。 x ?  x 。 0  1  x 。 x *  0  x 。 x +  1  x 。 x { n , m }  n  m  x ， n ， m 。 ( a | b | c )  a  b  c 。 ( x ) ，，。  re . search ()  groups () 。 1 ，；， 2  3 。 。 ( ? iLmsux ) iLmsux  re . I ( re . IGNORECASE ) :  re . M ( re . MULTILINE ) :  re . S ( re . DOTALL ) :  re . L ( re . LOCALE ) :  w W b B s S ， re . U ( re . UNICODE ) :  w W b B s S d D  unicode  re . X ( re . VERBOSE ) : ，。 ( ?: ) 。，。 ( ? P name  ) 。，。 ( ? P = name ) 。 ( ?#... ) “#”。：“ ab ( ?# comment ) cd ”“ abcd ” ( ? = ... ) 。。 ：“ a ( ? = d ) ”“ a12 ”“ a ” ( ? ! ... ) 。。 ：“ a ( ? ! d ) ”“ abc ”“ a ” ( ? = ... ) 。。 ：“ ( ? = d ) a ”“ 2 a ”“ a ” ( ? ! ... ) 。。 ：“ ( ? ! d ) a ”“ sa ”“ a ” ： 4 ，。 ( ? ( id / name ) yes - pattern | no - pattern )  id  name ， yes - pattern ，  no - pattern 。 “ | no - pattern ”。：“ ( d ) ab ( ? ( 1 ) d | c ) ”“ 1 ab2 ”“ abc ”   str2 = 12345@itv.cn print re . findall ( r (? = 12).+(?=@itv.cn ) , str2 ) ： [ 345 ] : [  ] 。，“ - ” 。 ，[ abc ]  a , b ,  c ；[ a - c ]， 。 。，[ a $] a  $ ； $  。 。 ^ ； ^   ^ 。 ，[ ^ 5 ]  5 。 。，[ s ,.] ,  . 。  。  Python ，。 ，。 ， [  ，： [  。 : 。： r bROAD$ ,  bROAD$ ， (  ) 。 : ，。“ ( ? :... ) ”。 ，；、，  (  ) 。 ，。 。 : ，。，。 ( ? P name ... ) ， ( ? P = name ) 。 MatchObject ，。  。 : ，，： 1 , 。、 ( tab ) 。，“”。 2 , 。“#”， python 。 ， re . VERBOSE  。。 re ： match () : 。 search () : ，。 findall () : ，。 finditer () : ，。 match  search ， None 。 import re s = 12abc345ab m = re . match ( r d+ , s ) m . group () , m . span () ( 12 , ( 0 , 2 )) m = re . match ( r d{3,} , s ) m is None True m = re . search ( r d{3,} , s ) m . group () , m . span () ( 345 , ( 5 , 8 )) m = re . search ( r d+ , s ) m . group () , m . span () ( 12 , ( 0 , 2 )) findall  (  ) ， finditer  match 、 search  MatchObject 。 ms = re . findall ( r d+ , s ) ms [ 12 , 345 ] ms = re . findall ( r d{5} , s ) ms [] for m in re . finditer ( r d+ , s ) : print m . group () , m . span () ... 12 ( 0 , 2 ) 345 ( 5 , 8 ) for m in re . finditer ( r d{5} , s ) : print m . group () , m . span () #  ... MatchObject match 、 search 、 finditer  —— MatchObject 。 group () : 。 start () : 。 end () : 。 span () : 、。 groups () : 。 groupdict () : 。 m = re . match ( r (d+)(P letter [abc]+) , s ) m . group () 12abc m . start () 0 m . end () 5 m . span () ( 0 , 5 ) m . groups () ( 12 , abc ) m . groupdict () { letter : abc } group () ，。 m . group ( 0 ) 12abc m . group ( 1 ) 12 m . group ( 2 ) abc m . group ( 1 , 2 ) ( 12 , abc ) m . group ( 0 , 1 , 2 ) ( 12abc , 12 , abc ) start () 、 end ()  span () 。 group () ， 0 。 m . start ( 0 ) , m . end ( 0 ) ( 0 , 5 ) m . start ( 1 ) , m . end ( 1 ) ( 0 , 2 ) m . start ( 2 ) , m . end ( 2 ) ( 2 , 5 ) m . span ( 0 ) ( 0 , 5 ) m . span ( 1 ) ( 0 , 2 ) m . span ( 2 ) ( 2 , 5 )   re . I 、 re . M ， (iLmsux) 。 s : 。 . 。 i : 。 L :  w ，。 m : 。 x : ，。 u : Unicode 。 。 re . findall ( r [a-z]+ , %123Abc%45xyz ) [ bc , xyz ] re . findall ( r [a-z]+ , %123Abc%45xyz , re . I ) [ Abc , xyz ] re . findall ( r (i)[a-z]+ , %123Abc%45xyz ) [ Abc , xyz ] ？ pattern = r ... ( d + ) # number ... ( [ a - z ] + ) # letter ... re . findall ( pattern , %123Abcn%45xyz , re . I | re . S | re . X ) [ ( 123 , Abc ) , ( 45 , xyz ) ]  ： ( P ... ) for m in re . finditer ( r (P number d+)(P letter [a-z]+) , %123Abc%45xyz , re . I ) : ... print m . groupdict () ... { number : 123 , letter : Abc } { number : 45 , letter : xyz } ： ( :... ) ，，。 for m in re . finditer ( r (:d+)([a-z]+) , %123Abc%45xyz , re . I ) : ... print m . groups () ... ( Abc , ) ( xyz , ) ：  ( P = name ) ，。 for m in re . finditer ( r a w+ /a , % a 123Abc /a % b 45xyz /b ) : ... print m . group () ... a 123 Abc / a for m in re . finditer ( r (w) w+ /(1) , % a 123Abc /a % b 45xyz /b ) : ... print m . group () ... a 123 Abc / a b 45 xyz / b for m in re . finditer ( r (P tag w) w+ /(P=tag) , % a 123Abc /a % b 45xyz / b ): ... print m . group () ... a 123 Abc / a b 45 xyz / b  ( = ... ) ：，。  ( ... ) ：，。  ( = ) ： ，。  ( ) ：，。 for m in re . finditer ( r d+(=[ab]) , %123Abc%45xyz%780b , re . I ) : ... print m . group () ... 123 780 for m in re . finditer ( r ( d)[a-z]{3,} , %123Abc%45xyz%byse , re . I ) : ... print m . group () ... byse 。  split :  pattern 。 (pattern) ，。 re . split ( r W , abc,123,x ) [ abc , 123 , x ] re . split ( r (W) , abc,123,x ) [ abc , , , 123 , , , x ] sub : 。。 re . sub ( r [a-z]+ , * , abc,123,x ) *,123,* re . sub ( r [a-z]+ , * , abc,123,x , 1 ) *,123,x subn ()  sub () ， (，) 。 re . subn ( r [a-z]+ , * , abc,123,x ) ( *,123,* , 2 ) ，。 def repl ( m ) : ... print m . group () ... return * * len ( m . group ()) ... re . subn ( r [a-z]+ , repl , abc,123,x ) abc x ( ***,123,* , 2 ) StringIO ， cStringIO 。 from contextlib import closing from cStringIO import StringIO with closing ( StringIO ( ab )) as f : ... print f , cd ... f . write ( 1234 ) ... print f . getvalue () abcd 1234  with  close () 。 getvalue () ， ( closed = False ) 。 struct struct  format ，。，、、 (  ) 、。 from struct import * hexstr = lambda s : map ( lambda c : hex ( ord ( c )) , s ) s = pack ( i , 0 x1234 ) hexstr ( s ) # 4  [ 0x34 , 0x12 , 0x0 , 0x0 ] unpack ( i , s ) # 。 4660 = 0 x1234 ( 4660 , ) s = pack ( i , 0 x1234 ) #  hexstr ( s ) [ 0x0 , 0x0 , 0x12 , 0x34 ] s = pack ( 2i2s , 0 x12 , 0 x34 , ab ) # 。。 hexstr ( s ) [ 0x12 , 0x0 , 0x0 , 0x0 , 0x34 , 0x0 , 0x0 , 0x0 , 0x61 , 0x62 ] unpack ( 2i2s , s ) ( 18 , 52 , ab )  bytearray 、 array 、 ctypes . create_str_buffer () 。 fmt = 3bi2s size = calcsize ( fmt ) # 。 buffer = bytearray ( size ) pack_into ( fmt , buffer , 0 , 0 x1 , 0 x2 , 0 x3 , 0 x1FFFFF , ab ) buffer bytearray ( b x01x02x03x00xffxffx1fx00ab ) unpack_from ( fmt , str ( buffer ) , 0 ) ( 1 , 2 , 3 , 2097151 , ab )","title":"re"},{"location":"python-base/#_5","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 #!/usr/bin/env python import os , sys # global definition # base = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, A, B, C, D, E, F] base = [ str ( x ) for x in range ( 10 )] + [ chr ( x ) for x in range ( ord ( A ), ord ( A ) + 6 )] # bin2dec #  to : int(str,n=10) def bin2dec ( string_num ): return str ( int ( string_num , 2 )) # hex2dec #  to  def hex2dec ( string_num ): return str ( int ( string_num . upper (), 16 )) # dec2bin #  to : bin() def dec2bin ( string_num ): num = int ( string_num ) mid = [] while True : if num == 0 : break num , rem = divmod ( num , 2 ) mid . append ( base [ rem ]) return . join ([ str ( x ) for x in mid [:: - 1 ]]) # dec2hex #  to : oct() #  to : hex() def dec2hex ( string_num ): num = int ( string_num ) mid = [] while True : if num == 0 : break num , rem = divmod ( num , 16 ) mid . append ( base [ rem ]) return . join ([ str ( x ) for x in mid [:: - 1 ]]) # hex2tobin #  to : bin(int(str,16)) def hex2bin ( string_num ): return dec2bin ( hex2dec ( string_num . upper ())) # bin2hex #  to : hex(int(str,2)) def bin2hex ( string_num ): return dec2hex ( bin2dec ( string_num ))","title":""},{"location":"python-base/#lambda-reduce-map-filter-zip","text":" lambda lambda ，，，，。 def f ( x , y ) : return x + y print f ( 2 , 3 ) # 5 g = lambda x , y : x + y print g ( 2 , 3 ) # 5 reduce ，， def add ( x , y ) : return x + y print reduce ( add , xrange ( 1 , 10 )) # 45 print reduce ( lambda x , y : x + y , xrange ( 1 , 10 )) # 45 map  map 。 print map ( lambda x : x ** 2 , xrange ( 1 , 6 ))  # [ 1 , 4 , 9 , 16 , 25 ] print map ( lambda x , y : x + y , [ 1 , 3 , 5 , 7 , 9 ], [ 2 , 4 , 6 , 8 , 10 ] ) # [ 3 , 7 , 11 , 15 , 19 ] print map ( None ,[ 1 , 3 , 5 , 7 , 9 ], [ 2 , 4 , 6 , 8 , 10 ] )  None ， zip  # [ ( 1 , 2 ) , ( 3 , 4 ) , ( 5 , 6 ) , ( 7 , 8 ) , ( 9 , 10 ) ] filter  filter  sequence  function ， True 。 def is_even ( x ) : if x % 2 == 0 : return True return False print filter ( is_even , xrange ( 1 , 11 )) # # [ 2 , 4 , 6 , 8 , 10 ] print filter ( lambda x : x % 2 , xrange ( 1 , 11 )) # # [ 1 , 3 , 5 , 7 , 9 ]  function  None ， sequence 。 zip  ， x = [ 1 , 2 , 3 ] y = [ 4 , 5 , 6 ] z = [ 7 , 8 , 9 ] xyz = zip ( x , y , z ) print xyz # [ ( 1 , 4 , 7 ) , ( 2 , 5 , 8 ) , ( 3 , 6 , 9 ) ] print zip ( * xyz ) #  zip  # [ ( 1 , 2 , 3 ) , ( 4 , 5 , 6 ) , ( 7 , 8 , 9 ) ]","title":"lambda reduce map filter zip"},{"location":"python-base/#_6","text":" Python ， cpu ， io （，） ，，， ， setDaemon ( True ) import threading def worker ( a_tid , a_account ): print a_tid , a_account for i in range ( 20 ): th = threading . Thread ( name = name , target = worker , args = ( ‘ key ’ ,), kwargs = { a_tid : a , a_account : 2 } )  #name，, target , args (，，), kwargs  th . start ()  # +： import socket import threading from Queue import Queue def scan ( port ): s = socket . socket () s . settimeout ( 0.1 ) if s . connect_ex (( localhost , port )) == 0 : print port , open s . close () def worker (): while not q . empty (): port = q . get ()  try : scan ( port ) finally : q . task_done () if __name__ == __main__ : q = Queue () map ( q . put , xrange ( 1 , 65535 ))  threads = [ threading . Thread ( target = worker ) for i in xrange ( 500 )]  500  map ( lambda x : x . start (), threads )  # q.join()  threading . Thread ： 1 ， __init__  threading . Thread . __init__ ( self , name = threadname ) # threadname  2 ， run () ，，。 3 ， getName () ， 4 ， setName () ， 5 ， start () ， 6 ， join ( timeout = None ) ，。 timeout ， timeout  7 ， setDaemon ( bool ) ，， start () 。 False 8 ， isDaemon () ， 9 ， isAlive () ，。  threading ，。  https : // docs . python . org / 2 / library / threading . html ? highlight = threading #module-threading。  import threading lock = threading . Lock ()  share = [ 0 , 1 ] num = 2 def AddNum (): global num lock . acquire ()  share . append ( num ) print share add: , num print now: , share num += 1 lock . release ()  Condition (  ) •，。 •， condition  wait () 。 • wait () ， lock （， wait ）。 • notify ，。 •  acquire  lock ， release 。 • condition  notify () ，，。 • notify ()  lock ， notify () ， lock 。 • condition . release ()  lock 。 •，， IndexError 。 from threading import Condition , Thread import time import random queue = [] condition = Condition () class ConsumerThread ( Thread ): def run ( self ): global queue while True : condition . acquire () if not queue : print Nothing in queue, consumer is waiting condition . wait ()  queue ， wait , ， print Producer added something to queue and notified the consumer num = queue . pop ( 0 ) print Consumed , num condition . release () time . sleep ( random . random ()) class ProducerThread ( Thread ): def run ( self ): nums = range ( 5 ) global queue while True : condition . acquire ()  num = random . choice ( nums ) queue . append ( num ) print Produced , num condition . notify ()  wait condition . release ()  time . sleep ( random . random ()) ProducerThread () . start () ConsumerThread () . start () （ Queue ）  • list ， Queue （）。 • condition ， lock 。 Queue ， condition  lock 。 • put 。 • put ( — )  lock 。 •， put () 。， wait () ，。 •  get 。 • get ()  lock 。 • get () ，，。 • get ()  put ()  notify () 。 Queue 。 from threading import Thread import time import random from Queue import Queue queue = Queue ( 10 ) class ProducerThread ( Thread ): def run ( self ): nums = range ( 5 ) global queue while True : num = random . choice ( nums ) queue . put ( num ) print Produced , num time . sleep ( random . random ()) class ConsumerThread ( Thread ): def run ( self ): global queue while True : num = queue . get () #queue.task_done() print Consumed , num time . sleep ( random . random ()) ProducerThread () . start () ConsumerThread () . start ()","title":""},{"location":"python-base/#_7","text":"  try : s = input ( Enter something -- ) # Python 2  raw_input () except EOFError as e :  EOFError ， e  print ( nWhy did you do an EOF on me? ) except :  print ( nWhy did you do an Exception on me? ) else :  print ( No exception was raised. ) finally : # , print ( finally ..... )  (  ) :   KeyError 。   ValueError 。   AttributeError 。   NameError 。   TypeError 。  ImportError 。 raise   raise  (  ) 。 / 。  Error  Exception 。  Python 3 ，。 Python 2 Python 3 ① raise MyException MyException ② raise MyException , error message raise MyException ( error message ) ③ raise MyException , error message , a_traceback raise MyException ( error message ) . with_traceback ( a_traceback ) ④ raise error message unsupported (  ) : ① ，，。 ② : Python 2 ； Python 3 。 ③  ( stack trace , ) 。 Python 2  3 。 ④  Python 2 ，。 Python 3 ，。 2 to3 。 ： raise RuntimeError (  ) #","title":""},{"location":"python-base/#_8","text":" def func (  ): ““” func “”“ print ( func ) # return #return，，， print ( ‘ func ’ ) # ”“”“”“ func () # ， func #，  return  ，，， () ， return ， return ， None ， print ， print 。 def func ( first , second ): return first + second a1 = func ( 4 , 5 ) print a1 a2 = func print func print a2 print a2 ( 3 , 4 ) ： 9 function func at 0x7f38bca44c80 function func at 0x7f38bca44c80 7  ， def func ( arg1 , * args , ** kw ): #*，；** print ( arg1: %s % arg1 ) print args print kw func ( A , B , C , D = 1 , E = 2 ) ： arg1 : A ( B , C ) { E : 2 , D : 1 } def func ( name , age = 10 ): # pass  Lambda ，，，。 lambda ，，，，。 Reduce Reduce ，，。  closures  import time def hl ( func ): def wrap (): begin = int ( time . time ()) print begin func () end = int ( time . time ()) print end print cost: , end - begin return end - begin return wrap def t (): time . sleep ( 1 ) hl ( t )()  、 import time def hl ( func ): def wrap (): begin = int ( time . time ()) print begin func () end = int ( time . time ()) print end print cost: , end - begin return end - begin return wrap @hl def t (): time . sleep ( 1 ) t () ############################## def mb ( func ): def wrap (): return b + func () + /b return wrap def mi ( func ): def wrap (): return i + func () + /i return wrap @mb @mi def hello (): return ( hello ) print ( hello ())","title":""},{"location":"python-base/#_9","text":"dict . clear ()  a = dict ( x = 1 , y = 2 )  a . clear ()  None dict . get ( key )  dict  key , value ， ，  None a = dict ( x = 1 , y = 2 ) a . get ( ‘ x ’ ) 、， values  None dict . keys ()  a = dict ( x = 1 , y = 2 )  a . keys ()  key  dict . values ()  a = {‘ x ’: 1 ,’ y ’: 2 }  a . values ()  value  dict . items ()  ( ,  )  a = {‘ x ’: 1 ,’ y ’: 2 }  a . items () [ ( y , 2 ) , ( x , 1 ) ] （ key ， value ） dict . copy () （） a = {‘ x ’: 1 ,’ y ’: 2 }  b = a . copy ()  dict . has_key ( key )  dict  key a . has_key ( ‘ x ’ ) 、（ key ，） return boole （ True or False ） dict . iteritems () （ key , value ）， for  a = { a : 1 , b : 2 } for k , v in a . iteritems () : for  ... print k , v ... a 1 b 2 s = a . iteritems () s . next () next  ( a , 1 ) s . next () ( b , 2 ) dict . iterkeys ()  key  dict . itervalues ()  value  dict . pop ( key [, default ] )  key ， dict [ key ]， key ，  default ， KeyError  a = {‘ x ’: 1 ,’ y ’: 2 ,’ z ’: 3 } a . pop ( ‘ x ’ ) 1  key a . pop ( ‘ abc ’,’ sky ’ ) sky  value dict . popitem ()  a = {‘ x ’: 1 ,’ y ’: 2 ,’ z ’: 3 } a . popitem ()  ( ‘ x ’, 1 ) （ key ， value ） dict . setdefault ( key , default = None )  key ， dict [ key ] = default 。 a = {‘ x ’: 1 } a . setdefalut ( ‘ y ’ )  key a . setdefault ( ‘ z ’, 3 )  value  None { x : 1 , y : None , z : 3 } dict . update ( dict2 )  dict2  -  dict a = { a : 1 } b = { b : 2 } a . update ( b )  a  None { a : 1 , b : 2 } dict . fromkeys ( seq , val = None ) ，  seq ， val   ( ， None ) a . fromkeys ( ‘ d ’, 3 )  key  value （）， { d : 3 }  a = { a : 1 , b : 2 } a . viewitems () dict_items ( [ ( a , 1 ) , ( b , 2 ) ] ) a . viewkeys () dict_keys ( [ a , b ] ) a . viewvalues () dict_values ( [ 1 , 2 ] )  sorted ( dic1 . iteritems () , key = lambda key : key [ 0 ], reverse = True )  key ， reverse = True ， sorted ( dic1 . iteritems () , key = lambda key : key [ 1 ], reverse = True )  value ","title":""},{"location":"python-base/#_10","text":"class （ oop ） web flask  salt zabbix cobbler  hadoop   ，     ，  def __init__ ( self ) :  def __del__ ( self ) :  f1 = Friut ( app , 33 ) self        ，  class Friut ( object ) :  count = 0  def __init__ ( self , name , weight ) :  self . name = name self . weight = weight Friut . count += 1 def info ( self ) :  print self . name , self . weight , Friut . count  @staticmethod def func_name ()  . func_name () @classmethod def func_name ( self )  . func_name ()   . func_name () dir (  )  __doc__ __name__ __module__  __main__ __base__ __dict__  、  class Parent ( object ) : # define parent class def myMethod ( self ) : print Calling parent method def setAttr ( self , attr ) : Parent . parentAttr = attr class Child ( Parent ) : # define child class Parent def myMethod ( self ) : print Calling child method myMethod  class JustCounter ( object ) : __secretCount = 0 def count ( self ) : self . __secretCount += 1 print self . __secretCount counter = JustCounter () counter . count () print counter . __secretCount  ， class super class A ( object ) : def __init__ ( self ) : print enter A class B ( A ) : # def __init__ ( self ) : print enter B super ( B , self ). __init__ () print leave B  B build in ：  ，  G  global E  L  local  import py  import sys print sys . path","title":""},{"location":"python-base/#_11","text":"  1 . for - in  Iterator (  )  2 . yield  Generator (  ) ， 3 . yield , for - in  ，， 1 . next  (  ) 2 . __iter__ （） type ( iter ( range ( 10 ))) Out [ 5 ]: listiterator  iter () 。: iter ( obj )  iter () ，，，:  0 。， __iter__ ()  next () . iter ( func ， sentinel )  iter () ， func ， sentinel 。 it = iter ( [ 1 , 2 , 3 , 4 , 5 ] ) while True : try : x = next ( it )  except StopIteration :  StopIteration （） break","title":""},{"location":"python-base/#_12","text":"，  str . rstrip ()  str  str . lstrip ()  str  str . strip ()  str  lstrip ()  rstrip () ，， str . center ( width ) , width  str . ljust ( width ) , width  str . rjust ( width ) , width  string . zfill ( width )  width ， string ， 0 str . expandtabs ( tabsize = 8 )  str  tab ， 8   a = ‘ t123abc23t ’ a . strip () ‘ 123 abc123 ’ a . srtip ( ‘ 123 ’ ) ‘ t123abc23t ’ a . rstrip () ‘ t123abc23 ’ a . lsrtip ( ‘ 123 ’ ) ‘ t123abc23t ’ s . expandtabs ( 4 ) 123abc23 s = hello s . center ( 20 ) hello  string . title ()    string ,，  str . lower ()  string  str . upper ()  string  str . swapcase ()  string  str . capitalize ()  ，，  ， str . isalnum ()  str  True , False str . isalpha ()  str  True , False str . isdigit ()  str  True  False str . isdecimal ()  string  True  False str . isspace ()  str ， True ， False str . istitle ()  str  (  title ())  True ， False str . isupper ()  str ， (  )  ， True ， False str . islower ()  str ， (  )  ， True ， False ################################################# ，（ True or False ） str . startswith ( obj , beg = 0 , end = len ( string ))  obj ， True ， False 。 beg  end ， str . endswith ( obj , beg = 0 , end = len ( string ))  obj ， beg  end   obj ，， True , False ，，， str . join ( sqp )  string ， seq  (  )   l = [ I , am , tom ] 、、， -- . join ( l ) I--am--tom 、、 key  str  str . split ( str = , num = string . count ( str ))  str  string ， num ， num  astr = ‘ I | am | tom ! ’ （） astr . split ( ‘ | ’ ) [ I , am , tom! ]  string . find ( str , beg = 0 , end = len ( string ))  str  string ，  beg  end ， ，， - 1 string . index ( str , beg = 0 , end = len ( string ))  find () ， str  string  ValueError . string . rfind ( str , beg = 0 , end = len ( string ) )  find () ，. string . rindex ( str , beg = 0 , end = len ( string ))  index () ， a = ‘ i am a student ’ （） a . find ( ‘ am ’ ) 2  - 1 str . replace ( str1 , str2 , num = string . count ( str1 ))  str  str1  str2 , num ， num  a = ‘ du , hello , du bye ’ ，（） a . replace ( ‘ du ’,’ minchao ’, 1 ) minchao,hello,du bye ， string . count ( str , beg = 0 , end = len ( string ))  str  string ， beg  end  str  a = ‘ du , hello , du bye ’ （） a . count ( ‘ du ’, 3 ) return 1  str  string . partition ( str )  find ()  split () , str ,    string     3      ( string_pre_str , str , string_post_str ) , string  str  string_pre_str == string . s = a b c d e ， s . partition ( c ) ( a b , c , d e ) s . partition ( f ) ( a b c d e , , ) string . rpartition ( str )  partition () ,. string . splitlines ( num = string . count ( n )) ，， num  num . s = 332 ， 2432 4343 s . splitlines () [ 332 , 2432 , 4343 ]   string . decode ( encoding = UTF-8 , errors = strict )  encoding  string ， ValueError    ，   errors     ignore   replace s =  s xc4xe3xbaxc3 s . decode ( encoding = GBK ) u u4f60u597d string . encode ( encoding = UTF-8 , errors = strict )  encoding  string ， ValueError ， errors   ignore  replace","title":""},{"location":"python-base/#_13","text":"tuple . index ( obj , i = 0 , j = len ( list ))  tuple [ k ]== obj  k  ,  k  [ i , j ) a = ( 1 , 2 , 3 , 4 , 5 , 6 , 2 )  tuple  （  ） a . index ( 2 )  obj  tuple  tuple . count ( obj )  obj  tuple  a = ( 1 , 2 , 3 , 3 , 3 , 4 )  、  、  a . count ( 1 )  tuple ","title":""},{"location":"python-base/#eval","text":"： str 。 ： eval ( source [, globals [, locals ]]) ： source ： Python  compile ()  globals ：。 dictionary locals ：。 map   list , tuple , dict  string 。 eval ，， ast  ast . literal_eval ()   a = [[1,2], [3,4], [5,6], [7,8], [9,0]] type ( a ) type str b = eval ( a ) print b [[ 1 , 2 ], [ 3 , 4 ], [ 5 , 6 ], [ 7 , 8 ], [ 9 , 0 ]] type ( b ) type list  a = {1: a , 2: b } type ( a ) type str b = eval ( a ) print b { 1 : a , 2 : b } type ( b ) type dict","title":"eval"},{"location":"python-lib/","text":"os os  。，。 os . sep 。 Linux 、 Unix  / ， Windows  \\\\ ， Mac OS  : 。 os . name 。 Windows ， nt ， Linux / Unix ， posix 。 os . getcwd () ， Python 。 os . getenv ( key ) 。 os . putenv ( key , value ) 。 os . listdir ( path ) 。 os . remove ( filePath ) 。 os . system ( shellStr )  shell ， windows 。 os . linesep 。， Windows  \\r \\n ， Linux  \\n  Mac  \\r 。 os . path . split ( pathname ) 。 os . path . isfile ( path ) 。 os . path . isdir ( path ) 。 os . path . existe ( path ) 。  、 pythony 3 . 0  file 。 、 pythony 3 . 0  open () : open ( file , mode = r , buffering = None , encoding = None , errors = None , newline = None , closefd = True ) 1 . mode (  ) : r : ，，， w : ，，，；，， a :  b : ；,: rb ； wb  t :  + : ,,: rb + : ，、，， wb + : ，、，，；，， u :   rt ，。 2 . buffering ： 0 :  1 :  1 :  int  =  :  3 . encoding 。 4 . closefd  True  False 。  False ,。， True 。 、 f . truncate () ： r+ , rb+ , w , wb , wb+ ，。 、 ( 1 ) ： ， f ， ,、，  (  long  ) 。 ( 2 ) :  r , r+ , rb+ , w , w+ , wb+  ， ，。 ( 3 ) : L = f . tell () ( 4 )  f . seek ( ,  ) #   long  int ， 2 , 2  3  = 0 ，   。  = 1 ， ，  。  = 2 ， ，，  。 、 1 . (  rt  )  s = f . readline () ： s ，，。 : ( 1 )  len ( s ) = 0  ( , 2 ) ( 2 ) ， 2 . (  rb 、 rb+ 、 wb+  )  s = f . read ( n ) : ( 1 )  len ( s ) = 0  ( 2 ) ， len ( s ) 。 ( 3 ) ，。 with open ( /tmp/passwd , r ) as f :  with  a . close () for eachline in f : print eachline a . read ( [ size ] ) ， a . readline ( [ size ] ) ，， size ， a . readlines ( [ size ] ) ，， size ， size ，。 a . fileno ()  a . tell () ， a . next () ，。 file  for … in file ， next () 。 a . seek ( offset [, whence ] )  offset 。 offset ，。  whence ， whence  0 ， 1 。 2 。 ， a  a + ，， a . write ( str )  str ， write ()  a . writelines ( seq )  seq  (  ) 。，。 a . flush ()  a . isatty () （ unix ） a . truncate ( [ size ] ) ，。 size ， ， 0 ，。 、 f . write ( s ) : s  : ( 1 ) ， len ( s ) 。 ( 2 ) ，。 、 [ 1 . os ] 1 .： os . rename ( old , new ) 2 .： os . remove ( file ) 3 .： os . listdir ( path ) 4 .： os . getcwd () 5 .： os . chdir ( newdir ) 6 .： os . makedirs ( r c:\\python \\t est ) 7 .： os . mkdir ( test ) 8 .： os . removedirs ( r c:\\python ) #。 9 .： os . rmdir ( test ) 10 .： os . stat ( file ) 11 .： os . chmod ( file ) 12 .： os . system ( dir ) 13 .： os . exec () , os . execvp () 14 .： osspawnv () 15 .： os . exit () , os . _exit () 16 .： os . path . split ( r c:\\python\\hello.py ) -- ( c: \\\\ python , hello.py ) 17 .： os . path . splitext ( r c:\\python\\hello.py ) -- ( c: \\\\ python \\\\ hello , .py ) 18 .： os . path . dirname ( r c:\\python\\hello.py ) -- c: \\\\ python 19 .： os . path . basename ( r r:\\python\\hello.py ) -- hello.py 20 .： os . path . exists ( r c:\\python\\hello.py ) -- True 21 .： os . path . isabs ( r .\\python\\ ) -- False 22 .： os . path . isdir ( r c:\\python ) -- True 23 .： os . path . isfile ( r c:\\python\\hello.py ) -- True 24 .： os . path . islink ( r c:\\python\\hello.py ) -- False 25 .： os . path . getsize ( filename ) 26 . ******* ： os . ismount ( c: \\\\ ) -- True 27 .： os . path . walk () 28 . : os . path . getatime ( myfile ) # ， 1970  1  1  29 .: os . path . getmtime ( myfile ) [ 2 . shutil ] 1 .： shutil . copy ( oldfile , newfle ) 2 .： shutil . copytree ( r .\\setup , r .\\backup ) 3 .： shutil . rmtree ( r .\\backup ) [ 3 . tempfile ] 1 .： tempfile . mktemp () -- filename 2 .： tempfile . TemporaryFile () [ 4 . StringIO ] # cStringIO  StringIO  1 .： f = StringIO . StringIO ( Hello world! ) 2 .： print f . read () # print f . getvalue () -- Hello world ! 3 .： f . write ( Good day! ) 4 .： f . close () [ 5 . glob ] 1 .： glob . glob ( r c:\\python\\*.py ) ###########  1  ################################# import os os_command = echo haha... # , (  0 , 1  ) result = os . system ( os_command ) if result == 0 : print ( run Successful ) else : print ( run FAILED ) # : os . system () ,。 (  ) # os . system ( os_command ) #  cmd , p = os . popen ( os_command ) # ，， print ( p . read ()) # p ， ###########  ( windows ) ########### def kill ( pid ) : kill process by pid for windows kill_command = taskkill /F /T /pid %s % pid os . system ( kill_command ) ###########  ( windows ) ########### # ， import os , time def __Is_Process_Running ( imagename ) : ： ：， 0  p = os . popen ( tasklist /FI IMAGENAME eq %s % imagename ) #  windows  tasklist  return p . read () . count ( imagename ) # p ， def test () : ：， while True : time . sleep ( 10 ) pid = __Is_Process_Running ( barfoo.exe ) if pid = 0 : # code ..... break if __name__ == __main__ : test () ###########  ########### import os #  proxy_server = os . popen ( cmd.exe /c start barfoo_proxy.exe ) #  ( ，， ) ， proxy_server . read () # ， test_file = open ( test.txt , wb ) test_file . write ( hello ) test_file . close () ###########  2  ################################# import os pathDir = r D:\\Work #  if not os . path . exists ( pathDir ) : os . mkdir ( pathDir ) # , os . makedirs ( pathDir )  target = pathDir + os . sep + test.txt print ( target ) #  os . sep , os . sep ,。 Linux 、 Unix  / ， Windows  \\\\ ，  Mac OS  : 。 ###########  3  (  ) ######################## import os import os . path rootdir = r D:\\Holemar\\1.notes\\28.Python \\t est # os . walk ， parent , dirnames , filenames  for parent , dirnames , filenames in os . walk ( rootdir ) : #  print ( parent is: + parent ) #  (  ) for dirname in dirnames : print ( dirname is: + dirname ) #  for filename in filenames : print ( filename with full path: + os . path . join ( parent , filename )) #  (  ) ls = os . listdir ( rootdir ) ###########  4  (  ) ################################# import os . path #：，， ( window  ) ，。 spath = d:/test/test.7z #  #  p , f = os . path . split ( spath ) #  print ( dir is: + p ) # : d : / test print ( file is: + f ) # : test . 7 z #  drv , left = os . path . splitdrive ( spath ) print ( driver is: + drv ) # : d : print ( left is: + left ) # : / test / test . 7 z #  f , ext = os . path . splitext ( spath ) print ( f is: + f ) # : d : / test / test print ( ext is: + ext ) # : 7 z ###########  4  (  txt  ) ################################# filePath = poem.txt f = open ( filePath , w ) # , Python 2 . x  open () / io . open ()  file () for a in range ( 0 , 10 ) : s = %5d %5d \\n % ( a , a * a ) f . write ( s ) #  f . close () #  io  f2 = open ( filePath ) # ，, r while True : line = f2 . readline () if len ( line ) == 0 : #  break print ( line , end = ) #  print ,  Python2 . x ：“ print line ,” f2 . close () # close the file #  import os os . remove ( filePath ) ###########  5  (  ) ################################# import os , os . path , time timestamp = os . path . getmtime ( __file__ ) #  time_tuple = time . localtime ( timestamp ) print time . strftime ( %Y-%m-%d %H:%M:%S , time_tuple ) # 2008 - 11 - 12 21 : 59 : 27 #  print time . strftime ( %Y-%m-%d %H:%M:%S , time . localtime ( os . path . getmtime ( __file__ ))) # 2008 - 11 - 12 21 : 59 : 27 random # import random # 01，0.0，1.0 print ( random . random () ) # 110 print ( random . uniform ( 1 , 10 ) ) #  print ( random . randint ( 1 , 5 ) ) # 15，1，5， for i in xrange ( 5 ): print ( i , random . randint ( 10 , 90 ) ) #  10~90 ( 10  90) # 0100(,1,) print ( random . randrange ( 0 , 101 , 2 ) ) #  print ( random . choice ( range ( 50 )) ) # 0~49 print ( random . choice ([ a , 2 , c ]) ) # ，、 print ( random . choice ( abcdefg ) ) #  # ( list, ) print ( random . sample ( abcdefghij , 3 ) ) print ( random . sample ([ a , 2 , c , 5 , 0 , ii ], 2 ) ) # , items = [ 1 , 2 , 3 , 4 , 5 , 6 ] random . shuffle ( items ) # ,:None print ( items ) #  request requests  : http : // cn . python - requests . org / en / latest / import requests requests . get ( ts_url , headers = { User-Agent : chrome/63/xxx }, timeout = 10 , proxies = { http : http://10.10.1.10:3128 }) r = requests . get ( http://www.zhidaow.com ) #  print r . status_code # ,: 200 print r . headers [ content-type ] # ,: text/html; charset=utf8 print r . headers # ,:{ content-encoding : gzip , transfer-encoding : chunked , content-type : text/html; charset=utf-8 ; ... } print r . encoding # ,: utf-8 print r . text #（PS，， r.content ）,:u !DOCTYPE html \\n html xmlns = http://www.w3.org/1999/xhtml ... print r . content #r.content，IDLEb。cygwin， 。 urllib2  urllib2 . urlopen ( url ) . read () 。 print r . json () #  json , json   #timeout，，。 requests . get ( http://github.com , timeout = 0.001 ) json  payload = { wd :  , rn : 100 } r = requests . get ( http://www.baidu.com/s , params = payload ) print r . url # , # post  r = requests . post ( http://www.baidu.com/s , params = payload )   IP ，。 requests  proxies 。 import requests proxies = { http : http://10.10.1.10:3128 , https : http://10.10.1.10:1080 , } requests . get ( http://www.zhidaow.com , proxies = proxies ) #，： proxies = { http : http://user:pass@10.10.1.10:3128/ , }  requests ： http : // docs . python - requests . org / en / latest / user / install . html #install requests ： http : // docs . python - requests . org / en / latest / user / quickstart . html requests ： http : // docs . python - requests . org / en / latest / user / advanced . html #advanced paramiko yum install python - devel - y pip install paramiko  AttributeError : module object has no attribute HAVE_DECL_MPZ_POWM_SEC  / usr / lib64 / python2 . 6 / site - packages / Crypto / Util / number . py  #if _fastmath is not None and not _fastmath.HAVE_DECL_MPZ_POWM_SEC: ) #!/usr/bin/env python #coding:utf-8 import paramiko import sys hostname = sys . argv [ 1 ] username = root passwd = sys . argv [ 2 ] paramiko . util . log_to_file ( syslogin.log ) #  paramiko  syslogin.log  #SSH ssh = paramiko . SSHClient () #  ssh  client  ssh . set_missing_host_key_policy ( paramiko . AutoAddPolicy ()) #HostKeys， ， load_sys - tem_host_keys () ， ~/. ssh / known_hosts ； ssh . load_system_host_keys () #  host_keys ， ~/.ssh/known_hosts ， # ssh . connect ( hostname = hostname , username = username , password = passwd ) #  ssh  #key privatekey = os . path . expanduser ( ~/.ssh/id_rsa ) # ，/root.id_rse key = paramiko . RSAKey . from_private_key_file ( privatekey ) # ssh . connect ( hostname = hostname , username = username , pkey = key ) stdin , stdout , stderr = ssh . exec_command ( free -m ) #  exec_command() print stdout . read () # ， Python ， stdout.readlines() ssh . close () #  ssh  try : #SFTP t = paramiko . Transport (( hostname , 22 )) t . connect ( username = username , password = passwd ) sftp = paramiko . SFTPClient . from_transport ( t ) localpath = /root/mylog.txt remotepath = /tmp/mylog.txt sftp . put ( localpath , remotepath ) # sftp . get ( remotepath , localpath ) # #SFTP sftp . mkdir ( /home/userdir , 0755 ) sftp . rmdir ( /home/userdir ) sftp . rename ( /home/test.sh , /home/testfile.sh ) sftp . stat ( /home/testfile.sh ) sftp . listdir ( /home ) t . close () except Exception , e : print str ( e ) hashlib # coding:utf-8 import hashlib a = a test string print hashlib . md5 ( a ) . hexdigest () print hashlib . sha1 ( a ) . hexdigest () print hashlib . sha224 ( a ) . hexdigest () print hashlib . sha256 ( a ) . hexdigest () print hashlib . sha384 ( a ) . hexdigest () print hashlib . sha512 ( a ) . hexdigest () zipfile 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 #!/usr/bin/env python # -*- coding: utf-8 -*- from zipfile import * import zipfile #zip def unzip (): source_zip = c: \\\\ update \\\\ SW_Servers_20120815.zip target_dir = c: \\\\ update \\\\ myzip = ZipFile ( source_zip ) myfilelist = myzip . namelist () for name in myfilelist : f_handle = open ( target_dir + name , wb ) f_handle . write ( myzip . read ( name )) f_handle . close () myzip . close () #zip def addzip (): f = zipfile . ZipFile ( archive.zip , w , zipfile . ZIP_DEFLATED ) f . write ( file_to_add.py ) f . close () # def adddirfile (): f = zipfile . ZipFile ( archive.zip , w , zipfile . ZIP_DEFLATED ) startdir = c: \\\\ mydirectory for dirpath , dirnames , filenames in os . walk ( startdir ): for filename in filenames : f . write ( os . path . join ( dirpath , filename )) f . close () pycurl 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 #!/usr/bin/env python #coding:utf-8 import os , sys import time import pycurl import StringIO URL = http://www.baidu.com #url c = pycurl . Curl () c . setopt ( pycurl . URL , URL ) #URL #  L1 = pycurl . Curl () L1buf = StringIO . StringIO () L1 . setopt ( pycurl . WRITEFUNCTION , L1buf . write ) L1 . perform () L1txt = L1buf . getvalue ()  ,  L1 . setopt ( pycurl . NOSIGNAL , 1 ) c . setopt ( pycurl . CUSTOMREQUEST , DELETE ) ， put ， post ， get ， delete ， HEAD c . setopt ( pycurl . NOBODY , True ) ， HEAD  c . setopt ( pycurl . HTTPHEADER , [ range: bytes=0-2048 ]) range  curl - H range: bytes=0-10 c . getinfo ( pycurl . CONTENT_LENGTH_DOWNLOAD )  c . setopt ( pycurl . CONNECTTIMEOUT , 5 ) # c . setopt ( pycurl . MAXREDIRS , 5 ) # c . setopt ( pycurl . USERAGENT , Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; .NET CLR 1.1.4322) ) # c . perform () # c . getinfo ( pycurl . HTTP_CODE ) #HTTP urllibstatus c . setopt ( pycurl . TIMEOUT , 5 ) # c . setopt ( pycurl . FORBID_REUSE , 1 ) #， c . setopt ( pycurl . MAXREDIRS , 1 ) #HTTP1 c . setopt ( pycurl . DNS_CACHE_TIMEOUT , 30 ) #dns30 #, ”wb”, httpin indexfile = open ( os . path . dirname ( os . path . realpath ( __file__ )) + /content.txt , wb ) c . setopt ( pycurl . WRITEHEADER , indexfile ) #HTTP HEADERindexfile c . setopt ( pycurl . WRITEDATA , indexfile ) #HTMLindexfile try : c . perform () # except Exception , e : print connecion error: + str ( e ) indexfile . close () c . close () sys . exit () NAMELOOKUP_TIME = c . getinfo ( c . NAMELOOKUP_TIME ) #DNS CONNECT_TIME = c . getinfo ( c . CONNECT_TIME ) # PRETRANSFER_TIME = c . getinfo ( c . PRETRANSFER_TIME ) # STARTTRANSFER_TIME = c . getinfo ( c . STARTTRANSFER_TIME ) # TOTAL_TIME = c . getinfo ( c . TOTAL_TIME ) # HTTP_CODE = c . getinfo ( c . HTTP_CODE ) #HTTP SIZE_DOWNLOAD = c . getinfo ( c . SIZE_DOWNLOAD ) # HEADER_SIZE = c . getinfo ( c . HEADER_SIZE ) #HTTP SPEED_DOWNLOAD = c . getinfo ( c . SPEED_DOWNLOAD ) ## # print HTTP: %s % ( HTTP_CODE ) print DNS: %.2f ms % ( NAMELOOKUP_TIME * 1000 ) print : %.2f ms % ( CONNECT_TIME * 1000 ) print : %.2f ms % ( PRETRANSFER_TIME * 1000 ) print : %.2f ms % ( STARTTRANSFER_TIME * 1000 ) print : %.2f ms % ( TOTAL_TIME * 1000 ) print : %d bytes/s % ( SIZE_DOWNLOAD ) print HTTP: %d byte % ( HEADER_SIZE ) print : %d bytes/s % ( SPEED_DOWNLOAD ) #Curl indexfile . close () c . close () urllib python  post  get  get ：  get ， url 。 、 import urllib import urllib2 url = http://192.168.81.16/cgi-bin/python_test/test.py?ServiceCode=aaaa req = urllib2 . Request ( url ) print req res_data = urllib2 . urlopen ( req ) res = res_data . read () print res 、 import httplib url = http://192.168.81.16/cgi-bin/python_test/test.py?ServiceCode=aaaa conn = httplib . HTTPConnection ( 192.168.81.16 ) conn . request ( method = GET , url = url ) response = conn . getresponse () res = response . read () print res post ：  post ， data  body ， url ， url 。 、 import urllib import urllib2 test_data = { ServiceCode : aaaa , b : bbbbb } test_data_urlencode = urllib . urlencode ( test_data ) requrl = http://192.168.81.16/cgi-bin/python_test/test.py req = urllib2 . Request ( url = requrl , data = test_data_urlencode ) print req res_data = urllib2 . urlopen ( req ) res = res_data . read () print res 、 import urllib import httplib test_data = { ServiceCode : aaaa , b : bbbbb } test_data_urlencode = urllib . urlencode ( test_data ) requrl = http://192.168.81.16/cgi-bin/python_test/test.py headerdata = { Host : 192.168.81.16 } conn = httplib . HTTPConnection ( 192.168.81.16 ) conn . request ( method = POST , url = requrl , body = test_data_urlencode , headers = headerdata ) response = conn . getresponse () res = response . read () print res  python  json ， urllib . urlencode ( test_data )  ;  urllib , urllib2 , httplib  httplib  http  https ， python ， urllib  urllib2  httplib 。 ： 1 、 HTTPConnection  httplib . HTTPConnection ( host [, port [, stict [, timeout ]]]) ，， /  host  (  IP  ) port  80 strict  False ，， BadStatusLine   : conn = httplib . HTTPConnection ( 192.168.81.16 ， 80 ) 。 2 、 HTTPConnection . request ( method , url [, body [, header ]])   method ， post  get ， ： method = POST  method = Get url ， (  CGI ,  CGI ) ： url = http://192.168.81.16/cgi-bin/python_test/test.py  CGI  url = http://192.168.81.16/python_test/test.html  body ， json ，， json  json  headers  http  headerdata = { Host : 192.168.81.16 }  : test_data = { ServiceCode : aaaa , b : bbbbb } test_data_urlencode = urllib . urlencode ( test_data ) requrl = http://192.168.81.16/cgi-bin/python_test/test.py headerdata = { Host : 192.168.81.16 } conn = httplib . HTTPConnection ( 192.168.81.16 ， 80 ) conn . request ( method = POST , url = requrl , body = test_data_urlencode , headers = headerdata ) conn ，， conn . close () 3 、 HTTPConnection . getresponse ()   http ， HTTPResponse 。 4 、 HTTPResponse ： HTTPResponse ： read ([ amt ]) ， amt ，，； getheader ( name [, default ])  header ， name ，， default  getheaders ()  header ： date = response . getheader ( date ); print date resheader = resheader = response . getheaders (); print resheader  : [( content-length , 295 ), ( accept-ranges , bytes ), ( server , Apache ), ( last-modified , Sat, 31 Mar 2012 10:07:02 GMT ), ( connection , close ), ( etag , e8744-127-4bc871e4fdd80 ), ( date , Mon, 03 Sep 2012 10:01:47 GMT ), ( content-type , text/html )] date = response . getheader ( date ); print date  date 。 smtplib  from email.mime.text import MIMEText from email.header import Header msg = MIMEText ( content , html , utf-8 ) #  msg . add_header ( Content-Type , text/plain; charset= utf-8 ) msg [ Subject ] = %s % Header ( subject , utf-8 ) #  #!/usr/bin/env python #coding:utf-8 import smtplib from email.mime.text import MIMEText import sys mail_host = smtp.qq.com mail_user = 2219722370 mail_pass = tyztnlzandbbeahj mail_postfix = qq.com def send_mail ( to_list , subject , content ): me = mail_user + + mail_user + @ + mail_postfix + msg = MIMEText ( content ) msg [ Subject ] = subject msg [ From ] = me msg [ To ] = , . join ( to_list ) try : s = smtplib . SMTP () #SMTP s . connect ( mail_host , 25 ) #connectsmtp s . starttls () #TLS（），SMTP，gmailsmtp s . login ( mail_user , mail_pass ) s . sendmail ( me , to_list , msg . as_string ()) s . quit () #smtp print ! return True except Exception as e : print : + str ( e ) return False if __name__ == __main__ : #send_mail(sys.argv[1], sys.argv[2], sys.argv[3]) to_list = [ liangguangyu@dachuizichan.com , 2219722370@qq.com ] send_mail ( to_list , title , msg ) # #!/usr/bin/env python #coding:utf-8 import smtplib from email.mime.text import MIMEText from email.mime.multipart import MIMEMultipart import sys mail_host = smtp.qq.com mail_user = 2219722370 mail_pass = tyztnlzandbbeahj mail_postfix = qq.com def send_mail ( to_list , subject , content ): me = mail_user + + mail_user + @ + mail_postfix + msg = MIMEMultipart ( related ) msgtext = MIMEText ( content ) msg [ Subject ] = subject msg [ From ] = me msg [ To ] = to_list attach = MIMEText ( open ( /etc/passwd , rb ) . read (), base64 , utf-8 ) # attach [ Content-Disposition ] = attachment; filename= \\ (12).xlsx \\ . decode ( utf-8 ) . encode ( gb18030 ) # msg . attach ( msgtext ) #MIMEMultipartMIMEText， msg . attach ( attach ) try : s = smtplib . SMTP () #SMTP s . connect ( mail_host , 25 ) #connectsmtp s . starttls () #TLS（），SMTP，gmailsmtp s . login ( mail_user , mail_pass ) s . sendmail ( me , to_list , msg . as_string ()) s . quit () #smtp print ! return True except Exception as e : print : + str ( e ) return False if __name__ == __main__ : #send_mail(sys.argv[1], sys.argv[2], sys.argv[3]) send_mail ( lgy_root@163.com , subject , msg ) smtplib 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 #!/usr/bin/env python #coding=utf-8 import smtplib from email.mime.multipart import MIMEMultipart from email.mime.text import MIMEText from email.mime.application import MIMEApplication def SendMail (): msgRoot = MIMEMultipart ( related ) msgRoot [ Subject ] = sql result msgRoot [ From ] = notice@dachuizichan.com to_list = [ liangguangyu@dachuizichan.com ] msgRoot [ To ] = , . join ( to_list ) msgzip1 = MIMEApplication ( open ( /script/sql/EXCEL.tar.gz , rb ) . read ()) msgzip1 . add_header ( Content-Disposition , attachment , filename = EXCEL.tar.gz ) msgRoot . attach ( msgzip1 ) msgzip2 = MIMEApplication ( open ( /script/sql/csv.tar.gz , rb ) . read ()) msgzip2 . add_header ( Content-Disposition , attachment , filename = csv.tar.gz ) msgRoot . attach ( msgzip2 ) sendText = sql  msgText = MIMEText ( sendText , txt , utf-8 ) msgRoot . attach ( msgText ) smtp = smtplib . SMTP_SSL () smtp . connect ( 183.232.93.197 , 465 ) smtp . login ( notice@dachuizichan.com , Dachui0002 ) smtp . sendmail ( msgRoot [ From ], to_list , msgRoot . as_string ()) smtp . quit () SendMail () ， MIMEMultipart ， attach 。， add_header 。  python ， MIME 。 MIMEBase |-- MIMENonMultipart |-- MIMEApplication |-- MIMEAudio |-- MIMEImage |-- MIMEMessage |-- MIMEText |-- MIMEMultipart ， MIMEBase ，。 MIMEMultipart  attach ， MIMENonMultipart ， attach 。 MIME ，，， MIMEImage ，， MIMEAudio ， word 、 excel ，  MIME ， google 。 ，， MIMEApplication ， MIMEApplication  application / octet - stream 。 application / octet - stream “，”，， qq ，， 。 。  foo . xlsx / foo . jpg / foo . pdf / foo . mp3  4 。 import smtplib from email.mime.multipart import MIMEMultipart from email.mime.text import MIMEText from email.mime.application import MIMEApplication _user = sigeken@qq.com _pwd = *** _to = 402363522@qq.com #Multipart msg = MIMEMultipart () msg [ Subject ] = don t panic msg [ From ] = _user msg [ To ] = _to #------ part = MIMEText ( ， ) msg . attach ( part ) #------ #xlsx part = MIMEApplication ( open ( foo.xlsx , rb ) . read ()) part . add_header ( Content-Disposition , attachment , filename = foo.xlsx ) msg . attach ( part ) #jpg part = MIMEApplication ( open ( foo.jpg , rb ) . read ()) part . add_header ( Content-Disposition , attachment , filename = foo.jpg ) msg . attach ( part ) #pdf part = MIMEApplication ( open ( foo.pdf , rb ) . read ()) part . add_header ( Content-Disposition , attachment , filename = foo.pdf ) msg . attach ( part ) #mp3 part = MIMEApplication ( open ( foo.mp3 , rb ) . read ()) part . add_header ( Content-Disposition , attachment , filename = foo.mp3 ) msg . attach ( part ) s = smtplib . SMTP ( smtp.qq.com , timeout = 30 ) #smtp,25 s . login ( _user , _pwd ) # s . sendmail ( _user , _to , msg . as_string ()) # s . close () pexpect Expect 。 Expect ，，。， ssh ， ftp 。 Expect  send , expect , spawn , interact 。 send ： expect ： spawn ： interact ： ================================================================ 2.7  Python ： pip install pyexpect  pyexpect ： In [ 1 ]: import pexpect In [ 2 ]: output , exitstatus = pexpect . run ( ls -l , withexitstatus = 1 ) In [ 3 ]: print output , exitstatus ：  output  exitstatus  ls -l  output withexitstatus = 1 ， exitstatus ================================================================  spawn ， ： 1 、 pexpect . spawn () ： child = pexpect . spawn ( ‘ command ’ ) 2 、 child . logfile ： (  ) f = file （’ / tmp / plog . out ’ , ‘ w ’） child . logfile = f 3 、 expect  index = child . expect ([ “”，”” pexpect . EOF ， pexpect . TIMEOUT ]) pexpect . EOF  pexpect . TIMEOUT ， 30 s  if  index ， index  0 “”， 1 ”” 4 、 sendline  , ： child . sendline ( ‘ command ’ ) #sendcontrol（‘c’）ctrl+c 5 、 try ， except  try : index = p . expect ([ good , bad ]) if index == 0 : do_something () elif index == 1 : do_something_else () except EOF : do_some_other_thing () except TIMEOUT : do_something_completely_different () 6 、 before  : p = pexpect . spawn ( /bin/ls ) p . expect ( pexpect . EOF ) print p . before  6  90 % 。  share ， 6 ，， ok ！ ================================================================  1 ：  ftp ， 192.168 . 100.194 ，， passwd ，。， ，： #!/usr/bin/env python import pexpect import sys child = pexpect . spawn ( ftp 192.168.100.194 ) child . expect ( Name .*: ) child . sendline ( sys . argv [ 1 ]) #，hello child . expect ( Password: ) child . sendline ( sys . argv [ 2 ]) #，123 child . expect ( ftp ) child . sendline ( get passwd ) #passwd child . expect ( ftp ) child . sendline ( bye ) # ： [ root @localhost test ] # python a.py hello 123 [ root @localhost test ] # ls a . py passwd  1  : import pexpect username = ptest key = 123456 f = file ( /tmp/plog.out , w ) if __name__ == __main__ : child = pexpect . spawn ( ftp localhost ) # child . logfile = f #f try : index = child . expect ([ Name ]) #Name if index == 0 : #0，Name， child . sendline ( username ) #sendline， index = child . expect ([ Password ]) #Password if index == 0 : child . sendline ( key ) #Pwassword，key index = child . expect ([ Login successful.*ftp ]) if index == 0 : child . sendline ( ls ) index = child . expect ([ test.mp3 ]) if index == 0 : child . sendline ( bin ) #，get child . sendline ( get test.mp3 ) #test.mp3 index = child . expect ([ Transfer complete.*ftp ]) if index == 0 : print download complete! child . sendline ( bye ) # except : print child . before print see /tmp/plog.out can find more info! ， / tmp / plog . out  ，，！ ================================================================  2 ：，。，。 #!/usr/bin/env python #coding=utf8 import pexpect # home = /root #、IP， info = { root@192.168.0.156 : 123456 } f = file ( /tmp/plog.out , w ) def genkey (): child = pexpect . spawn ( ssh-keygen -t rsa ) child . logfile = f try : index = child . expect ([ save the key ]) if index == 0 : child . sendline () index = child . expect ([ Enter passphrase , Overwrite ]) if index == 0 : child . sendline () index = child . expect ([ Enter same passphrase ]) if index == 0 : child . sendline () else : child . sendline ( n ) except : print child . before def copykey (): try : for k , v in info . items (): child = pexpect . spawn ( ssh-copy-id -i %s /.ssh/id_rsa.pub %s % ( home , k )) child . logfile = f index = child . expect ([ continue connecting , password ]) if index == 0 : child . sendline ( yes ) else : child . sendline ( v ) child . expect ( pexpect . EOF ) except : print child . before if __name__ == __main__ : genkey () copykey () ================================================================  3 ： ssh ，， ssh_newkey ,  password ： #!/usr/bin/env python #encoding=utf8 import pexpect import getpass , os #user: ssh  #host：ssh  #password：ssh  #command： ssh  def ssh_command ( user , host , password , command ): This runs a command on the remote host. This could also be done with the pxssh class, but this demonstrates what that class does at a simpler level. This returns a pexpect.spawn object. This handles the case when you try to connect to a new host and ssh asks you if you want to accept the public key fingerprint and continue connecting. ssh_newkey = Are you sure you want to continue connecting #  ssh  spawn . child = pexpect . spawn ( ssh -l %s %s %s % ( user , host , command )) i = child . expect ([ pexpect . TIMEOUT , ssh_newkey , password: ]) # ，，. if i == 0 : # Timeout print ERROR! print SSH could not login. Here is what SSH said: print child . before , child . after return None #  ssh  public key，. if i == 1 : # SSH does not have the public key. Just accept it. child . sendline ( yes ) child . expect ( password: ) i = child . expect ([ pexpect . TIMEOUT , password: ]) if i == 0 : # Timeout print ERROR! print SSH could not login. Here is what SSH said: print child . before , child . after return None # . child . sendline ( password ) return child def main (): #  ssh . host = raw_input ( Hostname: ) #  ssh . user = raw_input ( User: ) #  ssh . password = getpass . getpass () #  ssh . command = raw_input ( Enter the command: ) child = ssh_command ( user , host , password , command ) #  pexpect.EOF child . expect ( pexpect . EOF ) # . print child . before if __name__ == __main__ : try : main () except Exception , e : print str ( e ) os . _exit ( 1 ) 1.   shell  except ，， ssh  #!/usr/bin/env python # encoding: UTF-8 ssh-copy-id -i /root/.ssh/id_rsa.pub root@localhost import pexpect keyfile = /root/.ssh/id_rsa.pub target_user = root target_host = localhost command = ssh-copy-id -i + keyfile + + target_user + @ + target_host password = 123456 child = pexpect . spawn ( command ) try : index = child . expect ([ yes/no , password ]) if index == 0 : child . sendline ( yes ) index = child . expect ([ password ]) if index == 0 : child . sendline ( password ) else : child . sendline ( password ) except pexpect . EOF : print now to try U sshkey 2 、 #!/usr/bin/env python #coding:utf-8 import pexpect , sys child = pexpect . spawn ( ssh root@127.0.0.1 ) # pexpect.spawn(command, args=[], timeout=30, maxread=2000, searchwindowsize=None, logfile=None, cwd=None, env = None , ignore_sighup = True ) # command timeout；maxreadpex-pect， searchwindowsize ，。 #，pexpectshell，“ ”、“|”“*”，，，  / bin / bash ， #：child = pexpect.spawn( /bin/bash -c ls -l | grep LOG logs.txt ) # child.expect(pexpect.EOF) #Python，，。 # shell_cmd = ls -l | grep LOG logs.txt # child = pexpect.spawn( /bin/bash , [ -c , shell_cmd]) # child.expect(pexpect.EOF) fout = file ( mylog.txt , w ) #child.logfile = fout # child . logfile = sys . stdout #， passwd = 1 comm = free -m try : index = child . expect ([ yes/no , password: ]) #， if index == 0 : child . sendline ( yes ) child . expect ( password: ) child . sendline ( passwd ) child . expect ( # ) child . sendline ( comm ) child . expect ( # ) child . sendline ( exit ) elif index == 1 : child . sendline ( passwd ) child . expect ( # ) child . sendline ( comm ) child . expect ( # ) child . sendline ( exit ) else : print Error except Exception , e : print str ( e ) json # coding:utf-8 from json import dumps , loads a = { a : 1 , b : 2 , c : 3 } b = str ({ a : 1 , b : 2 , c : 3 }) print dumps ( a , indent = 4 )  { a : 1 , c : 3 , b : 2 } print dumps ( b , indent = 4 ) { a : 1, c : 3, b : 2} print dumps ( eval ( b ), indent = 4 ) { a : 1 , c : 3 , b : 2 }  json . dumps ， ascii ， # coding:utf-8 from json import dumps , loads test = loads ( { haha :  } ) print dumps ( test ) # { haha : \\u54c8\\u54c8 } print dumps ( test , ensure_ascii = False ) # { haha :  } ftplib ftp  from ftplib import FTP #ftp ftp = FTP () # ftp . set_pasv ( False )  ftp . set_debuglevel ( 2 ) #2， ftp . connect ( IP , port ) #ftp sever ftp . login ( user , password ) #， print ftp . getwelcome () # ftp . cwd ( xxx/xxx ) # bufsize = 1024 # filename = filename.txt # file_handle = open ( filename , wb ) . write # ftp . retrbinaly ( RETR filename.txt , file_handle , bufsize ) # ftp . set_debuglevel ( 0 ) # ftp . quit #ftp ftp  ftp . cwd ( pathname ) #FTP ftp . dir () # ftp . nlst () # ftp . mkd ( pathname ) # ftp . pwd () # ftp . rmd ( dirname ) # ftp . delete ( filename ) # ftp . rename ( fromname , toname ) #fromnametoname。 ftp . storbinaly ( STOR filename.txt , file_handel , bufsize ) # ftp . retrbinary ( RETR filename.txt , file_handel , bufsize ) #FTP ： from ftplib import FTP ftp = FTP () timeout = 30 port = 21 ftp . connect ( 192.168.1.188 , port , timeout ) # FTP ftp . login ( UserName , 888888 ) #  print ftp . getwelcome () #  ftp . cwd ( file/test ) # FTP list = ftp . nlst () #  for name in list : print ( name ) #  path = d:/data/ + name #  f = open ( path , wb ) #  filename = RETR + name # FTP ftp . retrbinary ( filename , f . write ) # FTP ftp . delete ( name ) # FTP ftp . storbinary ( STOR + filename , open ( path , rb )) # FTP ftp . quit () # FTP #!/usr/bin/python # -*- coding: utf-8 -*- import ftplib import os import socket HOST = ftp.mozilla.org DIRN = pub/mozilla.org/webtools FILE = bugzilla-3.6.7.tar.gz def main (): try : f = ftplib . FTP ( HOST ) except ( socket . error , socket . gaierror ): print ERROR:cannot reach %s % HOST return print ***Connected to host %s % HOST try : f . login () except ftplib . error_perm : print ERROR: cannot login anonymously f . quit () return print *** Logged in as anonymously try : f . cwd ( DIRN ) except ftplib . error_perm : print ERRORL cannot CD to %s % DIRN f . quit () return print *** Changed to %s folder % DIRN try : #retrbinary()  f . retrbinary ( RETR %s % FILE , open ( FILE , wb ) . write ) except ftplib . error_perm : print ERROR: cannot read file %s % FILE os . unlink ( FILE ) else : print *** Downloaded %s to CWD % FILE f . quit () return if __name__ == __main__ : main () datetime  import time print ( time . strftime ( %Y-%m- %d %H:%M:%S )) # time.strftime(format[, tuple]) struct_time(),  ,  : 2011 - 04 - 13 18 : 30 : 10 print ( time . strftime ( %Y-%m- %d %A %X , time . localtime ( time . time ()))) # ；  : 2011 - 04 - 13 Wednesday 18 : 30 : 10 print ( time . strftime ( %Y-%m- %d %A %X , time . localtime ())) # ； : 2011-04-13 Wednesday 18:30:10 print ( time . time ()) # Linux； : 1302687844.7；  time . localtime ( time . time ())  time  print ( time . ctime ( 1150269086.6630149 )) #time.ctime([seconds]) ，， 。 : Wed Apr 13 21 : 13 : 11 2011 print ( time . gmtime ( 1150269086.6630149 )) # time.gmtime([seconds]) UTC(0)  struct_time ， seconds ， print ( time . gmtime ()) # ： time.struct_time(tm_year=2014, tm_mon=8, tm_mday=27, tm_hour=7, tm_min = 28 , tm_sec = 19 , tm_wday = 2 , tm_yday = 239 , tm_isdst = 0 ) print ( time . localtime ( 1150269086.6630149 )) # time.localtime([seconds])  struct_time ， seconds ， print ( time . mktime ( time . localtime ())) # time.mktime(tuple) struct_time(float), ： 1409124869.0  from datetime import datetime datetime . strptime ( 2017 Sep 21 14:16:52 , %Y %b %d %H:%M:%S ) . strftime ( %Y-%m- %d %H:%M:%S ) # (、、、、、) print ( time . localtime ()) # : time.struct_time(tm_year=2014, tm_mon=8, tm_mday=27, tm_hour=15, tm_min = 10 , tm_sec = 16 , tm_wday = 2 , tm_yday = 239 , tm_isdst = 0 ) print ( time . localtime ()[:]) # : (2014, 8, 27, 15, 10, 16, 2, 239, 0) #  print ( time . localtime ()[ 1 ] - 1 ) # : 7 #  print ( time . localtime ()[ 1 ] + 2 ) # : 10 #  print ( time . localtime ()[ 0 ] - 1 ) # : 2013 #  import time , datetime print ( time . time ()) # ： 1409127119.16 print time . mktime ( time . strptime ( 2012-10-21 18:51:50 , %Y-%m- %d %H:%M:%S ))  print ( long ( time . time ())) # ： 1409127119 print ( time . mktime ( datetime . datetime . now () . timetuple () )) # ： 1409127119.0 print ( long ( time . mktime ( time . strptime ( 2014-03-25 19:25:33 , %Y-%m- %d %H:%M:%S )))) # ：1395746733 #  import time time . sleep ( 2 ) # 、、(datetime) import datetime #  print ( datetime . date . today ()) # : 2011-04-13 #  print ( datetime . date . today () + datetime . timedelta ( days =- 1 )) # : 2011-04-12 print ( datetime . date . today () - datetime . timedelta ( days = 1 )) # : 2011-04-12 # 10 print ( datetime . date . today () + datetime . timedelta ( days = 10 )) # : 2011-04-23 # 10， days  hours print ( datetime . datetime . now () + datetime . timedelta ( hours = 10 )) # : 2011-04-14 04:30:10.189000 #  1  d1 = datetime . datetime ( * time . localtime ()[: 3 ]) + datetime . timedelta ( days = 1 ) + datetime . timedelta ( hours = 1 ) # : 2011-04-13 01:00:00 print ( time . mktime ( d1 . timetuple () )) # ： 1409127119.0 # 、、(time) import time #  print ( time . strftime ( %Y-%m- %d %H:%M:%S , time . localtime ( time . time () + 24 * 60 * 60 ))) # 20 print ( time . strftime ( %Y-%m- %d %H:%M:%S , time . localtime ( time . time () + 20 * 24 * 60 * 60 ))) # 202 print ( time . strftime ( %Y-%m- %d %H:%M:%S , time . localtime ( time . time () + 20 * 24 * 60 * 60 - 2 * 60 * 60 ))) #(、): import datetime # ： datetime.datetime(year, month, day[, hour[, minute[, second[, microsecond[,tzinfo]]]]]) d1 = datetime . datetime ( 2005 , 2 , 16 ) d2 = datetime . datetime ( 2004 , 12 , 31 ) print (( d1 - d2 ) . days ) # ： 47 #： import time , datetime starttime = datetime . datetime . now () time . sleep ( 1 ) # 1 endtime = datetime . datetime . now () print (( endtime - starttime ) . seconds ) # , ： 1 print (( endtime - starttime ) . microseconds ) # ()； ： 14000 #  import time start = time . clock () func ( * args , ** kwargs ) #  end = time . clock () print ( used: + str ( end ) ) # : # 2( time.clock() ,) import time start = time . time () func ( * args , ** kwargs ) #  end = time . time () print ( used: + str ( end - start ) ) # : # time.clock()  clock () - floating point number ， ，； ， ,  import time time . sleep ( 1 ) print clock1: %s % time . clock () # : clock1:2.17698990094e-06 time . sleep ( 1 ) print clock2: %s % time . clock () # : clock2:1.00699529055 time . sleep ( 1 ) print clock3: %s % time . clock () # : clock3:2.00698720459 #    time import time s2 = 2012-02-16 ; a = time . strptime ( s2 , %Y-%m- %d ) print a # time.struct_time(tm_year=2012, tm_mon=2, tm_mday=16, tm_hour=0, tm_min=0, tm_sec=0, tm_wday=3, tm_yday = 47 , tm_isdst =- 1 ) print type ( a ) # type time.struct_time print repr ( a ) # time.struct_time(tm_year=2012, tm_mon=2, tm_mday=16, tm_hour=0, tm_min=0, tm_sec=0, tm_wday=3, tm_yday = 47 , tm_isdst =- 1 ) #    datetime import datetime date_str = 2008-11-10 17:53:59 dt_obj = datetime . datetime . strptime ( date_str , %Y-%m- %d %H:%M:%S ) print dt_obj # 2008-11-10 17:53:59 print dt_obj . strftime ( %Y-%m- %d %H:%M:%S ) # 2008-11-10 17:53:59 print type ( dt_obj ) # type datetime.datetime print repr ( dt_obj ) # datetime.datetime(2008, 11, 10, 17, 53, 59) # timestamp to time tuple in UTC import time timestamp = 1226527167.595983 time_tuple = time . gmtime ( timestamp ) print repr ( time_tuple ) # time.struct_time(tm_year=2008, tm_mon=11, tm_mday=12, tm_hour=21, tm_min=59, tm_sec=27, tm_wday = 2 , tm_yday = 317 , tm_isdst = 0 ) print time . strftime ( %Y-%m- %d %H:%M:%S , time_tuple ) # 2008-11-12 21:59:27 # timestamp to time tuple in local time ( time.time() ) import time timestamp = 1226527167.595983 time_tuple = time . localtime ( timestamp ) print repr ( time_tuple ) # time.struct_time(tm_year=2008, tm_mon=11, tm_mday=13, tm_hour=5, tm_min=59, tm_sec=27, tm_wday = 3 , tm_yday = 318 , tm_isdst = 0 ) print time . strftime ( %Y-%m- %d %H:%M:%S , time_tuple ) # 2008-11-13 05:59:27 # datetime  time import time , datetime # datetime  timetuple  time.struct_time print ( datetime . datetime . now () . timetuple ()) # ：time.struct_time(tm_year=2014, tm_mon=8, tm_mday=27, tm_hour=16, tm_min=7, tm_sec=37, tm_wday=2, tm_yday = 239 , tm_isdst =- 1 ) print ( time . localtime ()) # ：time.struct_time(tm_year=2014, tm_mon=8, tm_mday=27, tm_hour=16, tm_min=7, tm_sec=37, tm_wday=2, tm_yday = 239 , tm_isdst = 0 )  : %% : %  % A :  (  ),  : Tuesday % a :  (  ),  : Tue % B :  (  ),  : February % b :  (  ),  : Feb % c :  ,  : 02 / 15 / 11 16 : 50 : 57 % d :  ( 0 - 31 ),  : 15 % H : 24  ( 0 - 23 ) % I : 12  ( 01 - 12 ) % j :  ( 001 - 366 ),  : 046 % M :  ( 00 - 59 ),  : 50 % m :  ( 01 - 12 ),  : 02 % p :  (  A . M .  P . M .  ),  : PM % S :  ( 00 - 59 ),  : 57 % f :  (  datetime  , time  ) % X :  ,  : 16 : 50 : 57 % x :  ,  : 02 / 15 / 11 % Y :  ( 000 - 9999 ) % y :  ( 00 - 99 ) % U :  ( 00 - 53 )  ,  : 07 % W :  ( 00 - 53 )  ,  : 07 % w :  ( 0 - 6 ),  ,  : 2 (  0 ) % Z :  ,  :  % z :  ,  :  logging logging  # 1.  logging,  logging , import logging # logging，: NOTSET(0), DEBUG(10), INFO(20), WARNING(30), ERROR(40), CRITICAL ( 50 ) 。。 logging . basicConfig ( level = logging . INFO , format = %(asctime)s %(module)s . %(funcName)s %(lineno)s : %(levelname)s : %(message)s , datefmt = %Y-%m- %d %X , filename = log.log ) logging . info ( logging message ) # 2.  log  def initlog (): import logging logger = logging . getLogger () # ，， hdlr = logging . FileHandler ( crawl.log ) # Handler。loggingHandler，FileHandler, SocketHandler , SMTPHandler ， FileHandler 。 # ，。 # ，： %(message)s 。，，， 。 # logging，Formatter。：，，。 formatter = logging . Formatter ( %(asctime)s %(levelname)s : %(message)s ) hdlr . setFormatter ( formatter ) #  #logger.addHandler(hdlr) #  #  addHandler ,( handler),( handler)。 logger . handlers = [ hdlr ] # ,、。 # 。，30(WARNING)。 # ：logging.getLevelName(logger.getEffectiveLevel())。  ,  : info (), error (), debug () 。 # ，。。NOTSET（0）， 。 logger . setLevel ( logging . NOTSET ) return logger # ： logger = initlog () logger . info ( message info ) logger . error ( message error ) logging  Python  logging ，。 ，，， HTTP GET / POST ， SMTP ， Socket ， 。 logging  log4j ，。 logger ， handler ， filter ， formatter 。 logger ：，。 logger ：。  logging . getLogger ( name )  logger ， name  root ， name  getLogger   logger 。 handler ：（ log record ）（ destination ），， socket 。  logger  addHandler  0  handler ， handler ，。 filter ： handler 。 formatter ：。 formatter ：，。  log4j ， logger ， handler （ Level ）， logger  handler 。  ( log_test . py  ) ： import logging import logging.handlers LOG_FILE = tst.log # ,、, handler  handler = logging . handlers . RotatingFileHandler ( LOG_FILE , maxBytes = 1024 * 1024 , backupCount = 5 ) # handler, handler = logging . handlers . TimedRotatingFileHandler ( LOG_FILE , when = midnight , backupCount = 10 ) # log， #  backupCount log, 10  10  log fmt = %(asctime)s - %(filename)s : %(lineno)s - %(name)s - %(message)s formatter = logging . Formatter ( fmt ) # formatter handler . setFormatter ( formatter ) # handlerformatter logger = logging . getLogger ( tst ) # tstlogger logger . addHandler ( handler ) # loggerhandler logger . setLevel ( logging . DEBUG ) logger . info ( first info message ) #  log  logger . debug ( first debug message ) ： 2012 - 03 - 04 23 : 21 : 59 , 682 - log_test . py : 16 - tst - first info message 2012 - 03 - 04 23 : 21 : 59 , 682 - log_test . py : 17 - tst - first debug message  formatter ， % ( dict key ) s ，。： Format Description % ( name ) s Logger 。 Name of the logger ( logging channel ) . % ( levelno ) s 。 Numeric logging level for the message ( DEBUG , INFO , WARNING , ERROR , CRITICAL ) . % ( levelname ) s 。 Text logging level for the message ( DEBUG , INFO , WARNING , ERROR , CRITICAL ) . % ( pathname ) s ，。 Full pathname of the source file where the logging call was issued ( if available ) . % ( filename ) s 。 Filename portion of pathname . % ( module ) s 。 Module ( name portion of filename ) . % ( funcName ) s 。 Name of function containing the logging call . % ( lineno ) d 。 Source line number where the logging call was issued ( if available ) . % ( created ) f ， UNIX 。 Time when the LogRecord was created ( as returned by time . time ()) . % ( relativeCreated ) d ， Logger 。 Time in milliseconds when the LogRecord was created , relative to the time the logging module was loaded . % ( asctime ) s 。“ 2003 - 07 - 08 16 : 49 : 45 , 896 ”。。 Human - readable time when the LogRecord was created . By default this is of the form “ 2003 - 07 - 08 16 : 49 : 45 , 896 ” ( the numbers after the comma are millisecond portion of the time ) . % ( msecs ) d Millisecond portion of the time when the LogRecord was created . % ( thread ) d  ID 。。 Thread ID ( if available ) . % ( threadName ) s 。。 Thread name ( if available ) . % ( process ) d  ID 。。 Process ID ( if available ) . % ( message ) s 。 The logged message , computed as msg % args . ，。 logging  logging  python 。 python ， handler ， handler ， formatter 。 。 python 。  (  ) ： import logging import logging.config logging . config . fileConfig ( logging.conf ) #  # create logger logger = logging . getLogger ( simpleExample ) #  simpleExample  logger,  [ logger_simpleExample ] # application code logger . debug ( debug message ) logger . info ( info message ) logger . warn ( warn message ) logger . error ( error message ) logger . critical ( critical message )  logging . conf  : [ loggers ] keys = root , simpleExample [ handlers ] keys = consoleHandler [ formatters ] keys = simpleFormatter [ logger_root ] level = DEBUG handlers = consoleHandler [ logger_simpleExample ] level = DEBUG handlers = consoleHandler qualname = simpleExample propagate = 0 [ handler_consoleHandler ] class = StreamHandler level = DEBUG formatter = simpleFormatter args = ( sys . stdout ,) [ formatter_simpleFormatter ] format =% ( asctime ) s - % ( name ) s - % ( levelname ) s - % ( message ) s datefmt = loggin . conf ， r ^[(.*)]$ ，。  , 。  componentName_instanceName 。 。  handler ， class  handler ， logging ， RotatingFileHandler ，  class  : RotatingFileHandler  logging . handlers . RotatingFileHandler 。 args ，，。 ， logger ， a . b  a . c  logger  a  logger ， logger  root 。  handler ，。。  logging logging  python ， logging . getLogger ( log_name )  logger ， 。  logging  main  logging ，，  getLogger  Logger 。  :  logging . conf  : [ loggers ] keys = root , main [ handlers ] keys = consoleHandler , fileHandler [ formatters ] keys = fmt [ logger_root ] level = DEBUG handlers = consoleHandler [ logger_main ] level = DEBUG qualname = main handlers = fileHandler [ handler_consoleHandler ] class = StreamHandler level = DEBUG formatter = fmt args = ( sys . stdout ,) [ handler_fileHandler ] class = logging . handlers . RotatingFileHandler level = DEBUG formatter = fmt args = ( tst.log , a , 20000 , 5 ,) [ formatter_fmt ] format =% ( asctime ) s - % ( name ) s - % ( levelname ) s - % ( message ) s datefmt =  main . py ： import logging import logging.config logging . config . fileConfig ( logging.conf ) root_logger = logging . getLogger ( root ) root_logger . debug ( test root logger... ) logger = logging . getLogger ( main ) logger . info ( test main logger ) logger . info ( start import module \\ mod \\ ... ) import mod logger . debug ( let \\ s test mod.testLogger() ) mod . testLogger () root_logger . info ( finish test... )  mod . py ： import logging import submod logger = logging . getLogger ( main.mod ) logger . info ( logger of mod say something... ) def testLogger (): logger . debug ( this is mod.testLogger... ) submod . tst ()  submod . py ： import logging logger = logging . getLogger ( main.mod.submod ) logger . info ( logger of submod say something... ) def tst (): logger . info ( this is submod.tst()... )  python main . py ， log   tst . log  root logger ， logging . conf  main logger  logger  RotatingFileHandler ，  root logger 。  import os import logging import logging.handlers def init_log ( logfile , backupCount , debug = True ):  log_path = os . path . dirname ( logfile ) if not os . path . isdir ( log_path ): os . makedirs ( log_path ) logger = logging . getLogger () formatter = logging . Formatter ( [ %(asctime)s ]: %(module)s %(levelname)s %(message)s ) #  log  #handler_record = logging.FileHandler(logfile) handler_record = logging . handlers . TimedRotatingFileHandler ( logfile , when = midnight , backupCount = backupCount ) handler_record . setFormatter ( formatter ) logger . addHandler ( handler_record ) if debug : logger . setLevel ( logging . DEBUG ) handler_record . setLevel ( logging . DEBUG ) else : logger . setLevel ( logging . WARNING ) handler_record . setLevel ( logging . WARNING ) #  log  handler_email = logging . handlers . SMTPHandler ( mail.guoling.com , #  backend_program@guoling.com , #  fengwanli@guoling.com , # 。 (：[ 292598441@qq.com , fengwanli@guoling.com ]),  test email logging , #  ( backend_program@guoling.com , guoling ) # (CREDENTIALS) ) handler_email . setFormatter ( formatter ) handler_email . setLevel ( logging . ERROR ) email_logger = logging . getLogger ( email ) #  logger email_logger . addHandler ( handler_email ) email_logger . setLevel ( logging . ERROR ) # http  log  http_handler = logging . handlers . HTTPHandler ( 127.0.0.1:3333 , /log/ , method = GET ) http_handler . setFormatter ( formatter ) http_handler . setLevel ( logging . ERROR ) #  logger init_log ( ./log/run.log , 30 , False ) #  #os.remove( ./log/run.log ) logging . error ( u logging.error 。。。 ) #  log, email_logger = logging . getLogger ( email ) #  log msg = email_logger.error gbk  2... msg = msg . decode ( sys . stdin . encoding ) . encode ( gbk ) # , foxmail  email_logger . error ( msg ) # ,  mlogging ==================================== https : // pypi . python . org / pypi / mlogging /  :  log ，  : windows   : # linux  easy_install sudo easy_install mlogging","title":"python-lib"},{"location":"python-lib/#os","text":"os  。，。 os . sep 。 Linux 、 Unix  / ， Windows  \\\\ ， Mac OS  : 。 os . name 。 Windows ， nt ， Linux / Unix ， posix 。 os . getcwd () ， Python 。 os . getenv ( key ) 。 os . putenv ( key , value ) 。 os . listdir ( path ) 。 os . remove ( filePath ) 。 os . system ( shellStr )  shell ， windows 。 os . linesep 。， Windows  \\r \\n ， Linux  \\n  Mac  \\r 。 os . path . split ( pathname ) 。 os . path . isfile ( path ) 。 os . path . isdir ( path ) 。 os . path . existe ( path ) 。  、 pythony 3 . 0  file 。 、 pythony 3 . 0  open () : open ( file , mode = r , buffering = None , encoding = None , errors = None , newline = None , closefd = True ) 1 . mode (  ) : r : ，，， w : ，，，；，， a :  b : ；,: rb ； wb  t :  + : ,,: rb + : ，、，， wb + : ，、，，；，， u :   rt ，。 2 . buffering ： 0 :  1 :  1 :  int  =  :  3 . encoding 。 4 . closefd  True  False 。  False ,。， True 。 、 f . truncate () ： r+ , rb+ , w , wb , wb+ ，。 、 ( 1 ) ： ， f ， ,、，  (  long  ) 。 ( 2 ) :  r , r+ , rb+ , w , w+ , wb+  ， ，。 ( 3 ) : L = f . tell () ( 4 )  f . seek ( ,  ) #   long  int ， 2 , 2  3  = 0 ，   。  = 1 ， ，  。  = 2 ， ，，  。 、 1 . (  rt  )  s = f . readline () ： s ，，。 : ( 1 )  len ( s ) = 0  ( , 2 ) ( 2 ) ， 2 . (  rb 、 rb+ 、 wb+  )  s = f . read ( n ) : ( 1 )  len ( s ) = 0  ( 2 ) ， len ( s ) 。 ( 3 ) ，。 with open ( /tmp/passwd , r ) as f :  with  a . close () for eachline in f : print eachline a . read ( [ size ] ) ， a . readline ( [ size ] ) ，， size ， a . readlines ( [ size ] ) ，， size ， size ，。 a . fileno ()  a . tell () ， a . next () ，。 file  for … in file ， next () 。 a . seek ( offset [, whence ] )  offset 。 offset ，。  whence ， whence  0 ， 1 。 2 。 ， a  a + ，， a . write ( str )  str ， write ()  a . writelines ( seq )  seq  (  ) 。，。 a . flush ()  a . isatty () （ unix ） a . truncate ( [ size ] ) ，。 size ， ， 0 ，。 、 f . write ( s ) : s  : ( 1 ) ， len ( s ) 。 ( 2 ) ，。 、 [ 1 . os ] 1 .： os . rename ( old , new ) 2 .： os . remove ( file ) 3 .： os . listdir ( path ) 4 .： os . getcwd () 5 .： os . chdir ( newdir ) 6 .： os . makedirs ( r c:\\python \\t est ) 7 .： os . mkdir ( test ) 8 .： os . removedirs ( r c:\\python ) #。 9 .： os . rmdir ( test ) 10 .： os . stat ( file ) 11 .： os . chmod ( file ) 12 .： os . system ( dir ) 13 .： os . exec () , os . execvp () 14 .： osspawnv () 15 .： os . exit () , os . _exit () 16 .： os . path . split ( r c:\\python\\hello.py ) -- ( c: \\\\ python , hello.py ) 17 .： os . path . splitext ( r c:\\python\\hello.py ) -- ( c: \\\\ python \\\\ hello , .py ) 18 .： os . path . dirname ( r c:\\python\\hello.py ) -- c: \\\\ python 19 .： os . path . basename ( r r:\\python\\hello.py ) -- hello.py 20 .： os . path . exists ( r c:\\python\\hello.py ) -- True 21 .： os . path . isabs ( r .\\python\\ ) -- False 22 .： os . path . isdir ( r c:\\python ) -- True 23 .： os . path . isfile ( r c:\\python\\hello.py ) -- True 24 .： os . path . islink ( r c:\\python\\hello.py ) -- False 25 .： os . path . getsize ( filename ) 26 . ******* ： os . ismount ( c: \\\\ ) -- True 27 .： os . path . walk () 28 . : os . path . getatime ( myfile ) # ， 1970  1  1  29 .: os . path . getmtime ( myfile ) [ 2 . shutil ] 1 .： shutil . copy ( oldfile , newfle ) 2 .： shutil . copytree ( r .\\setup , r .\\backup ) 3 .： shutil . rmtree ( r .\\backup ) [ 3 . tempfile ] 1 .： tempfile . mktemp () -- filename 2 .： tempfile . TemporaryFile () [ 4 . StringIO ] # cStringIO  StringIO  1 .： f = StringIO . StringIO ( Hello world! ) 2 .： print f . read () # print f . getvalue () -- Hello world ! 3 .： f . write ( Good day! ) 4 .： f . close () [ 5 . glob ] 1 .： glob . glob ( r c:\\python\\*.py ) ###########  1  ################################# import os os_command = echo haha... # , (  0 , 1  ) result = os . system ( os_command ) if result == 0 : print ( run Successful ) else : print ( run FAILED ) # : os . system () ,。 (  ) # os . system ( os_command ) #  cmd , p = os . popen ( os_command ) # ，， print ( p . read ()) # p ， ###########  ( windows ) ########### def kill ( pid ) : kill process by pid for windows kill_command = taskkill /F /T /pid %s % pid os . system ( kill_command ) ###########  ( windows ) ########### # ， import os , time def __Is_Process_Running ( imagename ) : ： ：， 0  p = os . popen ( tasklist /FI IMAGENAME eq %s % imagename ) #  windows  tasklist  return p . read () . count ( imagename ) # p ， def test () : ：， while True : time . sleep ( 10 ) pid = __Is_Process_Running ( barfoo.exe ) if pid = 0 : # code ..... break if __name__ == __main__ : test () ###########  ########### import os #  proxy_server = os . popen ( cmd.exe /c start barfoo_proxy.exe ) #  ( ，， ) ， proxy_server . read () # ， test_file = open ( test.txt , wb ) test_file . write ( hello ) test_file . close () ###########  2  ################################# import os pathDir = r D:\\Work #  if not os . path . exists ( pathDir ) : os . mkdir ( pathDir ) # , os . makedirs ( pathDir )  target = pathDir + os . sep + test.txt print ( target ) #  os . sep , os . sep ,。 Linux 、 Unix  / ， Windows  \\\\ ，  Mac OS  : 。 ###########  3  (  ) ######################## import os import os . path rootdir = r D:\\Holemar\\1.notes\\28.Python \\t est # os . walk ， parent , dirnames , filenames  for parent , dirnames , filenames in os . walk ( rootdir ) : #  print ( parent is: + parent ) #  (  ) for dirname in dirnames : print ( dirname is: + dirname ) #  for filename in filenames : print ( filename with full path: + os . path . join ( parent , filename )) #  (  ) ls = os . listdir ( rootdir ) ###########  4  (  ) ################################# import os . path #：，， ( window  ) ，。 spath = d:/test/test.7z #  #  p , f = os . path . split ( spath ) #  print ( dir is: + p ) # : d : / test print ( file is: + f ) # : test . 7 z #  drv , left = os . path . splitdrive ( spath ) print ( driver is: + drv ) # : d : print ( left is: + left ) # : / test / test . 7 z #  f , ext = os . path . splitext ( spath ) print ( f is: + f ) # : d : / test / test print ( ext is: + ext ) # : 7 z ###########  4  (  txt  ) ################################# filePath = poem.txt f = open ( filePath , w ) # , Python 2 . x  open () / io . open ()  file () for a in range ( 0 , 10 ) : s = %5d %5d \\n % ( a , a * a ) f . write ( s ) #  f . close () #  io  f2 = open ( filePath ) # ，, r while True : line = f2 . readline () if len ( line ) == 0 : #  break print ( line , end = ) #  print ,  Python2 . x ：“ print line ,” f2 . close () # close the file #  import os os . remove ( filePath ) ###########  5  (  ) ################################# import os , os . path , time timestamp = os . path . getmtime ( __file__ ) #  time_tuple = time . localtime ( timestamp ) print time . strftime ( %Y-%m-%d %H:%M:%S , time_tuple ) # 2008 - 11 - 12 21 : 59 : 27 #  print time . strftime ( %Y-%m-%d %H:%M:%S , time . localtime ( os . path . getmtime ( __file__ ))) # 2008 - 11 - 12 21 : 59 : 27","title":"os"},{"location":"python-lib/#random","text":"# import random # 01，0.0，1.0 print ( random . random () ) # 110 print ( random . uniform ( 1 , 10 ) ) #  print ( random . randint ( 1 , 5 ) ) # 15，1，5， for i in xrange ( 5 ): print ( i , random . randint ( 10 , 90 ) ) #  10~90 ( 10  90) # 0100(,1,) print ( random . randrange ( 0 , 101 , 2 ) ) #  print ( random . choice ( range ( 50 )) ) # 0~49 print ( random . choice ([ a , 2 , c ]) ) # ，、 print ( random . choice ( abcdefg ) ) #  # ( list, ) print ( random . sample ( abcdefghij , 3 ) ) print ( random . sample ([ a , 2 , c , 5 , 0 , ii ], 2 ) ) # , items = [ 1 , 2 , 3 , 4 , 5 , 6 ] random . shuffle ( items ) # ,:None print ( items ) # ","title":"random"},{"location":"python-lib/#request","text":"requests  : http : // cn . python - requests . org / en / latest / import requests requests . get ( ts_url , headers = { User-Agent : chrome/63/xxx }, timeout = 10 , proxies = { http : http://10.10.1.10:3128 }) r = requests . get ( http://www.zhidaow.com ) #  print r . status_code # ,: 200 print r . headers [ content-type ] # ,: text/html; charset=utf8 print r . headers # ,:{ content-encoding : gzip , transfer-encoding : chunked , content-type : text/html; charset=utf-8 ; ... } print r . encoding # ,: utf-8 print r . text #（PS，， r.content ）,:u !DOCTYPE html \\n html xmlns = http://www.w3.org/1999/xhtml ... print r . content #r.content，IDLEb。cygwin， 。 urllib2  urllib2 . urlopen ( url ) . read () 。 print r . json () #  json , json   #timeout，，。 requests . get ( http://github.com , timeout = 0.001 ) json  payload = { wd :  , rn : 100 } r = requests . get ( http://www.baidu.com/s , params = payload ) print r . url # , # post  r = requests . post ( http://www.baidu.com/s , params = payload )   IP ，。 requests  proxies 。 import requests proxies = { http : http://10.10.1.10:3128 , https : http://10.10.1.10:1080 , } requests . get ( http://www.zhidaow.com , proxies = proxies ) #，： proxies = { http : http://user:pass@10.10.1.10:3128/ , }  requests ： http : // docs . python - requests . org / en / latest / user / install . html #install requests ： http : // docs . python - requests . org / en / latest / user / quickstart . html requests ： http : // docs . python - requests . org / en / latest / user / advanced . html #advanced","title":"request"},{"location":"python-lib/#paramiko","text":"yum install python - devel - y pip install paramiko  AttributeError : module object has no attribute HAVE_DECL_MPZ_POWM_SEC  / usr / lib64 / python2 . 6 / site - packages / Crypto / Util / number . py  #if _fastmath is not None and not _fastmath.HAVE_DECL_MPZ_POWM_SEC: ) #!/usr/bin/env python #coding:utf-8 import paramiko import sys hostname = sys . argv [ 1 ] username = root passwd = sys . argv [ 2 ] paramiko . util . log_to_file ( syslogin.log ) #  paramiko  syslogin.log  #SSH ssh = paramiko . SSHClient () #  ssh  client  ssh . set_missing_host_key_policy ( paramiko . AutoAddPolicy ()) #HostKeys， ， load_sys - tem_host_keys () ， ~/. ssh / known_hosts ； ssh . load_system_host_keys () #  host_keys ， ~/.ssh/known_hosts ， # ssh . connect ( hostname = hostname , username = username , password = passwd ) #  ssh  #key privatekey = os . path . expanduser ( ~/.ssh/id_rsa ) # ，/root.id_rse key = paramiko . RSAKey . from_private_key_file ( privatekey ) # ssh . connect ( hostname = hostname , username = username , pkey = key ) stdin , stdout , stderr = ssh . exec_command ( free -m ) #  exec_command() print stdout . read () # ， Python ， stdout.readlines() ssh . close () #  ssh  try : #SFTP t = paramiko . Transport (( hostname , 22 )) t . connect ( username = username , password = passwd ) sftp = paramiko . SFTPClient . from_transport ( t ) localpath = /root/mylog.txt remotepath = /tmp/mylog.txt sftp . put ( localpath , remotepath ) # sftp . get ( remotepath , localpath ) # #SFTP sftp . mkdir ( /home/userdir , 0755 ) sftp . rmdir ( /home/userdir ) sftp . rename ( /home/test.sh , /home/testfile.sh ) sftp . stat ( /home/testfile.sh ) sftp . listdir ( /home ) t . close () except Exception , e : print str ( e )","title":"paramiko"},{"location":"python-lib/#hashlib","text":"# coding:utf-8 import hashlib a = a test string print hashlib . md5 ( a ) . hexdigest () print hashlib . sha1 ( a ) . hexdigest () print hashlib . sha224 ( a ) . hexdigest () print hashlib . sha256 ( a ) . hexdigest () print hashlib . sha384 ( a ) . hexdigest () print hashlib . sha512 ( a ) . hexdigest ()","title":"hashlib"},{"location":"python-lib/#zipfile","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 #!/usr/bin/env python # -*- coding: utf-8 -*- from zipfile import * import zipfile #zip def unzip (): source_zip = c: \\\\ update \\\\ SW_Servers_20120815.zip target_dir = c: \\\\ update \\\\ myzip = ZipFile ( source_zip ) myfilelist = myzip . namelist () for name in myfilelist : f_handle = open ( target_dir + name , wb ) f_handle . write ( myzip . read ( name )) f_handle . close () myzip . close () #zip def addzip (): f = zipfile . ZipFile ( archive.zip , w , zipfile . ZIP_DEFLATED ) f . write ( file_to_add.py ) f . close () # def adddirfile (): f = zipfile . ZipFile ( archive.zip , w , zipfile . ZIP_DEFLATED ) startdir = c: \\\\ mydirectory for dirpath , dirnames , filenames in os . walk ( startdir ): for filename in filenames : f . write ( os . path . join ( dirpath , filename )) f . close ()","title":"zipfile"},{"location":"python-lib/#pycurl","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 #!/usr/bin/env python #coding:utf-8 import os , sys import time import pycurl import StringIO URL = http://www.baidu.com #url c = pycurl . Curl () c . setopt ( pycurl . URL , URL ) #URL #  L1 = pycurl . Curl () L1buf = StringIO . StringIO () L1 . setopt ( pycurl . WRITEFUNCTION , L1buf . write ) L1 . perform () L1txt = L1buf . getvalue ()  ,  L1 . setopt ( pycurl . NOSIGNAL , 1 ) c . setopt ( pycurl . CUSTOMREQUEST , DELETE ) ， put ， post ， get ， delete ， HEAD c . setopt ( pycurl . NOBODY , True ) ， HEAD  c . setopt ( pycurl . HTTPHEADER , [ range: bytes=0-2048 ]) range  curl - H range: bytes=0-10 c . getinfo ( pycurl . CONTENT_LENGTH_DOWNLOAD )  c . setopt ( pycurl . CONNECTTIMEOUT , 5 ) # c . setopt ( pycurl . MAXREDIRS , 5 ) # c . setopt ( pycurl . USERAGENT , Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; .NET CLR 1.1.4322) ) # c . perform () # c . getinfo ( pycurl . HTTP_CODE ) #HTTP urllibstatus c . setopt ( pycurl . TIMEOUT , 5 ) # c . setopt ( pycurl . FORBID_REUSE , 1 ) #， c . setopt ( pycurl . MAXREDIRS , 1 ) #HTTP1 c . setopt ( pycurl . DNS_CACHE_TIMEOUT , 30 ) #dns30 #, ”wb”, httpin indexfile = open ( os . path . dirname ( os . path . realpath ( __file__ )) + /content.txt , wb ) c . setopt ( pycurl . WRITEHEADER , indexfile ) #HTTP HEADERindexfile c . setopt ( pycurl . WRITEDATA , indexfile ) #HTMLindexfile try : c . perform () # except Exception , e : print connecion error: + str ( e ) indexfile . close () c . close () sys . exit () NAMELOOKUP_TIME = c . getinfo ( c . NAMELOOKUP_TIME ) #DNS CONNECT_TIME = c . getinfo ( c . CONNECT_TIME ) # PRETRANSFER_TIME = c . getinfo ( c . PRETRANSFER_TIME ) # STARTTRANSFER_TIME = c . getinfo ( c . STARTTRANSFER_TIME ) # TOTAL_TIME = c . getinfo ( c . TOTAL_TIME ) # HTTP_CODE = c . getinfo ( c . HTTP_CODE ) #HTTP SIZE_DOWNLOAD = c . getinfo ( c . SIZE_DOWNLOAD ) # HEADER_SIZE = c . getinfo ( c . HEADER_SIZE ) #HTTP SPEED_DOWNLOAD = c . getinfo ( c . SPEED_DOWNLOAD ) ## # print HTTP: %s % ( HTTP_CODE ) print DNS: %.2f ms % ( NAMELOOKUP_TIME * 1000 ) print : %.2f ms % ( CONNECT_TIME * 1000 ) print : %.2f ms % ( PRETRANSFER_TIME * 1000 ) print : %.2f ms % ( STARTTRANSFER_TIME * 1000 ) print : %.2f ms % ( TOTAL_TIME * 1000 ) print : %d bytes/s % ( SIZE_DOWNLOAD ) print HTTP: %d byte % ( HEADER_SIZE ) print : %d bytes/s % ( SPEED_DOWNLOAD ) #Curl indexfile . close () c . close ()","title":"pycurl"},{"location":"python-lib/#urllib","text":"python  post  get  get ：  get ， url 。 、 import urllib import urllib2 url = http://192.168.81.16/cgi-bin/python_test/test.py?ServiceCode=aaaa req = urllib2 . Request ( url ) print req res_data = urllib2 . urlopen ( req ) res = res_data . read () print res 、 import httplib url = http://192.168.81.16/cgi-bin/python_test/test.py?ServiceCode=aaaa conn = httplib . HTTPConnection ( 192.168.81.16 ) conn . request ( method = GET , url = url ) response = conn . getresponse () res = response . read () print res post ：  post ， data  body ， url ， url 。 、 import urllib import urllib2 test_data = { ServiceCode : aaaa , b : bbbbb } test_data_urlencode = urllib . urlencode ( test_data ) requrl = http://192.168.81.16/cgi-bin/python_test/test.py req = urllib2 . Request ( url = requrl , data = test_data_urlencode ) print req res_data = urllib2 . urlopen ( req ) res = res_data . read () print res 、 import urllib import httplib test_data = { ServiceCode : aaaa , b : bbbbb } test_data_urlencode = urllib . urlencode ( test_data ) requrl = http://192.168.81.16/cgi-bin/python_test/test.py headerdata = { Host : 192.168.81.16 } conn = httplib . HTTPConnection ( 192.168.81.16 ) conn . request ( method = POST , url = requrl , body = test_data_urlencode , headers = headerdata ) response = conn . getresponse () res = response . read () print res  python  json ， urllib . urlencode ( test_data )  ;  urllib , urllib2 , httplib  httplib  http  https ， python ， urllib  urllib2  httplib 。 ： 1 、 HTTPConnection  httplib . HTTPConnection ( host [, port [, stict [, timeout ]]]) ，， /  host  (  IP  ) port  80 strict  False ，， BadStatusLine   : conn = httplib . HTTPConnection ( 192.168.81.16 ， 80 ) 。 2 、 HTTPConnection . request ( method , url [, body [, header ]])   method ， post  get ， ： method = POST  method = Get url ， (  CGI ,  CGI ) ： url = http://192.168.81.16/cgi-bin/python_test/test.py  CGI  url = http://192.168.81.16/python_test/test.html  body ， json ，， json  json  headers  http  headerdata = { Host : 192.168.81.16 }  : test_data = { ServiceCode : aaaa , b : bbbbb } test_data_urlencode = urllib . urlencode ( test_data ) requrl = http://192.168.81.16/cgi-bin/python_test/test.py headerdata = { Host : 192.168.81.16 } conn = httplib . HTTPConnection ( 192.168.81.16 ， 80 ) conn . request ( method = POST , url = requrl , body = test_data_urlencode , headers = headerdata ) conn ，， conn . close () 3 、 HTTPConnection . getresponse ()   http ， HTTPResponse 。 4 、 HTTPResponse ： HTTPResponse ： read ([ amt ]) ， amt ，，； getheader ( name [, default ])  header ， name ，， default  getheaders ()  header ： date = response . getheader ( date ); print date resheader = resheader = response . getheaders (); print resheader  : [( content-length , 295 ), ( accept-ranges , bytes ), ( server , Apache ), ( last-modified , Sat, 31 Mar 2012 10:07:02 GMT ), ( connection , close ), ( etag , e8744-127-4bc871e4fdd80 ), ( date , Mon, 03 Sep 2012 10:01:47 GMT ), ( content-type , text/html )] date = response . getheader ( date ); print date  date 。","title":"urllib"},{"location":"python-lib/#smtplib","text":" from email.mime.text import MIMEText from email.header import Header msg = MIMEText ( content , html , utf-8 ) #  msg . add_header ( Content-Type , text/plain; charset= utf-8 ) msg [ Subject ] = %s % Header ( subject , utf-8 ) #  #!/usr/bin/env python #coding:utf-8 import smtplib from email.mime.text import MIMEText import sys mail_host = smtp.qq.com mail_user = 2219722370 mail_pass = tyztnlzandbbeahj mail_postfix = qq.com def send_mail ( to_list , subject , content ): me = mail_user + + mail_user + @ + mail_postfix + msg = MIMEText ( content ) msg [ Subject ] = subject msg [ From ] = me msg [ To ] = , . join ( to_list ) try : s = smtplib . SMTP () #SMTP s . connect ( mail_host , 25 ) #connectsmtp s . starttls () #TLS（），SMTP，gmailsmtp s . login ( mail_user , mail_pass ) s . sendmail ( me , to_list , msg . as_string ()) s . quit () #smtp print ! return True except Exception as e : print : + str ( e ) return False if __name__ == __main__ : #send_mail(sys.argv[1], sys.argv[2], sys.argv[3]) to_list = [ liangguangyu@dachuizichan.com , 2219722370@qq.com ] send_mail ( to_list , title , msg ) # #!/usr/bin/env python #coding:utf-8 import smtplib from email.mime.text import MIMEText from email.mime.multipart import MIMEMultipart import sys mail_host = smtp.qq.com mail_user = 2219722370 mail_pass = tyztnlzandbbeahj mail_postfix = qq.com def send_mail ( to_list , subject , content ): me = mail_user + + mail_user + @ + mail_postfix + msg = MIMEMultipart ( related ) msgtext = MIMEText ( content ) msg [ Subject ] = subject msg [ From ] = me msg [ To ] = to_list attach = MIMEText ( open ( /etc/passwd , rb ) . read (), base64 , utf-8 ) # attach [ Content-Disposition ] = attachment; filename= \\ (12).xlsx \\ . decode ( utf-8 ) . encode ( gb18030 ) # msg . attach ( msgtext ) #MIMEMultipartMIMEText， msg . attach ( attach ) try : s = smtplib . SMTP () #SMTP s . connect ( mail_host , 25 ) #connectsmtp s . starttls () #TLS（），SMTP，gmailsmtp s . login ( mail_user , mail_pass ) s . sendmail ( me , to_list , msg . as_string ()) s . quit () #smtp print ! return True except Exception as e : print : + str ( e ) return False if __name__ == __main__ : #send_mail(sys.argv[1], sys.argv[2], sys.argv[3]) send_mail ( lgy_root@163.com , subject , msg )","title":"smtplib"},{"location":"python-lib/#smtplib_1","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 #!/usr/bin/env python #coding=utf-8 import smtplib from email.mime.multipart import MIMEMultipart from email.mime.text import MIMEText from email.mime.application import MIMEApplication def SendMail (): msgRoot = MIMEMultipart ( related ) msgRoot [ Subject ] = sql result msgRoot [ From ] = notice@dachuizichan.com to_list = [ liangguangyu@dachuizichan.com ] msgRoot [ To ] = , . join ( to_list ) msgzip1 = MIMEApplication ( open ( /script/sql/EXCEL.tar.gz , rb ) . read ()) msgzip1 . add_header ( Content-Disposition , attachment , filename = EXCEL.tar.gz ) msgRoot . attach ( msgzip1 ) msgzip2 = MIMEApplication ( open ( /script/sql/csv.tar.gz , rb ) . read ()) msgzip2 . add_header ( Content-Disposition , attachment , filename = csv.tar.gz ) msgRoot . attach ( msgzip2 ) sendText = sql  msgText = MIMEText ( sendText , txt , utf-8 ) msgRoot . attach ( msgText ) smtp = smtplib . SMTP_SSL () smtp . connect ( 183.232.93.197 , 465 ) smtp . login ( notice@dachuizichan.com , Dachui0002 ) smtp . sendmail ( msgRoot [ From ], to_list , msgRoot . as_string ()) smtp . quit () SendMail () ， MIMEMultipart ， attach 。， add_header 。  python ， MIME 。 MIMEBase |-- MIMENonMultipart |-- MIMEApplication |-- MIMEAudio |-- MIMEImage |-- MIMEMessage |-- MIMEText |-- MIMEMultipart ， MIMEBase ，。 MIMEMultipart  attach ， MIMENonMultipart ， attach 。 MIME ，，， MIMEImage ，， MIMEAudio ， word 、 excel ，  MIME ， google 。 ，， MIMEApplication ， MIMEApplication  application / octet - stream 。 application / octet - stream “，”，， qq ，， 。 。  foo . xlsx / foo . jpg / foo . pdf / foo . mp3  4 。 import smtplib from email.mime.multipart import MIMEMultipart from email.mime.text import MIMEText from email.mime.application import MIMEApplication _user = sigeken@qq.com _pwd = *** _to = 402363522@qq.com #Multipart msg = MIMEMultipart () msg [ Subject ] = don t panic msg [ From ] = _user msg [ To ] = _to #------ part = MIMEText ( ， ) msg . attach ( part ) #------ #xlsx part = MIMEApplication ( open ( foo.xlsx , rb ) . read ()) part . add_header ( Content-Disposition , attachment , filename = foo.xlsx ) msg . attach ( part ) #jpg part = MIMEApplication ( open ( foo.jpg , rb ) . read ()) part . add_header ( Content-Disposition , attachment , filename = foo.jpg ) msg . attach ( part ) #pdf part = MIMEApplication ( open ( foo.pdf , rb ) . read ()) part . add_header ( Content-Disposition , attachment , filename = foo.pdf ) msg . attach ( part ) #mp3 part = MIMEApplication ( open ( foo.mp3 , rb ) . read ()) part . add_header ( Content-Disposition , attachment , filename = foo.mp3 ) msg . attach ( part ) s = smtplib . SMTP ( smtp.qq.com , timeout = 30 ) #smtp,25 s . login ( _user , _pwd ) # s . sendmail ( _user , _to , msg . as_string ()) # s . close ()","title":"smtplib"},{"location":"python-lib/#pexpect","text":"Expect 。 Expect ，，。， ssh ， ftp 。 Expect  send , expect , spawn , interact 。 send ： expect ： spawn ： interact ： ================================================================ 2.7  Python ： pip install pyexpect  pyexpect ： In [ 1 ]: import pexpect In [ 2 ]: output , exitstatus = pexpect . run ( ls -l , withexitstatus = 1 ) In [ 3 ]: print output , exitstatus ：  output  exitstatus  ls -l  output withexitstatus = 1 ， exitstatus ================================================================  spawn ， ： 1 、 pexpect . spawn () ： child = pexpect . spawn ( ‘ command ’ ) 2 、 child . logfile ： (  ) f = file （’ / tmp / plog . out ’ , ‘ w ’） child . logfile = f 3 、 expect  index = child . expect ([ “”，”” pexpect . EOF ， pexpect . TIMEOUT ]) pexpect . EOF  pexpect . TIMEOUT ， 30 s  if  index ， index  0 “”， 1 ”” 4 、 sendline  , ： child . sendline ( ‘ command ’ ) #sendcontrol（‘c’）ctrl+c 5 、 try ， except  try : index = p . expect ([ good , bad ]) if index == 0 : do_something () elif index == 1 : do_something_else () except EOF : do_some_other_thing () except TIMEOUT : do_something_completely_different () 6 、 before  : p = pexpect . spawn ( /bin/ls ) p . expect ( pexpect . EOF ) print p . before  6  90 % 。  share ， 6 ，， ok ！ ================================================================  1 ：  ftp ， 192.168 . 100.194 ，， passwd ，。， ，： #!/usr/bin/env python import pexpect import sys child = pexpect . spawn ( ftp 192.168.100.194 ) child . expect ( Name .*: ) child . sendline ( sys . argv [ 1 ]) #，hello child . expect ( Password: ) child . sendline ( sys . argv [ 2 ]) #，123 child . expect ( ftp ) child . sendline ( get passwd ) #passwd child . expect ( ftp ) child . sendline ( bye ) # ： [ root @localhost test ] # python a.py hello 123 [ root @localhost test ] # ls a . py passwd  1  : import pexpect username = ptest key = 123456 f = file ( /tmp/plog.out , w ) if __name__ == __main__ : child = pexpect . spawn ( ftp localhost ) # child . logfile = f #f try : index = child . expect ([ Name ]) #Name if index == 0 : #0，Name， child . sendline ( username ) #sendline， index = child . expect ([ Password ]) #Password if index == 0 : child . sendline ( key ) #Pwassword，key index = child . expect ([ Login successful.*ftp ]) if index == 0 : child . sendline ( ls ) index = child . expect ([ test.mp3 ]) if index == 0 : child . sendline ( bin ) #，get child . sendline ( get test.mp3 ) #test.mp3 index = child . expect ([ Transfer complete.*ftp ]) if index == 0 : print download complete! child . sendline ( bye ) # except : print child . before print see /tmp/plog.out can find more info! ， / tmp / plog . out  ，，！ ================================================================  2 ：，。，。 #!/usr/bin/env python #coding=utf8 import pexpect # home = /root #、IP， info = { root@192.168.0.156 : 123456 } f = file ( /tmp/plog.out , w ) def genkey (): child = pexpect . spawn ( ssh-keygen -t rsa ) child . logfile = f try : index = child . expect ([ save the key ]) if index == 0 : child . sendline () index = child . expect ([ Enter passphrase , Overwrite ]) if index == 0 : child . sendline () index = child . expect ([ Enter same passphrase ]) if index == 0 : child . sendline () else : child . sendline ( n ) except : print child . before def copykey (): try : for k , v in info . items (): child = pexpect . spawn ( ssh-copy-id -i %s /.ssh/id_rsa.pub %s % ( home , k )) child . logfile = f index = child . expect ([ continue connecting , password ]) if index == 0 : child . sendline ( yes ) else : child . sendline ( v ) child . expect ( pexpect . EOF ) except : print child . before if __name__ == __main__ : genkey () copykey () ================================================================  3 ： ssh ，， ssh_newkey ,  password ： #!/usr/bin/env python #encoding=utf8 import pexpect import getpass , os #user: ssh  #host：ssh  #password：ssh  #command： ssh  def ssh_command ( user , host , password , command ): This runs a command on the remote host. This could also be done with the pxssh class, but this demonstrates what that class does at a simpler level. This returns a pexpect.spawn object. This handles the case when you try to connect to a new host and ssh asks you if you want to accept the public key fingerprint and continue connecting. ssh_newkey = Are you sure you want to continue connecting #  ssh  spawn . child = pexpect . spawn ( ssh -l %s %s %s % ( user , host , command )) i = child . expect ([ pexpect . TIMEOUT , ssh_newkey , password: ]) # ，，. if i == 0 : # Timeout print ERROR! print SSH could not login. Here is what SSH said: print child . before , child . after return None #  ssh  public key，. if i == 1 : # SSH does not have the public key. Just accept it. child . sendline ( yes ) child . expect ( password: ) i = child . expect ([ pexpect . TIMEOUT , password: ]) if i == 0 : # Timeout print ERROR! print SSH could not login. Here is what SSH said: print child . before , child . after return None # . child . sendline ( password ) return child def main (): #  ssh . host = raw_input ( Hostname: ) #  ssh . user = raw_input ( User: ) #  ssh . password = getpass . getpass () #  ssh . command = raw_input ( Enter the command: ) child = ssh_command ( user , host , password , command ) #  pexpect.EOF child . expect ( pexpect . EOF ) # . print child . before if __name__ == __main__ : try : main () except Exception , e : print str ( e ) os . _exit ( 1 ) 1.   shell  except ，， ssh  #!/usr/bin/env python # encoding: UTF-8 ssh-copy-id -i /root/.ssh/id_rsa.pub root@localhost import pexpect keyfile = /root/.ssh/id_rsa.pub target_user = root target_host = localhost command = ssh-copy-id -i + keyfile + + target_user + @ + target_host password = 123456 child = pexpect . spawn ( command ) try : index = child . expect ([ yes/no , password ]) if index == 0 : child . sendline ( yes ) index = child . expect ([ password ]) if index == 0 : child . sendline ( password ) else : child . sendline ( password ) except pexpect . EOF : print now to try U sshkey 2 、 #!/usr/bin/env python #coding:utf-8 import pexpect , sys child = pexpect . spawn ( ssh root@127.0.0.1 ) # pexpect.spawn(command, args=[], timeout=30, maxread=2000, searchwindowsize=None, logfile=None, cwd=None, env = None , ignore_sighup = True ) # command timeout；maxreadpex-pect， searchwindowsize ，。 #，pexpectshell，“ ”、“|”“*”，，，  / bin / bash ， #：child = pexpect.spawn( /bin/bash -c ls -l | grep LOG logs.txt ) # child.expect(pexpect.EOF) #Python，，。 # shell_cmd = ls -l | grep LOG logs.txt # child = pexpect.spawn( /bin/bash , [ -c , shell_cmd]) # child.expect(pexpect.EOF) fout = file ( mylog.txt , w ) #child.logfile = fout # child . logfile = sys . stdout #， passwd = 1 comm = free -m try : index = child . expect ([ yes/no , password: ]) #， if index == 0 : child . sendline ( yes ) child . expect ( password: ) child . sendline ( passwd ) child . expect ( # ) child . sendline ( comm ) child . expect ( # ) child . sendline ( exit ) elif index == 1 : child . sendline ( passwd ) child . expect ( # ) child . sendline ( comm ) child . expect ( # ) child . sendline ( exit ) else : print Error except Exception , e : print str ( e )","title":"pexpect"},{"location":"python-lib/#json","text":"# coding:utf-8 from json import dumps , loads a = { a : 1 , b : 2 , c : 3 } b = str ({ a : 1 , b : 2 , c : 3 }) print dumps ( a , indent = 4 )  { a : 1 , c : 3 , b : 2 } print dumps ( b , indent = 4 ) { a : 1, c : 3, b : 2} print dumps ( eval ( b ), indent = 4 ) { a : 1 , c : 3 , b : 2 }  json . dumps ， ascii ， # coding:utf-8 from json import dumps , loads test = loads ( { haha :  } ) print dumps ( test ) # { haha : \\u54c8\\u54c8 } print dumps ( test , ensure_ascii = False ) # { haha :  }","title":"json"},{"location":"python-lib/#ftplib","text":"ftp  from ftplib import FTP #ftp ftp = FTP () # ftp . set_pasv ( False )  ftp . set_debuglevel ( 2 ) #2， ftp . connect ( IP , port ) #ftp sever ftp . login ( user , password ) #， print ftp . getwelcome () # ftp . cwd ( xxx/xxx ) # bufsize = 1024 # filename = filename.txt # file_handle = open ( filename , wb ) . write # ftp . retrbinaly ( RETR filename.txt , file_handle , bufsize ) # ftp . set_debuglevel ( 0 ) # ftp . quit #ftp ftp  ftp . cwd ( pathname ) #FTP ftp . dir () # ftp . nlst () # ftp . mkd ( pathname ) # ftp . pwd () # ftp . rmd ( dirname ) # ftp . delete ( filename ) # ftp . rename ( fromname , toname ) #fromnametoname。 ftp . storbinaly ( STOR filename.txt , file_handel , bufsize ) # ftp . retrbinary ( RETR filename.txt , file_handel , bufsize ) #FTP ： from ftplib import FTP ftp = FTP () timeout = 30 port = 21 ftp . connect ( 192.168.1.188 , port , timeout ) # FTP ftp . login ( UserName , 888888 ) #  print ftp . getwelcome () #  ftp . cwd ( file/test ) # FTP list = ftp . nlst () #  for name in list : print ( name ) #  path = d:/data/ + name #  f = open ( path , wb ) #  filename = RETR + name # FTP ftp . retrbinary ( filename , f . write ) # FTP ftp . delete ( name ) # FTP ftp . storbinary ( STOR + filename , open ( path , rb )) # FTP ftp . quit () # FTP #!/usr/bin/python # -*- coding: utf-8 -*- import ftplib import os import socket HOST = ftp.mozilla.org DIRN = pub/mozilla.org/webtools FILE = bugzilla-3.6.7.tar.gz def main (): try : f = ftplib . FTP ( HOST ) except ( socket . error , socket . gaierror ): print ERROR:cannot reach %s % HOST return print ***Connected to host %s % HOST try : f . login () except ftplib . error_perm : print ERROR: cannot login anonymously f . quit () return print *** Logged in as anonymously try : f . cwd ( DIRN ) except ftplib . error_perm : print ERRORL cannot CD to %s % DIRN f . quit () return print *** Changed to %s folder % DIRN try : #retrbinary()  f . retrbinary ( RETR %s % FILE , open ( FILE , wb ) . write ) except ftplib . error_perm : print ERROR: cannot read file %s % FILE os . unlink ( FILE ) else : print *** Downloaded %s to CWD % FILE f . quit () return if __name__ == __main__ : main ()","title":"ftplib"},{"location":"python-lib/#datetime","text":" import time print ( time . strftime ( %Y-%m- %d %H:%M:%S )) # time.strftime(format[, tuple]) struct_time(),  ,  : 2011 - 04 - 13 18 : 30 : 10 print ( time . strftime ( %Y-%m- %d %A %X , time . localtime ( time . time ()))) # ；  : 2011 - 04 - 13 Wednesday 18 : 30 : 10 print ( time . strftime ( %Y-%m- %d %A %X , time . localtime ())) # ； : 2011-04-13 Wednesday 18:30:10 print ( time . time ()) # Linux； : 1302687844.7；  time . localtime ( time . time ())  time  print ( time . ctime ( 1150269086.6630149 )) #time.ctime([seconds]) ，， 。 : Wed Apr 13 21 : 13 : 11 2011 print ( time . gmtime ( 1150269086.6630149 )) # time.gmtime([seconds]) UTC(0)  struct_time ， seconds ， print ( time . gmtime ()) # ： time.struct_time(tm_year=2014, tm_mon=8, tm_mday=27, tm_hour=7, tm_min = 28 , tm_sec = 19 , tm_wday = 2 , tm_yday = 239 , tm_isdst = 0 ) print ( time . localtime ( 1150269086.6630149 )) # time.localtime([seconds])  struct_time ， seconds ， print ( time . mktime ( time . localtime ())) # time.mktime(tuple) struct_time(float), ： 1409124869.0  from datetime import datetime datetime . strptime ( 2017 Sep 21 14:16:52 , %Y %b %d %H:%M:%S ) . strftime ( %Y-%m- %d %H:%M:%S ) # (、、、、、) print ( time . localtime ()) # : time.struct_time(tm_year=2014, tm_mon=8, tm_mday=27, tm_hour=15, tm_min = 10 , tm_sec = 16 , tm_wday = 2 , tm_yday = 239 , tm_isdst = 0 ) print ( time . localtime ()[:]) # : (2014, 8, 27, 15, 10, 16, 2, 239, 0) #  print ( time . localtime ()[ 1 ] - 1 ) # : 7 #  print ( time . localtime ()[ 1 ] + 2 ) # : 10 #  print ( time . localtime ()[ 0 ] - 1 ) # : 2013 #  import time , datetime print ( time . time ()) # ： 1409127119.16 print time . mktime ( time . strptime ( 2012-10-21 18:51:50 , %Y-%m- %d %H:%M:%S ))  print ( long ( time . time ())) # ： 1409127119 print ( time . mktime ( datetime . datetime . now () . timetuple () )) # ： 1409127119.0 print ( long ( time . mktime ( time . strptime ( 2014-03-25 19:25:33 , %Y-%m- %d %H:%M:%S )))) # ：1395746733 #  import time time . sleep ( 2 ) # 、、(datetime) import datetime #  print ( datetime . date . today ()) # : 2011-04-13 #  print ( datetime . date . today () + datetime . timedelta ( days =- 1 )) # : 2011-04-12 print ( datetime . date . today () - datetime . timedelta ( days = 1 )) # : 2011-04-12 # 10 print ( datetime . date . today () + datetime . timedelta ( days = 10 )) # : 2011-04-23 # 10， days  hours print ( datetime . datetime . now () + datetime . timedelta ( hours = 10 )) # : 2011-04-14 04:30:10.189000 #  1  d1 = datetime . datetime ( * time . localtime ()[: 3 ]) + datetime . timedelta ( days = 1 ) + datetime . timedelta ( hours = 1 ) # : 2011-04-13 01:00:00 print ( time . mktime ( d1 . timetuple () )) # ： 1409127119.0 # 、、(time) import time #  print ( time . strftime ( %Y-%m- %d %H:%M:%S , time . localtime ( time . time () + 24 * 60 * 60 ))) # 20 print ( time . strftime ( %Y-%m- %d %H:%M:%S , time . localtime ( time . time () + 20 * 24 * 60 * 60 ))) # 202 print ( time . strftime ( %Y-%m- %d %H:%M:%S , time . localtime ( time . time () + 20 * 24 * 60 * 60 - 2 * 60 * 60 ))) #(、): import datetime # ： datetime.datetime(year, month, day[, hour[, minute[, second[, microsecond[,tzinfo]]]]]) d1 = datetime . datetime ( 2005 , 2 , 16 ) d2 = datetime . datetime ( 2004 , 12 , 31 ) print (( d1 - d2 ) . days ) # ： 47 #： import time , datetime starttime = datetime . datetime . now () time . sleep ( 1 ) # 1 endtime = datetime . datetime . now () print (( endtime - starttime ) . seconds ) # , ： 1 print (( endtime - starttime ) . microseconds ) # ()； ： 14000 #  import time start = time . clock () func ( * args , ** kwargs ) #  end = time . clock () print ( used: + str ( end ) ) # : # 2( time.clock() ,) import time start = time . time () func ( * args , ** kwargs ) #  end = time . time () print ( used: + str ( end - start ) ) # : # time.clock()  clock () - floating point number ， ，； ， ,  import time time . sleep ( 1 ) print clock1: %s % time . clock () # : clock1:2.17698990094e-06 time . sleep ( 1 ) print clock2: %s % time . clock () # : clock2:1.00699529055 time . sleep ( 1 ) print clock3: %s % time . clock () # : clock3:2.00698720459 #    time import time s2 = 2012-02-16 ; a = time . strptime ( s2 , %Y-%m- %d ) print a # time.struct_time(tm_year=2012, tm_mon=2, tm_mday=16, tm_hour=0, tm_min=0, tm_sec=0, tm_wday=3, tm_yday = 47 , tm_isdst =- 1 ) print type ( a ) # type time.struct_time print repr ( a ) # time.struct_time(tm_year=2012, tm_mon=2, tm_mday=16, tm_hour=0, tm_min=0, tm_sec=0, tm_wday=3, tm_yday = 47 , tm_isdst =- 1 ) #    datetime import datetime date_str = 2008-11-10 17:53:59 dt_obj = datetime . datetime . strptime ( date_str , %Y-%m- %d %H:%M:%S ) print dt_obj # 2008-11-10 17:53:59 print dt_obj . strftime ( %Y-%m- %d %H:%M:%S ) # 2008-11-10 17:53:59 print type ( dt_obj ) # type datetime.datetime print repr ( dt_obj ) # datetime.datetime(2008, 11, 10, 17, 53, 59) # timestamp to time tuple in UTC import time timestamp = 1226527167.595983 time_tuple = time . gmtime ( timestamp ) print repr ( time_tuple ) # time.struct_time(tm_year=2008, tm_mon=11, tm_mday=12, tm_hour=21, tm_min=59, tm_sec=27, tm_wday = 2 , tm_yday = 317 , tm_isdst = 0 ) print time . strftime ( %Y-%m- %d %H:%M:%S , time_tuple ) # 2008-11-12 21:59:27 # timestamp to time tuple in local time ( time.time() ) import time timestamp = 1226527167.595983 time_tuple = time . localtime ( timestamp ) print repr ( time_tuple ) # time.struct_time(tm_year=2008, tm_mon=11, tm_mday=13, tm_hour=5, tm_min=59, tm_sec=27, tm_wday = 3 , tm_yday = 318 , tm_isdst = 0 ) print time . strftime ( %Y-%m- %d %H:%M:%S , time_tuple ) # 2008-11-13 05:59:27 # datetime  time import time , datetime # datetime  timetuple  time.struct_time print ( datetime . datetime . now () . timetuple ()) # ：time.struct_time(tm_year=2014, tm_mon=8, tm_mday=27, tm_hour=16, tm_min=7, tm_sec=37, tm_wday=2, tm_yday = 239 , tm_isdst =- 1 ) print ( time . localtime ()) # ：time.struct_time(tm_year=2014, tm_mon=8, tm_mday=27, tm_hour=16, tm_min=7, tm_sec=37, tm_wday=2, tm_yday = 239 , tm_isdst = 0 )  : %% : %  % A :  (  ),  : Tuesday % a :  (  ),  : Tue % B :  (  ),  : February % b :  (  ),  : Feb % c :  ,  : 02 / 15 / 11 16 : 50 : 57 % d :  ( 0 - 31 ),  : 15 % H : 24  ( 0 - 23 ) % I : 12  ( 01 - 12 ) % j :  ( 001 - 366 ),  : 046 % M :  ( 00 - 59 ),  : 50 % m :  ( 01 - 12 ),  : 02 % p :  (  A . M .  P . M .  ),  : PM % S :  ( 00 - 59 ),  : 57 % f :  (  datetime  , time  ) % X :  ,  : 16 : 50 : 57 % x :  ,  : 02 / 15 / 11 % Y :  ( 000 - 9999 ) % y :  ( 00 - 99 ) % U :  ( 00 - 53 )  ,  : 07 % W :  ( 00 - 53 )  ,  : 07 % w :  ( 0 - 6 ),  ,  : 2 (  0 ) % Z :  ,  :  % z :  ,  : ","title":"datetime"},{"location":"python-lib/#logging","text":"logging  # 1.  logging,  logging , import logging # logging，: NOTSET(0), DEBUG(10), INFO(20), WARNING(30), ERROR(40), CRITICAL ( 50 ) 。。 logging . basicConfig ( level = logging . INFO , format = %(asctime)s %(module)s . %(funcName)s %(lineno)s : %(levelname)s : %(message)s , datefmt = %Y-%m- %d %X , filename = log.log ) logging . info ( logging message ) # 2.  log  def initlog (): import logging logger = logging . getLogger () # ，， hdlr = logging . FileHandler ( crawl.log ) # Handler。loggingHandler，FileHandler, SocketHandler , SMTPHandler ， FileHandler 。 # ，。 # ，： %(message)s 。，，， 。 # logging，Formatter。：，，。 formatter = logging . Formatter ( %(asctime)s %(levelname)s : %(message)s ) hdlr . setFormatter ( formatter ) #  #logger.addHandler(hdlr) #  #  addHandler ,( handler),( handler)。 logger . handlers = [ hdlr ] # ,、。 # 。，30(WARNING)。 # ：logging.getLevelName(logger.getEffectiveLevel())。  ,  : info (), error (), debug () 。 # ，。。NOTSET（0）， 。 logger . setLevel ( logging . NOTSET ) return logger # ： logger = initlog () logger . info ( message info ) logger . error ( message error ) logging  Python  logging ，。 ，，， HTTP GET / POST ， SMTP ， Socket ， 。 logging  log4j ，。 logger ， handler ， filter ， formatter 。 logger ：，。 logger ：。  logging . getLogger ( name )  logger ， name  root ， name  getLogger   logger 。 handler ：（ log record ）（ destination ），， socket 。  logger  addHandler  0  handler ， handler ，。 filter ： handler 。 formatter ：。 formatter ：，。  log4j ， logger ， handler （ Level ）， logger  handler 。  ( log_test . py  ) ： import logging import logging.handlers LOG_FILE = tst.log # ,、, handler  handler = logging . handlers . RotatingFileHandler ( LOG_FILE , maxBytes = 1024 * 1024 , backupCount = 5 ) # handler, handler = logging . handlers . TimedRotatingFileHandler ( LOG_FILE , when = midnight , backupCount = 10 ) # log， #  backupCount log, 10  10  log fmt = %(asctime)s - %(filename)s : %(lineno)s - %(name)s - %(message)s formatter = logging . Formatter ( fmt ) # formatter handler . setFormatter ( formatter ) # handlerformatter logger = logging . getLogger ( tst ) # tstlogger logger . addHandler ( handler ) # loggerhandler logger . setLevel ( logging . DEBUG ) logger . info ( first info message ) #  log  logger . debug ( first debug message ) ： 2012 - 03 - 04 23 : 21 : 59 , 682 - log_test . py : 16 - tst - first info message 2012 - 03 - 04 23 : 21 : 59 , 682 - log_test . py : 17 - tst - first debug message  formatter ， % ( dict key ) s ，。： Format Description % ( name ) s Logger 。 Name of the logger ( logging channel ) . % ( levelno ) s 。 Numeric logging level for the message ( DEBUG , INFO , WARNING , ERROR , CRITICAL ) . % ( levelname ) s 。 Text logging level for the message ( DEBUG , INFO , WARNING , ERROR , CRITICAL ) . % ( pathname ) s ，。 Full pathname of the source file where the logging call was issued ( if available ) . % ( filename ) s 。 Filename portion of pathname . % ( module ) s 。 Module ( name portion of filename ) . % ( funcName ) s 。 Name of function containing the logging call . % ( lineno ) d 。 Source line number where the logging call was issued ( if available ) . % ( created ) f ， UNIX 。 Time when the LogRecord was created ( as returned by time . time ()) . % ( relativeCreated ) d ， Logger 。 Time in milliseconds when the LogRecord was created , relative to the time the logging module was loaded . % ( asctime ) s 。“ 2003 - 07 - 08 16 : 49 : 45 , 896 ”。。 Human - readable time when the LogRecord was created . By default this is of the form “ 2003 - 07 - 08 16 : 49 : 45 , 896 ” ( the numbers after the comma are millisecond portion of the time ) . % ( msecs ) d Millisecond portion of the time when the LogRecord was created . % ( thread ) d  ID 。。 Thread ID ( if available ) . % ( threadName ) s 。。 Thread name ( if available ) . % ( process ) d  ID 。。 Process ID ( if available ) . % ( message ) s 。 The logged message , computed as msg % args . ，。 logging  logging  python 。 python ， handler ， handler ， formatter 。 。 python 。  (  ) ： import logging import logging.config logging . config . fileConfig ( logging.conf ) #  # create logger logger = logging . getLogger ( simpleExample ) #  simpleExample  logger,  [ logger_simpleExample ] # application code logger . debug ( debug message ) logger . info ( info message ) logger . warn ( warn message ) logger . error ( error message ) logger . critical ( critical message )  logging . conf  : [ loggers ] keys = root , simpleExample [ handlers ] keys = consoleHandler [ formatters ] keys = simpleFormatter [ logger_root ] level = DEBUG handlers = consoleHandler [ logger_simpleExample ] level = DEBUG handlers = consoleHandler qualname = simpleExample propagate = 0 [ handler_consoleHandler ] class = StreamHandler level = DEBUG formatter = simpleFormatter args = ( sys . stdout ,) [ formatter_simpleFormatter ] format =% ( asctime ) s - % ( name ) s - % ( levelname ) s - % ( message ) s datefmt = loggin . conf ， r ^[(.*)]$ ，。  , 。  componentName_instanceName 。 。  handler ， class  handler ， logging ， RotatingFileHandler ，  class  : RotatingFileHandler  logging . handlers . RotatingFileHandler 。 args ，，。 ， logger ， a . b  a . c  logger  a  logger ， logger  root 。  handler ，。。  logging logging  python ， logging . getLogger ( log_name )  logger ， 。  logging  main  logging ，，  getLogger  Logger 。  :  logging . conf  : [ loggers ] keys = root , main [ handlers ] keys = consoleHandler , fileHandler [ formatters ] keys = fmt [ logger_root ] level = DEBUG handlers = consoleHandler [ logger_main ] level = DEBUG qualname = main handlers = fileHandler [ handler_consoleHandler ] class = StreamHandler level = DEBUG formatter = fmt args = ( sys . stdout ,) [ handler_fileHandler ] class = logging . handlers . RotatingFileHandler level = DEBUG formatter = fmt args = ( tst.log , a , 20000 , 5 ,) [ formatter_fmt ] format =% ( asctime ) s - % ( name ) s - % ( levelname ) s - % ( message ) s datefmt =  main . py ： import logging import logging.config logging . config . fileConfig ( logging.conf ) root_logger = logging . getLogger ( root ) root_logger . debug ( test root logger... ) logger = logging . getLogger ( main ) logger . info ( test main logger ) logger . info ( start import module \\ mod \\ ... ) import mod logger . debug ( let \\ s test mod.testLogger() ) mod . testLogger () root_logger . info ( finish test... )  mod . py ： import logging import submod logger = logging . getLogger ( main.mod ) logger . info ( logger of mod say something... ) def testLogger (): logger . debug ( this is mod.testLogger... ) submod . tst ()  submod . py ： import logging logger = logging . getLogger ( main.mod.submod ) logger . info ( logger of submod say something... ) def tst (): logger . info ( this is submod.tst()... )  python main . py ， log   tst . log  root logger ， logging . conf  main logger  logger  RotatingFileHandler ，  root logger 。  import os import logging import logging.handlers def init_log ( logfile , backupCount , debug = True ):  log_path = os . path . dirname ( logfile ) if not os . path . isdir ( log_path ): os . makedirs ( log_path ) logger = logging . getLogger () formatter = logging . Formatter ( [ %(asctime)s ]: %(module)s %(levelname)s %(message)s ) #  log  #handler_record = logging.FileHandler(logfile) handler_record = logging . handlers . TimedRotatingFileHandler ( logfile , when = midnight , backupCount = backupCount ) handler_record . setFormatter ( formatter ) logger . addHandler ( handler_record ) if debug : logger . setLevel ( logging . DEBUG ) handler_record . setLevel ( logging . DEBUG ) else : logger . setLevel ( logging . WARNING ) handler_record . setLevel ( logging . WARNING ) #  log  handler_email = logging . handlers . SMTPHandler ( mail.guoling.com , #  backend_program@guoling.com , #  fengwanli@guoling.com , # 。 (：[ 292598441@qq.com , fengwanli@guoling.com ]),  test email logging , #  ( backend_program@guoling.com , guoling ) # (CREDENTIALS) ) handler_email . setFormatter ( formatter ) handler_email . setLevel ( logging . ERROR ) email_logger = logging . getLogger ( email ) #  logger email_logger . addHandler ( handler_email ) email_logger . setLevel ( logging . ERROR ) # http  log  http_handler = logging . handlers . HTTPHandler ( 127.0.0.1:3333 , /log/ , method = GET ) http_handler . setFormatter ( formatter ) http_handler . setLevel ( logging . ERROR ) #  logger init_log ( ./log/run.log , 30 , False ) #  #os.remove( ./log/run.log ) logging . error ( u logging.error 。。。 ) #  log, email_logger = logging . getLogger ( email ) #  log msg = email_logger.error gbk  2... msg = msg . decode ( sys . stdin . encoding ) . encode ( gbk ) # , foxmail  email_logger . error ( msg ) # ,  mlogging ==================================== https : // pypi . python . org / pypi / mlogging /  :  log ，  : windows   : # linux  easy_install sudo easy_install mlogging","title":"logging"},{"location":"python-lib2/","text":" from colors import blue,cyan,green,magenta,red,white,yellow def color_test(): print blue( blue ,bold=True) print cyan( cyan ,bold=True) print green( green ,bold=True) print magenta( magenta ,bold=True) print red( red ,bold=True) print white( white ,bold=True) print yellow( yellow ,bold=True) def _wrap_with ( code ): def inner ( text , bold = False ): c = code if bold : c = 1; %s % c return \\033 [ %s m %s \\033 [0m % ( c , text ) return inner red = _wrap_with ( 31 ) green = _wrap_with ( 32 ) yellow = _wrap_with ( 33 ) blue = _wrap_with ( 34 ) magenta = _wrap_with ( 35 ) cyan = _wrap_with ( 36 ) white = _wrap_with ( 37 ) urlencode urlencode  urlencode  Dictionary d = { par1 : a , par2 : b ,} print urllib . urlencode ( m ) #par2=b par1=a urlencode   urlencode ， post  get 。 Python  http : // www . pythonclub . org / python - basic / codec 。 ： Google  baidu ， baidu  gb2312  , google  utf8 ， URL   urlencode ，”” : python  # coding: UTF-8  urllib . urlencode ( “” ) ： % E5 % B8 % 9 D % E5 % 9 B % BD ,  urlencode  utf8 “”。  gb2312 “”？ st = u  st = st . encode ( gb2312 ) m = { par : st ,} s = urllib . urlencode ( m ) print s #par=%B5%DB%B9%FA django  urlencode ，： from django.utils.http import urlquote a = urlquote (  ) print a  GBK   urllib  quote  URL ， GBK ， URI  URL 。 import urllib a =  a \\xb5\\xdb\\xb9\\xfa urllib . quote ( a ) %B5%DB%B9 %F A syslog  Cisco ASA 5550 Firewall2 . syslog  Cisco ASA 5550 Firewall logging enable logging timestamp logging trap warnings logging host inside 172.16 . 0.5 logging facility local0 172.16 . 0.5  syslog  syslog  * ： Python  3.0  chmod 700 syslogd ./ syslogd # -*- encoding: utf-8 -*- # Cisco ASA Firewall - Syslog Server by neo # Author: neo openunix@163.com import logging import socketserver import threading LOG_FILE = /var/log/asa5550.log logging . basicConfig ( level = logging . INFO , format = %(message)s , datefmt = , filename = LOG_FILE , filemode = a ) class SyslogUDPHandler ( socketserver . BaseRequestHandler ): def handle ( self ): data = bytes . decode ( self . request [ 0 ] . strip ()) socket = self . request [ 1 ] print ( %s : % self . client_address [ 0 ], str ( data )) logging . info ( str ( data )) # socket.sendto(data.upper(), self.client_address) if __name__ == __main__ : try : HOST , PORT = 0.0.0.0 , 515 server = socketserver . UDPServer (( HOST , PORT ), SyslogUDPHandler ) server . serve_forever ( poll_interval = 0.5 ) except ( IOError , SystemExit ): raise except KeyboardInterrupt : print ( Crtl+C Pressed. Shutting down. ) psutil  yum install python - devel python - pip - y pip install psutil #!/usr/bin/env python #coding:utf-8 import psutil def meminfo (): # mem = psutil . virtual_memory () print mem print mem . total , mem . used , mem . free # def cpuinfo (): #CPU,percpu=True print psutil . cpu_times ( percpu = True ) cpu = psutil . cpu_times () print cpu print cpu . user # print psutil . cpu_count () #CPU print psutil . cpu_count ( logical = False ) #CPU def swapinfo (): print psutil . swap_memory () #swap, def diskinfo (): print psutil . disk_partitions () # print psutil . disk_usage ( / ) #（） print psutil . disk_io_counters () #IO  print psutil . disk_io_counters ( perdisk = True ) # perdisk=True IO、 def netinfo (): print psutil . net_io_counters () #IO print psutil . net_io_counters ( pernic = True ) #IO def otherinfo (): from datetime import datetime print psutil . users () # boot_time = psutil . boot_time () #，Linux print datetime . fromtimestamp ( boot_time ) . strftime ( %Y-%m- %d %H：%M：%S ) # def proceinfo (): psutil . pids () #PID p = psutil . Process ( 1050 ) #Process，PID print p . name (), p . exe (), p . cwd (), p . status (), p . create_time (), p . uids (), p . gids (), p . cpu_times () #p.exe () #bin p.cpu_times () #CPU，user、systemCPU print p . cpu_affinity () , p . memory_percent () , p . memory_info () , p . io_counters () , p . num_threads () # getCPU  rss、vms IO  def popenuse (): from subprocess import PIPE p = psutil . Popen ([ /usr/bin/python , -c , print( hello ) ], stdout = PIPE ) print p . name () , p . username (), p . communicate () #print p.cpu_times() IPy 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 #!/usr/bin/env python #coding:utf-8 from IPy import IP #IPv4IPv6 print IP ( 10.0.0.0/8 ) . version () , IP ( ::1 ) . version () def wanduan (): ip = IP ( 192.168.0.0/24 ) print ip . len () #IP for x in ip : print x #IP def zhuanhuan (): print IP ( 192.168.1.20 ) . reverseNames () # print IP ( 8.8.8.8 ) . iptype () #ip， PUBLIC  PRIVATE print IP ( 8.8.8.8 ) . int () # print IP ( 8.8.8.8 ) . strHex () # print IP ( 8.8.8.8 ) . strBin () # print ( IP ( 0x8080808 )) #IP #IP print IP ( 192.168.1.0 ) . make_net ( 255.255.254.0 ) print IP ( 192.168.1.0/255.255.255.0 , make_net = True ) print IP ( 192.168.1.0-192.168.1.255 , make_net = True ) #strNormal for i in range ( 4 ): print strNormal( %s ): %s % ( i , IP ( 192.168.1.0/24 ) . strNormal ( i )) def jishuan ( ip_s ): ips = IP ( ip_s ) if len ( ips ) 1 : # print ( : %s % ips . net ()) print ( : %s % ips . netmask ()) print ( : %s % ips . broadcast ()) print ( : %s % ips . reverseNames ()[ 0 ]) print ( : %s % len ( ips )) else : #IP print ( IP: %s % ips . reverseNames ()[ 0 ]) print ( : %s % ips . strHex ()) print ( : %s % ips . strBin ()) print ( iptype: %s % ips . iptype ()) #，PRIVATE、PUBLIC、LOOPBACK difflib 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 #!/usr/bin/env python #coding:utf-8 import difflib # text1 = text1: This module provides classes and functions for comparing sequences. including HTML and context and unified diffs difflib document V7.4 and string text1_lines = text1 . splitlines () # text2 = text2: This module provides classes and functions for comparing sequences. including HTML and context and unifiled diffs. difflb document V7.5 text2_lines = text2 . splitlines () def diffstr (): d = difflib . Differ () #Differ diff = d . compare ( text1_lines , text2_lines ) print \\n . join ( list ( diff )) d = difflib . HtmlDiff () #html, python difflib_l1.py result.html, print d . make_file ( text1_lines , text2_lines ) # import sys try : textfile1 = sys . argv [ 1 ] textfile2 = sys . argv [ 2 ] except Exception , e : print Error: + str ( e ) print Usage: ./simple filename1 filename2 sys . exit () def readline ( filename ): # try : fileHandle = open ( filename , rb ) text = fileHandle . read () . splitlines () #， fileHandle . close () return text except IOError as error : print ( Read file Error: + str ( error )) sys . exit () text1_lines = readline ( textfile1 ) text2_lines = readline ( textfile2 ) d = difflib . HtmlDiff () print d . make_file ( text1_lines , text2_lines ) scapy yum - y install tcpdump graphviz ImageMagick pip install scapy #!/usr/bin/env python #coding:utf-8 import os , sys , time , subprocess import warnings , logging warnings . filterwarnings ( ignore , category = DeprecationWarning ) #scapy logging . getLogger ( scapy.runtime ) . setLevel ( logging . ERROR ) #IPv6 from scapy.all import traceroute domains = raw_input ( Please input one or more IP/domain: ) #IP target = domains . split ( ) dport = [ 80 ] # if len ( target ) = 1 and target [ 0 ] != : res , unans = traceroute ( target , dport = dport , retry =- 2 ) # res . graph ( target = test.svg ) #svg time . sleep ( 1 ) subprocess . Popen ( /usr/bin/convert test.svg test.png , shell = True ) #svgpng else : print IP/domain number of errors, exit  3 - 15 ，“ - ”；“ 11 ”；“ SA ”，  IP 。 3 - 16 （），“ - ” unk * ， ASN   IDC ， IP “ 202.102 . 69.210 ”“ CHINANET - JS - AS - AP ASNumber for CHINANET jiangsu province backbone , CN ” IP 。 nmap yum install nmap - y pip install python - nmap #!/usr/bin/env python #coding:utf-8 import sys import nmap scan_row = [] try : hosts = sys . argv [ 1 ] port = sys . argv [ 2 ] except IndexError : print Uasge ./scanport.py ip port sys . exit ( 1 ) try : nm = nmap . PortScanner () except namp . PortScannerError : print Nmap not found , sys . enc_info ()[ 0 ] sys . exit ( 2 ) except : print ( Unexpected error: , sys . exc_info ()[ 0 ]) sys . exit ( 3 ) try : nm . scan ( hosts = hosts , arguments = -v -sS -p + port ) except Exception , e : print Scan error: + str ( e ) for host in nm . all_hosts (): print ---------------------------------------------------------------------- print ( Host : %s ( %s ) % ( host , nm [ host ] . hostname ())) # print ( State : %s % nm [ host ] . state ()) #,up、down for proto in nm [ host ] . all_protocols (): # print ( ---------- ) print ( Protocol : %s % proto ) # lport = nm [ host ][ proto ] . keys () # lport . sort () # for port in lport : # print ( port : %s \\t state : %s % ( port , nm [ host ][ proto ][ port ][ state ])) ， www . qq . com 、 192.168 . 1. * 、 192.168 . 1.1 - 20 、 192.168 . 1.0 / 24 ， ， 80 , 443 , 22 、 80 , 22 - 443 。   fiddler   cookielib  cookie ， cookie ，。 # -*- coding: utf-8 -*- # !/usr/bin/python import urllib2 import urllib import cookielib import re auth_url = http://www.nowamagic.net/ home_url = http://www.nowamagic.net/ ; #  data = { username : nowamagic , password : pass } # urllib post_data = urllib . urlencode ( data ) #  headers = { Host : www.nowamagic.net , Referer : http://www.nowamagic.net } # CookieJarCookie cookieJar = cookielib . CookieJar () # opener opener = urllib2 . build_opener ( urllib2 . HTTPCookieProcessor ( cookieJar )) # cookie req = urllib2 . Request ( auth_url , post_data , headers ) result = opener . open ( req ) #  cookie result = opener . open ( home_url ) #  print result . read () ： 1.  cookie  import cookielib , urllib2 ckjar = cookielib . MozillaCookieJar ( os . path . join ( C:\\Documents and Settings \\t om\\Application Data \\ Mozilla \\ Firefox \\ Profiles \\ h5m61j1i . default , cookies . txt )) req = urllib2 . Request ( url , postdata , header ) req . add_header ( User-Agent , \\ Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1) ) opener = urllib2 . build_opener ( urllib2 . HTTPCookieProcessor ( ckjar ) ) f = opener . open ( req ) htm = f . read () f . close () 2.  cookie ， cookie  cookie  import cookielib , urllib2 req = urllib2 . Request ( url , postdata , header ) req . add_header ( User-Agent , \\ Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1) ) ckjar = cookielib . MozillaCookieJar ( filename ) ckproc = urllib2 . HTTPCookieProcessor ( ckjar ) opener = urllib2 . build_opener ( ckproc ) f = opener . open ( req ) htm = f . read () f . close () ckjar . save ( ignore_discard = True , ignore_expires = True ) 3.  cookie ,  cookie  import cookielib , urllib2 cookiejar = cookielib . CookieJar () urlOpener = urllib2 . build_opener ( urllib2 . HTTPCookieProcessor ( cookiejar )) values = { redirect : , email : abc@abc.com , password : password , rememberme : , submit : OK, Let Me In! } data = urllib . urlencode ( values ) request = urllib2 . Request ( url , data ) url = urlOpener . open ( request ) print url . info () page = url . read () request = urllib2 . Request ( url ) url = urlOpener . open ( request ) page = url . read () print page  file  open () ， file 。 with open ( test.txt , w ) as f : ... print isinstance ( f , file ) //  ... f . writelines ( map ( str , range ( 10 ))) True File Object ，。， close ，。 open ( test.txt , r ) . read () 0123456789 ， flush () ， sync () ，。 close () 。 ： r : 。 w : 。 ( truncate ) 。 a : 。。 b : 。 r + : ，，。 w + : ，，。 a + : ，，。 ，。 with open ( main.py , r ) as f : ... for line in f : print line ... ，， writelines 。 with open ( test.txt , w ) as f : ... f . write ( a ) ... f . writelines ( bc ) cat test . txt abc ， os . linesep 。 os . linesep \\n ， writelines ( str ) 。 readline () 。 xreadlines ()  readlines () ，。 binary  struct ，。 import struct data = struct . pack ( 2i2s , 0x1234 , 0xFF56 , ab ) open ( test.dat , w ) . write ( data ) ! xxd - g 1 test . dat 0000000 : 34 12 00 00 56 ff 00 00 61 62 4. .. V ... ab struct . unpack ( 2i2s , open ( test.dat ) . read ()) ( 4660 , 65366 , ab ) with open ( test.dat ) as f : //  ... def xread ( fmt ): ... n = struct . calcsize ( fmt ) //  ... s = f . read ( n ) ... return struct . unpack ( fmt , s ) ... print xread ( i ) ... print xread ( i ) ... print xread ( 2s ) ( 4660 ,) ( 65366 ,) ( ab ,) ， array ，。 import array datas = array . array ( i ) datas . append ( 0x1234 ) datas . append ( 0xFF56 ) datas . tofile ( open ( test.dat , w )) ! xxd - g 1 test . dat 0000000 : 34 12 00 00 56 ff 00 00 4. .. V ... d2 = array . array ( i ) d2 . fromfile ( open ( test.dat ), 2 ) d2 array ( i , [ 4660 , 65366 ])  bytearray ， Buffer ， struct 。 encoding  codecs  open () ，。 import sys reload ( sys ) sys . setdefaultencoding ( utf-8 ) with codecs . open ( test.txt , w , gbk ) as f : ... f . write (  ) ! xxd - g 1 test . txt 0000000 : d6 d0 b9 fa ....  . encode ( gbk ) \\xd6\\xd0\\xb9\\xfa s = codecs . open ( test.txt , encoding = gbk ) . read () s u \\u4e2d\\u56fd print s  descriptor ，。 import os fd = os . open ( test.txt , os . O_CREAT | os . O_RDWR , 0644 ) // 。 ls - l test . txt - rw - r -- r -- 1 yuhen staff 6 3 25 10 : 45 test . txt os . write ( fd , abc ) 3 f = os . fdopen ( fd , r+ ) // 。 f . seek ( 0 , os . SEEK_SET ) // 。 f . read () abc f . write ( 123 ) f . flush () // os ， // 。 os . lseek ( fd , 0 , os . SEEK_SET ) 0 os . read ( fd , 100 ) abc123 os . close ( fd ) // 。  fileno () 。 tempfile Python 。 NamedTemporaryFile ，。 TemporaryFile : ，。 NamedTemporaryFile : ，，。 SpooledTemporaryFile :  TemporaryFile ，，。 import tempfile , os.path tmp = tempfile . NamedTemporaryFile () tmp . name /var/folders/r2/4vkjhz6s6lz02hk6nh2qb99c0000gn/T/tmpYYB6p3 os . path . exists ( tmp . name ) True tmp . close () os . path . exists ( tmp . name ) False ，。 with tempfile . NamedTemporaryFile ( prefix = xxx_ , suffix = .tmp , dir = . ) as f : ... print f . name ... / Users / yuhen / test / xxx_SL3apY . tmp ： tempfile . gettempdir : 。 tempfile . gettempprefix : 。 tempfile . mkdtemp : 。 tempfile . mkstemp : ，，。 os . tempnam : ，。 os . tmpfile (): ，。 tempfile . gettempdir () /var/folders/r2/4vkjhz6s6lz02hk6nh2qb99c0000gn/T tempfile . gettempprefix () tmp d = tempfile . mkdtemp (); d /var/folders/r2/4vkjhz6s6lz02hk6nh2qb99c0000gn/T/tmpE_bRWd os . path . exists ( d ) True os . removedirs ( d ) fd , name = tempfile . mkstemp () os . write ( fd , 123 \\n ) 4 os . close ( fd ) os . path . exists ( name ) True os . remove ( name ) os . path ： 。 os . path . normpath ( ./../a/b/../c ) ../a/c ，。 os . path . expanduser ( ~/.vimrc ) /Users/yuhen/.vimrc os . path . expandvars ( $HOME/.vimrc ) /Users/yuhen/.vimrc ， basename 。 os . path . splitext ( os . path . basename ( /usr/local/lib/libevent.a )) ( libevent , .a ) os ：  walk ， (，，) ， fnmatch 。 for path , dirs , files in os . walk ( . ): ... for f in files : ... if fnmatch . fnmatch ( f , *.py ): ... print os . path . join ( path , f ) ./ main . py ./ bak / amqplib_test . py ./ bak / eventlet_test . py ./ bak / extract_text . py ./ bak / fabric_test . py ， glob  listdir ，。 glob . glob ( ./bak/[rs]*.py ) # : iglob [ ./bak/redis_test.py , ./bak/socket_test.py ] ， removedirs 。 shutil . rmtree () ，。 os . makedirs ( ./a/b/c ) open ( ./a/b/c/test.txt , w ) . write ( abc ) os . removedirs ( ./a/b/c ) OSError : [ Errno 66 ] Directory not empty : ./a/b/c import shutil shutil . rmtree ( ./a ) ，。 os . access ( a.txt , os . W_OK ) True ？ stat - x a . txt File : a.txt Size : 0 FileType : Regular File Mode : ( 0644 /- rw - r -- r -- ) Uid : ( 501 / yuhen ) Gid : ( 20 / staff ) Device : 1 , 2 Inode : 5111644 Links : 1 Access : Mon Mar 25 17 : 43 : 01 2013 Modify : Mon Mar 25 17 : 43 : 01 2013 Change : Mon Mar 25 17 : 43 : 01 2013 atime = time . mktime ( datetime . datetime ( 2010 , 10 , 1 ) . utctimetuple ()) mtime = time . mktime ( datetime . datetime ( 2010 , 11 , 2 ) . utctimetuple ()) os . utime ( a.txt , ( atime , mtime )) os . stat ( a.txt ) . st_atime == atime True ，。 oct ( os . stat ( a.txt ) . st_mode ) 0100644 shutil ： copytree ，。 shutil . copytree ( ./bak , ./b/bak , ignore = shutil . ignore_patterns ( *.pyc , *.bak )) filecmp filecmp ，，。 python  difflib  。 difflib ，。 filecmp ，： filecmp . cmp ( f1 , f2 [, shallow ]) ： 。 f1 , f2 。 shallow  （ os . stat ）。， True ， False 。 filecmp . cmpfiles ( dir1 , dir2 , common [, shallow ]) ： 。 dir1 , dir2 ， common 。  3  list ，、。， ，，。 filecmp  dircmp ，，，（ A ），。 dircmp ： report () ：（） report_partial_closure () ： report_full_closure () ： ： 1  1.txt ,  2  1.txt  2.txt ,  1.txt ， import filecmp x = filecmp . dircmp ( 1 , 2 ) x . report () diff 1 2 Only in 2 : [ 2.txt ] Identical files : [ 1.txt ]  1.txt ： import filecmp x = filecmp . dircmp ( 1 , 2 ) x . report () diff 1 2 Only in 2 : [ 2.txt ] Differing files : [ 1.txt ] dircmp ： left_list ：； right_list ：； common ：； left_only ：； right_only ：； common_dirs ：； common_files ：； common_funny ：； same_files ：； diff_files ：； funny_files ：，； subdirs ：， python ： A dictionary mapping names in common_dirs to dircmp objects csv # coding=gbk import csv rows = [[ AA , 39.48 , 6/11/2007 , 9:36am , - 0.18 , 181800 ], ( AIG , 71.38 , 6/11/2007 , 9:36am , - 0.15 , 195500 ), ( AXP , 62.58 , 6/11/2007 , , - 0.46 , 935000 ,  ), ] with open ( 121.csv , wb ) as f : f_csv = csv . writer ( f ) f_csv . writerows ( rows ) xlsxwriter  import xlrd import xlwt from xlutils.copy import copy oldWb = xlrd . open_workbook ( old_file , formatting_info = True )  xls  formatting_info ， newWb = copy ( oldWb ) # sheet = newWb . get_sheet ( 0 ) #sheetname=0 sheet . write ( row , col , data , style ) #row，col，data，style newWb . save ( new_file ) ： . xls 。  excel  #!/usr/bin/env python #coding:utf-8 import xlsxwriter import sys reload ( sys ) sys . setdefaultencoding ( utf-8 ) workbook = xlsxwriter . Workbook ( demo1.xlsx ) #Excel worksheet = workbook . add_worksheet () #Sheet1 worksheet2 = workbook . add_worksheet ( Foglio2 ) # Foglio2 title = [ u  , u  , u  , u  , u  , u  , u  , u  , u  ] buname = [ u  , u  , u  , u  , u  ] ##57 data = [ [ 150 , 152 , 158 , 149 , 155 , 145 , 148 ], [ 89 , 88 , 95 , 93 , 98 , 100 , 99 ], [ 201 , 200 , 198 , 175 , 170 , 198 , 195 ], [ 75 , 77 , 78 , 78 , 74 , 70 , 79 ], [ 88 , 85 , 87 , 90 , 93 , 88 , 84 ],] format = workbook . add_format () #format format . set_border ( 1 ) #format(1) format_title = workbook . add_format () #format_title format_title . set_border ( 1 ) #format_title(1) format_title . set_bg_color ( #cccccc ) #format_title # #cccccc  format_title . set_align ( center ) #format_title format_title . set_bold () #format_title format_ave = workbook . add_format () #format_ave format_ave . set_border ( 1 ) #format_ave(1) format_ave . set_num_format ( 0.00 ) #format_ave #、、,  worksheet . write_row ( A1 , title , format_title ) worksheet . write_column ( A2 , buname , format ) worksheet . write_row ( B2 , data [ 0 ], format ) worksheet . write_row ( B3 , data [ 1 ], format ) worksheet . write_row ( B4 , data [ 2 ], format ) worksheet . write_row ( B5 , data [ 3 ], format ) worksheet . write_row ( B6 , data [ 4 ], format ) # chart = workbook . add_chart ({ type : column }) #column () #area：；bar：；column： line： pie：； #scatter： stock： radar： # def chart_series ( cur_row ): worksheet . write_formula ( I + cur_row , =AVERAGE(B + cur_row + :H + cur_row + ) , format_ave ) #(AVERAGE) chart . add_series ({ categories : =Sheet1!$B$1:$H$1 , #“”(X) values : =Sheet1!$B$ + cur_row + :$H$ + cur_row , # line : { color : black }, #black() name : =Sheet1!$A$ + cur_row , # }) for row in range ( 2 , 7 ): #2～6 chart_series ( str ( row )) #chart.set_table() #X,  #chart.set_style(30) #,  chart . set_size ({ width : 577 , height : 287 }) # chart . set_title ({ name : u  }) #() chart . set_y_axis ({ name : Mb/s }) #y() worksheet . insert_chart ( A8 , chart ) #A8 workbook . close ()  random 。 seed ，。 seed ，，。 from random import * a = Random (); a . seed ( 1 ) [ a . randint ( 1 , 100 ) for i in range ( 20 )] [ 14 , 85 , 77 , 26 , 50 , 45 , 66 , 79 , 10 , 3 , 84 , 44 , 77 , 1 , 45 , 73 , 23 , 95 , 91 , 4 ] b = Random (); b . seed ( 1 ) [ b . randint ( 1 , 100 ) for i in range ( 20 )] [ 14 , 85 , 77 , 26 , 50 , 45 , 66 , 79 , 10 , 3 , 84 , 44 , 77 , 1 , 45 , 73 , 23 , 95 , 91 , 4 ]   N 。 getrandbits ( 5 ) 29L bin ( getrandbits ( 5 )) 0b11101  start = N stop 。 randrange ( 1 , 10 ) 2 randrange ( 1 , 10 , 3 ) #  4 randrange ( 1 , 10 , 3 ) 1 randrange ( 1 , 10 , 3 ) 7  a = N = b 。 randint ( 1 , 10 ) 5 。 import string string . digits 0123456789 choice ( string . digits ) 6 choice ( string . digits ) 1 choice ( string . digits ) 3 ，。 a = range ( 10 ) shuffle ( a ) a [ 6 , 4 , 8 , 7 , 5 , 3 , 0 , 9 , 2 , 1 ]  n 。 string . letters abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ sample ( string . letters , 10 ) [ I , F , W , O , r , o , A , K , i , h ] . join ( sample ( string . letters , 10 )) #  kMmSgPVWIi . join ( sample ( string . letters , 10 )) feCTyRZrHv  0.0 = N 1 。 random () 0.39559451765020448 random () 0.62378508101496177  min = N = max 。 uniform ( 1 , 10 ) 7.6889886379206587 uniform ( 10 , 1 ) 5.1617099528426609 、β、、、。","title":"python-lib2"},{"location":"python-lib2/#_1","text":"from colors import blue,cyan,green,magenta,red,white,yellow def color_test(): print blue( blue ,bold=True) print cyan( cyan ,bold=True) print green( green ,bold=True) print magenta( magenta ,bold=True) print red( red ,bold=True) print white( white ,bold=True) print yellow( yellow ,bold=True) def _wrap_with ( code ): def inner ( text , bold = False ): c = code if bold : c = 1; %s % c return \\033 [ %s m %s \\033 [0m % ( c , text ) return inner red = _wrap_with ( 31 ) green = _wrap_with ( 32 ) yellow = _wrap_with ( 33 ) blue = _wrap_with ( 34 ) magenta = _wrap_with ( 35 ) cyan = _wrap_with ( 36 ) white = _wrap_with ( 37 )","title":""},{"location":"python-lib2/#urlencode","text":"urlencode  urlencode  Dictionary d = { par1 : a , par2 : b ,} print urllib . urlencode ( m ) #par2=b par1=a urlencode   urlencode ， post  get 。 Python  http : // www . pythonclub . org / python - basic / codec 。 ： Google  baidu ， baidu  gb2312  , google  utf8 ， URL   urlencode ，”” : python  # coding: UTF-8  urllib . urlencode ( “” ) ： % E5 % B8 % 9 D % E5 % 9 B % BD ,  urlencode  utf8 “”。  gb2312 “”？ st = u  st = st . encode ( gb2312 ) m = { par : st ,} s = urllib . urlencode ( m ) print s #par=%B5%DB%B9%FA django  urlencode ，： from django.utils.http import urlquote a = urlquote (  ) print a  GBK   urllib  quote  URL ， GBK ， URI  URL 。 import urllib a =  a \\xb5\\xdb\\xb9\\xfa urllib . quote ( a ) %B5%DB%B9 %F A","title":"urlencode"},{"location":"python-lib2/#syslog","text":" Cisco ASA 5550 Firewall2 . syslog  Cisco ASA 5550 Firewall logging enable logging timestamp logging trap warnings logging host inside 172.16 . 0.5 logging facility local0 172.16 . 0.5  syslog  syslog  * ： Python  3.0  chmod 700 syslogd ./ syslogd # -*- encoding: utf-8 -*- # Cisco ASA Firewall - Syslog Server by neo # Author: neo openunix@163.com import logging import socketserver import threading LOG_FILE = /var/log/asa5550.log logging . basicConfig ( level = logging . INFO , format = %(message)s , datefmt = , filename = LOG_FILE , filemode = a ) class SyslogUDPHandler ( socketserver . BaseRequestHandler ): def handle ( self ): data = bytes . decode ( self . request [ 0 ] . strip ()) socket = self . request [ 1 ] print ( %s : % self . client_address [ 0 ], str ( data )) logging . info ( str ( data )) # socket.sendto(data.upper(), self.client_address) if __name__ == __main__ : try : HOST , PORT = 0.0.0.0 , 515 server = socketserver . UDPServer (( HOST , PORT ), SyslogUDPHandler ) server . serve_forever ( poll_interval = 0.5 ) except ( IOError , SystemExit ): raise except KeyboardInterrupt : print ( Crtl+C Pressed. Shutting down. )","title":"syslog"},{"location":"python-lib2/#psutil","text":" yum install python - devel python - pip - y pip install psutil #!/usr/bin/env python #coding:utf-8 import psutil def meminfo (): # mem = psutil . virtual_memory () print mem print mem . total , mem . used , mem . free # def cpuinfo (): #CPU,percpu=True print psutil . cpu_times ( percpu = True ) cpu = psutil . cpu_times () print cpu print cpu . user # print psutil . cpu_count () #CPU print psutil . cpu_count ( logical = False ) #CPU def swapinfo (): print psutil . swap_memory () #swap, def diskinfo (): print psutil . disk_partitions () # print psutil . disk_usage ( / ) #（） print psutil . disk_io_counters () #IO  print psutil . disk_io_counters ( perdisk = True ) # perdisk=True IO、 def netinfo (): print psutil . net_io_counters () #IO print psutil . net_io_counters ( pernic = True ) #IO def otherinfo (): from datetime import datetime print psutil . users () # boot_time = psutil . boot_time () #，Linux print datetime . fromtimestamp ( boot_time ) . strftime ( %Y-%m- %d %H：%M：%S ) # def proceinfo (): psutil . pids () #PID p = psutil . Process ( 1050 ) #Process，PID print p . name (), p . exe (), p . cwd (), p . status (), p . create_time (), p . uids (), p . gids (), p . cpu_times () #p.exe () #bin p.cpu_times () #CPU，user、systemCPU print p . cpu_affinity () , p . memory_percent () , p . memory_info () , p . io_counters () , p . num_threads () # getCPU  rss、vms IO  def popenuse (): from subprocess import PIPE p = psutil . Popen ([ /usr/bin/python , -c , print( hello ) ], stdout = PIPE ) print p . name () , p . username (), p . communicate () #print p.cpu_times()","title":"psutil"},{"location":"python-lib2/#ipy","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 #!/usr/bin/env python #coding:utf-8 from IPy import IP #IPv4IPv6 print IP ( 10.0.0.0/8 ) . version () , IP ( ::1 ) . version () def wanduan (): ip = IP ( 192.168.0.0/24 ) print ip . len () #IP for x in ip : print x #IP def zhuanhuan (): print IP ( 192.168.1.20 ) . reverseNames () # print IP ( 8.8.8.8 ) . iptype () #ip， PUBLIC  PRIVATE print IP ( 8.8.8.8 ) . int () # print IP ( 8.8.8.8 ) . strHex () # print IP ( 8.8.8.8 ) . strBin () # print ( IP ( 0x8080808 )) #IP #IP print IP ( 192.168.1.0 ) . make_net ( 255.255.254.0 ) print IP ( 192.168.1.0/255.255.255.0 , make_net = True ) print IP ( 192.168.1.0-192.168.1.255 , make_net = True ) #strNormal for i in range ( 4 ): print strNormal( %s ): %s % ( i , IP ( 192.168.1.0/24 ) . strNormal ( i )) def jishuan ( ip_s ): ips = IP ( ip_s ) if len ( ips ) 1 : # print ( : %s % ips . net ()) print ( : %s % ips . netmask ()) print ( : %s % ips . broadcast ()) print ( : %s % ips . reverseNames ()[ 0 ]) print ( : %s % len ( ips )) else : #IP print ( IP: %s % ips . reverseNames ()[ 0 ]) print ( : %s % ips . strHex ()) print ( : %s % ips . strBin ()) print ( iptype: %s % ips . iptype ()) #，PRIVATE、PUBLIC、LOOPBACK","title":"IPy"},{"location":"python-lib2/#difflib","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 #!/usr/bin/env python #coding:utf-8 import difflib # text1 = text1: This module provides classes and functions for comparing sequences. including HTML and context and unified diffs difflib document V7.4 and string text1_lines = text1 . splitlines () # text2 = text2: This module provides classes and functions for comparing sequences. including HTML and context and unifiled diffs. difflb document V7.5 text2_lines = text2 . splitlines () def diffstr (): d = difflib . Differ () #Differ diff = d . compare ( text1_lines , text2_lines ) print \\n . join ( list ( diff )) d = difflib . HtmlDiff () #html, python difflib_l1.py result.html, print d . make_file ( text1_lines , text2_lines ) # import sys try : textfile1 = sys . argv [ 1 ] textfile2 = sys . argv [ 2 ] except Exception , e : print Error: + str ( e ) print Usage: ./simple filename1 filename2 sys . exit () def readline ( filename ): # try : fileHandle = open ( filename , rb ) text = fileHandle . read () . splitlines () #， fileHandle . close () return text except IOError as error : print ( Read file Error: + str ( error )) sys . exit () text1_lines = readline ( textfile1 ) text2_lines = readline ( textfile2 ) d = difflib . HtmlDiff () print d . make_file ( text1_lines , text2_lines )","title":"difflib"},{"location":"python-lib2/#scapy","text":"yum - y install tcpdump graphviz ImageMagick pip install scapy #!/usr/bin/env python #coding:utf-8 import os , sys , time , subprocess import warnings , logging warnings . filterwarnings ( ignore , category = DeprecationWarning ) #scapy logging . getLogger ( scapy.runtime ) . setLevel ( logging . ERROR ) #IPv6 from scapy.all import traceroute domains = raw_input ( Please input one or more IP/domain: ) #IP target = domains . split ( ) dport = [ 80 ] # if len ( target ) = 1 and target [ 0 ] != : res , unans = traceroute ( target , dport = dport , retry =- 2 ) # res . graph ( target = test.svg ) #svg time . sleep ( 1 ) subprocess . Popen ( /usr/bin/convert test.svg test.png , shell = True ) #svgpng else : print IP/domain number of errors, exit  3 - 15 ，“ - ”；“ 11 ”；“ SA ”，  IP 。 3 - 16 （），“ - ” unk * ， ASN   IDC ， IP “ 202.102 . 69.210 ”“ CHINANET - JS - AS - AP ASNumber for CHINANET jiangsu province backbone , CN ” IP 。","title":"scapy"},{"location":"python-lib2/#nmap","text":"yum install nmap - y pip install python - nmap #!/usr/bin/env python #coding:utf-8 import sys import nmap scan_row = [] try : hosts = sys . argv [ 1 ] port = sys . argv [ 2 ] except IndexError : print Uasge ./scanport.py ip port sys . exit ( 1 ) try : nm = nmap . PortScanner () except namp . PortScannerError : print Nmap not found , sys . enc_info ()[ 0 ] sys . exit ( 2 ) except : print ( Unexpected error: , sys . exc_info ()[ 0 ]) sys . exit ( 3 ) try : nm . scan ( hosts = hosts , arguments = -v -sS -p + port ) except Exception , e : print Scan error: + str ( e ) for host in nm . all_hosts (): print ---------------------------------------------------------------------- print ( Host : %s ( %s ) % ( host , nm [ host ] . hostname ())) # print ( State : %s % nm [ host ] . state ()) #,up、down for proto in nm [ host ] . all_protocols (): # print ( ---------- ) print ( Protocol : %s % proto ) # lport = nm [ host ][ proto ] . keys () # lport . sort () # for port in lport : # print ( port : %s \\t state : %s % ( port , nm [ host ][ proto ][ port ][ state ])) ， www . qq . com 、 192.168 . 1. * 、 192.168 . 1.1 - 20 、 192.168 . 1.0 / 24 ， ， 80 , 443 , 22 、 80 , 22 - 443 。","title":"nmap"},{"location":"python-lib2/#_2","text":" fiddler   cookielib  cookie ， cookie ，。 # -*- coding: utf-8 -*- # !/usr/bin/python import urllib2 import urllib import cookielib import re auth_url = http://www.nowamagic.net/ home_url = http://www.nowamagic.net/ ; #  data = { username : nowamagic , password : pass } # urllib post_data = urllib . urlencode ( data ) #  headers = { Host : www.nowamagic.net , Referer : http://www.nowamagic.net } # CookieJarCookie cookieJar = cookielib . CookieJar () # opener opener = urllib2 . build_opener ( urllib2 . HTTPCookieProcessor ( cookieJar )) # cookie req = urllib2 . Request ( auth_url , post_data , headers ) result = opener . open ( req ) #  cookie result = opener . open ( home_url ) #  print result . read () ： 1.  cookie  import cookielib , urllib2 ckjar = cookielib . MozillaCookieJar ( os . path . join ( C:\\Documents and Settings \\t om\\Application Data \\ Mozilla \\ Firefox \\ Profiles \\ h5m61j1i . default , cookies . txt )) req = urllib2 . Request ( url , postdata , header ) req . add_header ( User-Agent , \\ Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1) ) opener = urllib2 . build_opener ( urllib2 . HTTPCookieProcessor ( ckjar ) ) f = opener . open ( req ) htm = f . read () f . close () 2.  cookie ， cookie  cookie  import cookielib , urllib2 req = urllib2 . Request ( url , postdata , header ) req . add_header ( User-Agent , \\ Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1) ) ckjar = cookielib . MozillaCookieJar ( filename ) ckproc = urllib2 . HTTPCookieProcessor ( ckjar ) opener = urllib2 . build_opener ( ckproc ) f = opener . open ( req ) htm = f . read () f . close () ckjar . save ( ignore_discard = True , ignore_expires = True ) 3.  cookie ,  cookie  import cookielib , urllib2 cookiejar = cookielib . CookieJar () urlOpener = urllib2 . build_opener ( urllib2 . HTTPCookieProcessor ( cookiejar )) values = { redirect : , email : abc@abc.com , password : password , rememberme : , submit : OK, Let Me In! } data = urllib . urlencode ( values ) request = urllib2 . Request ( url , data ) url = urlOpener . open ( request ) print url . info () page = url . read () request = urllib2 . Request ( url ) url = urlOpener . open ( request ) page = url . read () print page","title":""},{"location":"python-lib2/#_3","text":"file  open () ， file 。 with open ( test.txt , w ) as f : ... print isinstance ( f , file ) //  ... f . writelines ( map ( str , range ( 10 ))) True File Object ，。， close ，。 open ( test.txt , r ) . read () 0123456789 ， flush () ， sync () ，。 close () 。 ： r : 。 w : 。 ( truncate ) 。 a : 。。 b : 。 r + : ，，。 w + : ，，。 a + : ，，。 ，。 with open ( main.py , r ) as f : ... for line in f : print line ... ，， writelines 。 with open ( test.txt , w ) as f : ... f . write ( a ) ... f . writelines ( bc ) cat test . txt abc ， os . linesep 。 os . linesep \\n ， writelines ( str ) 。 readline () 。 xreadlines ()  readlines () ，。 binary  struct ，。 import struct data = struct . pack ( 2i2s , 0x1234 , 0xFF56 , ab ) open ( test.dat , w ) . write ( data ) ! xxd - g 1 test . dat 0000000 : 34 12 00 00 56 ff 00 00 61 62 4. .. V ... ab struct . unpack ( 2i2s , open ( test.dat ) . read ()) ( 4660 , 65366 , ab ) with open ( test.dat ) as f : //  ... def xread ( fmt ): ... n = struct . calcsize ( fmt ) //  ... s = f . read ( n ) ... return struct . unpack ( fmt , s ) ... print xread ( i ) ... print xread ( i ) ... print xread ( 2s ) ( 4660 ,) ( 65366 ,) ( ab ,) ， array ，。 import array datas = array . array ( i ) datas . append ( 0x1234 ) datas . append ( 0xFF56 ) datas . tofile ( open ( test.dat , w )) ! xxd - g 1 test . dat 0000000 : 34 12 00 00 56 ff 00 00 4. .. V ... d2 = array . array ( i ) d2 . fromfile ( open ( test.dat ), 2 ) d2 array ( i , [ 4660 , 65366 ])  bytearray ， Buffer ， struct 。 encoding  codecs  open () ，。 import sys reload ( sys ) sys . setdefaultencoding ( utf-8 ) with codecs . open ( test.txt , w , gbk ) as f : ... f . write (  ) ! xxd - g 1 test . txt 0000000 : d6 d0 b9 fa ....  . encode ( gbk ) \\xd6\\xd0\\xb9\\xfa s = codecs . open ( test.txt , encoding = gbk ) . read () s u \\u4e2d\\u56fd print s  descriptor ，。 import os fd = os . open ( test.txt , os . O_CREAT | os . O_RDWR , 0644 ) // 。 ls - l test . txt - rw - r -- r -- 1 yuhen staff 6 3 25 10 : 45 test . txt os . write ( fd , abc ) 3 f = os . fdopen ( fd , r+ ) // 。 f . seek ( 0 , os . SEEK_SET ) // 。 f . read () abc f . write ( 123 ) f . flush () // os ， // 。 os . lseek ( fd , 0 , os . SEEK_SET ) 0 os . read ( fd , 100 ) abc123 os . close ( fd ) // 。  fileno () 。 tempfile Python 。 NamedTemporaryFile ，。 TemporaryFile : ，。 NamedTemporaryFile : ，，。 SpooledTemporaryFile :  TemporaryFile ，，。 import tempfile , os.path tmp = tempfile . NamedTemporaryFile () tmp . name /var/folders/r2/4vkjhz6s6lz02hk6nh2qb99c0000gn/T/tmpYYB6p3 os . path . exists ( tmp . name ) True tmp . close () os . path . exists ( tmp . name ) False ，。 with tempfile . NamedTemporaryFile ( prefix = xxx_ , suffix = .tmp , dir = . ) as f : ... print f . name ... / Users / yuhen / test / xxx_SL3apY . tmp ： tempfile . gettempdir : 。 tempfile . gettempprefix : 。 tempfile . mkdtemp : 。 tempfile . mkstemp : ，，。 os . tempnam : ，。 os . tmpfile (): ，。 tempfile . gettempdir () /var/folders/r2/4vkjhz6s6lz02hk6nh2qb99c0000gn/T tempfile . gettempprefix () tmp d = tempfile . mkdtemp (); d /var/folders/r2/4vkjhz6s6lz02hk6nh2qb99c0000gn/T/tmpE_bRWd os . path . exists ( d ) True os . removedirs ( d ) fd , name = tempfile . mkstemp () os . write ( fd , 123 \\n ) 4 os . close ( fd ) os . path . exists ( name ) True os . remove ( name ) os . path ： 。 os . path . normpath ( ./../a/b/../c ) ../a/c ，。 os . path . expanduser ( ~/.vimrc ) /Users/yuhen/.vimrc os . path . expandvars ( $HOME/.vimrc ) /Users/yuhen/.vimrc ， basename 。 os . path . splitext ( os . path . basename ( /usr/local/lib/libevent.a )) ( libevent , .a ) os ：  walk ， (，，) ， fnmatch 。 for path , dirs , files in os . walk ( . ): ... for f in files : ... if fnmatch . fnmatch ( f , *.py ): ... print os . path . join ( path , f ) ./ main . py ./ bak / amqplib_test . py ./ bak / eventlet_test . py ./ bak / extract_text . py ./ bak / fabric_test . py ， glob  listdir ，。 glob . glob ( ./bak/[rs]*.py ) # : iglob [ ./bak/redis_test.py , ./bak/socket_test.py ] ， removedirs 。 shutil . rmtree () ，。 os . makedirs ( ./a/b/c ) open ( ./a/b/c/test.txt , w ) . write ( abc ) os . removedirs ( ./a/b/c ) OSError : [ Errno 66 ] Directory not empty : ./a/b/c import shutil shutil . rmtree ( ./a ) ，。 os . access ( a.txt , os . W_OK ) True ？ stat - x a . txt File : a.txt Size : 0 FileType : Regular File Mode : ( 0644 /- rw - r -- r -- ) Uid : ( 501 / yuhen ) Gid : ( 20 / staff ) Device : 1 , 2 Inode : 5111644 Links : 1 Access : Mon Mar 25 17 : 43 : 01 2013 Modify : Mon Mar 25 17 : 43 : 01 2013 Change : Mon Mar 25 17 : 43 : 01 2013 atime = time . mktime ( datetime . datetime ( 2010 , 10 , 1 ) . utctimetuple ()) mtime = time . mktime ( datetime . datetime ( 2010 , 11 , 2 ) . utctimetuple ()) os . utime ( a.txt , ( atime , mtime )) os . stat ( a.txt ) . st_atime == atime True ，。 oct ( os . stat ( a.txt ) . st_mode ) 0100644 shutil ： copytree ，。 shutil . copytree ( ./bak , ./b/bak , ignore = shutil . ignore_patterns ( *.pyc , *.bak ))","title":""},{"location":"python-lib2/#filecmp","text":"filecmp ，，。 python  difflib  。 difflib ，。 filecmp ，： filecmp . cmp ( f1 , f2 [, shallow ]) ： 。 f1 , f2 。 shallow  （ os . stat ）。， True ， False 。 filecmp . cmpfiles ( dir1 , dir2 , common [, shallow ]) ： 。 dir1 , dir2 ， common 。  3  list ，、。， ，，。 filecmp  dircmp ，，，（ A ），。 dircmp ： report () ：（） report_partial_closure () ： report_full_closure () ： ： 1  1.txt ,  2  1.txt  2.txt ,  1.txt ， import filecmp x = filecmp . dircmp ( 1 , 2 ) x . report () diff 1 2 Only in 2 : [ 2.txt ] Identical files : [ 1.txt ]  1.txt ： import filecmp x = filecmp . dircmp ( 1 , 2 ) x . report () diff 1 2 Only in 2 : [ 2.txt ] Differing files : [ 1.txt ] dircmp ： left_list ：； right_list ：； common ：； left_only ：； right_only ：； common_dirs ：； common_files ：； common_funny ：； same_files ：； diff_files ：； funny_files ：，； subdirs ：， python ： A dictionary mapping names in common_dirs to dircmp objects","title":"filecmp"},{"location":"python-lib2/#csv","text":"# coding=gbk import csv rows = [[ AA , 39.48 , 6/11/2007 , 9:36am , - 0.18 , 181800 ], ( AIG , 71.38 , 6/11/2007 , 9:36am , - 0.15 , 195500 ), ( AXP , 62.58 , 6/11/2007 , , - 0.46 , 935000 ,  ), ] with open ( 121.csv , wb ) as f : f_csv = csv . writer ( f ) f_csv . writerows ( rows )","title":"csv"},{"location":"python-lib2/#xlsxwriter","text":" import xlrd import xlwt from xlutils.copy import copy oldWb = xlrd . open_workbook ( old_file , formatting_info = True )  xls  formatting_info ， newWb = copy ( oldWb ) # sheet = newWb . get_sheet ( 0 ) #sheetname=0 sheet . write ( row , col , data , style ) #row，col，data，style newWb . save ( new_file ) ： . xls 。  excel  #!/usr/bin/env python #coding:utf-8 import xlsxwriter import sys reload ( sys ) sys . setdefaultencoding ( utf-8 ) workbook = xlsxwriter . Workbook ( demo1.xlsx ) #Excel worksheet = workbook . add_worksheet () #Sheet1 worksheet2 = workbook . add_worksheet ( Foglio2 ) # Foglio2 title = [ u  , u  , u  , u  , u  , u  , u  , u  , u  ] buname = [ u  , u  , u  , u  , u  ] ##57 data = [ [ 150 , 152 , 158 , 149 , 155 , 145 , 148 ], [ 89 , 88 , 95 , 93 , 98 , 100 , 99 ], [ 201 , 200 , 198 , 175 , 170 , 198 , 195 ], [ 75 , 77 , 78 , 78 , 74 , 70 , 79 ], [ 88 , 85 , 87 , 90 , 93 , 88 , 84 ],] format = workbook . add_format () #format format . set_border ( 1 ) #format(1) format_title = workbook . add_format () #format_title format_title . set_border ( 1 ) #format_title(1) format_title . set_bg_color ( #cccccc ) #format_title # #cccccc  format_title . set_align ( center ) #format_title format_title . set_bold () #format_title format_ave = workbook . add_format () #format_ave format_ave . set_border ( 1 ) #format_ave(1) format_ave . set_num_format ( 0.00 ) #format_ave #、、,  worksheet . write_row ( A1 , title , format_title ) worksheet . write_column ( A2 , buname , format ) worksheet . write_row ( B2 , data [ 0 ], format ) worksheet . write_row ( B3 , data [ 1 ], format ) worksheet . write_row ( B4 , data [ 2 ], format ) worksheet . write_row ( B5 , data [ 3 ], format ) worksheet . write_row ( B6 , data [ 4 ], format ) # chart = workbook . add_chart ({ type : column }) #column () #area：；bar：；column： line： pie：； #scatter： stock： radar： # def chart_series ( cur_row ): worksheet . write_formula ( I + cur_row , =AVERAGE(B + cur_row + :H + cur_row + ) , format_ave ) #(AVERAGE) chart . add_series ({ categories : =Sheet1!$B$1:$H$1 , #“”(X) values : =Sheet1!$B$ + cur_row + :$H$ + cur_row , # line : { color : black }, #black() name : =Sheet1!$A$ + cur_row , # }) for row in range ( 2 , 7 ): #2～6 chart_series ( str ( row )) #chart.set_table() #X,  #chart.set_style(30) #,  chart . set_size ({ width : 577 , height : 287 }) # chart . set_title ({ name : u  }) #() chart . set_y_axis ({ name : Mb/s }) #y() worksheet . insert_chart ( A8 , chart ) #A8 workbook . close ()","title":"xlsxwriter"},{"location":"python-lib2/#_4","text":"random 。 seed ，。 seed ，，。 from random import * a = Random (); a . seed ( 1 ) [ a . randint ( 1 , 100 ) for i in range ( 20 )] [ 14 , 85 , 77 , 26 , 50 , 45 , 66 , 79 , 10 , 3 , 84 , 44 , 77 , 1 , 45 , 73 , 23 , 95 , 91 , 4 ] b = Random (); b . seed ( 1 ) [ b . randint ( 1 , 100 ) for i in range ( 20 )] [ 14 , 85 , 77 , 26 , 50 , 45 , 66 , 79 , 10 , 3 , 84 , 44 , 77 , 1 , 45 , 73 , 23 , 95 , 91 , 4 ]   N 。 getrandbits ( 5 ) 29L bin ( getrandbits ( 5 )) 0b11101  start = N stop 。 randrange ( 1 , 10 ) 2 randrange ( 1 , 10 , 3 ) #  4 randrange ( 1 , 10 , 3 ) 1 randrange ( 1 , 10 , 3 ) 7  a = N = b 。 randint ( 1 , 10 ) 5 。 import string string . digits 0123456789 choice ( string . digits ) 6 choice ( string . digits ) 1 choice ( string . digits ) 3 ，。 a = range ( 10 ) shuffle ( a ) a [ 6 , 4 , 8 , 7 , 5 , 3 , 0 , 9 , 2 , 1 ]  n 。 string . letters abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ sample ( string . letters , 10 ) [ I , F , W , O , r , o , A , K , i , h ] . join ( sample ( string . letters , 10 )) #  kMmSgPVWIi . join ( sample ( string . letters , 10 )) feCTyRZrHv  0.0 = N 1 。 random () 0.39559451765020448 random () 0.62378508101496177  min = N = max 。 uniform ( 1 , 10 ) 7.6889886379206587 uniform ( 10 , 1 ) 5.1617099528426609 、β、、、。","title":""},{"location":"python-other/","text":"web # coding=utf-8 import urllib import urllib2 import cookielib import threading import time from Queue import Queue from time import sleep THREAD_NUM = 100 #  ONE_WORKER_NUM = 10000 #  LOOP_SLEEP = 0.5 # () #  ERROR_NUM = 0 requrl = http://cs.dachuizichan.com/login.do test_data = { loginid : 17326800227 , password : 111111 , rand : 1111 } test_data_urlencode = urllib . urlencode ( test_data ) header = { Host : cs.dachuizichan.com , Referer : http://cs.dachuizichan.com/manage/frame.do , User-Agent : Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome / 54.0 . 2840.71 Safari / 537.36 , Content-Type : application/x-www-form-urlencoded } cookieJar = cookielib . CookieJar () opener = urllib2 . build_opener ( urllib2 . HTTPCookieProcessor ( cookieJar )) req = urllib2 . Request ( requrl , test_data_urlencode , header ) result = opener . open ( req ) # for key in header: # req.add_header(key, header[key]) def doWork ( index ): t = threading . currentThread () try : result2 = opener . open ( http://cs.dachuizichan.com/manage/myDebtor/list.do ) print result2 . read () except urllib2 . URLError , e : print [ + t . name + + str ( index ) + ] print e global ERROR_NUM ERROR_NUM += 1 def working (): t = threading . currentThread () print [ + t . name + ] Sub Thread Begin i = 0 while i ONE_WORKER_NUM : i += 1 doWork ( i ) sleep ( LOOP_SLEEP ) print [ + t . name + ] Sub Thread End def main (): #doWork(0) #return t1 = time . time () Threads = [] #  for i in range ( THREAD_NUM ): t = threading . Thread ( target = working , name = T + str ( i )) t . setDaemon ( True ) Threads . append ( t ) for t in Threads : t . start () for t in Threads : t . join () print main thread end t2 = time . time () print ======================================== #print URL: , PERF_TEST_URL print : , THREAD_NUM , * , ONE_WORKER_NUM , = , THREAD_NUM * ONE_WORKER_NUM print (): , t2 - t1 print (): , ( t2 - t1 ) / ( THREAD_NUM * ONE_WORKER_NUM ) print : , 1 / (( t2 - t1 ) / ( THREAD_NUM * ONE_WORKER_NUM )) print : , ERROR_NUM if __name__ == __main__ : main () python  print \\n . join ( [ . join ( [ ( PYTHON! [ ( x - y ) % 7 ] if (( x * 0 . 05 ) ** 2 + ( y * 0 . 1 ) ** 2 - 1 ) ** 3 - ( x * 0 . 05 ) ** 2 * ( y * 0 . 1 ) ** 3 = 0 else ) for x in range ( - 30 , 30 ) ] ) for y in range ( 15 , - 15 , - 1 ) ] ) 99  print \\n . join ( [ . join ( [ %s*%s=%-2s % ( y , x , x * y ) for y in range ( 1 , x + 1 ) ] ) for x in range ( 1 , 10 ) ] )  print [ x [ 0 ] for x in [ ( a [ i ][ 0 ], a . append (( a [ i ][ 1 ], a [ i ][ 0 ] + a [ i ][ 1 ] ))) for a in ( [[ 1 , 1 ]], ) for i in xrange ( 100 ) ]] 8  _ = [ __import__ ( sys ) . stdout . write ( \\n . join ( . * i + Q + . * ( 8 - i - 1 ) for i in vec ) + \\n === \\n ) for vec in __import__ ( itertools ) . permutations ( xrange ( 8 )) if 8 == len ( set ( vec [ i ] + i for i in xrange ( 8 ))) == len ( set ( vec [ i ] - i for i in xrange ( 8 ))) ]  _ = _=%r;print _%%_ ;print _%_ print ( lambda x : x + str (( x , )))( print(lambda x:x+str((x,))) , )  # coding:utf-8 def fib ( n ):  from math import sqrt , pow return int ( 1 / sqrt ( 5 ) * ( pow (( 1 + sqrt ( 5 )) / 2 , n ) - pow (( 1 - sqrt ( 5 )) / 2 , n ))) def fib2 ( n ): ， if n == 0 : return 0 elif n == 1 : return 1 firstnum = 0 secondnum = 1 fibnum = 0 cnt = 1 while cnt n : fibnum = firstnum + secondnum firstnum , secondnum = secondnum , fibnum cnt += 1 return fibnum def fib3 ( n ): ， begin = [ 1 , 1 ] for count in xrange ( 1 , n - 2 ): begin . append ( begin [ - 1 ] + begin [ - 2 ]) return begin def fib4 ( n ):  if n = 1 : return n else : return fib4 ( n - 1 ) + fib4 ( n - 2 ) # fib1 fib2 fib4 for i in range ( 1 , 10 ): print fib4 ( i ) # fib3 print fib3 ( 10 )   Python ， ( container ) 、 ( iterable ) 、 ( iterator ) 、 ( generator ) 、  /  /  ( list , set , dict comprehension ) ，， 。 relations  ( container ) ，， in , not in 。 （） Python ，： list , deque , .... set , frozensets , .... dict , defaultdict , OrderedDict , Counter , .... tuple , namedtuple , … str ，、、，。， ，， list ， set ， tuples ： assert 1 in [ 1 , 2 , 3 ] # lists assert 4 not in [ 1 , 2 , 3 ] assert 1 in { 1 , 2 , 3 } # sets assert 4 not in { 1 , 2 , 3 } assert 1 in ( 1 , 2 , 3 ) # tuples assert 4 not in ( 1 , 2 , 3 )  dict  dict  key ： d = { 1 : foo , 2 : bar , 3 : qux } assert 1 in d assert foo not in d # foo  dict  ，，， ，： Bloom filter ， Bloom filter ， ， Bloom filter ，。  ( iterable ) ，，， files ， sockets 。 ，，，： x = [ 1 , 2 , 3 ] y = iter ( x ) z = iter ( x ) next ( y ) 1 next ( y ) 2 next ( z ) 1 type ( x ) class list type ( y ) class list_iterator  x ，，， list ， dict ， set 。 y  z ，，， 。， list_iterator ， set_iterator 。 __iter__  __next__  （ python2  next ， python3  __next__ ）， iter ()  next () 。 __iter__ ， 。 ： x = [ 1 , 2 , 3 ] for elem in x : ... ： iterable - vs - iterator . png ， GET_ITER ， iter ( x ) ， FOR_ITER  next () ， ，，。 import dis x = [ 1 , 2 , 3 ] dis . dis ( for _ in x: pass ) 1 0 SETUP_LOOP 14 ( to 17 ) 3 LOAD_NAME 0 ( x ) 6 GET_ITER 7 FOR_ITER 6 ( to 16 ) 10 STORE_NAME 1 ( _ ) 13 JUMP_ABSOLUTE 7 16 POP_BLOCK 17 LOAD_CONST 0 ( None ) 20 RETURN_VALUE  ( iterator ) ？， next () ， __next__ () （ python2  next () ），。 ，，。， itertools 。 ： from itertools import count counter = count ( start = 13 ) print next ( counter ) # 13 print next ( counter ) # 14 from itertools import cycle colors = cycle ( [ red , white , blue ] ) next ( colors ) # red next ( colors ) # white next ( colors ) # blue next ( colors ) # red from itertools import islice limited = islice ( colors , 0 , 4 ) print list ( limited ) # [ white , blue , red , white ] ，，： class Fib : def __init__ ( self ) : self . prev = 0 self . curr = 1 def __iter__ ( self ) : return self def next ( self ) : value = self . curr self . curr += self . prev self . prev = value return value f = Fib () print list ( islice ( f , 0 , 10 )) Fib （ __iter__ ），（ next ）。 prev  curr  。 next () ：  next ()   ，，。  ( generator )  Python ，，。  __iter__ ()  __next__ () ， yiled 。 （）， 。： def fib ( n ) : prev , curr = 0 , 1 while prev n : yield curr prev , curr = curr , curr + prev print [ x for x in fib ( 10 ) ] [ 1 , 1 , 2 , 3 , 5 , 8 , 13 , 21 , 34 , 55 ] fib  python ， return ，。 f = fib ()  ，， next 。  Python ，，， CPU ， 。，： def something () : result = [] for ... in ...: result . append ( x ) return result ： def iter_something () : for ... in ...: yield x  ( generator expression ) ，，。 a = ( x * x for x in xrange ( 10 )) print type ( a ) # type generator print sum ( a ) # 285  commands import commands commands . getstatusoutput ( cmd )  ( status , output ) commands . getoutput ( cmd )  os import os os . system ( echo \\ Hello World \\ ) or print os . popen ( ls -lt ) . read ()  shell  import os var = 123  var = 123 os . environ [ var ] = str ( var ) #environ os . system ( echo $var ) import os var = 123 os . popen ( wc -c , w ) . write ( var ) fabric pip install fabric fab - f fabfile - l  fab - f fabfile func   --------------------------------------- #!/usr/bin/env python #coding:utf-8 from fabric.api import * from fabric.context_managers import * from fabric.contrib.console import confirm env . user = root env . hosts = [ 192.168.1.21 , 192.168.1.22 ] env . password = LKs934jh3 @task @runs_once def tar_task (): #， with lcd ( /data/logs ): local ( tar -czf access.tar.gz access.log ) @task def put_task (): # run ( mkdir -p /data/logs ) with cd ( /data/logs ): with settings ( warn_only = True ): #put（）， result = put ( /data/logs/access.tar.gz , /data/logs/access.tar.gz ) if result . failed and not confirm ( put file failed, Continue[Y/N]? ): abort ( Aborting file put task! ) #，，（Y） @task def check_task (): # with settings ( warn_only = True ): #localcapture=True lmd5 = local ( md5sum /data/logs/access.tar.gz , capture = True ) . split ( )[ 0 ] rmd5 = run ( md5sum /data/logs/access.tar.gz ) . split ( )[ 0 ] if lmd5 == rmd5 : #md5 print OK else : print ERROR @task def go (): tar_task () put_task () check_task () LNMP  -------------------------------------------------- #!/usr/bin/env python #coding:utf-8 from fabric.colors import * from fabric.api import * env . user = root env . roledefs = { # webservers : [ 192.168.1.21 , 192.168.1.22 ], dbservers : [ 192.168.1.23 ] } env . passwords = { root@192.168.1.21:22 : SJk348ygd , root@192.168.1.22:22 : KSh458j4f , root@192.168.1.23:22 : KSdu43598 } @roles ( webservers ) #webtask webservers  def webtask (): #nginx php php-fpm print yellow ( Install nginx php php-fpm... ) with settings ( warn_only = True ): run ( yum -y install nginx ) run ( yum -y install php-fpm php-mysql php-mbstring php-xml php-mcrypt php-gd ) run ( chkconfig --levels 235 php-fpm on ) run ( chkconfig --levels 235 nginx on ) @roles ( dbservers ) # dbtask dbservers  def dbtask (): #mysql print yellow ( Install Mysql... ) with settings ( warn_only = True ): run ( yum -y install mysql mysql-server ) run ( chkconfig --levels 235 mysqld on ) @roles ( webservers , dbservers ) # publictask def publictask (): #，epel、ntp print yellow ( Install epel ntp... ) with settings ( warn_only = True ): run ( rpm -Uvh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm ) run ( yum -y install ntp ) def deploy (): # execute ( publictask ) execute ( webtask ) execute ( dbtask )  -------------------------------------------------- #!/usr/bin/env python #coding:utf-8 from fabric.api import * from fabric.colors import * from fabric.context_managers import * from fabric.contrib.console import confirm import time env . user = root env . hosts = [ 192.168.1.21 , 192.168.1.22 ] env . password = LKs934jh3 env . project_dev_source = /data/dev/Lwebadmin/ # env . project_tar_source = /data/dev/releases/ # env . project_pack_name = release #，release.tar.gz env . deploy_project_root = /data/www/Lwebadmin/ # env . deploy_release_dir = releases #， env . deploy_current_dir = current # env . deploy_version = time . strftime ( %Y%m %d ) + v2 # @runs_once def input_versionid (): #， return prompt ( please input project rollback version ID: , default = ) @task @runs_once def tar_source (): #， print yellow ( Creating source package... ) with lcd ( env . project_dev_source ): local ( tar -czf %s .tar.gz . % ( env . project_tar_source + env . project_pack_name )) print green ( Creating source package success! ) @task def put_package (): # print yellow ( Start put package... ) with settings ( warn_only = True ): with cd ( env . deploy_project_root + env . deploy_release_dir ): run ( mkdir %s % ( env . deploy_version )) # env . deploy_full_path = env . deploy_project_root + env . deploy_release_dir + / + env . deploy_version with settings ( warn_only = True ): # result = put ( env . project_tar_source + env . project_pack_name + .tar.gz , env . deploy_full_path ) if result . failed and no ( put file failed, Continue[Y/N]? ): abort ( Aborting file put task! ) with cd ( env . deploy_full_path ): # run ( tar -zxvf %s .tar.gz % ( env . project_pack_name )) run ( rm -rf %s .tar.gz % ( env . project_pack_name )) print green ( Put untar package success! ) @task def make_symlink (): # print yellow ( update current symlink ) env . deploy_full_path = env . deploy_project_root + env . deploy_release_dir + / + env . deploy_version with settings ( warn_only = True ): #，， run ( rm -rf %s % ( env . deploy_project_root + env . deploy_current_dir )) run ( ln -s %s %s % ( env . deploy_full_path , env . deploy_project_root + env . deploy_current_dir )) #，， print green ( rollback success! ) @task def go (): # tar_source () put_package () make_symlink ()   closures  import time def hl ( func ): def wrap (): begin = int ( time . time ()) print begin func () end = int ( time . time ()) print end print cost: , end - begin return end - begin return wrap def t (): time . sleep ( 1 ) hl ( t )()  、 import time def hl ( func ): def wrap (): begin = int ( time . time ()) print begin func () end = int ( time . time ()) print end print cost: , end - begin return end - begin return wrap @hl def t (): time . sleep ( 1 ) t () ############################## def mb ( func ): def wrap (): return b + func () + /b return wrap def mi ( func ): def wrap (): return i + func () + /i return wrap @mb @mi def hello (): return ( hello ) print ( hello ()) pip.conf #$ HOME / . pip / pip . conf [ global ] index - url = http : // pypi . douban . com / simple [ install ] trusted - host = pypi . douban . com  [ global ] index - url = http : // mirrors . aliyun . com / pypi / simple / [ install ] trusted - host = mirrors . aliyun . com windowsHOME ，  % HOME %/ pip / pip . ini  pip install Jinja2 - i http : // pypi . douban . com / simple   x = 6 y = 5 x , y = y , x print x # : 5 print y # : 6 if   C / Java  a = Hello if True else World b = Hello if False else World print a # : Hello print b # : World  # 、  nfc = [ Packers , 49ers ] afc = [ Ravens , Patriots ] print nfc + afc # : [ Packers , 49ers , Ravens , Patriots ] #   print str ( 1 ) + world # : 1 world # ， , ， print ` 1 ` + world # : 1 world # python2 . x  print  print 1 , world # : 1 world print nfc , 1 # : [ Packers , 49ers ] 1 # python3 . x  print  (  2. x  ) print ( 1 , world , end= ) # : 1 world print ( nfc , 1 , end= ) # : [ Packers , 49ers ] 1  ( :、、 )    (  ) teams = [ Packers , 49ers , Ravens , Patriots ] for index , team in enumerate ( teams ) : print index , team # : 0 Packers   items = [ 0 ] * 3 print ( items )   teams = [ Packers , 49ers , Ravens , Patriots ] print ( , . join ( teams ))   teams = [ Packers , 49ers , Ravens , Patriots ] print ( teams [ - 2 ]) #  (  ) print ( teams [ : ]) #  print ( teams [ ::- 1 ]) #  print ( teams [ :: 2 ]) #  print ( teams [ 1 :: 2 ]) #    x = 2 if 3 x 1 : print x # : 2 if 1 x 0 : print x # : 2  nfc = [ Packers , 49ers ] afc = [ Ravens , Patriots ] for teama , teamb in zip ( nfc , afc ) : print teama + vs. + teamb # 1: Packers vs . Ravens # 2: 49 ers vs . Patriots 60 FizzBuzz Jeff Atwood FizzBuzz，： ，1100，3“ Fizz ”，5“ Buzz ”，35“ FizzBuzz ”。 ，： for x in range ( 101 ) :print fizz [ x %3*4::]+ buzz [x%5*4::]or x False == True ，python , True  False  (  ) ，： False = True if False : print Hello else : print World # : Hello  import math def convertBytes ( bytes , lst = None ): if lst is None : lst = [ Bytes , KB , MB , GB , TB , PB ] i = int ( math . floor ( # ， math . log ( bytes , 1024 ) # (： a**b = N  b  a  N ) )) if i = len ( lst ): i = len ( lst ) - 1 return ( %.2f + + lst [ i ]) % ( bytes / math . pow ( 1024 , i ))","title":"python-other"},{"location":"python-other/#web","text":"# coding=utf-8 import urllib import urllib2 import cookielib import threading import time from Queue import Queue from time import sleep THREAD_NUM = 100 #  ONE_WORKER_NUM = 10000 #  LOOP_SLEEP = 0.5 # () #  ERROR_NUM = 0 requrl = http://cs.dachuizichan.com/login.do test_data = { loginid : 17326800227 , password : 111111 , rand : 1111 } test_data_urlencode = urllib . urlencode ( test_data ) header = { Host : cs.dachuizichan.com , Referer : http://cs.dachuizichan.com/manage/frame.do , User-Agent : Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome / 54.0 . 2840.71 Safari / 537.36 , Content-Type : application/x-www-form-urlencoded } cookieJar = cookielib . CookieJar () opener = urllib2 . build_opener ( urllib2 . HTTPCookieProcessor ( cookieJar )) req = urllib2 . Request ( requrl , test_data_urlencode , header ) result = opener . open ( req ) # for key in header: # req.add_header(key, header[key]) def doWork ( index ): t = threading . currentThread () try : result2 = opener . open ( http://cs.dachuizichan.com/manage/myDebtor/list.do ) print result2 . read () except urllib2 . URLError , e : print [ + t . name + + str ( index ) + ] print e global ERROR_NUM ERROR_NUM += 1 def working (): t = threading . currentThread () print [ + t . name + ] Sub Thread Begin i = 0 while i ONE_WORKER_NUM : i += 1 doWork ( i ) sleep ( LOOP_SLEEP ) print [ + t . name + ] Sub Thread End def main (): #doWork(0) #return t1 = time . time () Threads = [] #  for i in range ( THREAD_NUM ): t = threading . Thread ( target = working , name = T + str ( i )) t . setDaemon ( True ) Threads . append ( t ) for t in Threads : t . start () for t in Threads : t . join () print main thread end t2 = time . time () print ======================================== #print URL: , PERF_TEST_URL print : , THREAD_NUM , * , ONE_WORKER_NUM , = , THREAD_NUM * ONE_WORKER_NUM print (): , t2 - t1 print (): , ( t2 - t1 ) / ( THREAD_NUM * ONE_WORKER_NUM ) print : , 1 / (( t2 - t1 ) / ( THREAD_NUM * ONE_WORKER_NUM )) print : , ERROR_NUM if __name__ == __main__ : main ()","title":"web"},{"location":"python-other/#python","text":" print \\n . join ( [ . join ( [ ( PYTHON! [ ( x - y ) % 7 ] if (( x * 0 . 05 ) ** 2 + ( y * 0 . 1 ) ** 2 - 1 ) ** 3 - ( x * 0 . 05 ) ** 2 * ( y * 0 . 1 ) ** 3 = 0 else ) for x in range ( - 30 , 30 ) ] ) for y in range ( 15 , - 15 , - 1 ) ] ) 99  print \\n . join ( [ . join ( [ %s*%s=%-2s % ( y , x , x * y ) for y in range ( 1 , x + 1 ) ] ) for x in range ( 1 , 10 ) ] )  print [ x [ 0 ] for x in [ ( a [ i ][ 0 ], a . append (( a [ i ][ 1 ], a [ i ][ 0 ] + a [ i ][ 1 ] ))) for a in ( [[ 1 , 1 ]], ) for i in xrange ( 100 ) ]] 8  _ = [ __import__ ( sys ) . stdout . write ( \\n . join ( . * i + Q + . * ( 8 - i - 1 ) for i in vec ) + \\n === \\n ) for vec in __import__ ( itertools ) . permutations ( xrange ( 8 )) if 8 == len ( set ( vec [ i ] + i for i in xrange ( 8 ))) == len ( set ( vec [ i ] - i for i in xrange ( 8 ))) ]  _ = _=%r;print _%%_ ;print _%_ print ( lambda x : x + str (( x , )))( print(lambda x:x+str((x,))) , )","title":"python"},{"location":"python-other/#_1","text":"# coding:utf-8 def fib ( n ):  from math import sqrt , pow return int ( 1 / sqrt ( 5 ) * ( pow (( 1 + sqrt ( 5 )) / 2 , n ) - pow (( 1 - sqrt ( 5 )) / 2 , n ))) def fib2 ( n ): ， if n == 0 : return 0 elif n == 1 : return 1 firstnum = 0 secondnum = 1 fibnum = 0 cnt = 1 while cnt n : fibnum = firstnum + secondnum firstnum , secondnum = secondnum , fibnum cnt += 1 return fibnum def fib3 ( n ): ， begin = [ 1 , 1 ] for count in xrange ( 1 , n - 2 ): begin . append ( begin [ - 1 ] + begin [ - 2 ]) return begin def fib4 ( n ):  if n = 1 : return n else : return fib4 ( n - 1 ) + fib4 ( n - 2 ) # fib1 fib2 fib4 for i in range ( 1 , 10 ): print fib4 ( i ) # fib3 print fib3 ( 10 )","title":""},{"location":"python-other/#_2","text":" Python ， ( container ) 、 ( iterable ) 、 ( iterator ) 、 ( generator ) 、  /  /  ( list , set , dict comprehension ) ，， 。 relations  ( container ) ，， in , not in 。 （） Python ，： list , deque , .... set , frozensets , .... dict , defaultdict , OrderedDict , Counter , .... tuple , namedtuple , … str ，、、，。， ，， list ， set ， tuples ： assert 1 in [ 1 , 2 , 3 ] # lists assert 4 not in [ 1 , 2 , 3 ] assert 1 in { 1 , 2 , 3 } # sets assert 4 not in { 1 , 2 , 3 } assert 1 in ( 1 , 2 , 3 ) # tuples assert 4 not in ( 1 , 2 , 3 )  dict  dict  key ： d = { 1 : foo , 2 : bar , 3 : qux } assert 1 in d assert foo not in d # foo  dict  ，，， ，： Bloom filter ， Bloom filter ， ， Bloom filter ，。  ( iterable ) ，，， files ， sockets 。 ，，，： x = [ 1 , 2 , 3 ] y = iter ( x ) z = iter ( x ) next ( y ) 1 next ( y ) 2 next ( z ) 1 type ( x ) class list type ( y ) class list_iterator  x ，，， list ， dict ， set 。 y  z ，，， 。， list_iterator ， set_iterator 。 __iter__  __next__  （ python2  next ， python3  __next__ ）， iter ()  next () 。 __iter__ ， 。 ： x = [ 1 , 2 , 3 ] for elem in x : ... ： iterable - vs - iterator . png ， GET_ITER ， iter ( x ) ， FOR_ITER  next () ， ，，。 import dis x = [ 1 , 2 , 3 ] dis . dis ( for _ in x: pass ) 1 0 SETUP_LOOP 14 ( to 17 ) 3 LOAD_NAME 0 ( x ) 6 GET_ITER 7 FOR_ITER 6 ( to 16 ) 10 STORE_NAME 1 ( _ ) 13 JUMP_ABSOLUTE 7 16 POP_BLOCK 17 LOAD_CONST 0 ( None ) 20 RETURN_VALUE  ( iterator ) ？， next () ， __next__ () （ python2  next () ），。 ，，。， itertools 。 ： from itertools import count counter = count ( start = 13 ) print next ( counter ) # 13 print next ( counter ) # 14 from itertools import cycle colors = cycle ( [ red , white , blue ] ) next ( colors ) # red next ( colors ) # white next ( colors ) # blue next ( colors ) # red from itertools import islice limited = islice ( colors , 0 , 4 ) print list ( limited ) # [ white , blue , red , white ] ，，： class Fib : def __init__ ( self ) : self . prev = 0 self . curr = 1 def __iter__ ( self ) : return self def next ( self ) : value = self . curr self . curr += self . prev self . prev = value return value f = Fib () print list ( islice ( f , 0 , 10 )) Fib （ __iter__ ），（ next ）。 prev  curr  。 next () ：  next ()   ，，。  ( generator )  Python ，，。  __iter__ ()  __next__ () ， yiled 。 （）， 。： def fib ( n ) : prev , curr = 0 , 1 while prev n : yield curr prev , curr = curr , curr + prev print [ x for x in fib ( 10 ) ] [ 1 , 1 , 2 , 3 , 5 , 8 , 13 , 21 , 34 , 55 ] fib  python ， return ，。 f = fib ()  ，， next 。  Python ，，， CPU ， 。，： def something () : result = [] for ... in ...: result . append ( x ) return result ： def iter_something () : for ... in ...: yield x  ( generator expression ) ，，。 a = ( x * x for x in xrange ( 10 )) print type ( a ) # type generator print sum ( a ) # 285","title":""},{"location":"python-other/#_3","text":"commands import commands commands . getstatusoutput ( cmd )  ( status , output ) commands . getoutput ( cmd )  os import os os . system ( echo \\ Hello World \\ ) or print os . popen ( ls -lt ) . read ()  shell  import os var = 123  var = 123 os . environ [ var ] = str ( var ) #environ os . system ( echo $var ) import os var = 123 os . popen ( wc -c , w ) . write ( var )","title":""},{"location":"python-other/#fabric","text":"pip install fabric fab - f fabfile - l  fab - f fabfile func   --------------------------------------- #!/usr/bin/env python #coding:utf-8 from fabric.api import * from fabric.context_managers import * from fabric.contrib.console import confirm env . user = root env . hosts = [ 192.168.1.21 , 192.168.1.22 ] env . password = LKs934jh3 @task @runs_once def tar_task (): #， with lcd ( /data/logs ): local ( tar -czf access.tar.gz access.log ) @task def put_task (): # run ( mkdir -p /data/logs ) with cd ( /data/logs ): with settings ( warn_only = True ): #put（）， result = put ( /data/logs/access.tar.gz , /data/logs/access.tar.gz ) if result . failed and not confirm ( put file failed, Continue[Y/N]? ): abort ( Aborting file put task! ) #，，（Y） @task def check_task (): # with settings ( warn_only = True ): #localcapture=True lmd5 = local ( md5sum /data/logs/access.tar.gz , capture = True ) . split ( )[ 0 ] rmd5 = run ( md5sum /data/logs/access.tar.gz ) . split ( )[ 0 ] if lmd5 == rmd5 : #md5 print OK else : print ERROR @task def go (): tar_task () put_task () check_task () LNMP  -------------------------------------------------- #!/usr/bin/env python #coding:utf-8 from fabric.colors import * from fabric.api import * env . user = root env . roledefs = { # webservers : [ 192.168.1.21 , 192.168.1.22 ], dbservers : [ 192.168.1.23 ] } env . passwords = { root@192.168.1.21:22 : SJk348ygd , root@192.168.1.22:22 : KSh458j4f , root@192.168.1.23:22 : KSdu43598 } @roles ( webservers ) #webtask webservers  def webtask (): #nginx php php-fpm print yellow ( Install nginx php php-fpm... ) with settings ( warn_only = True ): run ( yum -y install nginx ) run ( yum -y install php-fpm php-mysql php-mbstring php-xml php-mcrypt php-gd ) run ( chkconfig --levels 235 php-fpm on ) run ( chkconfig --levels 235 nginx on ) @roles ( dbservers ) # dbtask dbservers  def dbtask (): #mysql print yellow ( Install Mysql... ) with settings ( warn_only = True ): run ( yum -y install mysql mysql-server ) run ( chkconfig --levels 235 mysqld on ) @roles ( webservers , dbservers ) # publictask def publictask (): #，epel、ntp print yellow ( Install epel ntp... ) with settings ( warn_only = True ): run ( rpm -Uvh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm ) run ( yum -y install ntp ) def deploy (): # execute ( publictask ) execute ( webtask ) execute ( dbtask )  -------------------------------------------------- #!/usr/bin/env python #coding:utf-8 from fabric.api import * from fabric.colors import * from fabric.context_managers import * from fabric.contrib.console import confirm import time env . user = root env . hosts = [ 192.168.1.21 , 192.168.1.22 ] env . password = LKs934jh3 env . project_dev_source = /data/dev/Lwebadmin/ # env . project_tar_source = /data/dev/releases/ # env . project_pack_name = release #，release.tar.gz env . deploy_project_root = /data/www/Lwebadmin/ # env . deploy_release_dir = releases #， env . deploy_current_dir = current # env . deploy_version = time . strftime ( %Y%m %d ) + v2 # @runs_once def input_versionid (): #， return prompt ( please input project rollback version ID: , default = ) @task @runs_once def tar_source (): #， print yellow ( Creating source package... ) with lcd ( env . project_dev_source ): local ( tar -czf %s .tar.gz . % ( env . project_tar_source + env . project_pack_name )) print green ( Creating source package success! ) @task def put_package (): # print yellow ( Start put package... ) with settings ( warn_only = True ): with cd ( env . deploy_project_root + env . deploy_release_dir ): run ( mkdir %s % ( env . deploy_version )) # env . deploy_full_path = env . deploy_project_root + env . deploy_release_dir + / + env . deploy_version with settings ( warn_only = True ): # result = put ( env . project_tar_source + env . project_pack_name + .tar.gz , env . deploy_full_path ) if result . failed and no ( put file failed, Continue[Y/N]? ): abort ( Aborting file put task! ) with cd ( env . deploy_full_path ): # run ( tar -zxvf %s .tar.gz % ( env . project_pack_name )) run ( rm -rf %s .tar.gz % ( env . project_pack_name )) print green ( Put untar package success! ) @task def make_symlink (): # print yellow ( update current symlink ) env . deploy_full_path = env . deploy_project_root + env . deploy_release_dir + / + env . deploy_version with settings ( warn_only = True ): #，， run ( rm -rf %s % ( env . deploy_project_root + env . deploy_current_dir )) run ( ln -s %s %s % ( env . deploy_full_path , env . deploy_project_root + env . deploy_current_dir )) #，， print green ( rollback success! ) @task def go (): # tar_source () put_package () make_symlink ()","title":"fabric"},{"location":"python-other/#_4","text":" closures  import time def hl ( func ): def wrap (): begin = int ( time . time ()) print begin func () end = int ( time . time ()) print end print cost: , end - begin return end - begin return wrap def t (): time . sleep ( 1 ) hl ( t )()  、 import time def hl ( func ): def wrap (): begin = int ( time . time ()) print begin func () end = int ( time . time ()) print end print cost: , end - begin return end - begin return wrap @hl def t (): time . sleep ( 1 ) t () ############################## def mb ( func ): def wrap (): return b + func () + /b return wrap def mi ( func ): def wrap (): return i + func () + /i return wrap @mb @mi def hello (): return ( hello ) print ( hello ())","title":""},{"location":"python-other/#pipconf","text":"#$ HOME / . pip / pip . conf [ global ] index - url = http : // pypi . douban . com / simple [ install ] trusted - host = pypi . douban . com  [ global ] index - url = http : // mirrors . aliyun . com / pypi / simple / [ install ] trusted - host = mirrors . aliyun . com windowsHOME ，  % HOME %/ pip / pip . ini  pip install Jinja2 - i http : // pypi . douban . com / simple","title":"pip.conf"},{"location":"python-other/#_5","text":" x = 6 y = 5 x , y = y , x print x # : 5 print y # : 6 if   C / Java  a = Hello if True else World b = Hello if False else World print a # : Hello print b # : World  # 、  nfc = [ Packers , 49ers ] afc = [ Ravens , Patriots ] print nfc + afc # : [ Packers , 49ers , Ravens , Patriots ] #   print str ( 1 ) + world # : 1 world # ， , ， print ` 1 ` + world # : 1 world # python2 . x  print  print 1 , world # : 1 world print nfc , 1 # : [ Packers , 49ers ] 1 # python3 . x  print  (  2. x  ) print ( 1 , world , end= ) # : 1 world print ( nfc , 1 , end= ) # : [ Packers , 49ers ] 1  ( :、、 )    (  ) teams = [ Packers , 49ers , Ravens , Patriots ] for index , team in enumerate ( teams ) : print index , team # : 0 Packers   items = [ 0 ] * 3 print ( items )   teams = [ Packers , 49ers , Ravens , Patriots ] print ( , . join ( teams ))   teams = [ Packers , 49ers , Ravens , Patriots ] print ( teams [ - 2 ]) #  (  ) print ( teams [ : ]) #  print ( teams [ ::- 1 ]) #  print ( teams [ :: 2 ]) #  print ( teams [ 1 :: 2 ]) #    x = 2 if 3 x 1 : print x # : 2 if 1 x 0 : print x # : 2  nfc = [ Packers , 49ers ] afc = [ Ravens , Patriots ] for teama , teamb in zip ( nfc , afc ) : print teama + vs. + teamb # 1: Packers vs . Ravens # 2: 49 ers vs . Patriots 60 FizzBuzz Jeff Atwood FizzBuzz，： ，1100，3“ Fizz ”，5“ Buzz ”，35“ FizzBuzz ”。 ，： for x in range ( 101 ) :print fizz [ x %3*4::]+ buzz [x%5*4::]or x False == True ，python , True  False  (  ) ，： False = True if False : print Hello else : print World # : Hello","title":""},{"location":"python-other/#_6","text":"import math def convertBytes ( bytes , lst = None ): if lst is None : lst = [ Bytes , KB , MB , GB , TB , PB ] i = int ( math . floor ( # ， math . log ( bytes , 1024 ) # (： a**b = N  b  a  N ) )) if i = len ( lst ): i = len ( lst ) - 1 return ( %.2f + + lst [ i ]) % ( bytes / math . pow ( 1024 , i ))","title":""},{"location":"python-web/","text":"django models from django.db.models import Count from django.db import connection select = { day : connection . ops . date_trunc_sql ( day , date_time )} #  countday = msg . objects . filter ( date_time__gte = start ) . filter ( date_time__lte = end ) . extra ( select = select ) . values ( day ) . annotate ( number = Count ( id )) days = [] for d in list ( countday ): days . append ([ str ( d [ day ]), d [ number ]]) days  [[ 2018-09-26 , 3 ], [ 2018-09-27 , 1 ], [ 2018-09-28 , 5 ], [ 2018-09-25 , 1 ], [ 2018-09-24 , 1 ]] countall = msg . objects . filter ( date_time__gte = start ) . filter ( date_time__lte = end ) . count () #  countuser = msg . objects . filter ( date_time__gte = start ) . filter ( date_time__lte = end ) . values_list ( user_name ) . annotate ( Count ( user_name )) #  userdata = list ( sorted ( countuser , key = lambda user : user [ 1 ], reverse = True ))[: 5 ] # 5 userdata  [( u root , 5 ), ( u pwm , 3 ), ( u test , 2 ), ( u lianggy , 1 )] http : // www . cnblogs . com / yangmv / p / 5327477. html   models . UserInfo . objects . all () models . UserInfo . objects . all () . values ( user ) #user models . UserInfo . objects . all () . values_list ( id , user ) #iduser， models . UserInfo . objects . get ( id = 1 ) models . UserInfo . objects . get ( user = yangmv )  models . UserInfo . objects . create ( user = yangmv , pwd = 123456 )  obj = models . UserInfo ( user = yangmv , pwd = 123456 ) obj . save ()  dic = { user : yangmv , pwd : 123456 } models . UserInfo . objects . create ( ** dic )  models . UserInfo . objects . filter ( user = yangmv ) . delete ()  models . UserInfo . objects . filter ( user = yangmv ) . update ( pwd = 520 )  obj = models . UserInfo . objects . get ( user = yangmv ) obj . pwd = 520 obj . save () 、 models . DateTimeField 　　 datetime ， auto_now = True ： auto_now_add ，。 class UserInfo ( models . Model ): name = models . CharField ( max_length = 32 ) ctime = models . DateTimeField ( auto_now = True ) uptime = models . DateTimeField ( auto_now_add = True ) from web import models def home ( request ): models . UserInfo . objects . create ( name = yangmv ) after = models . UserInfo . objects . all () print after [ 0 ] . ctime return render ( request , home/home.html )  ，，， makemigrations  ： 1 、，。，。 ( null = True ， blank = True  admin  ) 2 、，。， 2 、 ： models . ForeignKey (  ) ： models . ManyToManyField (  ) ： models . OneToOneField (  ) ： ：，（） ：，【】【】【】。 ：， ：， ：，（ ： 10 ，， 10 ， 5  ： class Game ( models . Model ): gname = models . CharField ( max_length = 32 ) class Host ( models . Model ): hostname = models . CharField ( max_length = 32 ) game = models . ForeignKey ( Game ) django uwsgi yum install nginx uwsgi uwsgi - plugin - python2 - y echo /usr/sbin/uwsgi --ini /data/admin/uwsgi.ini / etc / rc . local chmod + x / etc / rc . local  killall - 9 uwsgi / usr / sbin / uwsgi -- ini / data / admin / uwsgi . ini uwsgi . ini  [ uwsgi ] socket = 127 . 0 . 0 . 1 : 9090 master = true vhost = true no - site = true workers = 2 reload - mercy = 10 vacuum = true max - requests = 1000 limit - as = 512 buffer - size = 30000 plugins = python pidfile = / var / run / uwsgi . pid daemonize = / var / log / nginx / uwsgi . log pythonpath = / usr / lib / python2 . 7 / site - packages / pythonpath = / usr / lib64 / python2 . 7 / site - packages / nginx  gzip on ; server_tokens off ; location / { include uwsgi_params ; uwsgi_pass 127 . 0 . 0 . 1 : 9090 ; uwsgi_param UWSGI_SCRIPT admin . wsgi ; uwsgi_param UWSGI_CHDIR / data / admin / ; index index . html index . htm ; client_max_body_size 35 m ; } location / static / { root / data / admin / ; expires 10 d ; } uwsgi+nginx pip install Flask - Script uwsgi uwsgi - tools from flask import Flask app = Flask ( __name__ ) @app.route ( / ) def hello (): return Hello World! ，， Flask ， Flask  app ，，  Flask Script  manage . py  ，， window  FastCGI 。   manage . py ： #!/usr/bin/env python import os if os . path . exists ( .env ): print ( Importing environment from .env... ) for line in open ( .env ): var = line . strip () . split ( = ) if len ( var ) == 2 : os . environ [ var [ 0 ]] = var [ 1 ] from app import create_app from flask.ext.script import Manager , Shell #  app app = create_app ( os . getenv ( FLASK_CONFIG ) or default ) manager = Manager ( app ) def make_shell_context (): return dict ( app = app ) manager . add_command ( shell , Shell ( make_context = make_shell_context )) @manager.command def deploy (): Run deployment tasks. pass if __name__ == __main__ : manager . run ()  Flask : python manage . py runserver uwsgi  vim config . ini [ uwsgi ] # uwsgi  socket = 127.0 . 0.1 : 8001 #  chdir = / var / www / html / solr / buffer - size = 32768 post - buffering = 8192 # python  wsgi - file = log_uwsgi . py # python  application  callable = app #  processes = 4 # : threads = 2 # stats = 127.0 . 0.1 : 8002  uwsgi config . ini  uwsgi_curl 127.0 . 0.1 : 8001 supervisor  yum install supervisor nginx - y （ pip install supervisor ） vim / etc / supervisord . conf  [ program : my_flask ] command =/ usr / bin / uwsgi / var / www / html / solr / config . ini directory =/ var / www / html / solr / user = root autostart = true autorestart = true ;  loglevel = info log_stdout = true ; if true , log program stdout ( default true ) log_stderr = true ; if true , log program stderr ( def false ) logfile_maxbytes = 3 MB ; max # logfile bytes b4 rotation (default 50MB) logfile =/ var / log / upload . log  service supervisor start  service supervisor stop （， kill - 9 ） vim / ect / nginx / nginx . conf server { listen 80 ; server_name XXX . XXX . XXX ; # location / { include uwsgi_params ; uwsgi_pass 127.0 . 0.1 : 8001 ; # uwsgi ,uwsgi  # uwsgi_param UWSGI_PYHOME /home/www/my_flask/venv; #  uwsgi_param UWSGI_CHDIR / home / www / my_flask ; #  uwsgi_param UWSGI_SCRIPT manage : app ; #  } } post header  print request . headers print request . headers . get ( X-Real-Ip , request . remote_addr ) get  print request . args print request . args . get ( key ) post  print request . form print request . form . get ( key )  post / get  from flask import request args = request . args if request . method == GET else request . form a = args . get ( a , default ) form  print request . form print request . form [ name ] print request . form . get ( name ) print request . form . getlist ( name ) print request . form . get ( nickname , default = little apple ) upload api 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 #!/usr/bin/env python #coding:utf-8 import os import commands from flask import Flask , request , redirect , render_template import urllib import logging import re logging . basicConfig ( level = logging . INFO , format = %(levelname)s : %(message)s , filename = /var/log/upload.log ) UPLOAD_FOLDER = /var/www/html/logfile/now app = Flask ( __name__ ) app . config [ UPLOAD_FOLDER ] = UPLOAD_FOLDER #app.config[ MAX_CONTENT_LENGTH ] = 1 * 1024 * 1024 @app.route ( / , methods = [ GET , POST ]) def index (): if request . method == POST : #ALL_DATA = eval(request.get_data()) ALL_DATA = request . get_data () ALL_DATA = urllib . unquote ( ALL_DATA ) try : meetingid = re . findall ( r meetingid=[0-9]+ , ALL_DATA )[ 0 ] . split ( = )[ 1 ] fileName = re . findall ( r (? =fileName=).*\\d+\\.(?:error|log) , ALL_DATA )[ 0 ] . replace ( error , error.log ) except : print ALL_DATA return bad #print ALL_DATA PATH = os . path . join ( app . config [ UPLOAD_FOLDER ], meetingid ) if not os . path . isdir ( PATH ): os . mkdir ( PATH ) try : with open ( os . path . join ( PATH , fileName ), a ) as f : f . write ( ALL_DATA ) except IOError : os . _exit ( 1 ) return OK! @app.route ( /crossdomain.xml , methods = [ GET , POST ]) def cross (): return ?xml version= 1.0 ? cross-domain-policy allow-access-from domain= * / allow-access-from domain= www.3mang.com / /cross-domain-policy @app.route ( /download , methods = [ GET , POST ]) def download (): if request . method == POST : os . environ [ url ] = request . form [ url ] result = commands . getoutput ( /usr/local/solr/1.sh $url ) if re . match ( r .*.zip , result ): return render_template ( download.html , result = result ) else : return render_template ( download.html , message = result ) return render_template ( download.html ) @app.route ( /todayid , methods = [ GET , POST ]) def todayid (): if request . method == POST : os . environ [ classid ] = request . form [ classid ] result = commands . getoutput ( /usr/local/solr/2.sh $classid ) if re . match ( r .*.zip , result ): return render_template ( todayid.html , result = result ) else : return render_template ( todayid.html , message = result ) return render_template ( todayid.html ) if __name__ == __main__ : logging . info ( app . run ( host = 0.0.0.0 , threaded = True , port = 13966 , debug = False ))    context ， ， /  ，： ， ，   public 、 ， IP ， ... ， 、、、 post 、 cookie ...  session 、 .. http : // www . cnblogs . com / hazir / p / what_is_web_framework . html http : // blog . jobbole . com / 84870 / https : // www . zhihu . com / question / 34873227  from flask import Flask , render_template , session , request , abort , redirect , url_for app = Flask ( __name__ )  @app.route ( / , methods = [ GET , POST ]) def hello_world (): return redirect ( url_for ( login ))  / login ， url_for  @app.route ( /login ) def login (): abort ( 401 ) this_is_never_executed () @app.errorhandler ( 404 ) def page_not_found ( error ): return render_template ( page_not_found.html ), 404  404  @app.route ( /user/ username )  def show_user_profile ( username ): # show the user profile for that user return User %s % username   @app.route ( / ) def index (): if username in session : return Logged in as %s % escape ( session [ username ]) return You are not logged in @app.route ( /login , methods = [ GET , POST ]) def login (): if request . method == POST : session [ username ] = request . form [ username ] return redirect ( url_for ( index )) return form action= method= post p input type=text name=username p input type=submit value=Login /form @app.route ( /logout ) def logout (): # 。 session . pop ( username , None ) return redirect ( url_for ( index )) # ，： app . secret_key = A0Zr98j/3yX R~XHH!jmN]LWX/,?RT if __name__ == __main__ : app . run ( host = 0.0.0.0 , debug = True ,)  from flask import Flask , render_template , request app = Flask ( __name__ ) @app.route ( / , methods = [ GET , POST ]) def index (): user = request . form . get ( user , Flask ) return render_template ( index.html , user = user ) @app.route ( /hello/ name ) def hello ( name = None ): return render_template ( hello.html , name = name ) if __name__ == __main__ : app . run ( debug = True , host = 0.0.0.0 ) vim templates / index . html html title Flask - Vfast / title body h1 Hello , {{ user | title }} ! / h1 / br form method = POST input type = text , name = user input type = submit , name = submit / form / body / html vim templates / hello . html ! doctype html title Hello from Flask / title { % if name % } h1 Hello {{ name }} ! / h1 { % else % } h1 Hello World ! / h1 { % endif % }  from flask import Flask , render_template , request app = Flask ( __name__ ) @app.route ( / , methods = [ GET , POST ]) def index (): user = request . form . get ( user , Flask ) return render_template ( index.html , user = user ) @app.route ( /hello/ name ) def hello ( name = None ): return render_template ( hello.html , name = name ) if __name__ == __main__ : app . run ( debug = True , host = 0.0.0.0 ) vim templates / index . html html title Flask - Vfast / title body h1 Hello , {{ user | title }} ! / h1 / br form method = POST input type = text , name = user input type = submit , name = submit / form / body / html vim templates / hello . html ! doctype html title Hello from Flask / title { % if name % } h1 Hello {{ name }} ! / h1 { % else % } h1 Hello World ! / h1 { % endif % } falcon  curl http://127.0.0.1:8900 -d \"tos=lianggy@163.cn subject=dd content=aa\" 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 #!/usr/bin/env python #coding:utf-8 import os from flask import Flask , request import logging import sys reload ( sys ) sys . setdefaultencoding ( utf8 ) mailfrom = test mailserver = 172.29.0.68 logging . basicConfig ( level = logging . INFO , format = %(levelname)s : %(message)s , filename = mailapi.log ) app = Flask ( __name__ ) @app.route ( / , methods = [ GET , POST ]) def index (): if request . method == POST : content = request . form . get ( content ) tos = request . form . get ( tos ) subject = request . form . get ( subject ) try : mail = /usr/local/bin/sendEmail -f %s -t %s -u %s -m %s -s %s % ( mailfrom , tos , subject , content , mailserver ) result = os . popen ( mail ) . read () logging . info ( result ) return result except Exception , e : return str ( e ) return OK if __name__ == __main__ : logging . info ( app . run ( host = 127.0.0.1 , threaded = True , port = 8900 , debug = False )) #app.run(host= 0.0.0.0 , threaded=True,port=8900, debug=True) table table class = table table-condensed table-bordered caption title / caption thead tr th  / th th  / th th  / th th  / th / tr / thead tbody id = table_result tr td 1 / td td 2 / td td 3 / td td 4 / td / tr / tbody / table ul id = barcon class = pagination pull-right / ul //  js ： ------------------------------------------ goPage ( 1 , 6 ) ; function goPage ( pno , psize ) { var itable = document . getElementById ( table_result ) ;//ID var num = itable . rows . length ;//() var totalPage = 0 ;// var pageSize = psize ;// //  if ( num / pageSize parseInt ( num / pageSize )) { totalPage = parseInt ( num / pageSize ) + 1 ; } else { totalPage = parseInt ( num / pageSize ) ; } var currentPage = pno ;// var startRow = ( currentPage - 1 ) * pageSize + 1 ;// 1 var endRow = currentPage * pageSize ;// 6 endRow = ( endRow num ) ? num : endRow ; //  for ( var i = 1 ; i (num + 1); i++) { var irow = itable . rows [ i - 1 ] ; if ( i = startRow i = endRow ) { irow . style . display = table-row ; // } else { irow . style . display = none ; // } } var tempStr = ; if ( currentPage 1 ) { tempStr += li a href=\\ #\\ onClick=\\ goPage ( + (currentPage - 1) + , + psize + ) \\ laquo; /a /li for ( var j = 1 ; j = totalPage; j++) { tempStr += li a href=\\ #\\ onClick=\\ goPage ( + j + , + psize + ) \\ + j + /a /li } } else { tempStr += li a href=\\ #\\ laquo; /a /li ; for ( var j = 1 ; j = totalPage; j++) { tempStr += li a href=\\ #\\ onClick=\\ goPage ( + j + , + psize + ) \\ + j + /a /li } } if ( currentPage totalPage ) { tempStr += li a href=\\ #\\ onClick=\\ goPage ( + (currentPage + 1) + , + psize + ) \\ raquo; /a /li ; for ( var j = 1 ; j = totalPage; j++) { } } else { tempStr += li a href=\\ #\\ raquo; /a /li ; for ( var j = 1 ; j = totalPage; j++) { } } document . getElementById ( barcon ) . innerHTML = tempStr ; }","title":"python-web"},{"location":"python-web/#django-models","text":"from django.db.models import Count from django.db import connection select = { day : connection . ops . date_trunc_sql ( day , date_time )} #  countday = msg . objects . filter ( date_time__gte = start ) . filter ( date_time__lte = end ) . extra ( select = select ) . values ( day ) . annotate ( number = Count ( id )) days = [] for d in list ( countday ): days . append ([ str ( d [ day ]), d [ number ]]) days  [[ 2018-09-26 , 3 ], [ 2018-09-27 , 1 ], [ 2018-09-28 , 5 ], [ 2018-09-25 , 1 ], [ 2018-09-24 , 1 ]] countall = msg . objects . filter ( date_time__gte = start ) . filter ( date_time__lte = end ) . count () #  countuser = msg . objects . filter ( date_time__gte = start ) . filter ( date_time__lte = end ) . values_list ( user_name ) . annotate ( Count ( user_name )) #  userdata = list ( sorted ( countuser , key = lambda user : user [ 1 ], reverse = True ))[: 5 ] # 5 userdata  [( u root , 5 ), ( u pwm , 3 ), ( u test , 2 ), ( u lianggy , 1 )] http : // www . cnblogs . com / yangmv / p / 5327477. html   models . UserInfo . objects . all () models . UserInfo . objects . all () . values ( user ) #user models . UserInfo . objects . all () . values_list ( id , user ) #iduser， models . UserInfo . objects . get ( id = 1 ) models . UserInfo . objects . get ( user = yangmv )  models . UserInfo . objects . create ( user = yangmv , pwd = 123456 )  obj = models . UserInfo ( user = yangmv , pwd = 123456 ) obj . save ()  dic = { user : yangmv , pwd : 123456 } models . UserInfo . objects . create ( ** dic )  models . UserInfo . objects . filter ( user = yangmv ) . delete ()  models . UserInfo . objects . filter ( user = yangmv ) . update ( pwd = 520 )  obj = models . UserInfo . objects . get ( user = yangmv ) obj . pwd = 520 obj . save () 、 models . DateTimeField 　　 datetime ， auto_now = True ： auto_now_add ，。 class UserInfo ( models . Model ): name = models . CharField ( max_length = 32 ) ctime = models . DateTimeField ( auto_now = True ) uptime = models . DateTimeField ( auto_now_add = True ) from web import models def home ( request ): models . UserInfo . objects . create ( name = yangmv ) after = models . UserInfo . objects . all () print after [ 0 ] . ctime return render ( request , home/home.html )  ，，， makemigrations  ： 1 、，。，。 ( null = True ， blank = True  admin  ) 2 、，。， 2 、 ： models . ForeignKey (  ) ： models . ManyToManyField (  ) ： models . OneToOneField (  ) ： ：，（） ：，【】【】【】。 ：， ：， ：，（ ： 10 ，， 10 ， 5  ： class Game ( models . Model ): gname = models . CharField ( max_length = 32 ) class Host ( models . Model ): hostname = models . CharField ( max_length = 32 ) game = models . ForeignKey ( Game )","title":"django models"},{"location":"python-web/#django-uwsgi","text":"yum install nginx uwsgi uwsgi - plugin - python2 - y echo /usr/sbin/uwsgi --ini /data/admin/uwsgi.ini / etc / rc . local chmod + x / etc / rc . local  killall - 9 uwsgi / usr / sbin / uwsgi -- ini / data / admin / uwsgi . ini uwsgi . ini  [ uwsgi ] socket = 127 . 0 . 0 . 1 : 9090 master = true vhost = true no - site = true workers = 2 reload - mercy = 10 vacuum = true max - requests = 1000 limit - as = 512 buffer - size = 30000 plugins = python pidfile = / var / run / uwsgi . pid daemonize = / var / log / nginx / uwsgi . log pythonpath = / usr / lib / python2 . 7 / site - packages / pythonpath = / usr / lib64 / python2 . 7 / site - packages / nginx  gzip on ; server_tokens off ; location / { include uwsgi_params ; uwsgi_pass 127 . 0 . 0 . 1 : 9090 ; uwsgi_param UWSGI_SCRIPT admin . wsgi ; uwsgi_param UWSGI_CHDIR / data / admin / ; index index . html index . htm ; client_max_body_size 35 m ; } location / static / { root / data / admin / ; expires 10 d ; }","title":"django uwsgi"},{"location":"python-web/#uwsginginx","text":"pip install Flask - Script uwsgi uwsgi - tools from flask import Flask app = Flask ( __name__ ) @app.route ( / ) def hello (): return Hello World! ，， Flask ， Flask  app ，，  Flask Script  manage . py  ，， window  FastCGI 。   manage . py ： #!/usr/bin/env python import os if os . path . exists ( .env ): print ( Importing environment from .env... ) for line in open ( .env ): var = line . strip () . split ( = ) if len ( var ) == 2 : os . environ [ var [ 0 ]] = var [ 1 ] from app import create_app from flask.ext.script import Manager , Shell #  app app = create_app ( os . getenv ( FLASK_CONFIG ) or default ) manager = Manager ( app ) def make_shell_context (): return dict ( app = app ) manager . add_command ( shell , Shell ( make_context = make_shell_context )) @manager.command def deploy (): Run deployment tasks. pass if __name__ == __main__ : manager . run ()  Flask : python manage . py runserver uwsgi  vim config . ini [ uwsgi ] # uwsgi  socket = 127.0 . 0.1 : 8001 #  chdir = / var / www / html / solr / buffer - size = 32768 post - buffering = 8192 # python  wsgi - file = log_uwsgi . py # python  application  callable = app #  processes = 4 # : threads = 2 # stats = 127.0 . 0.1 : 8002  uwsgi config . ini  uwsgi_curl 127.0 . 0.1 : 8001 supervisor  yum install supervisor nginx - y （ pip install supervisor ） vim / etc / supervisord . conf  [ program : my_flask ] command =/ usr / bin / uwsgi / var / www / html / solr / config . ini directory =/ var / www / html / solr / user = root autostart = true autorestart = true ;  loglevel = info log_stdout = true ; if true , log program stdout ( default true ) log_stderr = true ; if true , log program stderr ( def false ) logfile_maxbytes = 3 MB ; max # logfile bytes b4 rotation (default 50MB) logfile =/ var / log / upload . log  service supervisor start  service supervisor stop （， kill - 9 ） vim / ect / nginx / nginx . conf server { listen 80 ; server_name XXX . XXX . XXX ; # location / { include uwsgi_params ; uwsgi_pass 127.0 . 0.1 : 8001 ; # uwsgi ,uwsgi  # uwsgi_param UWSGI_PYHOME /home/www/my_flask/venv; #  uwsgi_param UWSGI_CHDIR / home / www / my_flask ; #  uwsgi_param UWSGI_SCRIPT manage : app ; #  } }","title":"uwsgi+nginx"},{"location":"python-web/#post","text":"header  print request . headers print request . headers . get ( X-Real-Ip , request . remote_addr ) get  print request . args print request . args . get ( key ) post  print request . form print request . form . get ( key )  post / get  from flask import request args = request . args if request . method == GET else request . form a = args . get ( a , default ) form  print request . form print request . form [ name ] print request . form . get ( name ) print request . form . getlist ( name ) print request . form . get ( nickname , default = little apple )","title":"post"},{"location":"python-web/#upload-api","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 #!/usr/bin/env python #coding:utf-8 import os import commands from flask import Flask , request , redirect , render_template import urllib import logging import re logging . basicConfig ( level = logging . INFO , format = %(levelname)s : %(message)s , filename = /var/log/upload.log ) UPLOAD_FOLDER = /var/www/html/logfile/now app = Flask ( __name__ ) app . config [ UPLOAD_FOLDER ] = UPLOAD_FOLDER #app.config[ MAX_CONTENT_LENGTH ] = 1 * 1024 * 1024 @app.route ( / , methods = [ GET , POST ]) def index (): if request . method == POST : #ALL_DATA = eval(request.get_data()) ALL_DATA = request . get_data () ALL_DATA = urllib . unquote ( ALL_DATA ) try : meetingid = re . findall ( r meetingid=[0-9]+ , ALL_DATA )[ 0 ] . split ( = )[ 1 ] fileName = re . findall ( r (? =fileName=).*\\d+\\.(?:error|log) , ALL_DATA )[ 0 ] . replace ( error , error.log ) except : print ALL_DATA return bad #print ALL_DATA PATH = os . path . join ( app . config [ UPLOAD_FOLDER ], meetingid ) if not os . path . isdir ( PATH ): os . mkdir ( PATH ) try : with open ( os . path . join ( PATH , fileName ), a ) as f : f . write ( ALL_DATA ) except IOError : os . _exit ( 1 ) return OK! @app.route ( /crossdomain.xml , methods = [ GET , POST ]) def cross (): return ?xml version= 1.0 ? cross-domain-policy allow-access-from domain= * / allow-access-from domain= www.3mang.com / /cross-domain-policy @app.route ( /download , methods = [ GET , POST ]) def download (): if request . method == POST : os . environ [ url ] = request . form [ url ] result = commands . getoutput ( /usr/local/solr/1.sh $url ) if re . match ( r .*.zip , result ): return render_template ( download.html , result = result ) else : return render_template ( download.html , message = result ) return render_template ( download.html ) @app.route ( /todayid , methods = [ GET , POST ]) def todayid (): if request . method == POST : os . environ [ classid ] = request . form [ classid ] result = commands . getoutput ( /usr/local/solr/2.sh $classid ) if re . match ( r .*.zip , result ): return render_template ( todayid.html , result = result ) else : return render_template ( todayid.html , message = result ) return render_template ( todayid.html ) if __name__ == __main__ : logging . info ( app . run ( host = 0.0.0.0 , threaded = True , port = 13966 , debug = False ))","title":"upload api"},{"location":"python-web/#_1","text":"  context ， ， /  ，： ， ，   public 、 ， IP ， ... ， 、、、 post 、 cookie ...  session 、 .. http : // www . cnblogs . com / hazir / p / what_is_web_framework . html http : // blog . jobbole . com / 84870 / https : // www . zhihu . com / question / 34873227","title":""},{"location":"python-web/#_2","text":"from flask import Flask , render_template , session , request , abort , redirect , url_for app = Flask ( __name__ )  @app.route ( / , methods = [ GET , POST ]) def hello_world (): return redirect ( url_for ( login ))  / login ， url_for  @app.route ( /login ) def login (): abort ( 401 ) this_is_never_executed () @app.errorhandler ( 404 ) def page_not_found ( error ): return render_template ( page_not_found.html ), 404  404  @app.route ( /user/ username )  def show_user_profile ( username ): # show the user profile for that user return User %s % username   @app.route ( / ) def index (): if username in session : return Logged in as %s % escape ( session [ username ]) return You are not logged in @app.route ( /login , methods = [ GET , POST ]) def login (): if request . method == POST : session [ username ] = request . form [ username ] return redirect ( url_for ( index )) return form action= method= post p input type=text name=username p input type=submit value=Login /form @app.route ( /logout ) def logout (): # 。 session . pop ( username , None ) return redirect ( url_for ( index )) # ，： app . secret_key = A0Zr98j/3yX R~XHH!jmN]LWX/,?RT if __name__ == __main__ : app . run ( host = 0.0.0.0 , debug = True ,)","title":""},{"location":"python-web/#_3","text":"from flask import Flask , render_template , request app = Flask ( __name__ ) @app.route ( / , methods = [ GET , POST ]) def index (): user = request . form . get ( user , Flask ) return render_template ( index.html , user = user ) @app.route ( /hello/ name ) def hello ( name = None ): return render_template ( hello.html , name = name ) if __name__ == __main__ : app . run ( debug = True , host = 0.0.0.0 ) vim templates / index . html html title Flask - Vfast / title body h1 Hello , {{ user | title }} ! / h1 / br form method = POST input type = text , name = user input type = submit , name = submit / form / body / html vim templates / hello . html ! doctype html title Hello from Flask / title { % if name % } h1 Hello {{ name }} ! / h1 { % else % } h1 Hello World ! / h1 { % endif % }","title":""},{"location":"python-web/#_4","text":"from flask import Flask , render_template , request app = Flask ( __name__ ) @app.route ( / , methods = [ GET , POST ]) def index (): user = request . form . get ( user , Flask ) return render_template ( index.html , user = user ) @app.route ( /hello/ name ) def hello ( name = None ): return render_template ( hello.html , name = name ) if __name__ == __main__ : app . run ( debug = True , host = 0.0.0.0 ) vim templates / index . html html title Flask - Vfast / title body h1 Hello , {{ user | title }} ! / h1 / br form method = POST input type = text , name = user input type = submit , name = submit / form / body / html vim templates / hello . html ! doctype html title Hello from Flask / title { % if name % } h1 Hello {{ name }} ! / h1 { % else % } h1 Hello World ! / h1 { % endif % }","title":""},{"location":"python-web/#falcon","text":" curl http://127.0.0.1:8900 -d \"tos=lianggy@163.cn subject=dd content=aa\" 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 #!/usr/bin/env python #coding:utf-8 import os from flask import Flask , request import logging import sys reload ( sys ) sys . setdefaultencoding ( utf8 ) mailfrom = test mailserver = 172.29.0.68 logging . basicConfig ( level = logging . INFO , format = %(levelname)s : %(message)s , filename = mailapi.log ) app = Flask ( __name__ ) @app.route ( / , methods = [ GET , POST ]) def index (): if request . method == POST : content = request . form . get ( content ) tos = request . form . get ( tos ) subject = request . form . get ( subject ) try : mail = /usr/local/bin/sendEmail -f %s -t %s -u %s -m %s -s %s % ( mailfrom , tos , subject , content , mailserver ) result = os . popen ( mail ) . read () logging . info ( result ) return result except Exception , e : return str ( e ) return OK if __name__ == __main__ : logging . info ( app . run ( host = 127.0.0.1 , threaded = True , port = 8900 , debug = False )) #app.run(host= 0.0.0.0 , threaded=True,port=8900, debug=True)","title":"falcon"},{"location":"python-web/#table","text":"table class = table table-condensed table-bordered caption title / caption thead tr th  / th th  / th th  / th th  / th / tr / thead tbody id = table_result tr td 1 / td td 2 / td td 3 / td td 4 / td / tr / tbody / table ul id = barcon class = pagination pull-right / ul //  js ： ------------------------------------------ goPage ( 1 , 6 ) ; function goPage ( pno , psize ) { var itable = document . getElementById ( table_result ) ;//ID var num = itable . rows . length ;//() var totalPage = 0 ;// var pageSize = psize ;// //  if ( num / pageSize parseInt ( num / pageSize )) { totalPage = parseInt ( num / pageSize ) + 1 ; } else { totalPage = parseInt ( num / pageSize ) ; } var currentPage = pno ;// var startRow = ( currentPage - 1 ) * pageSize + 1 ;// 1 var endRow = currentPage * pageSize ;// 6 endRow = ( endRow num ) ? num : endRow ; //  for ( var i = 1 ; i (num + 1); i++) { var irow = itable . rows [ i - 1 ] ; if ( i = startRow i = endRow ) { irow . style . display = table-row ; // } else { irow . style . display = none ; // } } var tempStr = ; if ( currentPage 1 ) { tempStr += li a href=\\ #\\ onClick=\\ goPage ( + (currentPage - 1) + , + psize + ) \\ laquo; /a /li for ( var j = 1 ; j = totalPage; j++) { tempStr += li a href=\\ #\\ onClick=\\ goPage ( + j + , + psize + ) \\ + j + /a /li } } else { tempStr += li a href=\\ #\\ laquo; /a /li ; for ( var j = 1 ; j = totalPage; j++) { tempStr += li a href=\\ #\\ onClick=\\ goPage ( + j + , + psize + ) \\ + j + /a /li } } if ( currentPage totalPage ) { tempStr += li a href=\\ #\\ onClick=\\ goPage ( + (currentPage + 1) + , + psize + ) \\ raquo; /a /li ; for ( var j = 1 ; j = totalPage; j++) { } } else { tempStr += li a href=\\ #\\ raquo; /a /li ; for ( var j = 1 ; j = totalPage; j++) { } } document . getElementById ( barcon ) . innerHTML = tempStr ; }","title":"table"},{"location":"redis/","text":"redis-dump yum install ruby rubygems ruby - devel gem sources --add http://gems.ruby-china.org/ --remove http://rubygems.org/ gem sources - l gem install redis - dump redis - dump - u 127 . 0 . 0 . 1 : 6379 data . json (  redis ， 0 )  15 ： redis - dump - u 127 . 0 . 0 . 1 : 6379 - d 15 data . json redis - load - u 192 . 168 . 1 . 3 : 19000 data . json aof   Redis  AOF （ AOF ） # redis - cli - h ip - p port config set appendonly yes  AOF  Redis  (  AOF  append . aof ) # redis - cli - h ip - p 6379 - a pass --pipe appendonly.aof codis wget https : // github . com / CodisLabs / codis / releases / download / 3 . 2 . 0 / codis3 . 2 . 0 - go1 . 7 . 5 - linux . tar . gz (  ) https : // github . com / CodisLabs / codis / archive / release3 . 2 . zip ( ，， )  glibc2 . 14 export LD_LIBRARY_PATH =/ usr / local / glibc - 2 . 14 / lib / : $ LD_LIBRARY_PATH twemproxy https : // github . com / twitter / twemproxy  autoconf wget http : // ftp . gnu . org / gnu / autoconf / autoconf - 2 . 69 . tar . gz tar - zxf autoconf - 2 . 69 . tar . gz cd autoconf - 2 . 69 . / configure --prefix=/usr/local/autoconf make make install wget https : // github . com / twitter / twemproxy / archive / master . zip cd twemproxy - master / / usr / local / autoconf / bin / autoreconf - fvi . / configure --prefix=/usr/local/twemproxy make - j 8 make install cd / usr / local / twemproxy mkdir run conf vim / usr / local / twemproxy / conf / nutcracker . yml  alpha : listen : 127 . 0 . 0 . 1 : 22121 hash : fnv1a_64 distribution : ketama auto_eject_hosts : true redis : true server_retry_timeout : 2000 server_failure_limit : 1 servers : - 127 . 0 . 0 . 1 : 7000 : 1 - 127 . 0 . 0 . 1 : 7001 : 1  . / sbin / nutcracker - t  nutcracker - d - c / usr / local / twemproxy / conf / nutcracker . yml - p / usr / local / twemproxy / run / redisproxy . pid - o / usr / local / twemproxy / run / redisproxy . log sentinel  redis  # redis ， vim redis . conf slaveof 192 . 168 . 1 . 5 6379  nohup . / src / redis - server redis . conf redis - cli - h 192 . 168 . 1 . 5 info Replication  # Replication role : master # 192 . 168 . 9 . 18 : 6379  redis  connected_slaves : 1 slave0 : ip = 192 . 168 . 1 . 6 , port = 6379 , state = online , offset = 29 , lag = 0 sentinel . conf  （ sentinel  sentinel ， gossip ） port 26379 dir / tmp # master1 sentinel monitor master1 192 . 168 . 1 . 5 6379 2 # 2 ， 2  sentinel  master ， master ， sentinel ， sentinel  1 sentinel down - after - milliseconds master1 10000 # sentinel  master  PING  master   sentinel parallel - syncs master1 1 # failover ， slave  master ，，  failover ，， slave  replication 。 1  slave 。 sentinel failover - timeout master1 180000 # failover ， # master2  redis  .... . / src / redis - sentinel sentinel . conf  . / src / redis - cli - h 192 . 168 . 1 . 6 - p 26379 info Sentinel  # Sentinel sentinel_masters : 1 sentinel_tilt : 0 sentinel_running_scripts : 0 sentinel_scripts_queue_length : 0 master0 : name = master1 , status = ok , address = 192 . 168 . 1 . 5 : 6379 , slaves = 1 , sentinels = 1  redis ， sentinel  redis   redis ， sentinel  redis ， redis ， reids ： redis Sentinel  info Sentinel  VIP  VIP   failover 。  client - reconfig - script 。 # The following arguments are passed to the script : # # master - name role state from - ip from - port to - ip to - port  6  VIP ， Master ， VIP 。 failover ， ip  arp ，  arping  GRAP 。 ip 、 arping  root ， sudo 。 vim / var / lib / redis / failover . sh chmod 755 / var / lib / redis / failover . sh chown redis : / var / lib / redis / failover . sh echo - e redis \\t ALL=(ALL) \\t NOPASSWD:/sbin/ip,NOPASSWD:/sbin/arping / etc / sudoers . d / redis sed - i s|Defaults.*requiretty|#Defaults \\t requiretty| / etc / sudoers chmod 440 / etc / sudoers . d / redis # !/ bin / bash MASTER_IP = ${ 6 } MY_IP = 192.168.0.1 #  Server  IP VIP = 192.168.0.4 # VIP NETMASK = 24 # Netmask INTERFACE = eth0 #  if [ ${ MASTER_IP } = ${ MY_IP } ] ; then sudo / sbin / ip addr add ${ VIP } / ${ NETMASK } dev ${ INTERFACE } sudo / sbin / arping - q - c 3 - A ${ VIP } - I ${ INTERFACE } exit 0 else sudo / sbin / ip addr del ${ VIP } / ${ NETMASK } dev ${ INTERFACE } exit 0 fi exit 1 Redis - Sentinel   redis - sentonel 。  VIP 。 vim / etc / redis - sentinel . conf service redis - sentinel start chkconfig redis - sentinel on ip addr add 192 . 168 . 0 . 4 / 24 dev eth0 # sentinel . conf port 26379 logfile / var / log / redis / sentinel . log sentinel monitor mymaster 192 . 168 . 0 . 1 6379 2 sentinel down - after - milliseconds mymaster 3000 sentinel parallel - syncs mymaster 1 sentinel failover - timeout mymaster 60000 sentinel client - reconfig - script mymaster / var / lib / redis / failover . sh   kill master  failover ，。 sentinel down - after - milliseconds mymaster 3000  3  redis 。，。 redis tar zxf redis - 3 . 0 . 2 . tar . gz cd redis - 3 . 0 . 2 make cd src make install cp .. / redis . conf / etc  redis - server / dev / null  redis - server redis . conf  redis - server / etc / redis . conf 1 log . log 2 errlog . log （ 1 ， 2 ）  redis - cli shutdown  redis - cli ： redis - cli set hx value ： redis - cli get hx quit  dbsize ( integer ) 12  key  info  monitor  config get  flushdb  flushall   01 exits key //  key ， 1 ， 0  02 del key1 key2 .... keyN //  key , key ， 0  key  03 type key //  key  value 。 none  key , string ， list  set ... 04 keys pattern //  key , 05 randomkey //  key ,， 06 rename oldkey newkey //  key , newkey ，， 1 ， 0 。 oldkey   newkey  07 renamenx oldkey newkey // ， newkey  08 dbsize //  key  09 expire key seconds //  key ，。 1 ， 0  key  10 ttl key //  key  - 1  key  11 select db - index // ， 0 , 16 。 1 ， 0  12 move key db - index //  key 。 1 。 0  key ， 13 flushdb //  key ,。 14 flushall //  key ，。 string  01 set key value //  key  string  value , 1 ， 0  02 setnx key value // ， key ， 0 。 nx  not exist  03 get key //  key  string , key  nil 04 getset key value //  key ， key 。 key  nil 05 mget key1 key2 ... keyN //  key ， key ， nil 。, ， k1 , k2 . k3  nil 06 mset key1 value1 ... keyN valueN //  key ， 1 ， 0  07 msetnx key1 value1 ... keyN valueN // ， key 08 incr key //  key ,。 incr  int  value ， incr  key ， key  1 09 decr key // ，， decr  key ， key  - 1 10 incrby key integer //  incr ， ， key  key ， value  0 11 decrby key integer //  decr ，。 decrby ， incrby ，。 12 append key value //  key  value ,。 13 substr key start end //  key , key 。 0 ， list  01 lpush key string //  key  list ， 1 ， 0  key  list  02 rpush key string // ， 03 llen key //  key  list ， key  0 , key  list  04 lrange key start end // ， 0 ，， - 1  ， key  05 ltrim key start end //  list ，， 1 ， key  06 lset key index value //  list ， 1 ， key  07 lrem key count value //  key  list  count  value 。 count  0  08 lpop key //  list ，。 key  list  nil ， key   list  09 rpop // ， 10 blpop key1 ... keyN timeout //  list  lpop ， blpop list1 list2 list3 0 ,  list  list2 , list3  list2  lpop  list2 。 list ， timeout ， timeout  0 。， client  key1 ... keyN  key  push ， key  client 。 ， nil 。 unix  select  poll 11 brpop //  blpop ， 12 rpoplpush srckey destkey //  srckey  list  destkey  list ,， . srckey  nil set  01 sadd key member //  string , key  set ， 1 , 0 , key  set  02 srem key member //  key  set ， 1 ， member  key  0 ，  key  set  03 spop key //  key  set , set  key  nil 04 srandmember key //  spop ， set ， 05 smove srckey dstkey member //  srckey  set  member  dstkey  set ，。 1 ,  member  srckey  0 ， key  set  06 scard key //  set ， set  key  0 07 sismember key member //  member  set ， 1 ， 0  key  08 sinter key1 key2 ... keyN //  key  09 sinterstore dstkey key1 ... keyN //  sinter ， dstkey  10 sunion key1 key2 ... keyN //  key  11 sunionstore dstkey key1 ... keyN //  sunion ， dstkey  12 sdiff key1 key2 ... keyN //  key  13 sdiffstore dstkey key1 ... keyN //  sdiff ， dstkey  14 smembers key //  key  set ， sorted set  01 zadd key score member // ， score 02 zrem key member // ， 1 ， 0 03 zincrby key incr member //  member  score ， skip list 。 score  04 zrank key member // （）, score  05 zrevrank key member // , score  06 zrange key start end //  lrange 。 07 zrevrange key start end // ， score  08 zrangebyscore key min max //  score  09 zcount key min max //  score  10 zcard key //  11 zscore key element //  score 12 zremrangebyrank key min max //  13 zremrangebyscore key min max //  score  hash  01 hset key field value //  hash field ， key ， 02 hget key field //  hash field 03 hmget key filed1 .... fieldN //  hash filed 04 hmset key filed1 value1 ... filedN valueN //  hash  field 05 hincrby key field integer //  hash filed  06 hexists key field //  field  07 hdel key field //  hash field 08 hlen key //  hash  field  09 hkeys key //  hash  field 10 hvals key //  hash  value 11 hgetall //  hash  filed  value redis . conf ：  # daemonize yes # pid ， pidfile redis . pid # Redis  port 6379 #， timeout 300 # loglevel verbose #， logfile stdout #， 0 ， select N  databases 16 # disk  # Keys ， 900  disk  save 900 1 # 10  Keys ， 300  disk  save 300 10 # 1 w  keys ， 60  disk  save 60 10000 # dump . rdb  rdbcompression yes # dump  dbfilename dump . rdb # Redis  dir / home / falcon / redis - 2 . 0 . 0 / ########### Replication ##################### # Redis  # slaveof masterip masterport # masterauth master - password ############## SECURITY ########### # requirepass foobared ############### LIMITS ############## # # maxclients 128 # # maxmemory bytes ########## APPEND ONLY MODE ######### # appendonly no #  disk  # appendfsync always appendfsync everysec # appendfsync no ################ VIRTUAL MEMORY ########### # VM  vm - enabled no # vm - enabled yes vm - swap - file logs / redis . swap vm - max - memory 0 vm - page - size 32 vm - pages 134217728 vm - max - threads 4 ############# ADVANCED CONFIG ############### glueoutputbuf yes hash - max - zipmap - entries 64 hash - max - zipmap - value 512 # Hash  activerehashing yes spring  redis  java Clients ， redis  Jedis ， spring  redis ， ( Jedis , JRedis , and RJC ) ，  SPRING DATA - REDIS 。 1 、 maven ，。 2 、 pom . xml repository id spring - milestone / id name Spring Maven MILESTONE Repository / name url http : // maven . springframework . org / milestone / url / repository dependency groupId org . springframework . data / groupId artifactId spring - data - redis / artifactId version 1 . 0 . 0 . RC1 / version / dependency spring  bean id = jedisConnectionFactory class = org.springframework.data.redis.connection.jedis.JedisConnectionFactory property name = hostName value = localhost / property name = port value = 6636 / / bean bean id = redisTemplate class = org.springframework.data.redis.core.RedisTemplate property name = connectionFactory ref = jedisConnectionFactory / / bean Java  @ Service public class RedisService { @ Resource private RedisTemplate Serializable , Serializable template ; /** * rediskey-value * * @param key key * @param value value */ public void set ( final Serializable key , final Serializable value ) { template . execute ( new RedisCallback Object () { @ Override public Object doInRedis ( RedisConnection connection ) throws DataAccessException { byte [] key_ = RedisUtil . getBytesFromObject ( key ) ; byte [] value_ = RedisUtil . getBytesFromObject ( value ) ; connection . set ( key_ , value_ ) ; return true ; } } ) ; } /** * keyredisvalue * * @param key key */ public Serializable get ( final Serializable key ) { return template . execute ( new RedisCallback Serializable () { @ Override public Serializable doInRedis ( RedisConnection connection ) throws DataAccessException { byte [] keyBytes = RedisUtil . getBytesFromObject ( key ) ; byte [] bytes = connection . get ( keyBytes ) ; return ( Serializable ) RedisUtil . getObjectFromBytes ( bytes ) ; } } ) ; } }  JedisConnectionFactory ， Jedis ，。 web https : // github . com / erikdubbelboer / phpRedisAdmin https : // github . com / nrk / predis cd / var / www / html / wget https : // github . com / erikdubbelboer / phpRedisAdmin / archive / master . zip unzip master . zip rm - f master . zip cd phpRedisAdmin wget https : // github . com / nrk / predis / archive / v1 . 1 . zip ， vendor unzip v1 . 1 . zip rm - f v1 . 1 . zip mv predis - 1 . 1 vendor vim phpRedisAdmin / includes / config . sample . inc . php  redis ,（， redis ）  php ， yum search redis | grep php php - nrk - Predis . noarch : PHP client library for Redis php - pecl - redis . x86_64 : Extension for communicating with the Redis key - value php - redis . x86_64 : Extension for communicating with the Redis key - value store http : // ip / phpredis / redis cluster : redis cluster 1 : redis cluster  reids - cluster  redis3 . 0 ， antirez : http : // antirez . com / news / 49 ( ps :， ) ,  redis3 beta2 ( 2 . 9 . 51 ) . : Redis Cluster will support up to ~ 1000 nodes . ...  redis  cluster  (  ) : 1 ) : 2 ) : slave - master , 3 ) : Hot resharding : 4 ) :: cluster xxx 5 ) : ( nodes - port . conf )  6 ) : ASK  / MOVED . 2 : redis cluster  1 ) redis - cluster  : ( 1 )  redis  ( PING - PONG  ) ,. ( 2 )  fail . ( 3 )  redis , proxy ., ( 4 ) redis - cluster [ 0 - 16383 ] slot , cluster  node - slot - value 2 ) redis - cluster : ( 1 )  master , master  master  ( cluster - node - timeout ) , master . ( 2 ) : ( cluster_state : fail ) ,,， (( error ) CLUSTERDOWN The cluster is down )  a : master , master  slave . fail , slot [ 0 - 16383 ] fail . b : master ， slave  fail . : redis cluster  1 : redis cluster 1 ) : redis - cluster : redis - cluster , reshard ,. ( 1 )  zlib , gem install  ( no such file to load -- zlib ) # download : zlib - 1 . 2 . 6 . tar . / configure make make install ( 1 )  ruby : version ( 1 . 9 . 2 ) # ruby1 . 9 . 2 cd / path / ruby . / configure - prefix =/ usr / local / ruby make make install sudo cp ruby / usr / local / bin ( 2 )  rubygem : version ( 1 . 8 . 16 ) # rubygems - 1 . 8 . 16 . tgz cd / path / gem sudo ruby setup . rb sudo cp bin / gem / usr / local / bin ( 3 )  gem - redis : version ( 3 . 0 . 0 ) gem install redis -- version 3 . 0 . 0 #， https : // ruby . taobao . org / $ gem sources -- add https : // ruby . taobao . org / -- remove https : // rubygems . org / $ gem sources - l *** CURRENT SOURCES *** https : // ruby . taobao . org #  ruby . taobao . org $ gem install rails 2 )  redis - cluster cd / path / redis make sudo cp / opt / redis / src / redis - server / usr / local / bin sudo cp / opt / redis / src / redis - cli / usr / local / bin sudo cp / opt / redis / src / redis - trib . rb / usr / local / bin 2 : redis cluster 1 ) redis :  ( include ) ,. 2 ) redis . # GENERAL daemonize no tcp - backlog 511 timeout 0 tcp - keepalive 0 loglevel notice databases 16 dir / opt / redis / data slave - serve - stale - data yes # slave  slave - read - only yes # not use default repl - disable - tcp - nodelay yes slave - priority 100 # aof  appendonly yes # aof  appendfsync everysec # aof rewrite  fsync no - appendfsync - on - rewrite yes auto - aof - rewrite - min - size 64 mb lua - time - limit 5000 # redis  cluster - enabled yes # cluster - node - timeout 15000 cluster - migration - barrier 1 slowlog - log - slower - than 10000 slowlog - max - len 128 notify - keyspace - events hash - max - ziplist - entries 512 hash - max - ziplist - value 64 list - max - ziplist - entries 512 list - max - ziplist - value 64 set - max - intset - entries 512 zset - max - ziplist - entries 128 zset - max - ziplist - value 64 activerehashing yes client - output - buffer - limit normal 0 0 0 client - output - buffer - limit slave 256 mb 64 mb 60 client - output - buffer - limit pubsub 32 mb 8 mb 60 hz 10 aof - rewrite - incremental - fsync yes 3 ) redis . # include / opt / redis / redis - common . conf # tcp  port 6379 # maxmemory 100 m #: # volatile - lru - remove the key with an expire set using an LRU algorithm # allkeys - lru - remove any key accordingly to the LRU algorithm # volatile - random - remove a random key with an expire set # allkeys - random - remove a random key , any key # volatile - ttl - remove the key with the nearest expire time ( minor TTL ) # noeviction - don t expire at all, just return an error on write operations maxmemory - policy allkeys - lru # aof  appendfilename appendonly-6379.aof # rdb , slave  dbfilename dump - 6379 . rdb # cluster  (  ) cluster - config - file nodes - 6379 . conf # redis ， span style = font-size: 1em; line - height : 1 . 5 ; auto-aof-rewrite，forkredisrewrite, /span auto - aof - rewrite - percentage 80 - 100 3 : cluster  cluster , redis : http : // redis . readthedocs . org / en / latest /  CLUSTER INFO  CLUSTER NODES （ node ），。  CLUSTER MEET ip port  ip  port ，。 CLUSTER FORGET node_id  node_id 。 CLUSTER REPLICATE node_id  node_id 。 CLUSTER SAVECONFIG 。  ( slot ) CLUSTER ADDSLOTS slot [ slot ...]  （ slot ）（ assign ）。 CLUSTER DELSLOTS slot [ slot ...] 。 CLUSTER FLUSHSLOTS ，。 CLUSTER SETSLOT slot NODE node_id  slot  node_id ，，  ，。 CLUSTER SETSLOT slot MIGRATING node_id  slot  node_id 。 CLUSTER SETSLOT slot IMPORTING node_id  node_id   slot 。 CLUSTER SETSLOT slot STABLE  slot （ import ）（ migrate ）。  CLUSTER KEYSLOT key  key 。 CLUSTER COUNTKEYSINSLOT slot  slot 。 CLUSTER GETKEYSINSLOT slot count  count  slot 。 4 : redis cluster  1 )  ( 1 ) #（）, redis - server / opt / redis / conf / redis - 6380 . conf / opt / redis / logs / redis - 6380 . log 2 1 redis - server / opt / redis / conf / redis - 6381 . conf / opt / redis / logs / redis - 6381 . log 2 1 redis - server / opt / redis / conf / redis - 6382 . conf / opt / redis / logs / redis - 6382 . log 2 1 redis - server / opt / redis / conf / redis - 7380 . conf / opt / redis / logs / redis - 7380 . log 2 1 redis - server / opt / redis / conf / redis - 7381 . conf / opt / redis / logs / redis - 7381 . log 2 1 redis - server / opt / redis / conf / redis - 7382 . conf / opt / redis / logs / redis - 7382 . log 2 1 ( 2 ) : ruby  ( redis - trib . rb )  # redis - trib . rb  create  # -- replicas  Redis Cluster  Master  Slave  #, master  slave ( , slave  master  1000 ) redis - trib . rb create -- replicas 1 10 . 10 . 34 . 14 : 6380 10 . 10 . 34 . 14 : 6381 10 . 10 . 34 . 14 : 6382 10 . 10 . 34 . 14 : 7380 10 . 10 . 34 . 14 : 7381 10 . 10 . 34 . 14 : 7382 ( 3 ) :, # redis - trib . rb  check  # ip : port  redis - trib . rb check 1 10 . 10 . 34 . 14 : 6380 ,， ok  [ OK ] All nodes agree about slots configuration . Check for open slots ... Check slots coverage ... [ OK ] All 16384 slots covered . redis - cli - c - p 6379 ( - c  ) 2 ) : master  ( 1 )  master :（ empty node ）， slot , a ) : ( ps : establish_config . sh  ) sh establish_config . sh 6386 conf / redis - 6386 . conf b ) : nohup redis - server / opt / redis / conf / redis - 6386 . conf / opt / redis / logs / redis - 6386 . log 2 1 c ) : add - node ，  ip : port ,  ip : port redis - trib . rb add - node 10 . 10 . 34 . 14 : 6386 10 . 10 . 34 . 14 : 6381 node :，  slot 。， ，  d ) : slot redis - trib . rb reshard 10 . 10 . 34 . 14 : 6386 # slot  ( ps : 500 ) How many slots do you want to move ( from 1 to 16384 ) ? 500 # slot  node - id What is the receiving node ID ? f51e26b5d5ff74f85341f06f28f125b7254e61bf # slot : # all  master ， # slot  master  id , done  Please enter all the source node IDs . Type all to use all the nodes as source nodes for the hash slots . Type done once you entered all the source nodes IDs . Source node #1 : all # slot ， yes  slot . # Do you want to proceed with the proposed reshard plan ( yes / no ) ? yes # 3 ) : slave  a ) : master  b ) : redis - cli  shell ,: cluster replicate  master  node - id cluster replicate 2 b9ebcbd627ff0fd7a7bbcc5332fb09e72788835 note : slave ， dump  master ， slave ， slave  rdb ， rdb  Master , io ,.  slave  rdb  - rw - r -- r -- 1 root root 34946 Apr 17 18 : 23 dump - 6386 . rdb - rw - r -- r -- 1 root root 34946 Apr 17 18 : 23 dump - 7386 . rdb 4 ) : reshard :  / ， reshard slot , master  reshard ， reshard  master . 5 ) : slave  # redis - trib del - node ip : port node-id redis - trib . rb del - node 10 . 10 . 34 . 14 : 7386 c7ee2fca17cb79fe3c9822ced1d4f6c5e169e378 a ) : master  reshard  master  slot , (  master  slot  ) # 10 . 10 . 34 . 14 : 6386  master  10 . 10 . 34 . 14 : 6380  redis - trib . rb reshard 10 . 10 . 34 . 14 : 6380 # slot  ( ps : 500 ) How many slots do you want to move ( from 1 to 16384 ) ? 500 (  master  slot  ) # slot  node - id ( 10 . 10 . 34 . 14 : 6380 ) What is the receiving node ID ? c4a31c852f81686f6ed8bcd6d1b13accdc947fd2 ( ps : 10 . 10 . 34 . 14 : 6380  node - id ) Please enter all the source node IDs . Type all to use all the nodes as source nodes for the hash slots . Type done once you entered all the source nodes IDs . Source node #1 : f51e26b5d5ff74f85341f06f28f125b7254e61bf (  master  node - id ) Source node #2 : done # slot ， yes  slot . # Do you want to proceed with the proposed reshard plan ( yes / no ) ? yes b ) : master  redis - trib . rb del - node 10 . 10 . 34 . 14 : 6386 f51e26b5d5ff74f85341f06f28f125b7254e61bf redis-monitor https : // github . com / LittlePeng / redis - monitor RDBAOF RDBAOF RDB 。 AOFServer ， Server 。 MySQL binlog 。 Redis 。 Server 。 RedisAOFRDB 。 RedisAOF ， RDB ， AOF 。  RDB RDBRedis ，  。 RDB ， RDB  ， RDB 。  。  ， Amazon S3 ， RDB 。 RDB ， Redis 。 AOFRDB 。 RDB Redis （  ）  ， RDB 。  ， 5  ， Redis 。 RDBfork ()  。  、 CPUfork () Re disclients 。 AOFfork () logs 。 AOF AOFRedis ： fsync ： no fsync at all 、 fsync every second 、 fsync at every query 。 fsync every second ，  。 AOFappend only ，  。  （  ）   ， redis - check - aof 。 AOF ， RedisAOF 。 RedisAOF 。 Redis  ， Redis 。 AOF 。  。  ， FLUSHALL ， AOF ， Redis ServerFLUSHALLRedis Server 。 AOF AOFRDB 。 fsyncAOFRDB 。 no fsync at allAOFRDB ， fsync every second  ，  fsync at every query 。 RDB 。 bugAOF 。 bugs ，   。 bugsRDB 。  ： Redis AOFRDB ，  RDB 。  ，  ： AOFRedis ， AOF bugs ； AOF 。  ？  ，  ，  。  ， RDB 。  AOF ，  ， RDB ， AOF bugs 。  ， AOFRDB 。 RDB Redisdump . rdb 。 NM 、  、  、  。 redis 2.4.10  ： [ plain ] view plain copy CODE #9001key save 900 1 #30010key save 300 10 #6010000key save 60 10000 #saveRDB # rdbcompression yes # dbfilename dump . rdb # （ AOF ） dir / var / lib / redis / redis . conf 。  SAVE ， RDB 。 SAVE  ，   ， BGSAVE 。 BGSAVE 。  。 Redis ，   ， DB 。 LASTSAVE 。 RDB Redisdump ： Redis forks ； RDB ； RDBRDB 。 Rediscopy - on - write 。 AOF  ， Redis 、  、 RedisRedis  。  ，  。 AOF ，   。  ， AOF ： [ plain ] view plain copy CODE #AOF appendonly no #AOF appendonly yes appendonlyyes ， RedisAOF 。 RedisAOF 。 AOF 、 fsync 、 fsync 、 AOF 。 redis 2.4.10  ： [ plain ] view plain copy CODE #AOF appendfilename appendonly . aof #fsync appendfsync everysec #BGSAVEBGREWRITEAOFfsync ()  （ no ， yes ） no - appendfsync - on - rewrite no #AOF100 % 64mbAOF auto - aof - rewrite - percentage 100 auto - aof - rewrite - min - size 64 mb redis . conf 。   RedisAOF 。 Redis ， AOF  。 RedisBGREWRITEAOFRedis 。 Redis2 .2  BGREWRITEAOF , Redis2 .2  。 copy - on - write ，  ： Redis ； AOF ； memory （ AOF ，  ）； AOFmemory ； Redis 。 fsync Redis ，  ： no fsync at all  。  。 fsync every second  。  ，  。 fsync at every query AOF 。  。  （  ） fsync every second AOF AOFServerAOFRedis 。  ： AOF ； redis - check - aofAOF ； $ redis - check - aof --fix diff - u  （  ）； AOFRedis 。 RDBAOF ？ Redis = 2.2  RDB ；  ；  ； $ redis - cli config set appendonly yes $ redis - cli config set save （  ， RDBAOF ） keys ； writeAOF 。  ： redis . confRedis Server 。 Redis2 .0  RDB ；  ；  ；  redis - cli bgrewriteaofAOF ； AOFRedis Server ； redis . confAOF ； Redis Server ； keys ； writeAOF 。 AOFRDB Redis2 .4 RDBAOFAOFBGSAVE ， Redis I / O 。 RDBBGREWRITEAOFserverok ，   。 AOFRDB ， RedisAOF 。 Redis   。 Redis ， RDB 。  ： cronRDBRDB ； cronfindRDB （  ）； RDBRedis （  ）。  Redis 。  。   ： Amazon S3 。 RDB （ gpg - c ） S3 。   。  。 SCP 。  ： VPS ， ssh ， ssh client keyVPSauthorized_keys ， SCPVPS 。 VPS 。  ，  。 MD5SHA1 。  ，   。 Redis Redis  Redis  Redis  Redis ，，  Redis ，，，  Redis  IO 。 Redis  Slave  Master ，： Slave ： REDIS_REPL_NONE REDIS_REPL_CONNECT REDIS_REPL_CONNECTED Master ： REDIS_REPL_WAIT_BGSAVE_START REDIS_REPL_WAIT_BGSAVE_END REDIS_REPL_SEND_BULK REDIS_REPL_ONLINE ： Slave  slave of ， Slave ， REDIS_REPL_CONNECT 。 Slave  serverCron ( Redis  )  Master ， sync ， master   (  Redis  Slave  ) 。 Master  sync ，，，  Slave 。 Slave  Master ，，，， Master ， ， REDIS_REPL_CONNECTED ， Slave 。 Master ， Slave （ list ）， ， Slave , ， REDIS_REPL_ONLINE 。 ，： Redis  ， Slave  Master ， Master ， Slave ， M ySQL ，，。  Master ， Slave  Master ，  Slave ， Master ， Slave ，， S lave  ，。 ， Redis ，，。 Cache  Storage  Redis ，， Redis ， ，，， Redis ： Cache  Storage ？  Cache ，， Redis ， Memcached ，  Memcached 。  Storage ， Redis ， Redis ， ， G ， Redis ，，？ Redis  1 .  Redis 。  Redis ， Redis ，。  Redis ，，   Redis ， MySQL ， Twitter   gizzard ( https : // github . com / twitter / gizzard ) 。 ，，， 2 ， ？ ，， vector clock  ，，， Paxos  ，。 ， Redis ， Redis ，  Redis ，。 2 .  presharding  Redis 。  Redis ，：。  Redis ，，，   100 G ， 48 G ， Redis  IO ， 3 ~ 4  。 ，，， Redis  ， Redis ？ Redis  presharding ， Redis  ，，。 ：  Redis 。 。 ，，。 。 。 。  Redis ， Redis ， ，，。。 Redis   Redis ,  Redis ， Mysql Binlog  。  Redis  AOF ， AOF ， Redis  Rewrite ， ， AOF ， AOF  ， ， AOF ，， ，  AOF ，， ，。 Redis  MySQL   MySQL ， Redis  MySQL ？  MySQL ， Redis 。  MySQL ， MySQL  Redis 。 （ MySQL - Redis ） ： Redis ，，。 Redis ， Redis  ( aof ),   aof  ，， Redis 。 aof ， 。  presharding  Redis 。  2  Redis ， Redis ， Redis ，，","title":"redis"},{"location":"redis/#redis-dump","text":"yum install ruby rubygems ruby - devel gem sources --add http://gems.ruby-china.org/ --remove http://rubygems.org/ gem sources - l gem install redis - dump redis - dump - u 127 . 0 . 0 . 1 : 6379 data . json (  redis ， 0 )  15 ： redis - dump - u 127 . 0 . 0 . 1 : 6379 - d 15 data . json redis - load - u 192 . 168 . 1 . 3 : 19000 data . json aof   Redis  AOF （ AOF ） # redis - cli - h ip - p port config set appendonly yes  AOF  Redis  (  AOF  append . aof ) # redis - cli - h ip - p 6379 - a pass --pipe appendonly.aof","title":"redis-dump"},{"location":"redis/#codis","text":"wget https : // github . com / CodisLabs / codis / releases / download / 3 . 2 . 0 / codis3 . 2 . 0 - go1 . 7 . 5 - linux . tar . gz (  ) https : // github . com / CodisLabs / codis / archive / release3 . 2 . zip ( ，， )  glibc2 . 14 export LD_LIBRARY_PATH =/ usr / local / glibc - 2 . 14 / lib / : $ LD_LIBRARY_PATH","title":"codis"},{"location":"redis/#twemproxy","text":"https : // github . com / twitter / twemproxy  autoconf wget http : // ftp . gnu . org / gnu / autoconf / autoconf - 2 . 69 . tar . gz tar - zxf autoconf - 2 . 69 . tar . gz cd autoconf - 2 . 69 . / configure --prefix=/usr/local/autoconf make make install wget https : // github . com / twitter / twemproxy / archive / master . zip cd twemproxy - master / / usr / local / autoconf / bin / autoreconf - fvi . / configure --prefix=/usr/local/twemproxy make - j 8 make install cd / usr / local / twemproxy mkdir run conf vim / usr / local / twemproxy / conf / nutcracker . yml  alpha : listen : 127 . 0 . 0 . 1 : 22121 hash : fnv1a_64 distribution : ketama auto_eject_hosts : true redis : true server_retry_timeout : 2000 server_failure_limit : 1 servers : - 127 . 0 . 0 . 1 : 7000 : 1 - 127 . 0 . 0 . 1 : 7001 : 1  . / sbin / nutcracker - t  nutcracker - d - c / usr / local / twemproxy / conf / nutcracker . yml - p / usr / local / twemproxy / run / redisproxy . pid - o / usr / local / twemproxy / run / redisproxy . log","title":"twemproxy"},{"location":"redis/#sentinel","text":" redis  # redis ， vim redis . conf slaveof 192 . 168 . 1 . 5 6379  nohup . / src / redis - server redis . conf redis - cli - h 192 . 168 . 1 . 5 info Replication  # Replication role : master # 192 . 168 . 9 . 18 : 6379  redis  connected_slaves : 1 slave0 : ip = 192 . 168 . 1 . 6 , port = 6379 , state = online , offset = 29 , lag = 0 sentinel . conf  （ sentinel  sentinel ， gossip ） port 26379 dir / tmp # master1 sentinel monitor master1 192 . 168 . 1 . 5 6379 2 # 2 ， 2  sentinel  master ， master ， sentinel ， sentinel  1 sentinel down - after - milliseconds master1 10000 # sentinel  master  PING  master   sentinel parallel - syncs master1 1 # failover ， slave  master ，，  failover ，， slave  replication 。 1  slave 。 sentinel failover - timeout master1 180000 # failover ， # master2  redis  .... . / src / redis - sentinel sentinel . conf  . / src / redis - cli - h 192 . 168 . 1 . 6 - p 26379 info Sentinel  # Sentinel sentinel_masters : 1 sentinel_tilt : 0 sentinel_running_scripts : 0 sentinel_scripts_queue_length : 0 master0 : name = master1 , status = ok , address = 192 . 168 . 1 . 5 : 6379 , slaves = 1 , sentinels = 1  redis ， sentinel  redis   redis ， sentinel  redis ， redis ， reids ： redis Sentinel  info Sentinel  VIP  VIP   failover 。  client - reconfig - script 。 # The following arguments are passed to the script : # # master - name role state from - ip from - port to - ip to - port  6  VIP ， Master ， VIP 。 failover ， ip  arp ，  arping  GRAP 。 ip 、 arping  root ， sudo 。 vim / var / lib / redis / failover . sh chmod 755 / var / lib / redis / failover . sh chown redis : / var / lib / redis / failover . sh echo - e redis \\t ALL=(ALL) \\t NOPASSWD:/sbin/ip,NOPASSWD:/sbin/arping / etc / sudoers . d / redis sed - i s|Defaults.*requiretty|#Defaults \\t requiretty| / etc / sudoers chmod 440 / etc / sudoers . d / redis # !/ bin / bash MASTER_IP = ${ 6 } MY_IP = 192.168.0.1 #  Server  IP VIP = 192.168.0.4 # VIP NETMASK = 24 # Netmask INTERFACE = eth0 #  if [ ${ MASTER_IP } = ${ MY_IP } ] ; then sudo / sbin / ip addr add ${ VIP } / ${ NETMASK } dev ${ INTERFACE } sudo / sbin / arping - q - c 3 - A ${ VIP } - I ${ INTERFACE } exit 0 else sudo / sbin / ip addr del ${ VIP } / ${ NETMASK } dev ${ INTERFACE } exit 0 fi exit 1 Redis - Sentinel   redis - sentonel 。  VIP 。 vim / etc / redis - sentinel . conf service redis - sentinel start chkconfig redis - sentinel on ip addr add 192 . 168 . 0 . 4 / 24 dev eth0 # sentinel . conf port 26379 logfile / var / log / redis / sentinel . log sentinel monitor mymaster 192 . 168 . 0 . 1 6379 2 sentinel down - after - milliseconds mymaster 3000 sentinel parallel - syncs mymaster 1 sentinel failover - timeout mymaster 60000 sentinel client - reconfig - script mymaster / var / lib / redis / failover . sh   kill master  failover ，。 sentinel down - after - milliseconds mymaster 3000  3  redis 。，。","title":"sentinel"},{"location":"redis/#redis","text":"tar zxf redis - 3 . 0 . 2 . tar . gz cd redis - 3 . 0 . 2 make cd src make install cp .. / redis . conf / etc  redis - server / dev / null  redis - server redis . conf  redis - server / etc / redis . conf 1 log . log 2 errlog . log （ 1 ， 2 ）  redis - cli shutdown  redis - cli ： redis - cli set hx value ： redis - cli get hx quit  dbsize ( integer ) 12  key  info  monitor  config get  flushdb  flushall   01 exits key //  key ， 1 ， 0  02 del key1 key2 .... keyN //  key , key ， 0  key  03 type key //  key  value 。 none  key , string ， list  set ... 04 keys pattern //  key , 05 randomkey //  key ,， 06 rename oldkey newkey //  key , newkey ，， 1 ， 0 。 oldkey   newkey  07 renamenx oldkey newkey // ， newkey  08 dbsize //  key  09 expire key seconds //  key ，。 1 ， 0  key  10 ttl key //  key  - 1  key  11 select db - index // ， 0 , 16 。 1 ， 0  12 move key db - index //  key 。 1 。 0  key ， 13 flushdb //  key ,。 14 flushall //  key ，。 string  01 set key value //  key  string  value , 1 ， 0  02 setnx key value // ， key ， 0 。 nx  not exist  03 get key //  key  string , key  nil 04 getset key value //  key ， key 。 key  nil 05 mget key1 key2 ... keyN //  key ， key ， nil 。, ， k1 , k2 . k3  nil 06 mset key1 value1 ... keyN valueN //  key ， 1 ， 0  07 msetnx key1 value1 ... keyN valueN // ， key 08 incr key //  key ,。 incr  int  value ， incr  key ， key  1 09 decr key // ，， decr  key ， key  - 1 10 incrby key integer //  incr ， ， key  key ， value  0 11 decrby key integer //  decr ，。 decrby ， incrby ，。 12 append key value //  key  value ,。 13 substr key start end //  key , key 。 0 ， list  01 lpush key string //  key  list ， 1 ， 0  key  list  02 rpush key string // ， 03 llen key //  key  list ， key  0 , key  list  04 lrange key start end // ， 0 ，， - 1  ， key  05 ltrim key start end //  list ，， 1 ， key  06 lset key index value //  list ， 1 ， key  07 lrem key count value //  key  list  count  value 。 count  0  08 lpop key //  list ，。 key  list  nil ， key   list  09 rpop // ， 10 blpop key1 ... keyN timeout //  list  lpop ， blpop list1 list2 list3 0 ,  list  list2 , list3  list2  lpop  list2 。 list ， timeout ， timeout  0 。， client  key1 ... keyN  key  push ， key  client 。 ， nil 。 unix  select  poll 11 brpop //  blpop ， 12 rpoplpush srckey destkey //  srckey  list  destkey  list ,， . srckey  nil set  01 sadd key member //  string , key  set ， 1 , 0 , key  set  02 srem key member //  key  set ， 1 ， member  key  0 ，  key  set  03 spop key //  key  set , set  key  nil 04 srandmember key //  spop ， set ， 05 smove srckey dstkey member //  srckey  set  member  dstkey  set ，。 1 ,  member  srckey  0 ， key  set  06 scard key //  set ， set  key  0 07 sismember key member //  member  set ， 1 ， 0  key  08 sinter key1 key2 ... keyN //  key  09 sinterstore dstkey key1 ... keyN //  sinter ， dstkey  10 sunion key1 key2 ... keyN //  key  11 sunionstore dstkey key1 ... keyN //  sunion ， dstkey  12 sdiff key1 key2 ... keyN //  key  13 sdiffstore dstkey key1 ... keyN //  sdiff ， dstkey  14 smembers key //  key  set ， sorted set  01 zadd key score member // ， score 02 zrem key member // ， 1 ， 0 03 zincrby key incr member //  member  score ， skip list 。 score  04 zrank key member // （）, score  05 zrevrank key member // , score  06 zrange key start end //  lrange 。 07 zrevrange key start end // ， score  08 zrangebyscore key min max //  score  09 zcount key min max //  score  10 zcard key //  11 zscore key element //  score 12 zremrangebyrank key min max //  13 zremrangebyscore key min max //  score  hash  01 hset key field value //  hash field ， key ， 02 hget key field //  hash field 03 hmget key filed1 .... fieldN //  hash filed 04 hmset key filed1 value1 ... filedN valueN //  hash  field 05 hincrby key field integer //  hash filed  06 hexists key field //  field  07 hdel key field //  hash field 08 hlen key //  hash  field  09 hkeys key //  hash  field 10 hvals key //  hash  value 11 hgetall //  hash  filed  value redis . conf ：  # daemonize yes # pid ， pidfile redis . pid # Redis  port 6379 #， timeout 300 # loglevel verbose #， logfile stdout #， 0 ， select N  databases 16 # disk  # Keys ， 900  disk  save 900 1 # 10  Keys ， 300  disk  save 300 10 # 1 w  keys ， 60  disk  save 60 10000 # dump . rdb  rdbcompression yes # dump  dbfilename dump . rdb # Redis  dir / home / falcon / redis - 2 . 0 . 0 / ########### Replication ##################### # Redis  # slaveof masterip masterport # masterauth master - password ############## SECURITY ########### # requirepass foobared ############### LIMITS ############## # # maxclients 128 # # maxmemory bytes ########## APPEND ONLY MODE ######### # appendonly no #  disk  # appendfsync always appendfsync everysec # appendfsync no ################ VIRTUAL MEMORY ########### # VM  vm - enabled no # vm - enabled yes vm - swap - file logs / redis . swap vm - max - memory 0 vm - page - size 32 vm - pages 134217728 vm - max - threads 4 ############# ADVANCED CONFIG ############### glueoutputbuf yes hash - max - zipmap - entries 64 hash - max - zipmap - value 512 # Hash  activerehashing yes spring  redis  java Clients ， redis  Jedis ， spring  redis ， ( Jedis , JRedis , and RJC ) ，  SPRING DATA - REDIS 。 1 、 maven ，。 2 、 pom . xml repository id spring - milestone / id name Spring Maven MILESTONE Repository / name url http : // maven . springframework . org / milestone / url / repository dependency groupId org . springframework . data / groupId artifactId spring - data - redis / artifactId version 1 . 0 . 0 . RC1 / version / dependency spring  bean id = jedisConnectionFactory class = org.springframework.data.redis.connection.jedis.JedisConnectionFactory property name = hostName value = localhost / property name = port value = 6636 / / bean bean id = redisTemplate class = org.springframework.data.redis.core.RedisTemplate property name = connectionFactory ref = jedisConnectionFactory / / bean Java  @ Service public class RedisService { @ Resource private RedisTemplate Serializable , Serializable template ; /** * rediskey-value * * @param key key * @param value value */ public void set ( final Serializable key , final Serializable value ) { template . execute ( new RedisCallback Object () { @ Override public Object doInRedis ( RedisConnection connection ) throws DataAccessException { byte [] key_ = RedisUtil . getBytesFromObject ( key ) ; byte [] value_ = RedisUtil . getBytesFromObject ( value ) ; connection . set ( key_ , value_ ) ; return true ; } } ) ; } /** * keyredisvalue * * @param key key */ public Serializable get ( final Serializable key ) { return template . execute ( new RedisCallback Serializable () { @ Override public Serializable doInRedis ( RedisConnection connection ) throws DataAccessException { byte [] keyBytes = RedisUtil . getBytesFromObject ( key ) ; byte [] bytes = connection . get ( keyBytes ) ; return ( Serializable ) RedisUtil . getObjectFromBytes ( bytes ) ; } } ) ; } }  JedisConnectionFactory ， Jedis ，。","title":"redis"},{"location":"redis/#web","text":"https : // github . com / erikdubbelboer / phpRedisAdmin https : // github . com / nrk / predis cd / var / www / html / wget https : // github . com / erikdubbelboer / phpRedisAdmin / archive / master . zip unzip master . zip rm - f master . zip cd phpRedisAdmin wget https : // github . com / nrk / predis / archive / v1 . 1 . zip ， vendor unzip v1 . 1 . zip rm - f v1 . 1 . zip mv predis - 1 . 1 vendor vim phpRedisAdmin / includes / config . sample . inc . php  redis ,（， redis ）  php ， yum search redis | grep php php - nrk - Predis . noarch : PHP client library for Redis php - pecl - redis . x86_64 : Extension for communicating with the Redis key - value php - redis . x86_64 : Extension for communicating with the Redis key - value store http : // ip / phpredis /","title":"web"},{"location":"redis/#redis-cluster","text":": redis cluster 1 : redis cluster  reids - cluster  redis3 . 0 ， antirez : http : // antirez . com / news / 49 ( ps :， ) ,  redis3 beta2 ( 2 . 9 . 51 ) . : Redis Cluster will support up to ~ 1000 nodes . ...  redis  cluster  (  ) : 1 ) : 2 ) : slave - master , 3 ) : Hot resharding : 4 ) :: cluster xxx 5 ) : ( nodes - port . conf )  6 ) : ASK  / MOVED . 2 : redis cluster  1 ) redis - cluster  : ( 1 )  redis  ( PING - PONG  ) ,. ( 2 )  fail . ( 3 )  redis , proxy ., ( 4 ) redis - cluster [ 0 - 16383 ] slot , cluster  node - slot - value 2 ) redis - cluster : ( 1 )  master , master  master  ( cluster - node - timeout ) , master . ( 2 ) : ( cluster_state : fail ) ,,， (( error ) CLUSTERDOWN The cluster is down )  a : master , master  slave . fail , slot [ 0 - 16383 ] fail . b : master ， slave  fail . : redis cluster  1 : redis cluster 1 ) : redis - cluster : redis - cluster , reshard ,. ( 1 )  zlib , gem install  ( no such file to load -- zlib ) # download : zlib - 1 . 2 . 6 . tar . / configure make make install ( 1 )  ruby : version ( 1 . 9 . 2 ) # ruby1 . 9 . 2 cd / path / ruby . / configure - prefix =/ usr / local / ruby make make install sudo cp ruby / usr / local / bin ( 2 )  rubygem : version ( 1 . 8 . 16 ) # rubygems - 1 . 8 . 16 . tgz cd / path / gem sudo ruby setup . rb sudo cp bin / gem / usr / local / bin ( 3 )  gem - redis : version ( 3 . 0 . 0 ) gem install redis -- version 3 . 0 . 0 #， https : // ruby . taobao . org / $ gem sources -- add https : // ruby . taobao . org / -- remove https : // rubygems . org / $ gem sources - l *** CURRENT SOURCES *** https : // ruby . taobao . org #  ruby . taobao . org $ gem install rails 2 )  redis - cluster cd / path / redis make sudo cp / opt / redis / src / redis - server / usr / local / bin sudo cp / opt / redis / src / redis - cli / usr / local / bin sudo cp / opt / redis / src / redis - trib . rb / usr / local / bin 2 : redis cluster 1 ) redis :  ( include ) ,. 2 ) redis . # GENERAL daemonize no tcp - backlog 511 timeout 0 tcp - keepalive 0 loglevel notice databases 16 dir / opt / redis / data slave - serve - stale - data yes # slave  slave - read - only yes # not use default repl - disable - tcp - nodelay yes slave - priority 100 # aof  appendonly yes # aof  appendfsync everysec # aof rewrite  fsync no - appendfsync - on - rewrite yes auto - aof - rewrite - min - size 64 mb lua - time - limit 5000 # redis  cluster - enabled yes # cluster - node - timeout 15000 cluster - migration - barrier 1 slowlog - log - slower - than 10000 slowlog - max - len 128 notify - keyspace - events hash - max - ziplist - entries 512 hash - max - ziplist - value 64 list - max - ziplist - entries 512 list - max - ziplist - value 64 set - max - intset - entries 512 zset - max - ziplist - entries 128 zset - max - ziplist - value 64 activerehashing yes client - output - buffer - limit normal 0 0 0 client - output - buffer - limit slave 256 mb 64 mb 60 client - output - buffer - limit pubsub 32 mb 8 mb 60 hz 10 aof - rewrite - incremental - fsync yes 3 ) redis . # include / opt / redis / redis - common . conf # tcp  port 6379 # maxmemory 100 m #: # volatile - lru - remove the key with an expire set using an LRU algorithm # allkeys - lru - remove any key accordingly to the LRU algorithm # volatile - random - remove a random key with an expire set # allkeys - random - remove a random key , any key # volatile - ttl - remove the key with the nearest expire time ( minor TTL ) # noeviction - don t expire at all, just return an error on write operations maxmemory - policy allkeys - lru # aof  appendfilename appendonly-6379.aof # rdb , slave  dbfilename dump - 6379 . rdb # cluster  (  ) cluster - config - file nodes - 6379 . conf # redis ， span style = font-size: 1em; line - height : 1 . 5 ; auto-aof-rewrite，forkredisrewrite, /span auto - aof - rewrite - percentage 80 - 100 3 : cluster  cluster , redis : http : // redis . readthedocs . org / en / latest /  CLUSTER INFO  CLUSTER NODES （ node ），。  CLUSTER MEET ip port  ip  port ，。 CLUSTER FORGET node_id  node_id 。 CLUSTER REPLICATE node_id  node_id 。 CLUSTER SAVECONFIG 。  ( slot ) CLUSTER ADDSLOTS slot [ slot ...]  （ slot ）（ assign ）。 CLUSTER DELSLOTS slot [ slot ...] 。 CLUSTER FLUSHSLOTS ，。 CLUSTER SETSLOT slot NODE node_id  slot  node_id ，，  ，。 CLUSTER SETSLOT slot MIGRATING node_id  slot  node_id 。 CLUSTER SETSLOT slot IMPORTING node_id  node_id   slot 。 CLUSTER SETSLOT slot STABLE  slot （ import ）（ migrate ）。  CLUSTER KEYSLOT key  key 。 CLUSTER COUNTKEYSINSLOT slot  slot 。 CLUSTER GETKEYSINSLOT slot count  count  slot 。 4 : redis cluster  1 )  ( 1 ) #（）, redis - server / opt / redis / conf / redis - 6380 . conf / opt / redis / logs / redis - 6380 . log 2 1 redis - server / opt / redis / conf / redis - 6381 . conf / opt / redis / logs / redis - 6381 . log 2 1 redis - server / opt / redis / conf / redis - 6382 . conf / opt / redis / logs / redis - 6382 . log 2 1 redis - server / opt / redis / conf / redis - 7380 . conf / opt / redis / logs / redis - 7380 . log 2 1 redis - server / opt / redis / conf / redis - 7381 . conf / opt / redis / logs / redis - 7381 . log 2 1 redis - server / opt / redis / conf / redis - 7382 . conf / opt / redis / logs / redis - 7382 . log 2 1 ( 2 ) : ruby  ( redis - trib . rb )  # redis - trib . rb  create  # -- replicas  Redis Cluster  Master  Slave  #, master  slave ( , slave  master  1000 ) redis - trib . rb create -- replicas 1 10 . 10 . 34 . 14 : 6380 10 . 10 . 34 . 14 : 6381 10 . 10 . 34 . 14 : 6382 10 . 10 . 34 . 14 : 7380 10 . 10 . 34 . 14 : 7381 10 . 10 . 34 . 14 : 7382 ( 3 ) :, # redis - trib . rb  check  # ip : port  redis - trib . rb check 1 10 . 10 . 34 . 14 : 6380 ,， ok  [ OK ] All nodes agree about slots configuration . Check for open slots ... Check slots coverage ... [ OK ] All 16384 slots covered . redis - cli - c - p 6379 ( - c  ) 2 ) : master  ( 1 )  master :（ empty node ）， slot , a ) : ( ps : establish_config . sh  ) sh establish_config . sh 6386 conf / redis - 6386 . conf b ) : nohup redis - server / opt / redis / conf / redis - 6386 . conf / opt / redis / logs / redis - 6386 . log 2 1 c ) : add - node ，  ip : port ,  ip : port redis - trib . rb add - node 10 . 10 . 34 . 14 : 6386 10 . 10 . 34 . 14 : 6381 node :，  slot 。， ，  d ) : slot redis - trib . rb reshard 10 . 10 . 34 . 14 : 6386 # slot  ( ps : 500 ) How many slots do you want to move ( from 1 to 16384 ) ? 500 # slot  node - id What is the receiving node ID ? f51e26b5d5ff74f85341f06f28f125b7254e61bf # slot : # all  master ， # slot  master  id , done  Please enter all the source node IDs . Type all to use all the nodes as source nodes for the hash slots . Type done once you entered all the source nodes IDs . Source node #1 : all # slot ， yes  slot . # Do you want to proceed with the proposed reshard plan ( yes / no ) ? yes # 3 ) : slave  a ) : master  b ) : redis - cli  shell ,: cluster replicate  master  node - id cluster replicate 2 b9ebcbd627ff0fd7a7bbcc5332fb09e72788835 note : slave ， dump  master ， slave ， slave  rdb ， rdb  Master , io ,.  slave  rdb  - rw - r -- r -- 1 root root 34946 Apr 17 18 : 23 dump - 6386 . rdb - rw - r -- r -- 1 root root 34946 Apr 17 18 : 23 dump - 7386 . rdb 4 ) : reshard :  / ， reshard slot , master  reshard ， reshard  master . 5 ) : slave  # redis - trib del - node ip : port node-id redis - trib . rb del - node 10 . 10 . 34 . 14 : 7386 c7ee2fca17cb79fe3c9822ced1d4f6c5e169e378 a ) : master  reshard  master  slot , (  master  slot  ) # 10 . 10 . 34 . 14 : 6386  master  10 . 10 . 34 . 14 : 6380  redis - trib . rb reshard 10 . 10 . 34 . 14 : 6380 # slot  ( ps : 500 ) How many slots do you want to move ( from 1 to 16384 ) ? 500 (  master  slot  ) # slot  node - id ( 10 . 10 . 34 . 14 : 6380 ) What is the receiving node ID ? c4a31c852f81686f6ed8bcd6d1b13accdc947fd2 ( ps : 10 . 10 . 34 . 14 : 6380  node - id ) Please enter all the source node IDs . Type all to use all the nodes as source nodes for the hash slots . Type done once you entered all the source nodes IDs . Source node #1 : f51e26b5d5ff74f85341f06f28f125b7254e61bf (  master  node - id ) Source node #2 : done # slot ， yes  slot . # Do you want to proceed with the proposed reshard plan ( yes / no ) ? yes b ) : master  redis - trib . rb del - node 10 . 10 . 34 . 14 : 6386 f51e26b5d5ff74f85341f06f28f125b7254e61bf","title":"redis cluster"},{"location":"redis/#redis-monitor","text":"https : // github . com / LittlePeng / redis - monitor","title":"redis-monitor"},{"location":"redis/#rdbaof","text":"RDBAOF RDB 。 AOFServer ， Server 。 MySQL binlog 。 Redis 。 Server 。 RedisAOFRDB 。 RedisAOF ， RDB ， AOF 。  RDB RDBRedis ，  。 RDB ， RDB  ， RDB 。  。  ， Amazon S3 ， RDB 。 RDB ， Redis 。 AOFRDB 。 RDB Redis （  ）  ， RDB 。  ， 5  ， Redis 。 RDBfork ()  。  、 CPUfork () Re disclients 。 AOFfork () logs 。 AOF AOFRedis ： fsync ： no fsync at all 、 fsync every second 、 fsync at every query 。 fsync every second ，  。 AOFappend only ，  。  （  ）   ， redis - check - aof 。 AOF ， RedisAOF 。 RedisAOF 。 Redis  ， Redis 。 AOF 。  。  ， FLUSHALL ， AOF ， Redis ServerFLUSHALLRedis Server 。 AOF AOFRDB 。 fsyncAOFRDB 。 no fsync at allAOFRDB ， fsync every second  ，  fsync at every query 。 RDB 。 bugAOF 。 bugs ，   。 bugsRDB 。  ： Redis AOFRDB ，  RDB 。  ，  ： AOFRedis ， AOF bugs ； AOF 。  ？  ，  ，  。  ， RDB 。  AOF ，  ， RDB ， AOF bugs 。  ， AOFRDB 。 RDB Redisdump . rdb 。 NM 、  、  、  。 redis 2.4.10  ： [ plain ] view plain copy CODE #9001key save 900 1 #30010key save 300 10 #6010000key save 60 10000 #saveRDB # rdbcompression yes # dbfilename dump . rdb # （ AOF ） dir / var / lib / redis / redis . conf 。  SAVE ， RDB 。 SAVE  ，   ， BGSAVE 。 BGSAVE 。  。 Redis ，   ， DB 。 LASTSAVE 。 RDB Redisdump ： Redis forks ； RDB ； RDBRDB 。 Rediscopy - on - write 。 AOF  ， Redis 、  、 RedisRedis  。  ，  。 AOF ，   。  ， AOF ： [ plain ] view plain copy CODE #AOF appendonly no #AOF appendonly yes appendonlyyes ， RedisAOF 。 RedisAOF 。 AOF 、 fsync 、 fsync 、 AOF 。 redis 2.4.10  ： [ plain ] view plain copy CODE #AOF appendfilename appendonly . aof #fsync appendfsync everysec #BGSAVEBGREWRITEAOFfsync ()  （ no ， yes ） no - appendfsync - on - rewrite no #AOF100 % 64mbAOF auto - aof - rewrite - percentage 100 auto - aof - rewrite - min - size 64 mb redis . conf 。   RedisAOF 。 Redis ， AOF  。 RedisBGREWRITEAOFRedis 。 Redis2 .2  BGREWRITEAOF , Redis2 .2  。 copy - on - write ，  ： Redis ； AOF ； memory （ AOF ，  ）； AOFmemory ； Redis 。 fsync Redis ，  ： no fsync at all  。  。 fsync every second  。  ，  。 fsync at every query AOF 。  。  （  ） fsync every second AOF AOFServerAOFRedis 。  ： AOF ； redis - check - aofAOF ； $ redis - check - aof --fix diff - u  （  ）； AOFRedis 。 RDBAOF ？ Redis = 2.2  RDB ；  ；  ； $ redis - cli config set appendonly yes $ redis - cli config set save （  ， RDBAOF ） keys ； writeAOF 。  ： redis . confRedis Server 。 Redis2 .0  RDB ；  ；  ；  redis - cli bgrewriteaofAOF ； AOFRedis Server ； redis . confAOF ； Redis Server ； keys ； writeAOF 。 AOFRDB Redis2 .4 RDBAOFAOFBGSAVE ， Redis I / O 。 RDBBGREWRITEAOFserverok ，   。 AOFRDB ， RedisAOF 。 Redis   。 Redis ， RDB 。  ： cronRDBRDB ； cronfindRDB （  ）； RDBRedis （  ）。  Redis 。  。   ： Amazon S3 。 RDB （ gpg - c ） S3 。   。  。 SCP 。  ： VPS ， ssh ， ssh client keyVPSauthorized_keys ， SCPVPS 。 VPS 。  ，  。 MD5SHA1 。  ，   。","title":"RDBAOF"},{"location":"redis/#redis_1","text":"Redis  Redis  Redis  Redis ，，  Redis ，，，  Redis  IO 。 Redis  Slave  Master ，： Slave ： REDIS_REPL_NONE REDIS_REPL_CONNECT REDIS_REPL_CONNECTED Master ： REDIS_REPL_WAIT_BGSAVE_START REDIS_REPL_WAIT_BGSAVE_END REDIS_REPL_SEND_BULK REDIS_REPL_ONLINE ： Slave  slave of ， Slave ， REDIS_REPL_CONNECT 。 Slave  serverCron ( Redis  )  Master ， sync ， master   (  Redis  Slave  ) 。 Master  sync ，，，  Slave 。 Slave  Master ，，，， Master ， ， REDIS_REPL_CONNECTED ， Slave 。 Master ， Slave （ list ）， ， Slave , ， REDIS_REPL_ONLINE 。 ，： Redis  ， Slave  Master ， Master ， Slave ， M ySQL ，，。  Master ， Slave  Master ，  Slave ， Master ， Slave ，， S lave  ，。 ， Redis ，，。 Cache  Storage  Redis ，， Redis ， ，，， Redis ： Cache  Storage ？  Cache ，， Redis ， Memcached ，  Memcached 。  Storage ， Redis ， Redis ， ， G ， Redis ，，？ Redis  1 .  Redis 。  Redis ， Redis ，。  Redis ，，   Redis ， MySQL ， Twitter   gizzard ( https : // github . com / twitter / gizzard ) 。 ，，， 2 ， ？ ，， vector clock  ，，， Paxos  ，。 ， Redis ， Redis ，  Redis ，。 2 .  presharding  Redis 。  Redis ，：。  Redis ，，，   100 G ， 48 G ， Redis  IO ， 3 ~ 4  。 ，，， Redis  ， Redis ？ Redis  presharding ， Redis  ，，。 ：  Redis 。 。 ，，。 。 。 。  Redis ， Redis ， ，，。。 Redis   Redis ,  Redis ， Mysql Binlog  。  Redis  AOF ， AOF ， Redis  Rewrite ， ， AOF ， AOF  ， ， AOF ，， ，  AOF ，， ，。 Redis  MySQL   MySQL ， Redis  MySQL ？  MySQL ， Redis 。  MySQL ， MySQL  Redis 。 （ MySQL - Redis ） ： Redis ，，。 Redis ， Redis  ( aof ),   aof  ，， Redis 。 aof ， 。  presharding  Redis 。  2  Redis ， Redis ， Redis ，，","title":"Redis"},{"location":"saltstack/","text":"status $ ID :  state ，， apache 、 nginx  $ State : ， http : // docs . saltstack . com / ref / states / all / index . html - $ state : states  salt \\ * state . sls dhcp  salt \\ * state . sls dhcp / aaa  dhcp  aaa . sls salt \\ * state . sls dhcp test = True ， minion salt \\ * state . highstate / usr / lib / python2 . 6 / site - packages / salt / states  modules / usr / lib / python2 . 6 / site - packages / salt / modules  states ， / srv / salt  sls  state  file_roots : base : - / srv / salt  state  vim / srv / salt / dhcp / init . sls include : - dhcp . python_devel  dhcp  python_devel . sls cat / srv / salt / dhcp / python_devel . sls dhcp : pkg . installed salt \\ * state . sls dhcp [ root @ node1 salt ]# cat top . sls base : * : - test  test . sls test  sls  （ init . sls ） [ root @ node1 salt ]# cat test . sls httpd : # id (  name  ) pkg : # state - installed # state  state  / usr / lib / python2 . 6 / site - packages / salt / states  state salt node2 state . highstate sls （ require ） httpd : ID pkg : states  - installed  service . running : - require : ， - pkg : httpd  sls （. sls ） [ root @ node1 salt ]# salt node2 state . sls test ， ############################################### httpd : pkg : - installed service : - running - require : - pkg : httpd - watch : ， - file : / etc / httpd / conf / httpd . conf / etc / httpd / conf / httpd . conf : file : - managed - source : salt : // httpd . conf - require : - pkg : httpd ################################################ apache : pkg : - name : httpd - installed service . running : - name : httpd - require : - pkg : httpd - watch : - file : apache_config apache_config : file . managed : - name : / etc / httpd / conf / httpd . conf - source : salt : // httpd . conf - template : jinja  apache_config  jinja  - require : - pkg : httpd httpd . conf 1 、  2 、  3 、  https : // docs . saltstack . com / en / latest / ref / states / all / index . html vim user . sls { % for user in [ test1 , test1 , test3 , test4 ] % }  {{ user }}:  user . present { % endfor % } （ if  endif ）  sls  vim / srv / salt / top . sls base : ‘ * ’ - user - apache_start salt \\ * state . highstate  nginx nginx_source : file . recurse : # file . managed :， file . recurse  - name : / tmp / - source : salt : // nginx / extract_nginx : cmd . run : - cwd : / tmp - names : #  names ， name - tar xf nginx - 1 . 6 . 2 . tar . gz - tar xf pcre - 8 . 35 . tar . gz - require : - file : nginx_source nginx_compile : cmd . run : - cwd : / tmp / nginx - 1 . 6 . 2 - names : - . / configure -- prefix =/ usr / local / nginx -- with - pcre =/ tmp / pcre - 8 . 35 make - make install - require : - cmd : extract_nginx  state  sls  module  state  / usr / lib / python2 . 6 / site - packages / salt / states mkdir - pv / srv / salt / _states [ root @ node1 _states ]# cat wjj . py def bs ( name , x ) :  ret = {  name : name , changes : {}, result : False , comment : test_state  } try : result = x * x  ret [ changes ][ new ] = result ret [ result ] = True except :  ret [ changes ][ new ] = jisuan cuwu return ret  name  salt * saltutil . sync_all  state  sls  [ root @ node1 _states ]# cat / srv / salt / jisuan . sls test : wjj : - bs - x : 3 salt node2 state . sls jisuan tips : state  salt  __salt__ [ . ] (  ) # encoding = utf - 8 import logging import os log = logging . getLogger ( __name__ ) def touch ( name , path , file ) : ret = { name : name , changes : {}, result : True , comment : test_state } # log . error ( name ) # log . error ( path ) try : with open ( path + / + str ( file ) , w ) as f : f . write ( my test! ) except Exception , e : log . error ( str ( e )) return ret def delete ( name , path , file ) : ret = { name : name , changes : {}, result : True , comment : test_state } cmd = rm -fr + path + / + file os . system ( cmd ) ret [ result ] = True return ret pillar https : // docs . saltstack . com / en / latest / topics / pillar / index . html  / etc / salt / master  pillar_opts : Ture  False   / srv / pillar vim / srv / pillar / top . sls base : * : - vimrc - data - pkg vim / srv / pillar / data . sls bind : port : 53 listen - on : any vim / srv / pillar / vimrc . sls { % if grains [ id ]. endswith ( server ) % } id  server   startswith vimrc : salt : // edit / vimrc1 { % else % } vimrc : salt : // edit / vimrc2 { % endif % } vim / srv / pillar / pkg . sls { % if grains [ os ] == RedHat % } ， apache : httpd git : git { % elif grains [ os ] == Debian % } apache : apache2 git : git - core { % endif % }  salt * saltutil . refresh_pillar  salt \\ * pillar . items  pillar  state 、，“{{ pillar }}”，： {{ pillar [ appname ] }}（） {{ pillar [ flow ][ maxconn ] }}（） {{ salt [ pillar.get ] ( flow: maxconn , {}) }} Python API ： pillar [ flow ][ maxconn ] pillar . get ( flow:appname , {} ) 1 、 state  sls  vim / srv / salt / down_vimrc . sls / root / . vimrc : file . managed : - source : {{ pillar [ vimrc ] }}  pillar  - source : {{ salt [ pillar.get ] ( vimrc , salt://edit/vimrc2 ) }} pillar  key ， salt \\ * state . show_sls down_vimrc  2 、 salt - I nginx:80 cmd . run ls - I  pillar 3 、 pillar  vim / srv / salt / pillar_temp . sls { % set u = pillar [ u_name ] % }  pillar {{ u }}: user . present salt node2 state . sls pillar_temp pillar = { u_name : v1 }  pillar job [ root@salt-master salt ] # salt - I nginx:80 cmd . run sleep 100 - v Executing job with jid 20151011154835704857 salt - run job salt - run - d | grep jobs salt - run jobs . active jobs salt - run jobs . list_job 20130916125524463507 jidjobs salt - run jobs . list_jobs #jobs salt - run jobs . lookup_jid 20130916125524463507 #jidjobs salt - run jobs . print_job #jidjobs ------------------------------------------------- saltutiljob salt \\ * sys . doc saltutil | grep job salt * saltutil . find_cached_job job id #job cache salt node2 saltutil . find_job 20150810003021849521 jid salt node2 saltutil . is_running cmd . run  salt node2 saltutil . kill_job 20150810003232388165 job saltutil . running #minion ⾏ jobs saltutil . find_job jid #jidjob ( minion ⾏ jobs ) saltutil . signal_job jid single #jid saltutil . term_job jid # ⽌ jid ( 15 ) saltutil . kill_job jid # ⽌ jid ( 9 ) return  minion 。 Minion 。 event  Master  Return 。： http : // pengyao . org / salt - stack_master_retuner_over_event_system . html  redis   minion  / etc / salt / minion  redis . db : 0 #redis redis . host : vps.shencan.net #redis(ip) redis . port : 6379 #redis minion  redis  pip install redis python - c import redis; print redis.VERSION salt Minion cmd . run hostname -- return redis mysql  / usr / lib / python2 . 6 / site - packages / salt / returners /  cat mysql . py vim / etc / salt / minion （） mysql . host : 10.255.254.221 mysql . user : salt mysql . pass : 123 mysql . db : salt mysql . port : 3306  10.255 . 254.221  mysql   mysql   mysql ， salt ，， 123 GRANT ALL PRIVILEGES ON *.* TO salt @ % IDENTIFIED BY ‘ 123 ’；  sql  / tmp / salt . sql ， mysql - u root / tmp / salt . sql (  salt ， salt  jids ， salt_returns ) GRANT ALL PRIVILEGES ON *.* TO salt @ % IDENTIFIED BY ‘ 123 ’； CREATE DATABASE `salt` DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci ; USE `salt` ; DROP TABLE IF EXISTS `jids` ; CREATE TABLE `jids` ( `jid` varchar ( 255 ) NOT NULL , `load` mediumtext NOT NULL , UNIQUE KEY `jid` ( `jid` ) ) ENGINE = InnoDB DEFAULT CHARSET = utf8 ; DROP TABLE IF EXISTS `salt_returns` ; CREATE TABLE `salt_returns` ( `fun` varchar ( 50 ) NOT NULL , `jid` varchar ( 255 ) NOT NULL , `return` mediumtext NOT NULL , `id` varchar ( 255 ) NOT NULL , `success` varchar ( 10 ) NOT NULL , `full_ret` mediumtext NOT NULL , `alter_time` TIMESTAMP DEFAULT CURRENT_TIMESTAMP , KEY `id` ( `id` ), KEY `jid` ( `jid` ), KEY `fun` ( `fun` ) ) ENGINE = InnoDB DEFAULT CHARSET = utf8 ; DROP TABLE IF EXISTS `salt_events` ; CREATE TABLE `salt_events` ( `id` BIGINT NOT NULL AUTO_INCREMENT , `tag` varchar ( 255 ) NOT NULL , `data` varchar ( 1024 ) NOT NULL , `alter_time` TIMESTAMP DEFAULT CURRENT_TIMESTAMP , `master_id` varchar ( 255 ) NOT NULL , PRIMARY KEY ( `id` ), KEY `tag` ( `tag` ) ) ENGINE = InnoDB DEFAULT CHARSET = utf8 ;  python  mysql  yum install MySQL - python - y  mysql  returner ， mysql [ root @node1 ~ ] # salt node2 test.ping --return mysql node2 : True ----------------------------------------------------------------  salt  schedule  minion 。 schedule : uptime : function : status . uptime seconds : 60 returner : mysql meminfo : function : status . meminfo minutes : 5 returner : mysql api web  # chmod 755 / etc / salt / master / var / run / salt / var / cache / salt  master  external_auth : pam : a1 : - * : - test . * - cmd . * http : // docs . saltstack . com / en / latest / topics / eauth / index . html # acl - eauth  a1  salt - a pam * test . ping salt - a pam * cmd . run whoami  $ salt - T - a pam web \\ * test . ping [ a1 @ zabbix_server ~ ]$ salt - T - a pam * test . ping username : a1 password : zabbixnode1 . example . com : True API yum install salt - api - y cd / etc / pki / tls / certs # ,  key  RDNs make testcert cd / etc / pki / tls / private / #  key ， key ,  key ， openssl rsa - in localhost . key - out localhost_nopass . key  yum install gcc make python - devel libffi - develpip - python install PyOpenSSL salt - call tls . create_self_signed_cert #， salt - minion ， salt - call  salt - minion   saltapi . conf  vim / etc / salt / master . d / saltapi . conf rest_cherrypy : port : 8000 host : 127 . 0 . 0 . 1 # disable_ssl : true  https ssl_crt : / etc / pki / tls / certs / localhost . crt # ssl_key : / etc / pki / tls / certs / localhost . key external_auth : pam : saltapi : - . * - @runner - @wheel # useradd - M - s / sbin / nologin saltapi echo spassword | passwd saltapi -- stdin  master  salt - api ---------------------------------------- import json import urllib import urllib2 class SaltAPI ( object ) : __token_id = def __init__ ( self ) : self . __url = url self . __user = user self . __password = pass params = { eauth : pam , username : self . __user , password : self . __password } content = self . postRequest ( params , prefix = /login ) print content [ return ][ 0 ][ token ] self . __token_id = content [ return ][ 0 ][ token ] def postRequest ( self , obj , prefix = / ) : url = self . __url + prefix headers = { X-Auth-Token : self . __token_id } data = urllib . urlencode ( obj ) req = urllib2 . Request ( url , data , headers ) opener = urllib2 . urlopen ( req ) content = json . loads ( opener . read ()) return content def postRequest1 ( self , obj , prefix = / ) : url = self . __url + prefix headers = { X-Auth-Token : self . __token_id } req = urllib2 . Request ( url , obj , headers ) opener = urllib2 . urlopen ( req ) content = opener . info () return content def list_all_key ( self ) : params = { client : wheel , fun : key.list_all } content = self . postRequest ( params ) # minions = content [ return ][ 0 ][ data ][ return ][ minions ] # minions_pre = content [ return ][ 0 ][ data ][ return ][ minions_pre ] # return minions , minions_pre minions = content [ return ][ 0 ][ data ][ return ] return minions def delete_key ( self , node_name ) : params = { client : wheel , fun : key.delete , match : node_name } content = self . postRequest ( params ) ret = content [ return ][ 0 ][ data ][ success ] return ret def accept_key ( self , node_name ) : params = { client : wheel , fun : key.accept , match : node_name } content = self . postRequest ( params ) ret = content [ return ][ 0 ][ data ][ success ] return ret def reject_key ( self , node_name ) : params = { client : wheel , fun : key.reject , match : node_name } content = self . postRequest ( params ) ret = content [ return ][ 0 ][ data ][ success ] return ret def remote_noarg_execution ( self , tgt , fun ) : Execute commands without parameters params = { client : local , tgt : tgt , fun : fun } content = self . postRequest ( params ) ret = content [ return ][ 0 ][ tgt ] return ret def remote_execution ( self , tgt , fun , arg ) : Command execution with parameters params = { client : local , tgt : tgt , fun : fun , arg : arg } content = self . postRequest ( params ) ret = content [ return ][ 0 ][ tgt ] return ret def shell_remote_execution ( self , tgt , arg ) : Shell command execution with parameters params = { client : local , tgt : tgt , fun : cmd.run , arg : arg , expr_form : list } content = self . postRequest ( params ) ret = content [ return ][ 0 ] return ret def grains ( self , tgt , arg ) : Grains.item params = { client : local , tgt : tgt , fun : grains.item , arg : arg } content = self . postRequest ( params ) ret = content [ return ][ 0 ] return ret def target_remote_execution ( self , tgt , fun , arg ) : Use targeting for remote execution params = { client : local , tgt : tgt , fun : fun , arg : arg , expr_form : nodegroup } content = self . postRequest ( params ) jid = content [ return ][ 0 ][ jid ] return jid def deploy ( self , tgt , arg ) : Module deployment params = { client : local , tgt : tgt , fun : state.sls , arg : arg } content = self . postRequest ( params ) return content def async_deploy ( self , tgt , arg ) : Asynchronously send a command to connected minions params = { client : local_async , tgt : tgt , fun : state.sls , arg : arg } content = self . postRequest ( params ) jid = content [ return ][ 0 ][ jid ] return jid def target_deploy ( self , tgt , arg ) : Based on the list forms deployment params = { client : local_async , tgt : tgt , fun : state.sls , arg : arg , expr_form : list } content = self . postRequest ( params ) jid = content [ return ][ 0 ][ jid ] return jid def jobs_list ( self ) : Get Cache Jobs Defaut 24h url = self . __url + /jobs/ headers = { X-Auth-Token : self . __token_id } req = urllib2 . Request ( url , headers = headers ) opener = urllib2 . urlopen ( req ) content = json . loads ( opener . read ()) jid = content [ return ][ 0 ] return jid def runner_status ( self , arg ) : Return minion status params = { client : runner , fun : manage. + arg } content = self . postRequest ( params ) jid = content [ return ][ 0 ] return jid def runner ( self , arg ) : Return minion status params = { client : runner , fun : arg } content = self . postRequest ( params ) jid = content [ return ][ 0 ] return jid cl = SaltAPI () print cl . shell_remote_execution ( aws-ms1 , date ) print cl . grains ( aws-ms1 , ipv4 ) WEB ( halite )   https : // github . com / yueyongyue / saltshaker / yum install salt - api git cd / var / www / git clone https : // github . com / saltstack / halite cd halite / halite . / genindex . py - C vim / etc / salt / master rest_cherrypy : host : 0 . 0 . 0 . 0 port : 8080 debug : true disable_ssl : True static : / var / www / halite / halite app : / var / www / halite / halite / index . html external_auth : pam : salt : - . * - @runner - @wheel / etc / init . d / salt - master restart useradd salt echo salt | passwd – stdin salt salt - a pam \\ * test . ping   minion    salt - api salt - api - d  cd / var / www / halite / halite python server_bottle . py - d - C - l debug - s cherrypy  http : // ip : 8080 / app beacons https : // docs . saltstack . com / en / latest / topics / beacons / index . html https : // docs . saltstack . com / en / latest / ref / beacons / all / index . html # all - salt - beacons 1  minion  beacon beacons : service : httpd : onchangeonly : True uncleanshutdown : / var / run / httpd / httpd . pid  httpd  master  2  event  salt / beacon / centos2 / service / { _stamp : 2015-12-06T07:24:25.095014 , data : { httpd : { running : false , shutdown : clean }, id : centos2 }, tag : salt/beacon/centos2/service/ } 3  master ， tag vim / etc / salt / master reactor : - salt/beacon/znode2/service/ : - /srv/reactor/backup.sls 4  vim / srv / reactor / backup . sls { % if data [ data ][ httpd ][ running ] == False % } backup file : local . cmd . run : - tgt : {{ data [ data ][ id ]}} - arg : - /etc/init.d/httpd start { % endif % } # state . sls  sls   beacon  1 mkdir - pv / srv / salt / _beacons 2  3  salt * saltutil . sync_all 4 vim t . py # minion ， config beacons : t : - rm : / tmp / kk - interval : 2 [{ t1 : 1 },{ t2 : 2 }]  import  def beacon ( config ) : ret = [] r_dict = {}  config   ret return ret  # -*- coding : utf - 8 -*- import logging import re import pexpect log = logging . getLogger ( __name__ ) __virtualname__ = t def __virtual__ () : if salt . utils . is_windows () : return False else : return __virtualname__ def beacon ( config ) : code_block :: yaml beacons : t : - rm : / - interval : 100 ret = [] user = __salt__ [ cmd.run ] ( whoami ) logging . debug ( user ) r_dict = {} for t in config : for k , v in t . items () : cmd = grep ^.*rm.* /tmp/kk[[:space:]]$ /tmp/.shellog output , status = pexpect . run ( cmd , withexitstatus = 1 ) if status == 0 : logging . debug ( output ) r_dict = { user : output } logging . debug ( r_dict ) ret . append ( r_dict ) return ret zabbix_agent ls zabbix_linux_install / agent_install . sls init . sls zabbix_agentd . conf zabbix . repo cat init . sls include : - zabbix_linux_install . agent_install cat zabbix . repo [ zabbix ] baseurl = http : // mirrors . aliyun . com / zabbix / zabbix / 2 . 4 / rhel / 6 / x86_64 / gpgcheck = 0 cat agent_install . sls agent_install . sls / etc / yum . repos . d / zabbix . repo : file . managed : - source : salt : // zabbix_linux_install / zabbix . repo zabbix - agent : cmd . run : - name : yum install zabbix - agent - 2 . 4 . 5 - y - require : - file : / etc / yum . repos . d / zabbix . repo service . running : - require : - cmd : zabbix - agent - watch : - file : / etc / zabbix / zabbix_agentd . conf / etc / zabbix / zabbix_agentd . conf : file . managed : - source : salt : // zabbix_linux_install / zabbix_agentd . conf ( ： Hostname = {{ grains [ ip_interfaces ] [ eth1 ][ 0 ] }} ) - template : jinja - require : - cmd : zabbix - agent  { % set NODENAME = grains [ nodename ] % } { % set BINDIR = /usr/local/zabbix/sbin % } { % set LOGDIR = /var/log/zabbix % } { % set Serverip = 192.168.40.11 % } # source pacekages zabbix_source : file . managed : - name : / tmp / zabbix - 2 . 4 . 1 . tar . gz - unless : test - e / tmp / zabbix - 2 . 4 . 1 . tar . gz - source : salt : // files / common / zabbix / zabbix - 2 . 4 . 1 . tar . gz # trace zabbix extract_zabbix : cmd . run : - cwd : / tmp - names : - tar - zxf zabbix - 2 . 4 . 1 . tar . gz / dev / null 2 1 - unless : test - d / tmp / zabbix - 2 . 4 . 1 / - require : - file : zabbix_source # Add user zabbix_user : user . present : - name : zabbix - uid : 1000 - createhome : False - gid_from_name : True - shell : / sbin / nologin / var / log / zabbix : file . directory : - user : zabbix - group : zabbix - dir_mode : 755 - file_mode : 655 - recurse : - user - group init.sls 87 L , 2508 C agent_start_init : file . managed : - name : / etc / init . d / zabbix_agentd - user : root - mode : 0755 - source : salt : // files / common / zabbix / zabbix_agentd - source_hash : salt : // files / common / zabbix_agent / zabbix_agentd - template : jinja - defaults : ZABBIX_BIN : {{ BINDIR }} - unless : if [[ ${ cat / etc / init . d / zabbix_agentd | grep {{ BINDIR }} | awk - F = NR==1{print $2} } = {{ BINDIR }} ]] ;then exit 0;fi cmd . run : - names : - / sbin / chkconfig -- add zabbix_agentd - / sbin / chkconfig zabbix_agentd on - unless : / sbin / chkconfig -- list zabbix_agentd service . running : - name : zabbix_agentd - enable : True - restart : True zabbix_config_set : file . managed : - name : / usr / local / zabbix / etc / zabbix_agentd . conf - user : root - mode : 744 - source : salt : // files / common / zabbix / zabbix_agentd . conf - template : jinja - defaults : ServerADD : {{ Serverip }} AgentNAME : {{ NODENAME }} - unless : if grep {{ NODENAME }} / usr / local / zabbix / etc / zabbix_agentd . conf / dev / null 2 1 ;then exit 0;fi / usr / bin / zabbix_get : file . symlink : - target : / usr / local / zabbix / bin / zabbix_get - unless : test - L / usr / bin / zabbix_get / usr / bin / zabbix_sender : file . symlink : - target : / usr / local / zabbix / bin / zabbix_sender - unless : test - L / usr / bin / zabbix_sender salt  setproctitle ( Master / Minion  ) yum - y install python - setproctitle  salt service salt - master restart service salt - minion restart  Master  ps ax | grep salt | grep - v salt Master  (  ): 2943 ? S 0 : 00 / usr / bin / python / usr / bin / salt - master - d ProcessManager #  2944 ? S 0 : 00 / usr / bin / python / usr / bin / salt - master - d _clear_old_jobs #  Jobs  fileserver 2945 ? Sl 0 : 00 / usr / bin / python / usr / bin / salt - master - d Publisher #  PUB  Minion  2946 ? Sl 0 : 00 / usr / bin / python / usr / bin / salt - master - d EventPublisher # Event Publisher  2951 ? S 0 : 00 / usr / bin / python / usr / bin / salt - master - d ReqServer_ProcessManager # ReqServer  2952 ? Sl 0 : 01 / usr / bin / python / usr / bin / salt - master - d MWorker #  ,  Worker  2953 ? Sl 0 : 01 / usr / bin / python / usr / bin / salt - master - d MWorker #  2954 ? Sl 0 : 01 / usr / bin / python / usr / bin / salt - master - d MWorker 2955 ? Sl 0 : 01 / usr / bin / python / usr / bin / salt - master - d MWorker 2956 ? Sl 0 : 01 / usr / bin / python / usr / bin / salt - master - d MWorker 2957 ? Sl 0 : 00 / usr / bin / python / usr / bin / salt - master - d MWorkerQueue #  Ret  ( ROUTER )  Worker ( DEALER )  ,  Minion  (  ): 2003 ? Sl 0 : 01 / usr / bin / python / usr / bin / salt - minion - d # Minion  ,  Master  2069 ? S 0 : 00 / usr / bin / python / usr / bin / salt - minion - d 20150108034936245247 #  ,   jid   ,  Salt  ,  Master / Minion  ,  salt  ==   4505 4506 master  zeromq ， raet salt - call -- master = 10 . 21 . 40 . 23 -- id = host1 state . highstate yum  https : // repo . saltstack . com / # rhel salt ， http : // repo . saltstack . com / yum / redhat [ saltstack - repo ] name = SaltStack repo for RHEL / CentOS $ releasever baseurl = http : // repo . saltstack . com / yum / redhat / $ releasever / $ba search / latest enabled = 1 gpgcheck = 1 gpgkey = http : // repo . saltstack . com / yum / redhat / $ releasever / $ba search / latest / SALTSTACK - GPG - KEY . pub yum install epel - release yum install salt - master master  salt - 2014 . 1 . 10 - 4 . el6 . noarch salt - master - 2014 . 1 . 10 - 4 . el6 . noarch salt - minion - 2014 . 1 . 10 - 4 . el6 . noarch （ optional ） minion （） yum install salt - minion salt - 2014 . 1 . 10 - 4 . el6 . noarch salt - minion - 2014 . 1 . 10 - 4 . el6 . noarch  iptables - I INPUT - m state -- state new - m tcp - p tcp -- dport 4505 - j ACCEPT iptables - I INPUT - m state -- state new - m tcp - p tcp -- dport 4506 - j ACCEPT python  yum install swig yum install gcc gcc - c ++ yum install openssl - devel yum install libyaml - devel - y pip install M2Crypto pip install pyzmq pip uninstall PyCrypto pip uninstall salt Jinja2 msgpack - python PyYAML MarkupSafe pip install PyCrypto cd / usr / lib / python2 . 6 / site - packages / rm - fr salt salt - 2014 . 1 . 4 - py2 . 6 . egg - info / pip install salt http : // docs . saltstack . com / en / latest / http : // msgpack . org / zeromq   msgpack   salt  1 （） zeromq 2  2  msgpack  3  aes  4  4505 4506 5  block （，）   master  vim / etc / hosts master_ip master_name minion_ip minion_name    sk_buffer echo 16777216 / proc / sys / net / core / rmem_max echo 16777216 / proc / sys / net / core / wmem_max echo 4096 87380 16777216 / proc / sys / net / ipv4 / tcp_rmem echo 4096 87380 16777216 / proc / sys / net / ipv4 / tcp_wmem minion vim / etc / salt / minion id : node2 ( minion  )  master : 10 . 255 . 254 . 221 （ master  ip ） / etc / init . d / salt - minion start / etc / init . d / salt - master start  minion  [ root @ node1 salt ]# salt - key - L salt - key – A  minion - a minion   minion  salt * test . ping  .   shell  * *.example.com web?.example.com web[1-5].example.com regex  salt - E web1-(prod|devel).example.com list  salt - L web1,web2,web3 grains (  minion ， ) [ root @ node1 salt ]# salt node1 grains . ls salt - G os:CentOS test . ping  [ root @ node1 salt ]# vim / etc / salt / master salt - N  test . ping  - b （） salt * sys . doc  / usr / lib / python2 . 6 / site - packages / salt / modules test . ping (  minion  ) http : // docs . saltstack . com / en / latest / ref / modules / all / index . html [ root @ node1 modules ]# salt node3 cmd . run uptime salt  file_roots : base : - / srv / salt salt node2 cmd . script salt : // test . sh  / var / cache / salt / minion / files / base minion id service salt - minion stop rm - f / etc / salt / pki / minion / minion . pub rm - f / etc / salt / pki / minion / minion . pem echo $ ( hostname ) / etc / salt / minion_id service salt - minion start event 1 、 event   key tag  mininon data ，，， id  2 、 minion  master ， minion  master  salt - run state . event pretty = True  event minion  salt - call event . send tag data data , tag  master  salt zabbix_server state . sls apache_install  event : salt / job / 20151018191951447100 / ret / zabbix_server { tag  data , data _stamp : 2015-10-18T11:20:19.543008 , cmd : _return , fun : state.sls , fun_args : [ apache_install ], id : zabbix_server , jid : 20151018191951447100 , out : highstate , retcode : 0 , return : { pkg_|-httpd_|-httpd_|-installed : { __run_num__ : 0 , changes : {}, comment : Package httpd is already installed. , duration : 4001 . 181 , name : httpd , result : true , start_time : 11:20:14.264181 } }, success : true } }  master  reactor : - salt/job/* :  tag ， jid  *  - / srv / reactor / my_custom_module . sls  tag  mkdir - pv / srv / reactor / vim / srv / reactor / my_custom_module . sls { % if data [ fun_args ][ 0 ] == apache_install and data [ success ] == true % }  touch_new_file : local . state . sls : （ cmd . state . sls ） - tgt : zabbix_server  - arg : - newfile  / srv / salt / newfile . sls  - kwarg :  pillar pillar :  filename : {{ data [ fun_args ][ 0 ] }} { % endif % } ##{{ data }}  salt zabbix_server state . sls newfile pillar = { filename : apache_install } cat / srv / salt / newfile . sls / tmp / {{ pillar [ filename ]}}: file . managed : - source : salt : // passwd ， salt zabbix_server state . sls apache_install  (  ) ， newfile . sls  ， state ， salt centos2 sys . list_functions salt centos2 sys . list_functions sys - sys . argspec - sys . doc ， salt * sys . doc cmd  cmd ， - sys . list_functions module  function ， salt Minion sys . list_functions cmd - sys . list_modules Minion  module ， salt Minion sys . list_modules - sys . list_renderers  Return  - sys . list_returner_functions - sys . list_returners - sys . list_runner_functions - sys . list_runners - sys . list_state_functions  states  function ， salt Minion sys . list_state_functions file - sys . list_state_modules Minion  states  - sys . state_doc state  - sys . reload_modules - sys . renderer_doc - sys . returner_argspec - sys . returner_doc - sys . runner_argspec - sys . runner_doc - sys . state_argspec grains grains  master  minion  salt * grains . ls salt node1 grains . items salt node1 grains . item os salt - G os:CentOS test . ping 1 、 grains  salt Minion grains . append saltbook verycool salt * grains . setval key { sub-key : val , sub-key2 : val2 }  salt * grains . remove key val  2 、 minion  grains vim / etc / salt / minion . d / hostinfo . conf #grains,， grains : roles : - webserver - memcache deployment : datacenter4 cabinet : 13  minion / etc / init . d / salt - minion restart 3 、 master  grains ， minion mkdir / srv / salt / _grains vim / srv / salt / _grains / system . py import platform def get_system (): grains = {} # grains grains [ system ] = platform . platform () return grains # salt zabbix_agent saltutil . sync_grains #minion（/var/cache/salt/minion/extmods/grains/） salt zabbix_agent grains . item system #grains  grains  1 、 grains salt - G os:CentOS test . ping 2 、 top . sls  vim top . sls base : location:shanghai : - match : grain - webserver (  sls  ) salt * state . highstate ， location : shanghai  user . sls 3 、 state ， sls  { % set the_node_type = salt [ grains.get ]( grainskey ,  ) % } or grains [ os ] { % if the_node_type % } node_type:{{ the_node_type }} : - match : grain - {{ the_node_type }} { % endif % } 4 、 grains ， __grains__ [ key ] vim g1 . py def t1 (): return __grains__ [ location ] salt * saltutil . sync_modules  salt ‘ * ’ g1 . t1  modules  http : // docs . saltstack . com / ref / modules / all / index . html #all-salt-modules import salt.client client = salt . client . LocalClient () ret = client . cmd ( * , test.ping ) print ret Archive  salt centos1 archive . gunzip / tmp / sourcefile . txt . gz #gzunzip/tmp/sourcefile.txt.gz salt centos1 archive . gzip / tmp / sourcefile . txt #gzip/tmp/sourcefile.txt --- API ： client . cmd ( centos1 , archive.gunzip ， [ /tmp/sourcefile.txt.gz ]) cmd  salt centos1 cmd . run free -m # salt centos1 cmd . script salt : // script / test . sh #centos1test.sh，script/test.sh file_roots ， test . sh  minion  cache （ / var / cache / salt / minion / files / base / script / test . sh ）；  --- API ： client . cmd ( SN2013-08-021 , cmd.run ,[ free -m ]) cp  salt centos1 cp . cache_local_file / etc / hosts #/etc/hostssalt cache （ / var / cache / salt / minion / localfiles / ） salt centos1 cp . get_dir salt : // path / to / dir / / minion / dest #file_roots salt centos1 cp . get_file salt : // path / to / file / minion / dest #file_roots salt centos1 cp . get_url http : // www . slashdot . org / tmp / index . html #URL ----- API ： client . cmd ( centos1 , cp.get_file ,[ salt://path/to/file , /minion/dest ]) crontab  salt centos1 cron . raw_cron root or salt centos1 cron . list_tab root #、rootcrontab salt centos1 cron . set_job root * * * * 1 / usr / local / weekly #、root/usr/local/weekly salt centos1 cron . rm_job root / usr / local / weekly #、rootcrontab/usr/local/weekly ----- API ： client . cmd ( centos1 , cron.set_job ,[ root , * , * , * , * , * , /usr/echo ]) dnsutil DNS  salt centos1 dnsutil . hosts_append / etc / hosts 192.168 . 8.12 salt - master #hosts salt centos1 dnsutil . hosts_remove / etc / hosts salt - master #hosts ----- API ： client . cmd ( * , dnsutil.hosts_append ,[ /etc/hosts , 127.0.0.1 , ad1.yuk.co ]) file  salt centos2 file . check_hash / etc / fstab md5 : e4b13a1b984950ade18cbc8bc33be658 #/etc/fstabmd5  True salt * file . get_sum / etc / passwd md5 #、md5、sha1、sha224、sha256、sha384、sha512  salt * file . chown / etc / passwd root root #/etc/passwd、，  chown root : root / etc / passwd salt * file . copy / path / to / src / path / to / dst #/path/to/src/path/to/dst salt * file . directory_exists / etc #/etc，True， file . file_exists  salt * file . stats / etc / passwd #/etc/passwdstats salt * file . get_mode / etc / passwd #/etc/passwdmode，755、644 salt * file . set_mode / etc / passwd 0644 #/etc/passwdmode0644 salt * file . mkdir / opt / test #/opt/test salt * file . sed / etc / httpd / httpd . conf LogLevel warn LogLevel info #/etc/httpd/httpd.conf  LogLevel  warn  info salt * file . append / tmp / test / test . conf maxclient 100 #/tmp/test/test.conf maxclient 100 salt * file . remove / tmp / foo3 #/tmp/foo ------ API ： client . cmd ( * , file.remove ,[ /tmp/foo ]) iptables  salt * iptables . append filter INPUT rule = -m state --state RELATED,ESTABLISHED -j ACCEPT salt * iptables . insert filter INPUT position = 3 rule = -m state --state RELATED,ESTABLISHED -j ACCEPT #(append)、(insert)iptables,INPUT salt * iptables . delete filter INPUT position = 3 salt * iptables . delete filter INPUT rule = -m state --state RELATED,ESTABLISHED-j ACCEPT #3（position=3） salt * iptables . save / etc / sysconfig / iptables #(/etc/sysconfig/iptables) ---- API ： client . cmd ( SN2013-08-022 , iptables.append ,[ filter , INPUT , rule= \\ -p tcp --sport 80 -j ACCEPT \\ ]) netwrok  salt centos2 network . dig www . qq . com salt centos2 network . ping www . qq . com salt centos2 network . traceroute www . qq . com # centos2 dig、ping、traceroute salt centos2 network . hwaddr eth0 #MAC salt centos2 network . in_subnet 10.0 . 0.0 / 16 #10.0.0.0/16，True salt centos2 network . interfaces # salt centos2 network . ip_addrs #IP salt centos2 network . subnets # ---- API ： client . cmd ( SN2013-08-022 , network.ip_addrs ) pkg  salt * pkg . install php #PHP，，redhatyum，  yum - y install php salt * pkg . remove php #PHP salt * pkg . upgrade # ---- API ： client . cmd ( SN2013-08-022 , pkg.remove ,[ php ]) Service  salt * service . enable nginx salt * service . disable nginx #（enable）、（disable）nginx salt * service . reload nginx salt * service . restart nginx salt * service . start nginx salt * service . stop nginx salt * service . status nginx #nginxreload、restart、start、stop、status ----- API ： client . cmd ( SN2013-08-022 , service.stop ,[ nginx ]) other Saltstack  user （）、 group （）、 partition （）、 puppet （ puppet ）、 system （、）、 timezone （）、 nginx （ Nginx ）、 mount （），   / usr / lib / python2 . 6 / site - packages / salt / modules  minion ， master  minion  fileroot : / etc / salt / master / srv / salt 1 、 module  minion  2 、 master  2  modules ,  minion 3 、 mkdir – pv / srv / salt / _modules cd / srv / salt / _modules 4 、 module  cat file . py  File def t1 ( num )  ‘’‘ salt \\ * file . t1 ’‘’  return num * num  return  5 、 minion salt * saltutil . sync_modules  minion ： / var / cache / salt / minion / extmods / modules  : salt * saltutil . sync_all  zmq saltstack master  REQSERVER 1  client ， Mworker 2  minion  4506 bind ROUTER workers . ipc bind DEALER Publisher  client  minion 4505 bind PUB publish_pull . ipc bind PULL EVENTPUBLISHER  client ，，！ master_event_pull . ipc bind pull master_event_pub . ipc bind PUB MWORKER ， wokers . ipc connect REP minion 4505 connect SUB ( ， ) 4605 connect REQ (  )  job flow 1 salt * test . ping  client  2 client 4506 REQ connect  3 REQSERVER  MWOKER ， wokers . ipc 4 ，。 publish  client  minion 。 ClearFuncs . publish () MWokers  publish_pull . ipc connect PUSH 5  woker  evnetpublish master_event_pull . ipc connect push  eventpublish  pub  client  （ master_event_pub . ipc ） 6  Publisher  mininon 7  minion  4505  8 minion ，， 9 minion  master  4506 ， master  Mwoker 10 Mwoker ， eventpublish  11  LocalClient 。。 12  minion ，，。 salt - zmq . png","title":"saltstack"},{"location":"saltstack/#status","text":"$ ID :  state ，， apache 、 nginx  $ State : ， http : // docs . saltstack . com / ref / states / all / index . html - $ state : states  salt \\ * state . sls dhcp  salt \\ * state . sls dhcp / aaa  dhcp  aaa . sls salt \\ * state . sls dhcp test = True ， minion salt \\ * state . highstate / usr / lib / python2 . 6 / site - packages / salt / states  modules / usr / lib / python2 . 6 / site - packages / salt / modules  states ， / srv / salt  sls  state  file_roots : base : - / srv / salt  state  vim / srv / salt / dhcp / init . sls include : - dhcp . python_devel  dhcp  python_devel . sls cat / srv / salt / dhcp / python_devel . sls dhcp : pkg . installed salt \\ * state . sls dhcp [ root @ node1 salt ]# cat top . sls base : * : - test  test . sls test  sls  （ init . sls ） [ root @ node1 salt ]# cat test . sls httpd : # id (  name  ) pkg : # state - installed # state  state  / usr / lib / python2 . 6 / site - packages / salt / states  state salt node2 state . highstate sls （ require ） httpd : ID pkg : states  - installed  service . running : - require : ， - pkg : httpd  sls （. sls ） [ root @ node1 salt ]# salt node2 state . sls test ， ############################################### httpd : pkg : - installed service : - running - require : - pkg : httpd - watch : ， - file : / etc / httpd / conf / httpd . conf / etc / httpd / conf / httpd . conf : file : - managed - source : salt : // httpd . conf - require : - pkg : httpd ################################################ apache : pkg : - name : httpd - installed service . running : - name : httpd - require : - pkg : httpd - watch : - file : apache_config apache_config : file . managed : - name : / etc / httpd / conf / httpd . conf - source : salt : // httpd . conf - template : jinja  apache_config  jinja  - require : - pkg : httpd httpd . conf 1 、  2 、  3 、  https : // docs . saltstack . com / en / latest / ref / states / all / index . html vim user . sls { % for user in [ test1 , test1 , test3 , test4 ] % }  {{ user }}:  user . present { % endfor % } （ if  endif ）  sls  vim / srv / salt / top . sls base : ‘ * ’ - user - apache_start salt \\ * state . highstate  nginx nginx_source : file . recurse : # file . managed :， file . recurse  - name : / tmp / - source : salt : // nginx / extract_nginx : cmd . run : - cwd : / tmp - names : #  names ， name - tar xf nginx - 1 . 6 . 2 . tar . gz - tar xf pcre - 8 . 35 . tar . gz - require : - file : nginx_source nginx_compile : cmd . run : - cwd : / tmp / nginx - 1 . 6 . 2 - names : - . / configure -- prefix =/ usr / local / nginx -- with - pcre =/ tmp / pcre - 8 . 35 make - make install - require : - cmd : extract_nginx  state  sls  module  state  / usr / lib / python2 . 6 / site - packages / salt / states mkdir - pv / srv / salt / _states [ root @ node1 _states ]# cat wjj . py def bs ( name , x ) :  ret = {  name : name , changes : {}, result : False , comment : test_state  } try : result = x * x  ret [ changes ][ new ] = result ret [ result ] = True except :  ret [ changes ][ new ] = jisuan cuwu return ret  name  salt * saltutil . sync_all  state  sls  [ root @ node1 _states ]# cat / srv / salt / jisuan . sls test : wjj : - bs - x : 3 salt node2 state . sls jisuan tips : state  salt  __salt__ [ . ] (  ) # encoding = utf - 8 import logging import os log = logging . getLogger ( __name__ ) def touch ( name , path , file ) : ret = { name : name , changes : {}, result : True , comment : test_state } # log . error ( name ) # log . error ( path ) try : with open ( path + / + str ( file ) , w ) as f : f . write ( my test! ) except Exception , e : log . error ( str ( e )) return ret def delete ( name , path , file ) : ret = { name : name , changes : {}, result : True , comment : test_state } cmd = rm -fr + path + / + file os . system ( cmd ) ret [ result ] = True return ret","title":"status"},{"location":"saltstack/#pillar","text":"https : // docs . saltstack . com / en / latest / topics / pillar / index . html  / etc / salt / master  pillar_opts : Ture  False   / srv / pillar vim / srv / pillar / top . sls base : * : - vimrc - data - pkg vim / srv / pillar / data . sls bind : port : 53 listen - on : any vim / srv / pillar / vimrc . sls { % if grains [ id ]. endswith ( server ) % } id  server   startswith vimrc : salt : // edit / vimrc1 { % else % } vimrc : salt : // edit / vimrc2 { % endif % } vim / srv / pillar / pkg . sls { % if grains [ os ] == RedHat % } ， apache : httpd git : git { % elif grains [ os ] == Debian % } apache : apache2 git : git - core { % endif % }  salt * saltutil . refresh_pillar  salt \\ * pillar . items  pillar  state 、，“{{ pillar }}”，： {{ pillar [ appname ] }}（） {{ pillar [ flow ][ maxconn ] }}（） {{ salt [ pillar.get ] ( flow: maxconn , {}) }} Python API ： pillar [ flow ][ maxconn ] pillar . get ( flow:appname , {} ) 1 、 state  sls  vim / srv / salt / down_vimrc . sls / root / . vimrc : file . managed : - source : {{ pillar [ vimrc ] }}  pillar  - source : {{ salt [ pillar.get ] ( vimrc , salt://edit/vimrc2 ) }} pillar  key ， salt \\ * state . show_sls down_vimrc  2 、 salt - I nginx:80 cmd . run ls - I  pillar 3 、 pillar  vim / srv / salt / pillar_temp . sls { % set u = pillar [ u_name ] % }  pillar {{ u }}: user . present salt node2 state . sls pillar_temp pillar = { u_name : v1 }  pillar","title":"pillar"},{"location":"saltstack/#job","text":"[ root@salt-master salt ] # salt - I nginx:80 cmd . run sleep 100 - v Executing job with jid 20151011154835704857 salt - run job salt - run - d | grep jobs salt - run jobs . active jobs salt - run jobs . list_job 20130916125524463507 jidjobs salt - run jobs . list_jobs #jobs salt - run jobs . lookup_jid 20130916125524463507 #jidjobs salt - run jobs . print_job #jidjobs ------------------------------------------------- saltutiljob salt \\ * sys . doc saltutil | grep job salt * saltutil . find_cached_job job id #job cache salt node2 saltutil . find_job 20150810003021849521 jid salt node2 saltutil . is_running cmd . run  salt node2 saltutil . kill_job 20150810003232388165 job saltutil . running #minion ⾏ jobs saltutil . find_job jid #jidjob ( minion ⾏ jobs ) saltutil . signal_job jid single #jid saltutil . term_job jid # ⽌ jid ( 15 ) saltutil . kill_job jid # ⽌ jid ( 9 )","title":"job"},{"location":"saltstack/#return","text":" minion 。 Minion 。 event  Master  Return 。： http : // pengyao . org / salt - stack_master_retuner_over_event_system . html  redis   minion  / etc / salt / minion  redis . db : 0 #redis redis . host : vps.shencan.net #redis(ip) redis . port : 6379 #redis minion  redis  pip install redis python - c import redis; print redis.VERSION salt Minion cmd . run hostname -- return redis mysql  / usr / lib / python2 . 6 / site - packages / salt / returners /  cat mysql . py vim / etc / salt / minion （） mysql . host : 10.255.254.221 mysql . user : salt mysql . pass : 123 mysql . db : salt mysql . port : 3306  10.255 . 254.221  mysql   mysql   mysql ， salt ，， 123 GRANT ALL PRIVILEGES ON *.* TO salt @ % IDENTIFIED BY ‘ 123 ’；  sql  / tmp / salt . sql ， mysql - u root / tmp / salt . sql (  salt ， salt  jids ， salt_returns ) GRANT ALL PRIVILEGES ON *.* TO salt @ % IDENTIFIED BY ‘ 123 ’； CREATE DATABASE `salt` DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci ; USE `salt` ; DROP TABLE IF EXISTS `jids` ; CREATE TABLE `jids` ( `jid` varchar ( 255 ) NOT NULL , `load` mediumtext NOT NULL , UNIQUE KEY `jid` ( `jid` ) ) ENGINE = InnoDB DEFAULT CHARSET = utf8 ; DROP TABLE IF EXISTS `salt_returns` ; CREATE TABLE `salt_returns` ( `fun` varchar ( 50 ) NOT NULL , `jid` varchar ( 255 ) NOT NULL , `return` mediumtext NOT NULL , `id` varchar ( 255 ) NOT NULL , `success` varchar ( 10 ) NOT NULL , `full_ret` mediumtext NOT NULL , `alter_time` TIMESTAMP DEFAULT CURRENT_TIMESTAMP , KEY `id` ( `id` ), KEY `jid` ( `jid` ), KEY `fun` ( `fun` ) ) ENGINE = InnoDB DEFAULT CHARSET = utf8 ; DROP TABLE IF EXISTS `salt_events` ; CREATE TABLE `salt_events` ( `id` BIGINT NOT NULL AUTO_INCREMENT , `tag` varchar ( 255 ) NOT NULL , `data` varchar ( 1024 ) NOT NULL , `alter_time` TIMESTAMP DEFAULT CURRENT_TIMESTAMP , `master_id` varchar ( 255 ) NOT NULL , PRIMARY KEY ( `id` ), KEY `tag` ( `tag` ) ) ENGINE = InnoDB DEFAULT CHARSET = utf8 ;  python  mysql  yum install MySQL - python - y  mysql  returner ， mysql [ root @node1 ~ ] # salt node2 test.ping --return mysql node2 : True ----------------------------------------------------------------  salt  schedule  minion 。 schedule : uptime : function : status . uptime seconds : 60 returner : mysql meminfo : function : status . meminfo minutes : 5 returner : mysql","title":"return"},{"location":"saltstack/#api-web","text":" # chmod 755 / etc / salt / master / var / run / salt / var / cache / salt  master  external_auth : pam : a1 : - * : - test . * - cmd . * http : // docs . saltstack . com / en / latest / topics / eauth / index . html # acl - eauth  a1  salt - a pam * test . ping salt - a pam * cmd . run whoami  $ salt - T - a pam web \\ * test . ping [ a1 @ zabbix_server ~ ]$ salt - T - a pam * test . ping username : a1 password : zabbixnode1 . example . com : True API yum install salt - api - y cd / etc / pki / tls / certs # ,  key  RDNs make testcert cd / etc / pki / tls / private / #  key ， key ,  key ， openssl rsa - in localhost . key - out localhost_nopass . key  yum install gcc make python - devel libffi - develpip - python install PyOpenSSL salt - call tls . create_self_signed_cert #， salt - minion ， salt - call  salt - minion   saltapi . conf  vim / etc / salt / master . d / saltapi . conf rest_cherrypy : port : 8000 host : 127 . 0 . 0 . 1 # disable_ssl : true  https ssl_crt : / etc / pki / tls / certs / localhost . crt # ssl_key : / etc / pki / tls / certs / localhost . key external_auth : pam : saltapi : - . * - @runner - @wheel # useradd - M - s / sbin / nologin saltapi echo spassword | passwd saltapi -- stdin  master  salt - api ---------------------------------------- import json import urllib import urllib2 class SaltAPI ( object ) : __token_id = def __init__ ( self ) : self . __url = url self . __user = user self . __password = pass params = { eauth : pam , username : self . __user , password : self . __password } content = self . postRequest ( params , prefix = /login ) print content [ return ][ 0 ][ token ] self . __token_id = content [ return ][ 0 ][ token ] def postRequest ( self , obj , prefix = / ) : url = self . __url + prefix headers = { X-Auth-Token : self . __token_id } data = urllib . urlencode ( obj ) req = urllib2 . Request ( url , data , headers ) opener = urllib2 . urlopen ( req ) content = json . loads ( opener . read ()) return content def postRequest1 ( self , obj , prefix = / ) : url = self . __url + prefix headers = { X-Auth-Token : self . __token_id } req = urllib2 . Request ( url , obj , headers ) opener = urllib2 . urlopen ( req ) content = opener . info () return content def list_all_key ( self ) : params = { client : wheel , fun : key.list_all } content = self . postRequest ( params ) # minions = content [ return ][ 0 ][ data ][ return ][ minions ] # minions_pre = content [ return ][ 0 ][ data ][ return ][ minions_pre ] # return minions , minions_pre minions = content [ return ][ 0 ][ data ][ return ] return minions def delete_key ( self , node_name ) : params = { client : wheel , fun : key.delete , match : node_name } content = self . postRequest ( params ) ret = content [ return ][ 0 ][ data ][ success ] return ret def accept_key ( self , node_name ) : params = { client : wheel , fun : key.accept , match : node_name } content = self . postRequest ( params ) ret = content [ return ][ 0 ][ data ][ success ] return ret def reject_key ( self , node_name ) : params = { client : wheel , fun : key.reject , match : node_name } content = self . postRequest ( params ) ret = content [ return ][ 0 ][ data ][ success ] return ret def remote_noarg_execution ( self , tgt , fun ) : Execute commands without parameters params = { client : local , tgt : tgt , fun : fun } content = self . postRequest ( params ) ret = content [ return ][ 0 ][ tgt ] return ret def remote_execution ( self , tgt , fun , arg ) : Command execution with parameters params = { client : local , tgt : tgt , fun : fun , arg : arg } content = self . postRequest ( params ) ret = content [ return ][ 0 ][ tgt ] return ret def shell_remote_execution ( self , tgt , arg ) : Shell command execution with parameters params = { client : local , tgt : tgt , fun : cmd.run , arg : arg , expr_form : list } content = self . postRequest ( params ) ret = content [ return ][ 0 ] return ret def grains ( self , tgt , arg ) : Grains.item params = { client : local , tgt : tgt , fun : grains.item , arg : arg } content = self . postRequest ( params ) ret = content [ return ][ 0 ] return ret def target_remote_execution ( self , tgt , fun , arg ) : Use targeting for remote execution params = { client : local , tgt : tgt , fun : fun , arg : arg , expr_form : nodegroup } content = self . postRequest ( params ) jid = content [ return ][ 0 ][ jid ] return jid def deploy ( self , tgt , arg ) : Module deployment params = { client : local , tgt : tgt , fun : state.sls , arg : arg } content = self . postRequest ( params ) return content def async_deploy ( self , tgt , arg ) : Asynchronously send a command to connected minions params = { client : local_async , tgt : tgt , fun : state.sls , arg : arg } content = self . postRequest ( params ) jid = content [ return ][ 0 ][ jid ] return jid def target_deploy ( self , tgt , arg ) : Based on the list forms deployment params = { client : local_async , tgt : tgt , fun : state.sls , arg : arg , expr_form : list } content = self . postRequest ( params ) jid = content [ return ][ 0 ][ jid ] return jid def jobs_list ( self ) : Get Cache Jobs Defaut 24h url = self . __url + /jobs/ headers = { X-Auth-Token : self . __token_id } req = urllib2 . Request ( url , headers = headers ) opener = urllib2 . urlopen ( req ) content = json . loads ( opener . read ()) jid = content [ return ][ 0 ] return jid def runner_status ( self , arg ) : Return minion status params = { client : runner , fun : manage. + arg } content = self . postRequest ( params ) jid = content [ return ][ 0 ] return jid def runner ( self , arg ) : Return minion status params = { client : runner , fun : arg } content = self . postRequest ( params ) jid = content [ return ][ 0 ] return jid cl = SaltAPI () print cl . shell_remote_execution ( aws-ms1 , date ) print cl . grains ( aws-ms1 , ipv4 ) WEB ( halite )   https : // github . com / yueyongyue / saltshaker / yum install salt - api git cd / var / www / git clone https : // github . com / saltstack / halite cd halite / halite . / genindex . py - C vim / etc / salt / master rest_cherrypy : host : 0 . 0 . 0 . 0 port : 8080 debug : true disable_ssl : True static : / var / www / halite / halite app : / var / www / halite / halite / index . html external_auth : pam : salt : - . * - @runner - @wheel / etc / init . d / salt - master restart useradd salt echo salt | passwd – stdin salt salt - a pam \\ * test . ping   minion    salt - api salt - api - d  cd / var / www / halite / halite python server_bottle . py - d - C - l debug - s cherrypy  http : // ip : 8080 / app","title":"api web"},{"location":"saltstack/#beacons","text":"https : // docs . saltstack . com / en / latest / topics / beacons / index . html https : // docs . saltstack . com / en / latest / ref / beacons / all / index . html # all - salt - beacons 1  minion  beacon beacons : service : httpd : onchangeonly : True uncleanshutdown : / var / run / httpd / httpd . pid  httpd  master  2  event  salt / beacon / centos2 / service / { _stamp : 2015-12-06T07:24:25.095014 , data : { httpd : { running : false , shutdown : clean }, id : centos2 }, tag : salt/beacon/centos2/service/ } 3  master ， tag vim / etc / salt / master reactor : - salt/beacon/znode2/service/ : - /srv/reactor/backup.sls 4  vim / srv / reactor / backup . sls { % if data [ data ][ httpd ][ running ] == False % } backup file : local . cmd . run : - tgt : {{ data [ data ][ id ]}} - arg : - /etc/init.d/httpd start { % endif % } # state . sls  sls   beacon  1 mkdir - pv / srv / salt / _beacons 2  3  salt * saltutil . sync_all 4 vim t . py # minion ， config beacons : t : - rm : / tmp / kk - interval : 2 [{ t1 : 1 },{ t2 : 2 }]  import  def beacon ( config ) : ret = [] r_dict = {}  config   ret return ret  # -*- coding : utf - 8 -*- import logging import re import pexpect log = logging . getLogger ( __name__ ) __virtualname__ = t def __virtual__ () : if salt . utils . is_windows () : return False else : return __virtualname__ def beacon ( config ) : code_block :: yaml beacons : t : - rm : / - interval : 100 ret = [] user = __salt__ [ cmd.run ] ( whoami ) logging . debug ( user ) r_dict = {} for t in config : for k , v in t . items () : cmd = grep ^.*rm.* /tmp/kk[[:space:]]$ /tmp/.shellog output , status = pexpect . run ( cmd , withexitstatus = 1 ) if status == 0 : logging . debug ( output ) r_dict = { user : output } logging . debug ( r_dict ) ret . append ( r_dict ) return ret","title":"beacons"},{"location":"saltstack/#zabbix_agent","text":"ls zabbix_linux_install / agent_install . sls init . sls zabbix_agentd . conf zabbix . repo cat init . sls include : - zabbix_linux_install . agent_install cat zabbix . repo [ zabbix ] baseurl = http : // mirrors . aliyun . com / zabbix / zabbix / 2 . 4 / rhel / 6 / x86_64 / gpgcheck = 0 cat agent_install . sls agent_install . sls / etc / yum . repos . d / zabbix . repo : file . managed : - source : salt : // zabbix_linux_install / zabbix . repo zabbix - agent : cmd . run : - name : yum install zabbix - agent - 2 . 4 . 5 - y - require : - file : / etc / yum . repos . d / zabbix . repo service . running : - require : - cmd : zabbix - agent - watch : - file : / etc / zabbix / zabbix_agentd . conf / etc / zabbix / zabbix_agentd . conf : file . managed : - source : salt : // zabbix_linux_install / zabbix_agentd . conf ( ： Hostname = {{ grains [ ip_interfaces ] [ eth1 ][ 0 ] }} ) - template : jinja - require : - cmd : zabbix - agent  { % set NODENAME = grains [ nodename ] % } { % set BINDIR = /usr/local/zabbix/sbin % } { % set LOGDIR = /var/log/zabbix % } { % set Serverip = 192.168.40.11 % } # source pacekages zabbix_source : file . managed : - name : / tmp / zabbix - 2 . 4 . 1 . tar . gz - unless : test - e / tmp / zabbix - 2 . 4 . 1 . tar . gz - source : salt : // files / common / zabbix / zabbix - 2 . 4 . 1 . tar . gz # trace zabbix extract_zabbix : cmd . run : - cwd : / tmp - names : - tar - zxf zabbix - 2 . 4 . 1 . tar . gz / dev / null 2 1 - unless : test - d / tmp / zabbix - 2 . 4 . 1 / - require : - file : zabbix_source # Add user zabbix_user : user . present : - name : zabbix - uid : 1000 - createhome : False - gid_from_name : True - shell : / sbin / nologin / var / log / zabbix : file . directory : - user : zabbix - group : zabbix - dir_mode : 755 - file_mode : 655 - recurse : - user - group init.sls 87 L , 2508 C agent_start_init : file . managed : - name : / etc / init . d / zabbix_agentd - user : root - mode : 0755 - source : salt : // files / common / zabbix / zabbix_agentd - source_hash : salt : // files / common / zabbix_agent / zabbix_agentd - template : jinja - defaults : ZABBIX_BIN : {{ BINDIR }} - unless : if [[ ${ cat / etc / init . d / zabbix_agentd | grep {{ BINDIR }} | awk - F = NR==1{print $2} } = {{ BINDIR }} ]] ;then exit 0;fi cmd . run : - names : - / sbin / chkconfig -- add zabbix_agentd - / sbin / chkconfig zabbix_agentd on - unless : / sbin / chkconfig -- list zabbix_agentd service . running : - name : zabbix_agentd - enable : True - restart : True zabbix_config_set : file . managed : - name : / usr / local / zabbix / etc / zabbix_agentd . conf - user : root - mode : 744 - source : salt : // files / common / zabbix / zabbix_agentd . conf - template : jinja - defaults : ServerADD : {{ Serverip }} AgentNAME : {{ NODENAME }} - unless : if grep {{ NODENAME }} / usr / local / zabbix / etc / zabbix_agentd . conf / dev / null 2 1 ;then exit 0;fi / usr / bin / zabbix_get : file . symlink : - target : / usr / local / zabbix / bin / zabbix_get - unless : test - L / usr / bin / zabbix_get / usr / bin / zabbix_sender : file . symlink : - target : / usr / local / zabbix / bin / zabbix_sender - unless : test - L / usr / bin / zabbix_sender","title":"zabbix_agent"},{"location":"saltstack/#salt","text":" setproctitle ( Master / Minion  ) yum - y install python - setproctitle  salt service salt - master restart service salt - minion restart  Master  ps ax | grep salt | grep - v salt Master  (  ): 2943 ? S 0 : 00 / usr / bin / python / usr / bin / salt - master - d ProcessManager #  2944 ? S 0 : 00 / usr / bin / python / usr / bin / salt - master - d _clear_old_jobs #  Jobs  fileserver 2945 ? Sl 0 : 00 / usr / bin / python / usr / bin / salt - master - d Publisher #  PUB  Minion  2946 ? Sl 0 : 00 / usr / bin / python / usr / bin / salt - master - d EventPublisher # Event Publisher  2951 ? S 0 : 00 / usr / bin / python / usr / bin / salt - master - d ReqServer_ProcessManager # ReqServer  2952 ? Sl 0 : 01 / usr / bin / python / usr / bin / salt - master - d MWorker #  ,  Worker  2953 ? Sl 0 : 01 / usr / bin / python / usr / bin / salt - master - d MWorker #  2954 ? Sl 0 : 01 / usr / bin / python / usr / bin / salt - master - d MWorker 2955 ? Sl 0 : 01 / usr / bin / python / usr / bin / salt - master - d MWorker 2956 ? Sl 0 : 01 / usr / bin / python / usr / bin / salt - master - d MWorker 2957 ? Sl 0 : 00 / usr / bin / python / usr / bin / salt - master - d MWorkerQueue #  Ret  ( ROUTER )  Worker ( DEALER )  ,  Minion  (  ): 2003 ? Sl 0 : 01 / usr / bin / python / usr / bin / salt - minion - d # Minion  ,  Master  2069 ? S 0 : 00 / usr / bin / python / usr / bin / salt - minion - d 20150108034936245247 #  ,   jid   ,  Salt  ,  Master / Minion  , ","title":"salt"},{"location":"saltstack/#salt_1","text":" ==   4505 4506 master  zeromq ， raet salt - call -- master = 10 . 21 . 40 . 23 -- id = host1 state . highstate yum  https : // repo . saltstack . com / # rhel salt ， http : // repo . saltstack . com / yum / redhat [ saltstack - repo ] name = SaltStack repo for RHEL / CentOS $ releasever baseurl = http : // repo . saltstack . com / yum / redhat / $ releasever / $ba search / latest enabled = 1 gpgcheck = 1 gpgkey = http : // repo . saltstack . com / yum / redhat / $ releasever / $ba search / latest / SALTSTACK - GPG - KEY . pub yum install epel - release yum install salt - master master  salt - 2014 . 1 . 10 - 4 . el6 . noarch salt - master - 2014 . 1 . 10 - 4 . el6 . noarch salt - minion - 2014 . 1 . 10 - 4 . el6 . noarch （ optional ） minion （） yum install salt - minion salt - 2014 . 1 . 10 - 4 . el6 . noarch salt - minion - 2014 . 1 . 10 - 4 . el6 . noarch  iptables - I INPUT - m state -- state new - m tcp - p tcp -- dport 4505 - j ACCEPT iptables - I INPUT - m state -- state new - m tcp - p tcp -- dport 4506 - j ACCEPT python  yum install swig yum install gcc gcc - c ++ yum install openssl - devel yum install libyaml - devel - y pip install M2Crypto pip install pyzmq pip uninstall PyCrypto pip uninstall salt Jinja2 msgpack - python PyYAML MarkupSafe pip install PyCrypto cd / usr / lib / python2 . 6 / site - packages / rm - fr salt salt - 2014 . 1 . 4 - py2 . 6 . egg - info / pip install salt http : // docs . saltstack . com / en / latest / http : // msgpack . org / zeromq   msgpack   salt  1 （） zeromq 2  2  msgpack  3  aes  4  4505 4506 5  block （，）   master  vim / etc / hosts master_ip master_name minion_ip minion_name    sk_buffer echo 16777216 / proc / sys / net / core / rmem_max echo 16777216 / proc / sys / net / core / wmem_max echo 4096 87380 16777216 / proc / sys / net / ipv4 / tcp_rmem echo 4096 87380 16777216 / proc / sys / net / ipv4 / tcp_wmem minion vim / etc / salt / minion id : node2 ( minion  )  master : 10 . 255 . 254 . 221 （ master  ip ） / etc / init . d / salt - minion start / etc / init . d / salt - master start  minion  [ root @ node1 salt ]# salt - key - L salt - key – A  minion - a minion   minion  salt * test . ping  .   shell  * *.example.com web?.example.com web[1-5].example.com regex  salt - E web1-(prod|devel).example.com list  salt - L web1,web2,web3 grains (  minion ， ) [ root @ node1 salt ]# salt node1 grains . ls salt - G os:CentOS test . ping  [ root @ node1 salt ]# vim / etc / salt / master salt - N  test . ping  - b （） salt * sys . doc  / usr / lib / python2 . 6 / site - packages / salt / modules test . ping (  minion  ) http : // docs . saltstack . com / en / latest / ref / modules / all / index . html [ root @ node1 modules ]# salt node3 cmd . run uptime salt  file_roots : base : - / srv / salt salt node2 cmd . script salt : // test . sh  / var / cache / salt / minion / files / base","title":"salt"},{"location":"saltstack/#minion-id","text":"service salt - minion stop rm - f / etc / salt / pki / minion / minion . pub rm - f / etc / salt / pki / minion / minion . pem echo $ ( hostname ) / etc / salt / minion_id service salt - minion start","title":"minion id"},{"location":"saltstack/#event","text":"1 、 event   key tag  mininon data ，，， id  2 、 minion  master ， minion  master  salt - run state . event pretty = True  event minion  salt - call event . send tag data data , tag  master  salt zabbix_server state . sls apache_install  event : salt / job / 20151018191951447100 / ret / zabbix_server { tag  data , data _stamp : 2015-10-18T11:20:19.543008 , cmd : _return , fun : state.sls , fun_args : [ apache_install ], id : zabbix_server , jid : 20151018191951447100 , out : highstate , retcode : 0 , return : { pkg_|-httpd_|-httpd_|-installed : { __run_num__ : 0 , changes : {}, comment : Package httpd is already installed. , duration : 4001 . 181 , name : httpd , result : true , start_time : 11:20:14.264181 } }, success : true } }  master  reactor : - salt/job/* :  tag ， jid  *  - / srv / reactor / my_custom_module . sls  tag  mkdir - pv / srv / reactor / vim / srv / reactor / my_custom_module . sls { % if data [ fun_args ][ 0 ] == apache_install and data [ success ] == true % }  touch_new_file : local . state . sls : （ cmd . state . sls ） - tgt : zabbix_server  - arg : - newfile  / srv / salt / newfile . sls  - kwarg :  pillar pillar :  filename : {{ data [ fun_args ][ 0 ] }} { % endif % } ##{{ data }}  salt zabbix_server state . sls newfile pillar = { filename : apache_install } cat / srv / salt / newfile . sls / tmp / {{ pillar [ filename ]}}: file . managed : - source : salt : // passwd ， salt zabbix_server state . sls apache_install  (  ) ， newfile . sls","title":"event"},{"location":"saltstack/#_1","text":"， state ， salt centos2 sys . list_functions salt centos2 sys . list_functions sys - sys . argspec - sys . doc ， salt * sys . doc cmd  cmd ， - sys . list_functions module  function ， salt Minion sys . list_functions cmd - sys . list_modules Minion  module ， salt Minion sys . list_modules - sys . list_renderers  Return  - sys . list_returner_functions - sys . list_returners - sys . list_runner_functions - sys . list_runners - sys . list_state_functions  states  function ， salt Minion sys . list_state_functions file - sys . list_state_modules Minion  states  - sys . state_doc state  - sys . reload_modules - sys . renderer_doc - sys . returner_argspec - sys . returner_doc - sys . runner_argspec - sys . runner_doc - sys . state_argspec","title":""},{"location":"saltstack/#grains","text":"grains  master  minion  salt * grains . ls salt node1 grains . items salt node1 grains . item os salt - G os:CentOS test . ping 1 、 grains  salt Minion grains . append saltbook verycool salt * grains . setval key { sub-key : val , sub-key2 : val2 }  salt * grains . remove key val  2 、 minion  grains vim / etc / salt / minion . d / hostinfo . conf #grains,， grains : roles : - webserver - memcache deployment : datacenter4 cabinet : 13  minion / etc / init . d / salt - minion restart 3 、 master  grains ， minion mkdir / srv / salt / _grains vim / srv / salt / _grains / system . py import platform def get_system (): grains = {} # grains grains [ system ] = platform . platform () return grains # salt zabbix_agent saltutil . sync_grains #minion（/var/cache/salt/minion/extmods/grains/） salt zabbix_agent grains . item system #grains  grains  1 、 grains salt - G os:CentOS test . ping 2 、 top . sls  vim top . sls base : location:shanghai : - match : grain - webserver (  sls  ) salt * state . highstate ， location : shanghai  user . sls 3 、 state ， sls  { % set the_node_type = salt [ grains.get ]( grainskey ,  ) % } or grains [ os ] { % if the_node_type % } node_type:{{ the_node_type }} : - match : grain - {{ the_node_type }} { % endif % } 4 、 grains ， __grains__ [ key ] vim g1 . py def t1 (): return __grains__ [ location ] salt * saltutil . sync_modules  salt ‘ * ’ g1 . t1 ","title":"grains"},{"location":"saltstack/#modules","text":" http : // docs . saltstack . com / ref / modules / all / index . html #all-salt-modules import salt.client client = salt . client . LocalClient () ret = client . cmd ( * , test.ping ) print ret Archive  salt centos1 archive . gunzip / tmp / sourcefile . txt . gz #gzunzip/tmp/sourcefile.txt.gz salt centos1 archive . gzip / tmp / sourcefile . txt #gzip/tmp/sourcefile.txt --- API ： client . cmd ( centos1 , archive.gunzip ， [ /tmp/sourcefile.txt.gz ]) cmd  salt centos1 cmd . run free -m # salt centos1 cmd . script salt : // script / test . sh #centos1test.sh，script/test.sh file_roots ， test . sh  minion  cache （ / var / cache / salt / minion / files / base / script / test . sh ）；  --- API ： client . cmd ( SN2013-08-021 , cmd.run ,[ free -m ]) cp  salt centos1 cp . cache_local_file / etc / hosts #/etc/hostssalt cache （ / var / cache / salt / minion / localfiles / ） salt centos1 cp . get_dir salt : // path / to / dir / / minion / dest #file_roots salt centos1 cp . get_file salt : // path / to / file / minion / dest #file_roots salt centos1 cp . get_url http : // www . slashdot . org / tmp / index . html #URL ----- API ： client . cmd ( centos1 , cp.get_file ,[ salt://path/to/file , /minion/dest ]) crontab  salt centos1 cron . raw_cron root or salt centos1 cron . list_tab root #、rootcrontab salt centos1 cron . set_job root * * * * 1 / usr / local / weekly #、root/usr/local/weekly salt centos1 cron . rm_job root / usr / local / weekly #、rootcrontab/usr/local/weekly ----- API ： client . cmd ( centos1 , cron.set_job ,[ root , * , * , * , * , * , /usr/echo ]) dnsutil DNS  salt centos1 dnsutil . hosts_append / etc / hosts 192.168 . 8.12 salt - master #hosts salt centos1 dnsutil . hosts_remove / etc / hosts salt - master #hosts ----- API ： client . cmd ( * , dnsutil.hosts_append ,[ /etc/hosts , 127.0.0.1 , ad1.yuk.co ]) file  salt centos2 file . check_hash / etc / fstab md5 : e4b13a1b984950ade18cbc8bc33be658 #/etc/fstabmd5  True salt * file . get_sum / etc / passwd md5 #、md5、sha1、sha224、sha256、sha384、sha512  salt * file . chown / etc / passwd root root #/etc/passwd、，  chown root : root / etc / passwd salt * file . copy / path / to / src / path / to / dst #/path/to/src/path/to/dst salt * file . directory_exists / etc #/etc，True， file . file_exists  salt * file . stats / etc / passwd #/etc/passwdstats salt * file . get_mode / etc / passwd #/etc/passwdmode，755、644 salt * file . set_mode / etc / passwd 0644 #/etc/passwdmode0644 salt * file . mkdir / opt / test #/opt/test salt * file . sed / etc / httpd / httpd . conf LogLevel warn LogLevel info #/etc/httpd/httpd.conf  LogLevel  warn  info salt * file . append / tmp / test / test . conf maxclient 100 #/tmp/test/test.conf maxclient 100 salt * file . remove / tmp / foo3 #/tmp/foo ------ API ： client . cmd ( * , file.remove ,[ /tmp/foo ]) iptables  salt * iptables . append filter INPUT rule = -m state --state RELATED,ESTABLISHED -j ACCEPT salt * iptables . insert filter INPUT position = 3 rule = -m state --state RELATED,ESTABLISHED -j ACCEPT #(append)、(insert)iptables,INPUT salt * iptables . delete filter INPUT position = 3 salt * iptables . delete filter INPUT rule = -m state --state RELATED,ESTABLISHED-j ACCEPT #3（position=3） salt * iptables . save / etc / sysconfig / iptables #(/etc/sysconfig/iptables) ---- API ： client . cmd ( SN2013-08-022 , iptables.append ,[ filter , INPUT , rule= \\ -p tcp --sport 80 -j ACCEPT \\ ]) netwrok  salt centos2 network . dig www . qq . com salt centos2 network . ping www . qq . com salt centos2 network . traceroute www . qq . com # centos2 dig、ping、traceroute salt centos2 network . hwaddr eth0 #MAC salt centos2 network . in_subnet 10.0 . 0.0 / 16 #10.0.0.0/16，True salt centos2 network . interfaces # salt centos2 network . ip_addrs #IP salt centos2 network . subnets # ---- API ： client . cmd ( SN2013-08-022 , network.ip_addrs ) pkg  salt * pkg . install php #PHP，，redhatyum，  yum - y install php salt * pkg . remove php #PHP salt * pkg . upgrade # ---- API ： client . cmd ( SN2013-08-022 , pkg.remove ,[ php ]) Service  salt * service . enable nginx salt * service . disable nginx #（enable）、（disable）nginx salt * service . reload nginx salt * service . restart nginx salt * service . start nginx salt * service . stop nginx salt * service . status nginx #nginxreload、restart、start、stop、status ----- API ： client . cmd ( SN2013-08-022 , service.stop ,[ nginx ]) other Saltstack  user （）、 group （）、 partition （）、 puppet （ puppet ）、 system （、）、 timezone （）、 nginx （ Nginx ）、 mount （），   / usr / lib / python2 . 6 / site - packages / salt / modules  minion ， master  minion  fileroot : / etc / salt / master / srv / salt 1 、 module  minion  2 、 master  2  modules ,  minion 3 、 mkdir – pv / srv / salt / _modules cd / srv / salt / _modules 4 、 module  cat file . py  File def t1 ( num )  ‘’‘ salt \\ * file . t1 ’‘’  return num * num  return  5 、 minion salt * saltutil . sync_modules  minion ： / var / cache / salt / minion / extmods / modules  : salt * saltutil . sync_all ","title":"modules"},{"location":"saltstack/#zmq","text":"saltstack master  REQSERVER 1  client ， Mworker 2  minion  4506 bind ROUTER workers . ipc bind DEALER Publisher  client  minion 4505 bind PUB publish_pull . ipc bind PULL EVENTPUBLISHER  client ，，！ master_event_pull . ipc bind pull master_event_pub . ipc bind PUB MWORKER ， wokers . ipc connect REP minion 4505 connect SUB ( ， ) 4605 connect REQ (  )  job flow 1 salt * test . ping  client  2 client 4506 REQ connect  3 REQSERVER  MWOKER ， wokers . ipc 4 ，。 publish  client  minion 。 ClearFuncs . publish () MWokers  publish_pull . ipc connect PUSH 5  woker  evnetpublish master_event_pull . ipc connect push  eventpublish  pub  client  （ master_event_pub . ipc ） 6  Publisher  mininon 7  minion  4505  8 minion ，， 9 minion  master  4506 ， master  Mwoker 10 Mwoker ， eventpublish  11  LocalClient 。。 12  minion ，，。 salt - zmq . png","title":"zmq"},{"location":"shell/","text":"shellip  ip 。。 ( nali ) nali   . / configue make make install  url 。  www . ip138 . com www . ip . cn  IP 。  shell  ip . cn 。  : [ root @ localhost ~ ]# curl ip . cn ? ip = 114 . 114 . 114 . 114 IP ： 114 . 114 . 114 . 114 ：  [ root @ localhost ~ ]#  curl 。  : ： 。  awk - F 。：  : [ root @ localhost ~ ]# cat getip . sh # !/ bin / bash Getip = $ ( curl - s ip . cn ? ip = $1 ) IParea = $ ( echo $ Getip | awk - F ： {print $3} | awk {print $1} ) IPisp = $ ( echo $ Getip | awk - F ： {print $3} | awk {print $2} ) if [ ! $1 ] ;then IP = $ ( echo $ Getip | awk - F ： {print $2} | awk {print $1} ) echo $ IP $ IParea $ IPisp else echo $1 $ IParea $ IPisp fi [ root @ localhost ~ ]# . / getip . sh 114 . 114 . 114 . 114 114 . 114 . 114 . 114   。 php  ip . cn ：  : ? php header ( Content-Type: text/html;charset=utf-8 ) ; $ user_IP = ( $ _SERVER [ HTTP_VIA ] ) ? $ _SERVER [ HTTP_X_FORWARDED_FOR ] : $ _SERVER [ REMOTE_ADDR ] ; $ user_IP = ( $ user_IP ) ? $ user_IP : $ _SERVER [ REMOTE_ADDR ] ; $ ip = ( $ _GET [ ip ] ) ? $ _GET [ ip ] : $ user_IP ; $c h = curl_init ( http://www.ip.cn?ip=$ip ) ; curl_setopt ( $c h , CURLOPT_USERAGENT , curl/7.31 ) ; curl_setopt ( $c h , CURLOPT_RETURNTRANSFER , true ) ; curl_setopt ( $c h , CURLOPT_BINARYTRANSFER , true ) ; $ output = curl_exec ( $c h ) ; $ output2 = substr ( $ output , 5 ) ; $ row = split ( ,$ output2 ) ; $c ip = $ row [ 0 ] ; $ca rea = substr ( $ row [ 1 ], 9 ) ; $c isp = $ row [ 2 ] ; $ s = ( $ _GET [ s ] ) ? $ _GET [ s ] : 0 ; if ( $ s == 0 ) { echo $cip $carea $cisp ; } else { $ca rea1 = substr ( $ca rea , 0 , 9 ) ; echo $cip $carea1 $cisp ; } curl_close ( $c h ) ; ?  : [ root @ localhost html ]# curl localhost ? ip = 114 . 114 . 114 . 114 114 . 114 . 114 . 114   [ root @ localhost html ]# 。。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 #!/usr/bin/env bash for i in ` chkconfig --list | awk {print $1} ` ; do if [[ $i = atd || $i = crond || $i = irqbalance || $i = network || $i = sshd || $i = rsyslog || $i = httpd || $i = salt-* || $i = zabbix_* ]] ; then chkconfig --level 3 $i on else chkconfig $i off fi done grep -v ^# /etc/ssh/sshd_config | grep -v ^ $ | grep ^UseDNS no /dev/null if [[ $? -ne 0 ]] ; then sed -i 122a\\UseDNS no /etc/ssh/sshd_config /etc/init.d/sshd restart fi cat /etc/profile EOF if [ $SHELL = /bin/ksh ]; then ulimit -p 16384 ulimit -n 65536 ulimit -c unlimited else ulimit -u 16384 -n 65536 -c unlimited fi EOF source /etc/profile ##set ulimit file cat /etc/security/limits.conf EOF * soft nproc 10000 * hard nproc 16384 * soft nofile 65536 * hard nofile 65536 EOF ## set sysctl cat /etc/sysctl.conf EOF fs.aio-max-nr = 1048576 fs.file-max = 6815744 net.ipv4.ip_local_port_range = 10000 65000 net.ipv4.ip_conntrack_max = 10240 net.ipv4.tcp_max_syn_backlog = 65536 net.core.netdev_max_backlog = 32768 net.ipv4.tcp_syncookies = 1 net.ipv4.tcp_tw_reuse = 1 net.ipv4.tcp_tw_recycle = 1 net.ipv4.tcp_fin_timeout = 30 net.core.rmem_default=262144 net.core.wmem_default=262144 net.core.rmem_max=4194304 net.core.wmem_max=4194304 net.ipv4.tcp_timestamps =0 net.ipv4.tcp_sack =1 net.ipv4.tcp_window_scaling =1 EOF sysctl -p ##install yum install -y @base ntp gcc gcc-c++ make telnet openssl lrzsz vim openssl-devel unzip gd gd-devel libcurl-devel ##set clock ntpdate us.pool.ntp.org ##set ssh port #set -- $(sed -n /^Port/ p /etc/ssh/sshd_config) #port=$2 #if [[ xx${port} == xx ]] #then # cat /etc/ssh/sshd_config EOF #Port 7522 #EOF #elif [[ ${port} -eq 7522 ]] #then # sed -i s/7522/22/g /etc/ssh/sshd_config # echo ok #elif [[ ${port} -eq 22 ]] #then # sed -i s/22/7522/g /etc/ssh/sshd_config #fi #service sshd restart ##set ssh listener ip is Private IP. ssh ssh - copy - id - i . ssh / id_rsa . pub - p 27005 root @192.168.3.129 rsync - e ssh - p Port sftp - o port = 9999 dachui @210.14.133.237 vi ~/ . ssh / config Port 20022 cd ~/ . ssh chmod 600 config  vi / etc / ssh / ssh_config Port 20022 txtcsv sed s/\\t/,\\t/g jigou . txt 1 . csv ，\\ t sed s/\\t/\\t,/g jigou . txt 1 . csv  \\ t ，  csv   csv 。 Excel ， 12 ，；  15 ，， 15 ， 0 。 ： ， \\t . if if .... ; then .... elif .... ; then .... else .... fi [[ $c pu_int 600 . 0 ]] ，  awk - F . {print $1}  if [[ $CmdLine =~ install ]] || [[ $CmdLine =~ remove ]] || [[ $CmdLine =~ update ]] ;then MAIL fi - b  ，（） - c  ，（） - d  ，（） - e  （） - f  ，（） - L  ，（） - p  ，（） - s  ，（） - S  ，（）  1 - nt  2  1  2 （）  1 - ot  2  1  2 （）  1 - ef  2  1  2  Inode ， 。   1 - eq   1  2 （）  1 - ne   1  2 （）  1 - gt  2  1  2 （）  1 - lt  2  1  2 （）  1 - ge  2  1  2 （）  1 - le  2  1  2 （） - z  （） - n  （）  1 ==  2  1  2 （）  1 !=  2  1  2 （）  1 - a  2 ， 1  2 ，  1 - o  2 ， 1  2 ， ！ ，  bash - r . bash_profile  / bin / bash - r . bashrc set - o ignoreeof alias exit = kill $(ps aux | grep logcat@pts | grep -v grep | awk {print $2} ) set - o option (  ) set + o option (  ) set - o noclobber  echo kick tmp - bash : tmp : Cannot overwrite existing file set - o ignoreeof ， logout  exit  shell 。 set - o noglob  noglob ， shell 。 * 、?、［］  ，。，， 。 ：  cd 。  $ PATH , $ SHELL , $BA SH_ENV  $E NV   $ SHELLOPTS ， shell 。 。  / 。  exec  shell 。 。 。 vip 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 #!/usr/bin/env bash vip = 192.168.1.20/24 key = 5 stop_vip = /sbin/ifconfig em2: $key down start_vip = /sbin/ifconfig em2: $key $vip pingtest = $( fping 192 .168.1.20 2 /dev/null | grep -c alive ) while true do if [ $pingtest -ne 1 ] ; then echo redis master is down $start_vip exit 1 else conne = $( /usr/local/redis-3.0.0/src/redis-cli -h 192 .168.1.20 ping 2 /dev/null | grep -c PONG ) if [ $conne -ne 1 ] ; then echo redis master is unreachable pingtest2 = $( fping 192 .168.1.20 2 /dev/null | grep -c alive ) [ $pingtest2 -eq 1 ] ssh root@192.168.1.5 $stop_vip $start_vip exit 2 fi fi sleep 2 echo ====================== done hostname  / etc / sysconfig / network  HOSTNAME  hostname +  ，  sed sed N;s/ \\n / /g  sed N;N;s/ \\n / /g  # h :  H ： g ： G ： x :  n :  N ： d :  D ： sed n;d test . txt # sed - n 1~2p test . txt # sed - n n;p ip # sed - n 2~2p test . txt # sed 1!G;h;$!d test . txt # sed $!d fsta # sed G test . txt # sed /^$/d;G test . txt #， # sed /^#\\|^$/d fstab ## sed 1,8d fstab #1 - 8  sed /^#/d fstab ----- sed - n /^#/p fstab # sed 10a\\ IP fstab # 10  sed /^tmpfs/a\\ IP fstab # tmpfs  sed /^tmpfs/a\\Hello \\n word fstab # sed /^tmpfs/i\\hello \\n word fstab # sed /^tmpfs/c\\hello \\n word fstab # sed /^tmpfs/w b.txt fstab # b . txt sed /^tmpfs/!d fstab # tmpfs  sed s/r..t/ er/g / etc / passwd # r .. t  er sed s/^[[:space:]]\\+// / boot / grub / grub . conf # echo /etc/sysconfig | sed s#[^/]\\+$## # sed  sed ，$ var  $ echo | sed s/^/$RANDOM.rmvb_/g sed ， $var ， $ echo | sed s/^/ $RANDOM .rmvb_/g sed  sed  `shell command`  $(shell command)  $ echo | sed s/^/ ` echo $ RANDOM ` .rmvb_/g $ echo | sed s/^/ $ ( echo $ RANDOM ) .rmvb_/g $ echo | sed s/^/ $ ( date + %Y%m%d ) .rmvb_/g sed options script file ： sed [ options ] {command}[flags] [ filename ] - e script  ， - f script  - n  - i ，， -- follow - symlinks  - i . bak . bak 。 - r  !  （ shell ） q  w  r filename  R   （） sed  a  i  p  d  s  c  y  N D P h H  /  g G  /  / s replace echo this is a test | sed s/test/text/ sed s/dog/cat / data1 sed - e s/brown/green/;s/dog/cat/ data1 sed - n 1p data1 # sed - n $p data1 # sed - n 1,2p data1 # sed - n 2,$p data1 # s / pattern / repleacement / flags sed 1,3y/abc/ABC/ newfile y ， flags   g ： p ： w file : sed 2{s/fox/elephant/;s/dog/cat/} data1 sed 2,${s/fox/elephant/;s/dog/cat/} data1 sed 1,10y/abcde/ABCDE/ example . file  1 — 10  abcde ，，。 y ，（） modify file sed - i sed - i //i filename sed - i //d filename  【】  sed - i 4iabc data3  abc sed - i 4aabc data3  abc sed - i /abc/c789 data3  abc  789  sed - i 4d data3 sed - i /number 2/d data3   This is line number 2 . this is a test line number 2 . sed - i /line number 2/cthis is test line number 2 data3 sed - n $= test  test  sed    ^ ： /^ sed /  sed 。 $ ： / sed $ /  sed 。 . ： / s . d /  s ， d 。 * ： /*sed/sed。 [] ，/[Ss]ed/sedSed。 [^] ，：/[^A-RT-Z]ed/A-RT-Z，ed。 \\(..\\) ，s/\\(love\\)able/\\1rs，loveablelovers。 ，s/love/** **/ ， love  ** love ** 。 \\ ，: / \\ love /  love 。 \\ ， / love \\ /  love 。 x \\{ m \\}  x ， m ，： / 0 \\{ 5 \\} /  5  o 。 x \\{ m ,\\}  x , m ，： / o \\{ 5 ,\\} /  5  o 。 x \\{ m , n \\}  x ， m ， n ，： / o \\{ 5 , 10 \\} /  5 -- 10  o 。 awk awk     awk awk options program file  awk $ 4 = [31/Jan/2018:16:00:00 $ 4 = [31/Jan/2018:16:30:00 log  awk { split ( $ 4 , array , [ ); if ( array [ 2 ] = 31/Jan/2018:17:00:00 array [ 2 ] = 31/Jan/2018:17:30:00 ){ print $ 0 }} log  uv awk { a [ $ 1 ] ++ } END { for ( i in a ) print i , a [ i ]} localhost_access_log .2016 - 10 - 12. txt | wc - l pv wc - l localhost_access_log .2016 - 10 - 12. txt  awk { for ( i = 0 ; ++ i = NF ;) a [ i ] = a [ i ] ? a [ i ] FS $ i : $ i } END { for ( i = 0 ; i ++ NF ;) print a [ i ]} 1. txt name age alice 21 ==== ryan 30  awk { sum = 0 for ( n = 1 ; n 5 ; n ++ ) ( sum += $ n ) print sum } t2  awk { sum += $ 1 } END { print sum } t2 - F fs   - f file  - v var = value  awk  - mf N  - mr N  - w keyword  awk  awk 。。 awk ， 。 $ 0  $ 1  $ 2  $ N N $ NF  awk   / etc / passwd  ： UID ： GID ： shell 【$ 5 $ 3 $ 4 $ 7 】 ： 　 username : root UID : 0 GID : 0 SHELL : / bin / bash echo my name is rich | awk { $ 4 = dave ; print $ 0 }  [ root @ VFAST ~ ] # vim script2 { print $ 5 s userid is $ 1 } [ root @ VFAST ~ ] # awk - F : - f script2 / etc / passwd  【】 [ root @ VFAST ~ ] # awk BEGIN { print hello world! } hello world !  awk command awk     1.    $ 1 $ 2 $ n   FS ， awk  awk    FIELDWIDTHS ， FS  RS  OFS  ORS  cat / etc / passwd [ root @ VFAST ~ ] # awk - F : { print $ 1 , $ 2 , $ 3 } / etc / passwd  [ root @ VFAST ~ ] # awk BEGIN { FS = : } { print $ 1 , $ 2 , $ 3 } / etc / passwd [ root @ VFAST ~ ] # awk BEGIN { FS = : ; OFS = - } { print $ 1 , $ 2 , $ 3 } / etc / passwd FIELDWIDTHS ，，，，  FIELDWIDTHS  vim data3 1005.324759.37 115 - 2.349194.00 05 b10 .1298100.1 [ root @ VFAST ~ ] # awk BEGIN { FIELDWIDTHS = 3 5 2 5 } { print $ 1 , $ 2 , $ 3 , $ 4 } data3 100 5.324 75 9.37 115 - 2.34 91 94.00 05 b 10.12 98 100.1 RS ORS  awk ， RS  ，， [ root @ VFAST ~ ] # cat data7 Riley Mullen 123 Main Street Chicago , IL 60602 ( 312 ) 555 - 1234 [ root @ VFAST ~ ] # awk BEGIN { FS = \\n ; RS = } { print $ 1 , $ 4 } data7 Riley Mullen ( 312 ) 555 - 1234  RS ，， awk  [ root @ VFAST ~ ] # cat data7 | awk BEGIN { FS = \\n ; RS = }{ print $ 1 , $ 2 , $ 3 , $ 4 } Riley Mullen 123 Main Street Chicago , IL 60602 ( 312 ) 555 - 1234 [ root @ VFAST ~ ] # awk BEGIN { FS = \\n ; OFS = - } { print $ 1 , $ 2 , $ 3 , $ 4 } data7 Riley Mullen --- 123 Main Street --- Chicago , IL 60602 --- ( 312 ) 555 - 1234 --- vim vfast 123 456 789 123456 789 awk BEGIN { RS = \\n ; ORS = *** }{ print $ 0 } vfast   [ root @ VFAST ~ ] # awk BEGIN { testing = this is a test print testing testing = 45 print testing } this is a test 45  [ root @ VFAST ~ ] # awk BEGIN { x = 4 ; x = x * 2 + 3 ; print x } 11  vim script0 BEGIN { FS = : } { print $ n } [ root @ VFAST ~ ] # awk - f script0 n = 1 / etc / passwd $ n  1  awk ，，，。 。。  var [ index ] = element var ， index ， element  EXAMPLES : var [ 1 ] = 1 var [ 2 ] = 2 [ root @ VFAST ~ ] # awk BEGIN { var [ 1 ] = 1 var [ 2 ] = 2 total = var [ 1 ] + var [ 2 ] print total }  3 3 awk NR == 1 { print $ 2 } / proc / meminfo  / proc / memeinfo  NR    awk NR == 1 { t = $ 2 } NR == 2 { f = $ 2 ; print f / t * 100 } / proc / meminfo vim aa 1 2 3 4 awk { sum += $ 1 } END { print sum } aa awk END { print NR } test  test  awk END { print $ 0 } test  awk END { print NF } test  2.3 .  : 、 = 、 == 、 != 、 = 、 ~ 、 !~   ==  !=  awk - F : $ 1 == root { print $ 0 } / etc / passwd awk - F : $ 1 != root { print $ 0 } / etc / passwd ~ !~  awk - F : $ 1 ~ ro { print $ 0 } / etc / passwd awk - F : $ 1 !~ ro { print $ 0 } / etc / passwd  = = == vim file 1 2 3 4 awk $ 1 2 { print $ 0 } file awk $ 1 = 2 { print $ 0 } file awk $ 1 2 { print $ 0 } file awk $ 1 = 2 { print $ 0 } file awk $ 1 == 2 { print $ 0 } file  : awk { if ( $ 4 ~/ ASIMA / ) print $ 0 } temp  ASIMA ，  : awk $ 3 == 48 { print $ 0 } temp  3  48   : awk $ 0 !~ / ASIMA / temp  ASIMA   : awk $ 1 != asima temp  : awk { if ( $ 1 $ 2 ) print $ 1 is smaller } temp  : awk / [ Gg ] reen / temp  Green ， green   : awk $ 1 ~/^ ... a / temp  1  a ，’ ^ ’，’ . ’  : awk $ 0 ~/ ( abc ) | ( efg ) / temp  | ， AND  : awk { if ( $ 1 == a $ 2 == b ) print $ 0 } temp OR  : awk { if ( $ 1 == a || $ 1 == b ) print $ 0 } temp awk  awk { if ( $ 1 9 ) print $ 1 } 10 awk ` { if ( $ 1 9 ) print $ 1 * 2 } data ` 20 or awk { if ( $ 1 9 ) { x = $ 1 * 2 print x }} data else awk { if ( $ 1 9 ) print $ 1 * 2 ; else print $ 1 / 2 } data or awk { if ( $ 1 9 ) { x = $ 1 * 2 print x } else { y = $ 1 / 2 }} data while  while ( condition ) { satements } cat data1 1 2 3 4 5 6 7 8 9 awk { total = 0 i = 1 while ( i 4 ) { total += $ i i ++ } print total } data1 total += $ i i ++  data1  1  3  break continue awk { total = 0 i = 1 while ( i 4 ) { total += $ i if ( i == 2 ) break i ++ } print total } data1 $ 1 + $ 2 awk { total = 0 for ( i = 1 ; i 4 ; i ++ ) { total += $ i } print total } data1  $ 1 + $ 2 + $ 3  do - while  do { statements } while ( condition ) awk { total = 0 i = 1 do { total += $ i i ++ } while ( total 150 ) print total } data1  total  150  150   150   150   while  awk { a = 0 i = 1 do { a += $ i i ++ } while ( a 150 ) print a } data 10 7 3 [ root @ instructor tmp ] # awk { a = 0 i = 1 do { a += $ i i ++ } while ( a 150 ) print a } data 263 187 287  [ root @ instructor tmp ] # awk { a = 0 i = 1 do { a += $ i i ++ } while ( a 150 ) print a } data [ root @ instructor tmp ] # cat data1 100 110 20 160 150 140 130 10 20 $ 1  160  while ，$ 2  150 $ 3  150   system   awk  shell  awk BEGIN { system ( echo hello )} hello or [ root @ baism  ] # awk BEGIN { system ( date )} 2014  04  30   11 : 06 : 23 CST   system ( )  cat a . txt 192.168.1 192.168.2 192.168.3 172.16.3 192.16.1 192.16.2 192.16.3 10.0.4  192.168.1 - 192.168.3 172.16.3 192.16.3 - 192.16.1 10.0.4 [ root @ instructor ~ ] # awk BEGIN { RS = ; FS = \\n ; OFS = \\n }{ print $ 1 - $ 3 , $ 4 , $ 7 - $ 4 , $ 8 } aa . txt 192.168.1 - 192.168.3 172.16.3 192.16.3 - 172.16.3 10.0.4 zhangsan Beijing . China san @163. com 010 - 12345678 wangwu Tianjin . China wu @163. com 010 - 23456789 awk BEGIN { RS = ; FS = \\n }{ print ~~~~~~~~~~~~~~~~~~~~~~~~ }{ print $ 1 , $ 2 \\n $ 3 , $ 4 } data awk Linux Web  ： 1 . TCP  netstat - nat | awk {print $6} | sort | uniq - c | sort - rn netstat - n | awk /^tcp/ {++S[$NF]};END {for(a in S) print a, S[a]}  netstat - n | awk /^tcp/ {++state[$NF]}; END {for(key in state) print key, \\t ,state[key]} netstat - n | awk /^tcp/ {++arr[$NF]};END {for(k in arr) print k, t ,arr[k]} netstat - n | awk /^tcp/ {print $NF} | sort | uniq - c | sort - rn netstat - ant | awk {print $NF} | grep - v [a-z] | sort | uniq - c 2 . 20  IP （）： netstat - anlp | grep 80 | grep tcp | awk {print $5} | awk - F : {print $1} | sort | uniq - c | sort - nr | head - n20 netstat - ant | awk /:80/{split($5,ip, : );++A[ip[1]]}END{for(i in A) print A[i],i} | sort - rn | head - n20 3 . tcpdump  80  tcpdump - i eth0 - tnn dst port 80 - c 1000 | awk - F . {print $1 . $2 . $3 . $4}’ | sort | uniq -c | sort -nr |head -20 4 . time_wait  netstat - n | grep TIME_WAIT | awk {print $5} | sort | uniq - c | sort - rn | head - n20 5 . SYN  netstat - an | grep SYN | awk {print $5} | awk - F : {print $1}’ | sort | uniq -c | sort -nr | more 6 . netstat - ntlp | grep 80 | awk {print $7} | cut - d / - f1  1 （ Apache ）： 1 . 10  ip  cat access . log | awk {print $1}’|sort|uniq -c|sort -nr|head -10 cat access . log | awk {counts[$(11)]+=1}; END {for(url in counts) print counts[url], url}’ 2 ., 20 cat access . log | awk {print $11}’|sort|uniq -c|sort -nr|head -20 3 . exe （） cat access . log | awk ($7~/.exe/){print $10 $1 $4 $7}’|sort -nr|head -20 4 . 200000 byte (  200 kb )  exe  cat access . log | awk ($10 200000 $7~/.exe/){print $7}’|sort -n|uniq -c|sort -nr|head -100 5 .， cat access . log | awk ($7~/.php/){print $NF $1 $4 $7}’|sort -nr|head -100 6 . (  60  )  cat access . log | awk ($NF 60 $7~/.php/){print $7}’|sort -n|uniq -c|sort -nr|head -100 7 . 30  cat access . log | awk ($NF 30){print $7}’|sort -n|uniq -c|sort -nr|head -20 8 .（ G ) cat access . log | awk {sum+=$10} END {print sum/1024/1024/1024}’ 9 . 404  awk ($9 ~/404/)’ access.log | awk { print $9 , $7 }’ | sort 10 .  http status cat access . log | awk {counts[$(9)]+=1}; END {for(code in counts) print code, counts[code]} cat access . log | awk {print $9} | sort | uniq - c | sort - rn 10 .，。 / usr / sbin / tcpdump - i eth0 - l - s 0 - w - dst port 80 | strings | grep - i user - agent | grep - i - E bot|crawler|slurp|spider  2 ( Squid ） zcat squid_access . log . tar . gz | awk {print $10,$7} | awk BEGIN{FS= [ /] }{trfc[$4]+=$1}END { for ( domain in trfc ) { printf %st%dn , domain , trfc [ domain ]}}  1 . sql / usr / sbin / tcpdump - i eth0 - s 0 - l - w - dst port 3306 | strings | egrep - i SELECT|UPDATE|DELETE | INSERT | SET | COMMIT | ROLLBACK | CREATE | DROP | ALTER | CALL  Debug  1 . strace - p pid 2 . PID gdb - p pid  ls - AF | grep ^\\.  find - name .?* expect  ssh - keygen - q - t rsa - N - f / root / . ssh / id_rsa yum install expect expect * ，。 # !/ usr / bin / expect set ip [ lindex $a rgv 0 ] set pass [ lindex $a rgv 1 ] spawn ssh - copy - id - i / root / . ssh / id_rsa . pub $ ip expect { (yes/no)? { send yes \\n expect password: { send $pass \\n } } password: { send $pass \\n } } expect eof chmod expect_l1 . sh . / expect_l1 . sh ip pass ， bash ， sh except_l1 . sh ----------------------------------- sudo # !/ usr / bin / expect set timeout 10 spawn sudo - i expect *password* send Tm121#^gnaM \\n interact #，  expect - c spawn sudo -i;expect * password * ;send Tm121 # ^ gnaM \\n ;interact select 1 2 3 4 5 6 7 8 9 10 11 #!/bin/sh PS3 = make your choice in (1-4): select i in www groad net exit do case $i in www ) echo 1-www ;; groad ) echo 2-groad ;; net ) echo 3-net ;; exit ) exit ;; esac done  |  ， arping - h 2 1 | tail - n 1 ,  （  （ stderr ）  ） 1 ，   ：   。  ： mail - s “ mail test ” test @ahlinux . com file1 file1  ， mail test ，  。 2 ，   ：   。  ： ls - l list  “ ls - l ” list  。  ：  !  ，  ，  。  ： ls - lg ! list  “ ls - lg ” list  。  ：   。  ： cc file1 . c error file1 . c error  。  ：   。  ： ls - lag list  “ ls - lag ” list  。  ：   。  ： cc file2 . c error file2 . c error  。  、   ，  /  。  ，  ；  ；  Windows  ， Linux  ，   ，  ，  。  Linux  ：  （ stdin ）  ；  （ stdout ）  ；  （ stderr ）   （  std  standard ）。  BASH  1 ，  2 。   ，  。  、  I / O  ，  。  ： $ ls ls_result $ ls - l ls_result  ls  ls_result  ls_result  ，  。   （  ）  ，   ，   。  ： $ find / home - name lost * 2 err_result   2 ， 2  。  / home  ，   err_result  。  find / home - name lost * 2 》 err_result  ？  find / home - name lost * all_result ，  all_result  ，   ，  ？  ： $ find / home - name lost * all_result 2 1  ，  all_result  。   。  ，  ： $ find / home - name lost * all_result  ，  ： $ find / home - name lost * 2 / dev / null  ，  ，  ？ $ find / home - name lost * all_result 1 2 $ find / home - name lost * 2 all_result 1 2 $ find / home - name lost * 2 1 all_result  - ，  ： $ （ cd / source / directory tar cf - . ） | （ cd / dest / directory tar xvfp - ）  / source / directory  ，  / dest / directory  ，  / source / directory  / dest / directory  。  ，  ： n -  n  -  （  ） n -  n  -  while read 1 、 $ca t a . txt 200 : 2 300 : 3 400 : 4 500 : 5 2 、 while  # !/ bin / ksh while read line do echo $ line done a . txt  1 . mv xxxx {,. bak } mv xxxx xxxx . bak 2 . esc + .  3 . diff ( ssh host1 cat file1 ) ( ssh host2 cat file2 ) diff  4 . ctrl + r  xxx ， xxx  5 . Python - m SimpleHTTPServer ， HTTP ， 6 . vim  root ， : w ! sudo tee % 。 ( w ： vim ，“” ！ sudo tee % ：  shell ， % 。   w  tee ， tee  root  。 ) 7 . ctrl + z ， fg 。 8 .  su ， ssh ， ctrl + d ( ， exit , logout ) 。 9 . sudo !!  sudo 。 10 . ，，，： ctrl + z ，； ； disown - h % 1 （ % n  jobs ，， % 1 ）。 echo read echo - e  \\t tab  \\n  - n  echo $?  echo $#  echo $ *  $@。“$ * ”，。“$@” echo $ n  B = $ RANDOM  $ (( RANDOM % 10 )) 10  read - p  - t  - s  - n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  kill - l crtl + C SIGINT ctrl + Z SIGTSTP   EXIT ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  trap  trap commands signals  trap echo hehe SIGINT  ctrl - c  hehe ,  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~   “ - ”  trap - SIGINT  ctrl - c  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ count = 1 trap echo hello SIGINT while [ $c ount - lt 50 ] do echo #loop $count sleep 3 count = $[ $c ount + 1 ] if [ $c ount - eq 5 ] then trap - SIGINT echo I just remove the trap fi done ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ trap echo hello SIGINT  ctrl - c   $c ount  1 - 5  ctrl - c  if [ $c ount - eq 5 ] then trap - SIGINT echo I just remove the trap fi  $c ount = 5    ctrl - c  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  nohup scripts and jobs kill % ID  755   sh / script ## 1111 and nohup / script # #2222   1111  2222     . / test1 . / test2   nohup scripts ctrl - z bg fg ctrl - z  fg  bg  nice  - 19 ---- 20   nice - n - 10 . / test renice  renice 10 - p 1234 - p pid ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  at batch cron at atq atrm batch  batch - f filename time   cron  cron  crontab - e anacron  cron  linux   linux  anacron  ， anacron  （ / etc / anacron ）  period delay identifier command period   delay  anacron ， ， identifier   cut sort cut - c  - c 1 - 5 1 - 5  - c 5  5  - d  - f  - f1 - 3 1 - 3  - f 4  - b byte sort - r  - n  - k2  2  - t : ： shell linux shell   echo  , echo ， - e 　　： 　　 echo - e \\033[；m\\033[0m 　　： 　　 echo - e \\033[41;36m something here \\033[0m 　　 41 ， 36  　　： ? www . 2 cto . com ? 　　 1 、 　　 2 、 m 　　 3 、，， 　　， 　　 　　 echo - e “\\ 033 [ 31 m  \\ 033 [ 0 m ” 　　 echo - e “\\ 033 [ 34 m  \\ 033 [ 0 m ” 　　 echo - e “\\ 033 [ 41 ; 33 m  \\ 033 [ 0 m ” 　　 echo - e “\\ 033 [ 41 ; 37 m  \\ 033 [ 0 m ” 　　： 30 —– 37 　　 echo - e “\\ 033 [ 30 m  \\ 033 [ 0 m ” 　　 echo - e “\\ 033 [ 31 m  \\ 033 [ 0 m ” 　　 echo - e “\\ 033 [ 32 m  \\ 033 [ 0 m ” 　　 echo - e “\\ 033 [ 33 m  \\ 033 [ 0 m ” 　　 echo - e “\\ 033 [ 34 m  \\ 033 [ 0 m ” 　　 echo - e “\\ 033 [ 35 m  \\ 033 [ 0 m ” 　　 echo - e “\\ 033 [ 36 m  \\ 033 [ 0 m ” 　　 echo - e “\\ 033 [ 37 m  \\ 033 [ 0 m ” 　　： 40 —– 47 　　 echo - e “\\ 033 [ 40 ; 37 m  \\ 033 [ 0 m ” 　　 echo - e “\\ 033 [ 41 ; 37 m  \\ 033 [ 0 m ” 　　 echo - e “\\ 033 [ 42 ; 37 m  \\ 033 [ 0 m ” 　　 echo - e “\\ 033 [ 43 ; 37 m  \\ 033 [ 0 m ” 　　 echo - e “\\ 033 [ 44 ; 37 m  \\ 033 [ 0 m ” 　　 echo - e “\\ 033 [ 45 ; 37 m  \\ 033 [ 0 m ” 　　 echo - e “\\ 033 [ 46 ; 37 m  \\ 033 [ 0 m ” 　　 echo - e “\\ 033 [ 47 ; 30 m  \\ 033 [ 0 m ” 　　 ? www . 2 cto . com ? 　　\\ 33 [ 0 m  　　\\ 33 [ 1 m  　　\\ 33 [ 4 m  　　\\ 33 [ 5 m  　　\\ 33 [ 7 m  　　\\ 33 [ 8 m  ? 　　\\ 33 [ 30 m — \\ 33 [ 37 m  　　\\ 33 [ 40 m — \\ 33 [ 47 m  　　\\ 33 [ nA  n  　　\\ 33 [ nB  n  　　\\ 33 [ nC  n  　　\\ 33 [ nD  n  　　\\ 33 [ y ; xH  　　\\ 33 [ 2 J  　　\\ 33 [ K  　　\\ 33 [ s  　　\\ 33 [ u  　　\\ 33 [ ? 25 l  　　\\ 33 [ ? 25 h   、 ： ^ [ 0 - 9 ] * $ n ： ^ \\ d { n }$  n ： ^ \\ d { n , }$ m - n ： ^ \\ d { m , n }$ ： ^ ( 0 | [ 1 - 9 ][ 0 - 9 ] * ) $ ： ^ ([ 1 - 9 ][ 0 - 9 ] * ) + (.[ 0 - 9 ] { 1 , 2 } ) ? $  1 - 2 ： ^ ( \\ - ) ? \\ d + ( \\ . \\ d { 1 , 2 } ) ? $ 、、： ^ ( \\ -| \\ + ) ? \\ d + ( \\ . \\ d + ) ? $ ： ^ [ 0 - 9 ] + (.[ 0 - 9 ] { 2 } ) ? $  1 ~ 3 ： ^ [ 0 - 9 ] + (.[ 0 - 9 ] { 1 , 3 } ) ? $ ： ^ [ 1 - 9 ] \\ d * $  ^ ([ 1 - 9 ][ 0 - 9 ] * ) { 1 , 3 }$  ^ \\ +? [ 1 - 9 ][ 0 - 9 ] * $ ： ^ \\ - [ 1 - 9 ][] 0 - 9 ″ * $  ^- [ 1 - 9 ] \\ d * $ ： ^ \\ d + $  ^ [ 1 - 9 ] \\ d *| 0 $ ： ^- [ 1 - 9 ] \\ d *| 0 $  ^ (( - \\ d + ) | ( 0 + )) $ ： ^ \\ d + ( \\ . \\ d + ) ? $  ^ [ 1 - 9 ] \\ d * \\ . \\ d *| 0 \\ . \\ d * [ 1 - 9 ] \\ d *| 0 ? \\ . 0 +| 0 $ ： ^ (( - \\ d + ( \\ . \\ d + ) ? ) | ( 0 + ( \\ . 0 + ) ? )) $  ^ ( - ([ 1 - 9 ] \\ d * \\ . \\ d *| 0 \\ . \\ d * [ 1 - 9 ] \\ d * )) | 0 ? \\ . 0 +| 0 $ ： ^ [ 1 - 9 ] \\ d * \\ . \\ d *| 0 \\ . \\ d * [ 1 - 9 ] \\ d * $  ^ (([ 0 - 9 ] + \\ .[ 0 - 9 ] * [ 1 - 9 ][ 0 - 9 ] * ) | ([ 0 - 9 ] * [ 1 - 9 ][ 0 - 9 ] * \\ .[ 0 - 9 ] + ) | ([ 0 - 9 ] * [ 1 - 9 ][ 0 - 9 ] * )) $ ： ^- ([ 1 - 9 ] \\ d * \\ . \\ d *| 0 \\ . \\ d * [ 1 - 9 ] \\ d * ) $  ^ ( - (([ 0 - 9 ] + \\ .[ 0 - 9 ] * [ 1 - 9 ][ 0 - 9 ] * ) | ([ 0 - 9 ] * [ 1 - 9 ][ 0 - 9 ] * \\ .[ 0 - 9 ] + ) | ([ 0 - 9 ] * [ 1 - 9 ][ 0 - 9 ] * ))) $ ： ^ ( -? \\ d + )( \\ . \\ d + ) ? $  ^-? ([ 1 - 9 ] \\ d * \\ . \\ d *| 0 \\ . \\ d * [ 1 - 9 ] \\ d *| 0 ? \\ . 0 +| 0 ) $ 、 ： ^ [ \\ u4e00 - \\ u9fa5 ] { 0 , }$ ： ^ [ A - Za - z0 - 9 ] + $  ^ [ A - Za - z0 - 9 ] { 4 , 40 }$  3 - 20 ： ^ . { 3 , 20 }$  26 ： ^ [ A - Za - z ] + $  26 ： ^ [ A - Z ] + $  26 ： ^ [ a - z ] + $  26 ： ^ [ A - Za - z0 - 9 ] + $ 、 26 ： ^ \\ w + $  ^ \\ w { 3 , 20 }$ 、、： ^ [ \\ u4E00 - \\ u9FA5A - Za - z0 - 9 _ ] + $ 、、： ^ [ \\ u4E00 - \\ u9FA5A - Za - z0 - 9 ] + $  ^ [ \\ u4E00 - \\ u9FA5A - Za - z0 - 9 ] { 2 , 20 }$  ^% ’ ,; =? $\\”： [ ^% ,; =? $\\ x22 ] +  ~ ： [ ^~ \\ x22 ] + 、 Email ： ^ \\ w + ([ -+ .] \\ w + ) *@ \\ w + ([ - .] \\ w + ) * \\ . \\ w + ([ - .] \\ w + ) * $ ： [ a - zA - Z0 - 9 ][ - a - zA - Z0 - 9 ] { 0 , 62 } ( / .[ a - zA - Z0 - 9 ][ - a - zA - Z0 - 9 ] { 0 , 62 } ) +/ . ? InternetURL ： [ a - zA - z ] + : // [ ^ \\ s ] *  ^ http : // ([ \\ w - ] + \\ .) + [ \\ w - ] + ( / [ \\ w - . /?% = ] * ) ? $ ： ^ ( 13 [ 0 - 9 ] | 14 [ 5 | 7 ] | 15 [ 0 | 1 | 2 | 3 | 5 | 6 | 7 | 8 | 9 ] | 18 [ 0 | 1 | 2 | 3 | 5 | 6 | 7 | 8 | 9 ]) \\ d { 8 }$  ( “ XXX - XXXXXXX ”、” XXXX - XXXXXXXX ”、” XXX - XXXXXXX ”、” XXX - XXXXXXXX ”、” XXXXXXX ”” XXXXXXXX ) ： ^ ( $$\\ d { 3 , 4 } - ) | \\ d { 3 . 4 } - ) ? \\ d { 7 , 8 }$  ( 0511 - 4405222 、 021 - 87888822 ) ：\\ d { 3 } - \\ d { 8 } | \\ d { 4 } - \\ d { 7 }  ( 15 、 18  ) ： ^ \\ d { 15 } | \\ d { 18 }$  ( 、 x  ) ： ^ ([ 0 - 9 ]) { 7 , 18 } ( x | X ) ? $  ^ \\ d { 8 , 18 } | [ 0 - 9 x ] { 8 , 18 } | [ 0 - 9 X ] { 8 , 18 } ? $  ( ， 5 - 16 ， ) ： ^ [ a - zA - Z ][ a - zA - Z0 - 9 _ ] { 4 , 15 }$  ( ， 6 ~ 18 ，、 ) ： ^ [ a - zA - Z ] \\ w { 5 , 17 }$  ( ，， 8 - 10  ) ： ^ ( ?= . * \\ d )( ?= . * [ a - z ])( ?= . * [ A - Z ]). { 8 , 10 }$ ： ^ \\ d { 4 } - \\ d { 1 , 2 } - \\ d { 1 , 2 }  12  ( 01 ～ 09  1 ～ 12 ) ： ^ ( 0 ? [ 1 - 9 ] | 1 [ 0 - 2 ]) $  31  ( 01 ～ 09  1 ～ 31 ) ： ^ (( 0 ? [ 1 - 9 ]) | (( 1 | 2 )[ 0 - 9 ]) | 30 | 31 ) $ ：  : ” 10000 . 00 ″  “ 10 , 000 . 00 ″ ,  “”  “ 10000 ″  “ 10 , 000 ″： ^ [ 1 - 9 ][ 0 - 9 ] * $  0 ，，” 0 ″，： ^ ( 0 | [ 1 - 9 ][ 0 - 9 ] * ) $  0  0  . ： ^ ( 0 |-? [ 1 - 9 ][ 0 - 9 ] * ) $  0  0  .  0  . ， .  ： ^ [ 0 - 9 ] + (.[ 0 - 9 ] + ) ? $ ， 1 ，” 10 . ”， “ 10 ″  “ 10 . 2 ″ ： ^ [ 0 - 9 ] + (.[ 0 - 9 ] { 2 } ) ? $ ，，： ^ [ 0 - 9 ] + (.[ 0 - 9 ] { 1 , 2 } ) ? $ 。，： ^ [ 0 - 9 ] { 1 , 3 } (,[ 0 - 9 ] { 3 } ) * (.[ 0 - 9 ] { 1 , 2 } ) ? $ 1  3 ，  + 3 ，，： ^ ([ 0 - 9 ] +| [ 0 - 9 ] { 1 , 3 } (,[ 0 - 9 ] { 3 } ) * )(.[ 0 - 9 ] { 1 , 2 } ) ? $ ：，” + ”” * ”。 ( ， ? ) ， ， xml ： ^ ([ a - zA - Z ] +-? ) + [ a - zA - Z0 - 9 ] + \\\\ .[ x | X ][ m | M ][ l | L ] $ ： [ \\ u4e00 - \\ u9fa5 ] ： [ ^ \\ x00 - \\ xff ] ( ， (  2 ， ASCII  1 )) ：\\ n \\ s * \\ r (  ) HTML ： ( \\ S *? )[ ^ ] * . *? / \\ 1 | . *? / ( ，， ) ： ^ \\ s *| \\ s * $ ( ^ \\ s * ) | ( \\ s * $ ) (  ( 、、 ) ，  )  QQ ： [ 1 - 9 ][ 0 - 9 ] { 4 , } (  QQ  10000  ) ： [ 1 - 9 ] \\ d { 5 } ( ?! \\ d ) (  6  ) IP ：\\ d + \\ . \\ d + \\ . \\ d + \\ . \\ d + (  IP  ) IP ： (( ? :( ? : 25 [ 0 - 5 ] | 2 [ 0 - 4 ] \\\\ d | [ 01 ] ? \\\\ d ? \\\\ d ) \\\\ .) { 3 } ( ? : 25 [ 0 - 5 ] | 2 [ 0 - 4 ] \\\\ d | [ 01 ] ? \\\\ d ? \\\\ d ))","title":"shell"},{"location":"shell/#shellip","text":" ip 。。 ( nali ) nali   . / configue make make install  url 。  www . ip138 . com www . ip . cn  IP 。  shell  ip . cn 。  : [ root @ localhost ~ ]# curl ip . cn ? ip = 114 . 114 . 114 . 114 IP ： 114 . 114 . 114 . 114 ：  [ root @ localhost ~ ]#  curl 。  : ： 。  awk - F 。：  : [ root @ localhost ~ ]# cat getip . sh # !/ bin / bash Getip = $ ( curl - s ip . cn ? ip = $1 ) IParea = $ ( echo $ Getip | awk - F ： {print $3} | awk {print $1} ) IPisp = $ ( echo $ Getip | awk - F ： {print $3} | awk {print $2} ) if [ ! $1 ] ;then IP = $ ( echo $ Getip | awk - F ： {print $2} | awk {print $1} ) echo $ IP $ IParea $ IPisp else echo $1 $ IParea $ IPisp fi [ root @ localhost ~ ]# . / getip . sh 114 . 114 . 114 . 114 114 . 114 . 114 . 114   。 php  ip . cn ：  : ? php header ( Content-Type: text/html;charset=utf-8 ) ; $ user_IP = ( $ _SERVER [ HTTP_VIA ] ) ? $ _SERVER [ HTTP_X_FORWARDED_FOR ] : $ _SERVER [ REMOTE_ADDR ] ; $ user_IP = ( $ user_IP ) ? $ user_IP : $ _SERVER [ REMOTE_ADDR ] ; $ ip = ( $ _GET [ ip ] ) ? $ _GET [ ip ] : $ user_IP ; $c h = curl_init ( http://www.ip.cn?ip=$ip ) ; curl_setopt ( $c h , CURLOPT_USERAGENT , curl/7.31 ) ; curl_setopt ( $c h , CURLOPT_RETURNTRANSFER , true ) ; curl_setopt ( $c h , CURLOPT_BINARYTRANSFER , true ) ; $ output = curl_exec ( $c h ) ; $ output2 = substr ( $ output , 5 ) ; $ row = split ( ,$ output2 ) ; $c ip = $ row [ 0 ] ; $ca rea = substr ( $ row [ 1 ], 9 ) ; $c isp = $ row [ 2 ] ; $ s = ( $ _GET [ s ] ) ? $ _GET [ s ] : 0 ; if ( $ s == 0 ) { echo $cip $carea $cisp ; } else { $ca rea1 = substr ( $ca rea , 0 , 9 ) ; echo $cip $carea1 $cisp ; } curl_close ( $c h ) ; ?  : [ root @ localhost html ]# curl localhost ? ip = 114 . 114 . 114 . 114 114 . 114 . 114 . 114   [ root @ localhost html ]# 。。","title":"shellip"},{"location":"shell/#_1","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 #!/usr/bin/env bash for i in ` chkconfig --list | awk {print $1} ` ; do if [[ $i = atd || $i = crond || $i = irqbalance || $i = network || $i = sshd || $i = rsyslog || $i = httpd || $i = salt-* || $i = zabbix_* ]] ; then chkconfig --level 3 $i on else chkconfig $i off fi done grep -v ^# /etc/ssh/sshd_config | grep -v ^ $ | grep ^UseDNS no /dev/null if [[ $? -ne 0 ]] ; then sed -i 122a\\UseDNS no /etc/ssh/sshd_config /etc/init.d/sshd restart fi cat /etc/profile EOF if [ $SHELL = /bin/ksh ]; then ulimit -p 16384 ulimit -n 65536 ulimit -c unlimited else ulimit -u 16384 -n 65536 -c unlimited fi EOF source /etc/profile ##set ulimit file cat /etc/security/limits.conf EOF * soft nproc 10000 * hard nproc 16384 * soft nofile 65536 * hard nofile 65536 EOF ## set sysctl cat /etc/sysctl.conf EOF fs.aio-max-nr = 1048576 fs.file-max = 6815744 net.ipv4.ip_local_port_range = 10000 65000 net.ipv4.ip_conntrack_max = 10240 net.ipv4.tcp_max_syn_backlog = 65536 net.core.netdev_max_backlog = 32768 net.ipv4.tcp_syncookies = 1 net.ipv4.tcp_tw_reuse = 1 net.ipv4.tcp_tw_recycle = 1 net.ipv4.tcp_fin_timeout = 30 net.core.rmem_default=262144 net.core.wmem_default=262144 net.core.rmem_max=4194304 net.core.wmem_max=4194304 net.ipv4.tcp_timestamps =0 net.ipv4.tcp_sack =1 net.ipv4.tcp_window_scaling =1 EOF sysctl -p ##install yum install -y @base ntp gcc gcc-c++ make telnet openssl lrzsz vim openssl-devel unzip gd gd-devel libcurl-devel ##set clock ntpdate us.pool.ntp.org ##set ssh port #set -- $(sed -n /^Port/ p /etc/ssh/sshd_config) #port=$2 #if [[ xx${port} == xx ]] #then # cat /etc/ssh/sshd_config EOF #Port 7522 #EOF #elif [[ ${port} -eq 7522 ]] #then # sed -i s/7522/22/g /etc/ssh/sshd_config # echo ok #elif [[ ${port} -eq 22 ]] #then # sed -i s/22/7522/g /etc/ssh/sshd_config #fi #service sshd restart ##set ssh listener ip is Private IP.","title":""},{"location":"shell/#ssh","text":"ssh - copy - id - i . ssh / id_rsa . pub - p 27005 root @192.168.3.129 rsync - e ssh - p Port sftp - o port = 9999 dachui @210.14.133.237 vi ~/ . ssh / config Port 20022 cd ~/ . ssh chmod 600 config  vi / etc / ssh / ssh_config Port 20022","title":"ssh"},{"location":"shell/#txtcsv","text":"sed s/\\t/,\\t/g jigou . txt 1 . csv ，\\ t sed s/\\t/\\t,/g jigou . txt 1 . csv  \\ t ，  csv   csv 。 Excel ， 12 ，；  15 ，， 15 ， 0 。 ： ， \\t .","title":"txtcsv"},{"location":"shell/#if","text":"if .... ; then .... elif .... ; then .... else .... fi [[ $c pu_int 600 . 0 ]] ，  awk - F . {print $1}  if [[ $CmdLine =~ install ]] || [[ $CmdLine =~ remove ]] || [[ $CmdLine =~ update ]] ;then MAIL fi - b  ，（） - c  ，（） - d  ，（） - e  （） - f  ，（） - L  ，（） - p  ，（） - s  ，（） - S  ，（）  1 - nt  2  1  2 （）  1 - ot  2  1  2 （）  1 - ef  2  1  2  Inode ， 。   1 - eq   1  2 （）  1 - ne   1  2 （）  1 - gt  2  1  2 （）  1 - lt  2  1  2 （）  1 - ge  2  1  2 （）  1 - le  2  1  2 （） - z  （） - n  （）  1 ==  2  1  2 （）  1 !=  2  1  2 （）  1 - a  2 ， 1  2 ，  1 - o  2 ， 1  2 ， ！ ，","title":"if"},{"location":"shell/#_2","text":"bash - r . bash_profile  / bin / bash - r . bashrc set - o ignoreeof alias exit = kill $(ps aux | grep logcat@pts | grep -v grep | awk {print $2} ) set - o option (  ) set + o option (  ) set - o noclobber  echo kick tmp - bash : tmp : Cannot overwrite existing file set - o ignoreeof ， logout  exit  shell 。 set - o noglob  noglob ， shell 。 * 、?、［］  ，。，， 。 ：  cd 。  $ PATH , $ SHELL , $BA SH_ENV  $E NV   $ SHELLOPTS ， shell 。 。  / 。  exec  shell 。 。 。","title":""},{"location":"shell/#vip","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 #!/usr/bin/env bash vip = 192.168.1.20/24 key = 5 stop_vip = /sbin/ifconfig em2: $key down start_vip = /sbin/ifconfig em2: $key $vip pingtest = $( fping 192 .168.1.20 2 /dev/null | grep -c alive ) while true do if [ $pingtest -ne 1 ] ; then echo redis master is down $start_vip exit 1 else conne = $( /usr/local/redis-3.0.0/src/redis-cli -h 192 .168.1.20 ping 2 /dev/null | grep -c PONG ) if [ $conne -ne 1 ] ; then echo redis master is unreachable pingtest2 = $( fping 192 .168.1.20 2 /dev/null | grep -c alive ) [ $pingtest2 -eq 1 ] ssh root@192.168.1.5 $stop_vip $start_vip exit 2 fi fi sleep 2 echo ====================== done","title":"vip"},{"location":"shell/#hostname","text":" / etc / sysconfig / network  HOSTNAME  hostname +  ， ","title":"hostname"},{"location":"shell/#sed","text":"sed N;s/ \\n / /g  sed N;N;s/ \\n / /g  # h :  H ： g ： G ： x :  n :  N ： d :  D ： sed n;d test . txt # sed - n 1~2p test . txt # sed - n n;p ip # sed - n 2~2p test . txt # sed 1!G;h;$!d test . txt # sed $!d fsta # sed G test . txt # sed /^$/d;G test . txt #， # sed /^#\\|^$/d fstab ## sed 1,8d fstab #1 - 8  sed /^#/d fstab ----- sed - n /^#/p fstab # sed 10a\\ IP fstab # 10  sed /^tmpfs/a\\ IP fstab # tmpfs  sed /^tmpfs/a\\Hello \\n word fstab # sed /^tmpfs/i\\hello \\n word fstab # sed /^tmpfs/c\\hello \\n word fstab # sed /^tmpfs/w b.txt fstab # b . txt sed /^tmpfs/!d fstab # tmpfs  sed s/r..t/ er/g / etc / passwd # r .. t  er sed s/^[[:space:]]\\+// / boot / grub / grub . conf # echo /etc/sysconfig | sed s#[^/]\\+$## # sed  sed ，$ var  $ echo | sed s/^/$RANDOM.rmvb_/g sed ， $var ， $ echo | sed s/^/ $RANDOM .rmvb_/g sed  sed  `shell command`  $(shell command)  $ echo | sed s/^/ ` echo $ RANDOM ` .rmvb_/g $ echo | sed s/^/ $ ( echo $ RANDOM ) .rmvb_/g $ echo | sed s/^/ $ ( date + %Y%m%d ) .rmvb_/g sed options script file ： sed [ options ] {command}[flags] [ filename ] - e script  ， - f script  - n  - i ，， -- follow - symlinks  - i . bak . bak 。 - r  !  （ shell ） q  w  r filename  R   （） sed  a  i  p  d  s  c  y  N D P h H  /  g G  /  / s replace echo this is a test | sed s/test/text/ sed s/dog/cat / data1 sed - e s/brown/green/;s/dog/cat/ data1 sed - n 1p data1 # sed - n $p data1 # sed - n 1,2p data1 # sed - n 2,$p data1 # s / pattern / repleacement / flags sed 1,3y/abc/ABC/ newfile y ， flags   g ： p ： w file : sed 2{s/fox/elephant/;s/dog/cat/} data1 sed 2,${s/fox/elephant/;s/dog/cat/} data1 sed 1,10y/abcde/ABCDE/ example . file  1 — 10  abcde ，，。 y ，（） modify file sed - i sed - i //i filename sed - i //d filename  【】  sed - i 4iabc data3  abc sed - i 4aabc data3  abc sed - i /abc/c789 data3  abc  789  sed - i 4d data3 sed - i /number 2/d data3   This is line number 2 . this is a test line number 2 . sed - i /line number 2/cthis is test line number 2 data3 sed - n $= test  test  sed    ^ ： /^ sed /  sed 。 $ ： / sed $ /  sed 。 . ： / s . d /  s ， d 。 * ： /*sed/sed。 [] ，/[Ss]ed/sedSed。 [^] ，：/[^A-RT-Z]ed/A-RT-Z，ed。 \\(..\\) ，s/\\(love\\)able/\\1rs，loveablelovers。 ，s/love/** **/ ， love  ** love ** 。 \\ ，: / \\ love /  love 。 \\ ， / love \\ /  love 。 x \\{ m \\}  x ， m ，： / 0 \\{ 5 \\} /  5  o 。 x \\{ m ,\\}  x , m ，： / o \\{ 5 ,\\} /  5  o 。 x \\{ m , n \\}  x ， m ， n ，： / o \\{ 5 , 10 \\} /  5 -- 10  o 。","title":"sed"},{"location":"shell/#awk","text":"awk     awk awk options program file  awk $ 4 = [31/Jan/2018:16:00:00 $ 4 = [31/Jan/2018:16:30:00 log  awk { split ( $ 4 , array , [ ); if ( array [ 2 ] = 31/Jan/2018:17:00:00 array [ 2 ] = 31/Jan/2018:17:30:00 ){ print $ 0 }} log  uv awk { a [ $ 1 ] ++ } END { for ( i in a ) print i , a [ i ]} localhost_access_log .2016 - 10 - 12. txt | wc - l pv wc - l localhost_access_log .2016 - 10 - 12. txt  awk { for ( i = 0 ; ++ i = NF ;) a [ i ] = a [ i ] ? a [ i ] FS $ i : $ i } END { for ( i = 0 ; i ++ NF ;) print a [ i ]} 1. txt name age alice 21 ==== ryan 30  awk { sum = 0 for ( n = 1 ; n 5 ; n ++ ) ( sum += $ n ) print sum } t2  awk { sum += $ 1 } END { print sum } t2 - F fs   - f file  - v var = value  awk  - mf N  - mr N  - w keyword  awk  awk 。。 awk ， 。 $ 0  $ 1  $ 2  $ N N $ NF  awk   / etc / passwd  ： UID ： GID ： shell 【$ 5 $ 3 $ 4 $ 7 】 ： 　 username : root UID : 0 GID : 0 SHELL : / bin / bash echo my name is rich | awk { $ 4 = dave ; print $ 0 }  [ root @ VFAST ~ ] # vim script2 { print $ 5 s userid is $ 1 } [ root @ VFAST ~ ] # awk - F : - f script2 / etc / passwd  【】 [ root @ VFAST ~ ] # awk BEGIN { print hello world! } hello world !  awk command awk     1.    $ 1 $ 2 $ n   FS ， awk  awk    FIELDWIDTHS ， FS  RS  OFS  ORS  cat / etc / passwd [ root @ VFAST ~ ] # awk - F : { print $ 1 , $ 2 , $ 3 } / etc / passwd  [ root @ VFAST ~ ] # awk BEGIN { FS = : } { print $ 1 , $ 2 , $ 3 } / etc / passwd [ root @ VFAST ~ ] # awk BEGIN { FS = : ; OFS = - } { print $ 1 , $ 2 , $ 3 } / etc / passwd FIELDWIDTHS ，，，，  FIELDWIDTHS  vim data3 1005.324759.37 115 - 2.349194.00 05 b10 .1298100.1 [ root @ VFAST ~ ] # awk BEGIN { FIELDWIDTHS = 3 5 2 5 } { print $ 1 , $ 2 , $ 3 , $ 4 } data3 100 5.324 75 9.37 115 - 2.34 91 94.00 05 b 10.12 98 100.1 RS ORS  awk ， RS  ，， [ root @ VFAST ~ ] # cat data7 Riley Mullen 123 Main Street Chicago , IL 60602 ( 312 ) 555 - 1234 [ root @ VFAST ~ ] # awk BEGIN { FS = \\n ; RS = } { print $ 1 , $ 4 } data7 Riley Mullen ( 312 ) 555 - 1234  RS ，， awk  [ root @ VFAST ~ ] # cat data7 | awk BEGIN { FS = \\n ; RS = }{ print $ 1 , $ 2 , $ 3 , $ 4 } Riley Mullen 123 Main Street Chicago , IL 60602 ( 312 ) 555 - 1234 [ root @ VFAST ~ ] # awk BEGIN { FS = \\n ; OFS = - } { print $ 1 , $ 2 , $ 3 , $ 4 } data7 Riley Mullen --- 123 Main Street --- Chicago , IL 60602 --- ( 312 ) 555 - 1234 --- vim vfast 123 456 789 123456 789 awk BEGIN { RS = \\n ; ORS = *** }{ print $ 0 } vfast   [ root @ VFAST ~ ] # awk BEGIN { testing = this is a test print testing testing = 45 print testing } this is a test 45  [ root @ VFAST ~ ] # awk BEGIN { x = 4 ; x = x * 2 + 3 ; print x } 11  vim script0 BEGIN { FS = : } { print $ n } [ root @ VFAST ~ ] # awk - f script0 n = 1 / etc / passwd $ n  1  awk ，，，。 。。  var [ index ] = element var ， index ， element  EXAMPLES : var [ 1 ] = 1 var [ 2 ] = 2 [ root @ VFAST ~ ] # awk BEGIN { var [ 1 ] = 1 var [ 2 ] = 2 total = var [ 1 ] + var [ 2 ] print total }  3 3 awk NR == 1 { print $ 2 } / proc / meminfo  / proc / memeinfo  NR    awk NR == 1 { t = $ 2 } NR == 2 { f = $ 2 ; print f / t * 100 } / proc / meminfo vim aa 1 2 3 4 awk { sum += $ 1 } END { print sum } aa awk END { print NR } test  test  awk END { print $ 0 } test  awk END { print NF } test  2.3 .  : 、 = 、 == 、 != 、 = 、 ~ 、 !~   ==  !=  awk - F : $ 1 == root { print $ 0 } / etc / passwd awk - F : $ 1 != root { print $ 0 } / etc / passwd ~ !~  awk - F : $ 1 ~ ro { print $ 0 } / etc / passwd awk - F : $ 1 !~ ro { print $ 0 } / etc / passwd  = = == vim file 1 2 3 4 awk $ 1 2 { print $ 0 } file awk $ 1 = 2 { print $ 0 } file awk $ 1 2 { print $ 0 } file awk $ 1 = 2 { print $ 0 } file awk $ 1 == 2 { print $ 0 } file  : awk { if ( $ 4 ~/ ASIMA / ) print $ 0 } temp  ASIMA ，  : awk $ 3 == 48 { print $ 0 } temp  3  48   : awk $ 0 !~ / ASIMA / temp  ASIMA   : awk $ 1 != asima temp  : awk { if ( $ 1 $ 2 ) print $ 1 is smaller } temp  : awk / [ Gg ] reen / temp  Green ， green   : awk $ 1 ~/^ ... a / temp  1  a ，’ ^ ’，’ . ’  : awk $ 0 ~/ ( abc ) | ( efg ) / temp  | ， AND  : awk { if ( $ 1 == a $ 2 == b ) print $ 0 } temp OR  : awk { if ( $ 1 == a || $ 1 == b ) print $ 0 } temp awk  awk { if ( $ 1 9 ) print $ 1 } 10 awk ` { if ( $ 1 9 ) print $ 1 * 2 } data ` 20 or awk { if ( $ 1 9 ) { x = $ 1 * 2 print x }} data else awk { if ( $ 1 9 ) print $ 1 * 2 ; else print $ 1 / 2 } data or awk { if ( $ 1 9 ) { x = $ 1 * 2 print x } else { y = $ 1 / 2 }} data while  while ( condition ) { satements } cat data1 1 2 3 4 5 6 7 8 9 awk { total = 0 i = 1 while ( i 4 ) { total += $ i i ++ } print total } data1 total += $ i i ++  data1  1  3  break continue awk { total = 0 i = 1 while ( i 4 ) { total += $ i if ( i == 2 ) break i ++ } print total } data1 $ 1 + $ 2 awk { total = 0 for ( i = 1 ; i 4 ; i ++ ) { total += $ i } print total } data1  $ 1 + $ 2 + $ 3  do - while  do { statements } while ( condition ) awk { total = 0 i = 1 do { total += $ i i ++ } while ( total 150 ) print total } data1  total  150  150   150   150   while  awk { a = 0 i = 1 do { a += $ i i ++ } while ( a 150 ) print a } data 10 7 3 [ root @ instructor tmp ] # awk { a = 0 i = 1 do { a += $ i i ++ } while ( a 150 ) print a } data 263 187 287  [ root @ instructor tmp ] # awk { a = 0 i = 1 do { a += $ i i ++ } while ( a 150 ) print a } data [ root @ instructor tmp ] # cat data1 100 110 20 160 150 140 130 10 20 $ 1  160  while ，$ 2  150 $ 3  150   system   awk  shell  awk BEGIN { system ( echo hello )} hello or [ root @ baism  ] # awk BEGIN { system ( date )} 2014  04  30   11 : 06 : 23 CST   system ( )  cat a . txt 192.168.1 192.168.2 192.168.3 172.16.3 192.16.1 192.16.2 192.16.3 10.0.4  192.168.1 - 192.168.3 172.16.3 192.16.3 - 192.16.1 10.0.4 [ root @ instructor ~ ] # awk BEGIN { RS = ; FS = \\n ; OFS = \\n }{ print $ 1 - $ 3 , $ 4 , $ 7 - $ 4 , $ 8 } aa . txt 192.168.1 - 192.168.3 172.16.3 192.16.3 - 172.16.3 10.0.4 zhangsan Beijing . China san @163. com 010 - 12345678 wangwu Tianjin . China wu @163. com 010 - 23456789 awk BEGIN { RS = ; FS = \\n }{ print ~~~~~~~~~~~~~~~~~~~~~~~~ }{ print $ 1 , $ 2 \\n $ 3 , $ 4 } data","title":"awk"},{"location":"shell/#awk_1","text":"Linux Web  ： 1 . TCP  netstat - nat | awk {print $6} | sort | uniq - c | sort - rn netstat - n | awk /^tcp/ {++S[$NF]};END {for(a in S) print a, S[a]}  netstat - n | awk /^tcp/ {++state[$NF]}; END {for(key in state) print key, \\t ,state[key]} netstat - n | awk /^tcp/ {++arr[$NF]};END {for(k in arr) print k, t ,arr[k]} netstat - n | awk /^tcp/ {print $NF} | sort | uniq - c | sort - rn netstat - ant | awk {print $NF} | grep - v [a-z] | sort | uniq - c 2 . 20  IP （）： netstat - anlp | grep 80 | grep tcp | awk {print $5} | awk - F : {print $1} | sort | uniq - c | sort - nr | head - n20 netstat - ant | awk /:80/{split($5,ip, : );++A[ip[1]]}END{for(i in A) print A[i],i} | sort - rn | head - n20 3 . tcpdump  80  tcpdump - i eth0 - tnn dst port 80 - c 1000 | awk - F . {print $1 . $2 . $3 . $4}’ | sort | uniq -c | sort -nr |head -20 4 . time_wait  netstat - n | grep TIME_WAIT | awk {print $5} | sort | uniq - c | sort - rn | head - n20 5 . SYN  netstat - an | grep SYN | awk {print $5} | awk - F : {print $1}’ | sort | uniq -c | sort -nr | more 6 . netstat - ntlp | grep 80 | awk {print $7} | cut - d / - f1  1 （ Apache ）： 1 . 10  ip  cat access . log | awk {print $1}’|sort|uniq -c|sort -nr|head -10 cat access . log | awk {counts[$(11)]+=1}; END {for(url in counts) print counts[url], url}’ 2 ., 20 cat access . log | awk {print $11}’|sort|uniq -c|sort -nr|head -20 3 . exe （） cat access . log | awk ($7~/.exe/){print $10 $1 $4 $7}’|sort -nr|head -20 4 . 200000 byte (  200 kb )  exe  cat access . log | awk ($10 200000 $7~/.exe/){print $7}’|sort -n|uniq -c|sort -nr|head -100 5 .， cat access . log | awk ($7~/.php/){print $NF $1 $4 $7}’|sort -nr|head -100 6 . (  60  )  cat access . log | awk ($NF 60 $7~/.php/){print $7}’|sort -n|uniq -c|sort -nr|head -100 7 . 30  cat access . log | awk ($NF 30){print $7}’|sort -n|uniq -c|sort -nr|head -20 8 .（ G ) cat access . log | awk {sum+=$10} END {print sum/1024/1024/1024}’ 9 . 404  awk ($9 ~/404/)’ access.log | awk { print $9 , $7 }’ | sort 10 .  http status cat access . log | awk {counts[$(9)]+=1}; END {for(code in counts) print code, counts[code]} cat access . log | awk {print $9} | sort | uniq - c | sort - rn 10 .，。 / usr / sbin / tcpdump - i eth0 - l - s 0 - w - dst port 80 | strings | grep - i user - agent | grep - i - E bot|crawler|slurp|spider  2 ( Squid ） zcat squid_access . log . tar . gz | awk {print $10,$7} | awk BEGIN{FS= [ /] }{trfc[$4]+=$1}END { for ( domain in trfc ) { printf %st%dn , domain , trfc [ domain ]}}  1 . sql / usr / sbin / tcpdump - i eth0 - s 0 - l - w - dst port 3306 | strings | egrep - i SELECT|UPDATE|DELETE | INSERT | SET | COMMIT | ROLLBACK | CREATE | DROP | ALTER | CALL  Debug  1 . strace - p pid 2 . PID gdb - p pid","title":"awk"},{"location":"shell/#_3","text":"ls - AF | grep ^\\.  find - name .?*","title":""},{"location":"shell/#expect","text":" ssh - keygen - q - t rsa - N - f / root / . ssh / id_rsa yum install expect expect * ，。 # !/ usr / bin / expect set ip [ lindex $a rgv 0 ] set pass [ lindex $a rgv 1 ] spawn ssh - copy - id - i / root / . ssh / id_rsa . pub $ ip expect { (yes/no)? { send yes \\n expect password: { send $pass \\n } } password: { send $pass \\n } } expect eof chmod expect_l1 . sh . / expect_l1 . sh ip pass ， bash ， sh except_l1 . sh ----------------------------------- sudo # !/ usr / bin / expect set timeout 10 spawn sudo - i expect *password* send Tm121#^gnaM \\n interact #，  expect - c spawn sudo -i;expect * password * ;send Tm121 # ^ gnaM \\n ;interact","title":"expect"},{"location":"shell/#select","text":"1 2 3 4 5 6 7 8 9 10 11 #!/bin/sh PS3 = make your choice in (1-4): select i in www groad net exit do case $i in www ) echo 1-www ;; groad ) echo 2-groad ;; net ) echo 3-net ;; exit ) exit ;; esac done","title":"select"},{"location":"shell/#_4","text":"|  ， arping - h 2 1 | tail - n 1 ,  （  （ stderr ）  ） 1 ，   ：   。  ： mail - s “ mail test ” test @ahlinux . com file1 file1  ， mail test ，  。 2 ，   ：   。  ： ls - l list  “ ls - l ” list  。  ：  !  ，  ，  。  ： ls - lg ! list  “ ls - lg ” list  。  ：   。  ： cc file1 . c error file1 . c error  。  ：   。  ： ls - lag list  “ ls - lag ” list  。  ：   。  ： cc file2 . c error file2 . c error  。  、   ，  /  。  ，  ；  ；  Windows  ， Linux  ，   ，  ，  。  Linux  ：  （ stdin ）  ；  （ stdout ）  ；  （ stderr ）   （  std  standard ）。  BASH  1 ，  2 。   ，  。  、  I / O  ，  。  ： $ ls ls_result $ ls - l ls_result  ls  ls_result  ls_result  ，  。   （  ）  ，   ，   。  ： $ find / home - name lost * 2 err_result   2 ， 2  。  / home  ，   err_result  。  find / home - name lost * 2 》 err_result  ？  find / home - name lost * all_result ，  all_result  ，   ，  ？  ： $ find / home - name lost * all_result 2 1  ，  all_result  。   。  ，  ： $ find / home - name lost * all_result  ，  ： $ find / home - name lost * 2 / dev / null  ，  ，  ？ $ find / home - name lost * all_result 1 2 $ find / home - name lost * 2 all_result 1 2 $ find / home - name lost * 2 1 all_result  - ，  ： $ （ cd / source / directory tar cf - . ） | （ cd / dest / directory tar xvfp - ）  / source / directory  ，  / dest / directory  ，  / source / directory  / dest / directory  。  ，  ： n -  n  -  （  ） n -  n  - ","title":""},{"location":"shell/#while-read","text":"1 、 $ca t a . txt 200 : 2 300 : 3 400 : 4 500 : 5 2 、 while  # !/ bin / ksh while read line do echo $ line done a . txt","title":"while read"},{"location":"shell/#_5","text":"1 . mv xxxx {,. bak } mv xxxx xxxx . bak 2 . esc + .  3 . diff ( ssh host1 cat file1 ) ( ssh host2 cat file2 ) diff  4 . ctrl + r  xxx ， xxx  5 . Python - m SimpleHTTPServer ， HTTP ， 6 . vim  root ， : w ! sudo tee % 。 ( w ： vim ，“” ！ sudo tee % ：  shell ， % 。   w  tee ， tee  root  。 ) 7 . ctrl + z ， fg 。 8 .  su ， ssh ， ctrl + d ( ， exit , logout ) 。 9 . sudo !!  sudo 。 10 . ，，，： ctrl + z ，； ； disown - h % 1 （ % n  jobs ，， % 1 ）。","title":""},{"location":"shell/#echo-read","text":"echo - e  \\t tab  \\n  - n  echo $?  echo $#  echo $ *  $@。“$ * ”，。“$@” echo $ n  B = $ RANDOM  $ (( RANDOM % 10 )) 10  read - p  - t  - s  - n ","title":"echo read"},{"location":"shell/#_6","text":" ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  kill - l crtl + C SIGINT ctrl + Z SIGTSTP   EXIT ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  trap  trap commands signals  trap echo hehe SIGINT  ctrl - c  hehe ,  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~   “ - ”  trap - SIGINT  ctrl - c  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ count = 1 trap echo hello SIGINT while [ $c ount - lt 50 ] do echo #loop $count sleep 3 count = $[ $c ount + 1 ] if [ $c ount - eq 5 ] then trap - SIGINT echo I just remove the trap fi done ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ trap echo hello SIGINT  ctrl - c   $c ount  1 - 5  ctrl - c  if [ $c ount - eq 5 ] then trap - SIGINT echo I just remove the trap fi  $c ount = 5    ctrl - c  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  nohup scripts and jobs kill % ID  755   sh / script ## 1111 and nohup / script # #2222   1111  2222     . / test1 . / test2   nohup scripts ctrl - z bg fg ctrl - z  fg  bg  nice  - 19 ---- 20   nice - n - 10 . / test renice  renice 10 - p 1234 - p pid ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  at batch cron at atq atrm batch  batch - f filename time   cron  cron  crontab - e anacron  cron  linux   linux  anacron  ， anacron  （ / etc / anacron ）  period delay identifier command period   delay  anacron ， ， identifier  ","title":""},{"location":"shell/#cut-sort","text":"cut - c  - c 1 - 5 1 - 5  - c 5  5  - d  - f  - f1 - 3 1 - 3  - f 4  - b byte sort - r  - n  - k2  2  - t : ：","title":"cut sort"},{"location":"shell/#shell","text":"linux shell   echo  , echo ， - e 　　： 　　 echo - e \\033[；m\\033[0m 　　： 　　 echo - e \\033[41;36m something here \\033[0m 　　 41 ， 36  　　： ? www . 2 cto . com ? 　　 1 、 　　 2 、 m 　　 3 、，， 　　， 　　 　　 echo - e “\\ 033 [ 31 m  \\ 033 [ 0 m ” 　　 echo - e “\\ 033 [ 34 m  \\ 033 [ 0 m ” 　　 echo - e “\\ 033 [ 41 ; 33 m  \\ 033 [ 0 m ” 　　 echo - e “\\ 033 [ 41 ; 37 m  \\ 033 [ 0 m ” 　　： 30 —– 37 　　 echo - e “\\ 033 [ 30 m  \\ 033 [ 0 m ” 　　 echo - e “\\ 033 [ 31 m  \\ 033 [ 0 m ” 　　 echo - e “\\ 033 [ 32 m  \\ 033 [ 0 m ” 　　 echo - e “\\ 033 [ 33 m  \\ 033 [ 0 m ” 　　 echo - e “\\ 033 [ 34 m  \\ 033 [ 0 m ” 　　 echo - e “\\ 033 [ 35 m  \\ 033 [ 0 m ” 　　 echo - e “\\ 033 [ 36 m  \\ 033 [ 0 m ” 　　 echo - e “\\ 033 [ 37 m  \\ 033 [ 0 m ” 　　： 40 —– 47 　　 echo - e “\\ 033 [ 40 ; 37 m  \\ 033 [ 0 m ” 　　 echo - e “\\ 033 [ 41 ; 37 m  \\ 033 [ 0 m ” 　　 echo - e “\\ 033 [ 42 ; 37 m  \\ 033 [ 0 m ” 　　 echo - e “\\ 033 [ 43 ; 37 m  \\ 033 [ 0 m ” 　　 echo - e “\\ 033 [ 44 ; 37 m  \\ 033 [ 0 m ” 　　 echo - e “\\ 033 [ 45 ; 37 m  \\ 033 [ 0 m ” 　　 echo - e “\\ 033 [ 46 ; 37 m  \\ 033 [ 0 m ” 　　 echo - e “\\ 033 [ 47 ; 30 m  \\ 033 [ 0 m ” 　　 ? www . 2 cto . com ? 　　\\ 33 [ 0 m  　　\\ 33 [ 1 m  　　\\ 33 [ 4 m  　　\\ 33 [ 5 m  　　\\ 33 [ 7 m  　　\\ 33 [ 8 m  ? 　　\\ 33 [ 30 m — \\ 33 [ 37 m  　　\\ 33 [ 40 m — \\ 33 [ 47 m  　　\\ 33 [ nA  n  　　\\ 33 [ nB  n  　　\\ 33 [ nC  n  　　\\ 33 [ nD  n  　　\\ 33 [ y ; xH  　　\\ 33 [ 2 J  　　\\ 33 [ K  　　\\ 33 [ s  　　\\ 33 [ u  　　\\ 33 [ ? 25 l  　　\\ 33 [ ? 25 h ","title":"shell"},{"location":"shell/#_7","text":"、 ： ^ [ 0 - 9 ] * $ n ： ^ \\ d { n }$  n ： ^ \\ d { n , }$ m - n ： ^ \\ d { m , n }$ ： ^ ( 0 | [ 1 - 9 ][ 0 - 9 ] * ) $ ： ^ ([ 1 - 9 ][ 0 - 9 ] * ) + (.[ 0 - 9 ] { 1 , 2 } ) ? $  1 - 2 ： ^ ( \\ - ) ? \\ d + ( \\ . \\ d { 1 , 2 } ) ? $ 、、： ^ ( \\ -| \\ + ) ? \\ d + ( \\ . \\ d + ) ? $ ： ^ [ 0 - 9 ] + (.[ 0 - 9 ] { 2 } ) ? $  1 ~ 3 ： ^ [ 0 - 9 ] + (.[ 0 - 9 ] { 1 , 3 } ) ? $ ： ^ [ 1 - 9 ] \\ d * $  ^ ([ 1 - 9 ][ 0 - 9 ] * ) { 1 , 3 }$  ^ \\ +? [ 1 - 9 ][ 0 - 9 ] * $ ： ^ \\ - [ 1 - 9 ][] 0 - 9 ″ * $  ^- [ 1 - 9 ] \\ d * $ ： ^ \\ d + $  ^ [ 1 - 9 ] \\ d *| 0 $ ： ^- [ 1 - 9 ] \\ d *| 0 $  ^ (( - \\ d + ) | ( 0 + )) $ ： ^ \\ d + ( \\ . \\ d + ) ? $  ^ [ 1 - 9 ] \\ d * \\ . \\ d *| 0 \\ . \\ d * [ 1 - 9 ] \\ d *| 0 ? \\ . 0 +| 0 $ ： ^ (( - \\ d + ( \\ . \\ d + ) ? ) | ( 0 + ( \\ . 0 + ) ? )) $  ^ ( - ([ 1 - 9 ] \\ d * \\ . \\ d *| 0 \\ . \\ d * [ 1 - 9 ] \\ d * )) | 0 ? \\ . 0 +| 0 $ ： ^ [ 1 - 9 ] \\ d * \\ . \\ d *| 0 \\ . \\ d * [ 1 - 9 ] \\ d * $  ^ (([ 0 - 9 ] + \\ .[ 0 - 9 ] * [ 1 - 9 ][ 0 - 9 ] * ) | ([ 0 - 9 ] * [ 1 - 9 ][ 0 - 9 ] * \\ .[ 0 - 9 ] + ) | ([ 0 - 9 ] * [ 1 - 9 ][ 0 - 9 ] * )) $ ： ^- ([ 1 - 9 ] \\ d * \\ . \\ d *| 0 \\ . \\ d * [ 1 - 9 ] \\ d * ) $  ^ ( - (([ 0 - 9 ] + \\ .[ 0 - 9 ] * [ 1 - 9 ][ 0 - 9 ] * ) | ([ 0 - 9 ] * [ 1 - 9 ][ 0 - 9 ] * \\ .[ 0 - 9 ] + ) | ([ 0 - 9 ] * [ 1 - 9 ][ 0 - 9 ] * ))) $ ： ^ ( -? \\ d + )( \\ . \\ d + ) ? $  ^-? ([ 1 - 9 ] \\ d * \\ . \\ d *| 0 \\ . \\ d * [ 1 - 9 ] \\ d *| 0 ? \\ . 0 +| 0 ) $ 、 ： ^ [ \\ u4e00 - \\ u9fa5 ] { 0 , }$ ： ^ [ A - Za - z0 - 9 ] + $  ^ [ A - Za - z0 - 9 ] { 4 , 40 }$  3 - 20 ： ^ . { 3 , 20 }$  26 ： ^ [ A - Za - z ] + $  26 ： ^ [ A - Z ] + $  26 ： ^ [ a - z ] + $  26 ： ^ [ A - Za - z0 - 9 ] + $ 、 26 ： ^ \\ w + $  ^ \\ w { 3 , 20 }$ 、、： ^ [ \\ u4E00 - \\ u9FA5A - Za - z0 - 9 _ ] + $ 、、： ^ [ \\ u4E00 - \\ u9FA5A - Za - z0 - 9 ] + $  ^ [ \\ u4E00 - \\ u9FA5A - Za - z0 - 9 ] { 2 , 20 }$  ^% ’ ,; =? $\\”： [ ^% ,; =? $\\ x22 ] +  ~ ： [ ^~ \\ x22 ] + 、 Email ： ^ \\ w + ([ -+ .] \\ w + ) *@ \\ w + ([ - .] \\ w + ) * \\ . \\ w + ([ - .] \\ w + ) * $ ： [ a - zA - Z0 - 9 ][ - a - zA - Z0 - 9 ] { 0 , 62 } ( / .[ a - zA - Z0 - 9 ][ - a - zA - Z0 - 9 ] { 0 , 62 } ) +/ . ? InternetURL ： [ a - zA - z ] + : // [ ^ \\ s ] *  ^ http : // ([ \\ w - ] + \\ .) + [ \\ w - ] + ( / [ \\ w - . /?% = ] * ) ? $ ： ^ ( 13 [ 0 - 9 ] | 14 [ 5 | 7 ] | 15 [ 0 | 1 | 2 | 3 | 5 | 6 | 7 | 8 | 9 ] | 18 [ 0 | 1 | 2 | 3 | 5 | 6 | 7 | 8 | 9 ]) \\ d { 8 }$  ( “ XXX - XXXXXXX ”、” XXXX - XXXXXXXX ”、” XXX - XXXXXXX ”、” XXX - XXXXXXXX ”、” XXXXXXX ”” XXXXXXXX ) ： ^ ( $$\\ d { 3 , 4 } - ) | \\ d { 3 . 4 } - ) ? \\ d { 7 , 8 }$  ( 0511 - 4405222 、 021 - 87888822 ) ：\\ d { 3 } - \\ d { 8 } | \\ d { 4 } - \\ d { 7 }  ( 15 、 18  ) ： ^ \\ d { 15 } | \\ d { 18 }$  ( 、 x  ) ： ^ ([ 0 - 9 ]) { 7 , 18 } ( x | X ) ? $  ^ \\ d { 8 , 18 } | [ 0 - 9 x ] { 8 , 18 } | [ 0 - 9 X ] { 8 , 18 } ? $  ( ， 5 - 16 ， ) ： ^ [ a - zA - Z ][ a - zA - Z0 - 9 _ ] { 4 , 15 }$  ( ， 6 ~ 18 ，、 ) ： ^ [ a - zA - Z ] \\ w { 5 , 17 }$  ( ，， 8 - 10  ) ： ^ ( ?= . * \\ d )( ?= . * [ a - z ])( ?= . * [ A - Z ]). { 8 , 10 }$ ： ^ \\ d { 4 } - \\ d { 1 , 2 } - \\ d { 1 , 2 }  12  ( 01 ～ 09  1 ～ 12 ) ： ^ ( 0 ? [ 1 - 9 ] | 1 [ 0 - 2 ]) $  31  ( 01 ～ 09  1 ～ 31 ) ： ^ (( 0 ? [ 1 - 9 ]) | (( 1 | 2 )[ 0 - 9 ]) | 30 | 31 ) $ ：  : ” 10000 . 00 ″  “ 10 , 000 . 00 ″ ,  “”  “ 10000 ″  “ 10 , 000 ″： ^ [ 1 - 9 ][ 0 - 9 ] * $  0 ，，” 0 ″，： ^ ( 0 | [ 1 - 9 ][ 0 - 9 ] * ) $  0  0  . ： ^ ( 0 |-? [ 1 - 9 ][ 0 - 9 ] * ) $  0  0  .  0  . ， .  ： ^ [ 0 - 9 ] + (.[ 0 - 9 ] + ) ? $ ， 1 ，” 10 . ”， “ 10 ″  “ 10 . 2 ″ ： ^ [ 0 - 9 ] + (.[ 0 - 9 ] { 2 } ) ? $ ，，： ^ [ 0 - 9 ] + (.[ 0 - 9 ] { 1 , 2 } ) ? $ 。，： ^ [ 0 - 9 ] { 1 , 3 } (,[ 0 - 9 ] { 3 } ) * (.[ 0 - 9 ] { 1 , 2 } ) ? $ 1  3 ，  + 3 ，，： ^ ([ 0 - 9 ] +| [ 0 - 9 ] { 1 , 3 } (,[ 0 - 9 ] { 3 } ) * )(.[ 0 - 9 ] { 1 , 2 } ) ? $ ：，” + ”” * ”。 ( ， ? ) ， ， xml ： ^ ([ a - zA - Z ] +-? ) + [ a - zA - Z0 - 9 ] + \\\\ .[ x | X ][ m | M ][ l | L ] $ ： [ \\ u4e00 - \\ u9fa5 ] ： [ ^ \\ x00 - \\ xff ] ( ， (  2 ， ASCII  1 )) ：\\ n \\ s * \\ r (  ) HTML ： ( \\ S *? )[ ^ ] * . *? / \\ 1 | . *? / ( ，， ) ： ^ \\ s *| \\ s * $ ( ^ \\ s * ) | ( \\ s * $ ) (  ( 、、 ) ，  )  QQ ： [ 1 - 9 ][ 0 - 9 ] { 4 , } (  QQ  10000  ) ： [ 1 - 9 ] \\ d { 5 } ( ?! \\ d ) (  6  ) IP ：\\ d + \\ . \\ d + \\ . \\ d + \\ . \\ d + (  IP  ) IP ： (( ? :( ? : 25 [ 0 - 5 ] | 2 [ 0 - 4 ] \\\\ d | [ 01 ] ? \\\\ d ? \\\\ d ) \\\\ .) { 3 } ( ? : 25 [ 0 - 5 ] | 2 [ 0 - 4 ] \\\\ d | [ 01 ] ? \\\\ d ? \\\\ d ))","title":""},{"location":"source/","text":"gem https : // ruby . taobao . org / (  ) http : // gems . ruby - china . org / $ gem sources --add http://gems.ruby-china.org/ --remove http://rubygems.org/ $ gem sources - l *** CURRENT SOURCES *** https : // ruby . taobao . org #  ruby . taobao . org $ gem install rails cpan cpan   ： cpan o conf prerequisites_policy follow o conf commit exit   PERL_MM_USE_DEFAULT = 1  vim / usr / share / perl5 / CPAN / Config . pm  urllist = [ q [ http : // mirrors . 163 . com / cpan / ]] rpmforge  http : // pkgs . repoforge . org / rpmforge - release / （ rpm ）  http : // mirror . bjtu . edu . cn / repoforge / cat / etc / yum . repo . d / rpmforge . repo ### Name : RPMforge RPM Repository for RHEL 6 - dag ### URL : http : // rpmforge . net / [ rpmforge ] name = RHEL $ releasever - RPMforge . net - dag baseurl = http : // mirror . bjtu . edu . cn / repoforge / redhat / el6 / en / $ba search / rpmforge mirrorlist = http : // mirror . bjtu . edu . cn / repoforge / redhat / el6 / en / mirrors - rpmforge # mirrorlist = file : /// etc / yum . repos . d / mirrors - rpmforge enabled = 1 protect = 0 gpgkey = file : /// etc / pki / rpm - gpg / RPM - GPG - KEY - rpmforge - dag gpgcheck = 0 yum  yum   rpm ， yum 。，， yum ，，  yum ， yum ， yum  repodata ，。  yum  repodata 。  yum  yum  rsync ， rsync 。 http : // mirrors . ustc . edu . cn / status / CentOS ： rsync : // mirrors . ustc . edu . cn / centos / epel ： rsync : // mirrors . ustc . edu . cn / epel / ： #  rsync  yum ，、， CentOS6  rpm ， rpm  21 G ， 300 G 。 #  base ，， rpm ， 3 G ，。 / usr / bin / rsync - av rsync : // mirrors . ustc . edu . cn / centos / 6 / os / x86_64 / / data / yum_data / centos / 6 / os / x86_64 / / usr / bin / rsync - av rsync : // mirrors . ustc . edu . cn / centos / 6 / extras / x86_64 / / data / yum_data / centos / 6 / extras / x86_64 / / usr / bin / rsync - av rsync : // mirrors . ustc . edu . cn / centos / 6 / updates / x86_64 / / data / yum_data / centos / 6 / updates / x86_64 / # epel  / usr / bin / rsync - av – exclude = debug rsync : // mirrors . ustc . edu . cn / epel / 6 / x86_64 / / data / yum_data / epel / 6 / x86_64 /  yum  #  dns ，， hosts 。 echo ‘ 192 . 168 . 0 . 200 mirrors . aliyun . com ’ / etc / hosts","title":"source"},{"location":"source/#gem","text":"https : // ruby . taobao . org / (  ) http : // gems . ruby - china . org / $ gem sources --add http://gems.ruby-china.org/ --remove http://rubygems.org/ $ gem sources - l *** CURRENT SOURCES *** https : // ruby . taobao . org #  ruby . taobao . org $ gem install rails","title":"gem"},{"location":"source/#cpan","text":"cpan   ： cpan o conf prerequisites_policy follow o conf commit exit   PERL_MM_USE_DEFAULT = 1  vim / usr / share / perl5 / CPAN / Config . pm  urllist = [ q [ http : // mirrors . 163 . com / cpan / ]]","title":"cpan"},{"location":"source/#rpmforge","text":" http : // pkgs . repoforge . org / rpmforge - release / （ rpm ）  http : // mirror . bjtu . edu . cn / repoforge / cat / etc / yum . repo . d / rpmforge . repo ### Name : RPMforge RPM Repository for RHEL 6 - dag ### URL : http : // rpmforge . net / [ rpmforge ] name = RHEL $ releasever - RPMforge . net - dag baseurl = http : // mirror . bjtu . edu . cn / repoforge / redhat / el6 / en / $ba search / rpmforge mirrorlist = http : // mirror . bjtu . edu . cn / repoforge / redhat / el6 / en / mirrors - rpmforge # mirrorlist = file : /// etc / yum . repos . d / mirrors - rpmforge enabled = 1 protect = 0 gpgkey = file : /// etc / pki / rpm - gpg / RPM - GPG - KEY - rpmforge - dag gpgcheck = 0","title":"rpmforge"},{"location":"source/#yum","text":" yum   rpm ， yum 。，， yum ，，  yum ， yum ， yum  repodata ，。  yum  repodata 。  yum  yum  rsync ， rsync 。 http : // mirrors . ustc . edu . cn / status / CentOS ： rsync : // mirrors . ustc . edu . cn / centos / epel ： rsync : // mirrors . ustc . edu . cn / epel / ： #  rsync  yum ，、， CentOS6  rpm ， rpm  21 G ， 300 G 。 #  base ，， rpm ， 3 G ，。 / usr / bin / rsync - av rsync : // mirrors . ustc . edu . cn / centos / 6 / os / x86_64 / / data / yum_data / centos / 6 / os / x86_64 / / usr / bin / rsync - av rsync : // mirrors . ustc . edu . cn / centos / 6 / extras / x86_64 / / data / yum_data / centos / 6 / extras / x86_64 / / usr / bin / rsync - av rsync : // mirrors . ustc . edu . cn / centos / 6 / updates / x86_64 / / data / yum_data / centos / 6 / updates / x86_64 / # epel  / usr / bin / rsync - av – exclude = debug rsync : // mirrors . ustc . edu . cn / epel / 6 / x86_64 / / data / yum_data / epel / 6 / x86_64 /  yum  #  dns ，， hosts 。 echo ‘ 192 . 168 . 0 . 200 mirrors . aliyun . com ’ / etc / hosts","title":"yum"},{"location":"tcp-issue/","text":"TCP Web，TCP，TCP 11。TCP，。TCP 11，TCP。 TCP ，TCP，，Web， ： ：Web，。 ：WebRedisMySQL， 。，Web。 ：。  HTTP，TCP11， 。 ： ，、。。 CLOSED：。 SYN_SENT：（CLOSED- SYN_SENT） CLOSED，TCP，TCPSYN， CLOSESYN_SENT。 ，，。 ESTABLISHED：（SYN_SENT- ESTABLISHED） TCP，ACKSYN，， ACK，SYN_SENTESTABLISHED， ，，TCP， 。：SYN，ACK ：ACK。 ： ！ESTABLISHED，， ，。 LISTEN： Web，Nginx，80，TCP LISTEN，CLOSE。 SYN_RCVD：(LISTEN- SYN_RCVD) ，LISTENNginxSYN，LISTEN SYN_RCVD，，SYN_SENT。SYN， SYNACK。 ESTABLISHED：（SYN_RCVD ESTABLISHED） SYNACK，ACK，ACK， SYN_RCVDESTABLISHED。 ，，TCP，， ，TCP，。 ，seq=x。SYN1。CLOSEDSYN_SENT。 ，CLOSEDLISTEND，SYN，TCPSYN、AC1， ack=x+1，seq=y。LISTENSYN_RCVD。 ，TCPACK1，ack=y+1，seq=x+1， ESTABLISHEN ，EXTABLISHED。 TCP： ， ESTABLISHED 。 。 FIN_WAIT_1:（ESTABLISHED- FIN_WAIT_1）：ESTABLISHED， FIN，，ESTABLISHEDFIN_WAIT_1。 CLOSE_WAIT：(ESTABLISHED- CLOSE_WAIT)，， ，FIN，ACK，ESTABLISHEDCLOSE_WAIT。 FIN_WAIT_2：(FIN_WAIT_1- FIN_WAIT_2)，， ACK，FIN，， FIN_WAIT_1FIN_WAIT_2。 LAST_ACK:(CLOSE_WAIT- LAST_ACK) ，。 “”。，，HTTP，， ，TCP，FIN。 CLOSE_WAITLAST_ACK。？。 TIME_WAIT：（FIN_WAIT_2- TIME_WAIT） FINLAST_ACK，FIN，FIN_WAIT_2TIME_WAIT。 ACK。 CLOSED：(LAST_ACK- CLOSED)， ACK，LAST_ACKCLOSED。，。 ：TIME_WAIT。。 TIME_WAIT： TCP； 。 Linux，60，CLOSED。 ：。， 。， ，TIME_WAIT。 Too many open files java . net . SocketException : Too many open files at java . net . Socket . createImpl ( Socket . java : 388 ) at java . net . Socket . connect ( Socket . java : 517 ) at java . net . Socket . connect ( Socket . java : 469 ) at sun . net . NetworkClient . doConnect ( NetworkClient . java : 163 ) at sun . net . www . http . HttpClient . openServer ( HttpClient . java : 394 ) at sun . net . www . http . HttpClient . openServer ( HttpClient . java : 529 ) at sun . net . www . http . HttpClient . init ( HttpClient . java : 233 ) at sun . net . www . http . HttpClient . New ( HttpClient . java : 306 ) at sun . net . www . http . HttpClient . New ( HttpClient . java : 323 ) at sun . net . www . protocol . http . HttpURLConnection . getNewHttpClient ( HttpURLConnection . java : 852 ) at sun . net . www . protocol . http . HttpURLConnection . plainConnect ( HttpURLConnection . java : 793 ) at sun . net . www . protocol . http . HttpURLConnection . connect ( HttpURLConnection . java : 718 ) at sun . net . www . protocol . http . HttpURLConnection . getOutputStream ( HttpURLConnection . java : 896 ) at a8 . mms . util . Tools . postObject ( Tools . java : 301 ) ：“ Too many open files ” ：， socket  closed_wait ， port  1024 ，  close_wait ， port “ Too many open files ”，。 close_wait  socket ，： ： 、：  ServerSocket  accept ()  Socket  read () ， setSoTimeout ()  （ 0 ，）；，，， 。 ， read () ， 1 ， read ()  1 ，  Socket ，。 、： ， TCP / IP ； ： / proc / sys / fs / file - max ， sysctl . conf ； ulimit  shell ， limits . conf ； lsof ,；：,,,,, ； ，， limits . conf ；  cat / proc / sys / fs / file - max  65536 ，；  ulimit - a ； open files  4096 （ 1024 ) ,  open files  8192 ；： 1 . root ， / etc / security / limits . conf vi / etc / security / limits . conf  xxx - nofile 8192 xxx ， * ，，。 # domain type item value * soft nofile 8192 * hard nofile 8192 # 8192 。 2 .  / etc / pam . d / login  / etc / pam . d / sshd ： session required pam_limits . so 。 3 .  bash  ulimit - a ： 、 ：（,,） sysctl - w net . ipv4 . tcp_keepalive_time = 600 sysctl - w net . ipv4 . tcp_keepalive_probes = 2 sysctl - w net . ipv4 . tcp_keepalive_intvl = 2 ： Linux ，。 、 ，；。 vi / etc / sysctl . conf ，： net . ipv4 . tcp_keepalive_time = 1800 net . ipv4 . tcp_keepalive_probes = 3 net . ipv4 . tcp_keepalive_intvl = 15  / etc / sysctl . conf , network  / etc / rc . d / init . d / network restart ， sysctl ，。 ------------------------------------------------------------ ：  FIN ，， socket  FIN  Client ， Socket  CLOSE_WAIT （ LAST_ACK ）。， CLOSE_WAIT  2 （ 7200 ，  2 ）。 CLOSE_WAIT ，，。，  TCP / IP ， tcp_keepalive_ * ： tcp_keepalive_time ： / proc / sys / net / ipv4 / tcp_keepalive_time INTEGER ， 7200 ( 2  )  keepalive ， TCP  keepalive 。 1800 。 tcp_keepalive_probes ： INTEGER / proc / sys / net / ipv4 / tcp_keepalive_probes INTEGER ， 9 TCP  keepalive 。 ( : SO_KEEPALIVE ., . 5  ) tcp_keepalive_intvl ： INTEGER / proc / sys / net / ipv4 / tcp_keepalive_intvl INTEGER ， 75 ，。（， TCP  keepalive ）。  tcp_keepalive_probes 。 75 ，  11 。 ( ,,. web , 15  ) 【】 1 . “ Too many open files ”。 2 .  TIME_WAIT  sockets 。  Linux  TCP  (  ) ： netstat - n | awk /^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]} ： ESTABLISHED 1423 FIN_WAIT1 1 FIN_WAIT2 262 SYN_SENT 1 TIME_WAIT 962 ulimit - a  time_wait vi / etc / sysctl . conf  / etc / sysctl . conf ，：  net . ipv4 . tcp_syncookies = 1 net . ipv4 . tcp_tw_reuse = 1 net . ipv4 . tcp_tw_recycle = 1 ： net . ipv4 . tcp_syncookies = 1  SYN Cookies 。 SYN ， cookies ， SYN ，  0 ，； net . ipv4 . tcp_tw_reuse = 1 。 TIME - WAIT sockets  TCP ， 0 ，； net . ipv4 . tcp_tw_recycle = 1  TCP  TIME - WAIT sockets ， 0 ，。 ，： / sbin / sysctl - p last_ack netstat - ant | fgrep : | cut - b 77 - 90 | sort | uniq - c 6 CLOSE \\ _WAIT 7 CLOSING 6838 ESTABLISHED 1037 FIN_WAIT1 357 FIN \\ _WAIT2 5830 LAST_ACK 2 LISTEN 276 SYN \\ _RECV 71 TIME \\ _WAIT [ root@ccsafe ~ ] #  ，  [ root@ccsafe ~ ] # vmstat 2 procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu------ r b swpd free buff cache si so bi bo in cs us sy id wa st 1 0 0 3091812 363032 284132 0 0 0 0 1 1 0 0 100 0 0 0 0 0 3091812 363032 284132 0 0 0 0 13750 3174 0 5 94 0 0 0 0 0 3091936 363032 284132 0 0 0 0 13666 3057 1 5 94 0 0 0 0 0 3092060 363032 284132 0 0 0 16 13749 3030 0 5 95 0 0 0 0 0 3092060 363032 284132 0 0 0 0 13822 3144 0 5 95 0 0 0 0 0 3092060 363032 284132 0 0 0 0 13390 2961 0 5 95 0 0 0 0 0 3092060 363032 284132 0 0 0 0 13541 3182 0 6 94 0 0 socket [ root@ccsafe ~ ] # sar - n SOCK 5 Linux 2.6.18 - 53.1.13 . el5PAE ( ccsafe ) 10 / 21 / 2008 06 : 31 : 43 PM totsck tcpsck udpsck rawsck ip - frag tcp - tw 06 : 31 : 48 PM 6951 13868 1 0 0 430 Average : 6951 13868 1 0 0 430 TCP ， LAST_ACK ESTABLISHED - CLOSE_WAIT - （ ACK ） - LAST_ACK - ( FIN + ACK ) - CLOSED LAST_ACK ，  LAST_ACK ... [ root@ccsafe ~ ] # sysctl - a | grep last_ack net . ipv4 . netfilter . ip_conntrack_tcp_timeout_last_ack = 30 [ root@ccsafe ~ ] # sysctl - w net . ipv4 . netfilter . ip_conntrack_tcp_timeout_last_ack = 10 net . ipv4 . netfilter . ip_conntrack_tcp_timeout_last_ack = 10 [ root@ccsafe ~ ] # sysctl - p [ root@ccsafe ~ ] # watch - n 10 netstat -ant|fgrep : |cut -b 77-90|sort |uniq -c Every 5.0 s : netstat - ant | fgrep : | cut - b 77 - 90 | sort | uniq - c 6 CLOSE \\ _WAIT 9 CLOSING 6420 ESTABLISHED 693 FIN \\ _WAIT1 391 FIN \\ _WAIT2 5081 LAST_ACK 2 LISTEN 203 SYN \\ _RECV 66 TIME \\ _WAIT LAST_ACK [ root@ccsafe ~ ] # netstat - ant | fgrep LAST_ACK | cut - b 49 - 75 | cut - d : - f1 | sort | uniq - c | sort - nr --key=1,7|head -5 101 220.160.210.6 46 222.75.65.69 31 221.0.91.118 24 222.210.8.160 22 60.161.81.28 [ root@ccsafe ~ ] # [ root@ccsafe ~ ] # netstat - an | grep 220.160.210.6 tcp 0 17280 10.1.1.145 : 80 220.160.210.6 : 52787 ESTABLISHED tcp 1 14401 10.1.1.145 : 80 220.160.210.6 : 52513 LAST_ACK tcp 1 14401 10.1.1.145 : 80 220.160.210.6 : 52769 LAST_ACK tcp 1 14401 10.1.1.145 : 80 220.160.210.6 : 52768 LAST_ACK tcp 0 8184 10.1.1.145 : 80 220.160.210.6 : 52515 LAST_ACK tcp 1 14401 10.1.1.145 : 80 220.160.210.6 : 52514 LAST_ACK tcp 0 8184 10.1.1.145 : 80 220.160.210.6 : 52781 LAST_ACK TCP80 ， nginxkeepalive ... [ root@ccsafe ~ ] # / usr / local / nginx / sbin / nginx - t - c / usr / local / nginx / conf / nginx . conf 2008 / 10 / 21 19 : 15 : 31 [ info ] 21352 #0 : the configuration file / usr / local / nginx / conf / nginx . conf syntax is ok 2008 / 10 / 21 19 : 15 : 31 [ info ] 21352 #0 : the configuration file / usr / local / nginx / conf / nginx . conf was tested successfully [ root@ccsafe ~ ] # ps aux | egrep (PID|nginx) USER PID % CPU % MEM VSZ RSS TTY STAT START TIME COMMAND root 8290 0.0 0.0 7572 1124 ? Ss Oct04 0 : 00 nginx : master process / usr / local / nginx / sbin / nginx nobody 8291 0.2 0.3 19704 13776 ? S Oct04 71 : 35 nginx : worker process nobody 8292 0.3 0.2 17604 11680 ? S Oct04 77 : 26 nginx : worker process nobody 8293 0.2 0.4 22528 16636 ? S Oct04 58 : 13 nginx : worker process nobody 8294 0.3 0.4 24944 19020 ? S Oct04 94 : 07 nginx : worker process nobody 8295 0.3 0.5 27496 21508 ? S Oct04 84 : 41 nginx : worker process nobody 8296 0.3 0.1 13388 7496 ? S Oct04 84 : 14 nginx : worker process nobody 8297 0.2 0.0 9196 3268 ? S Oct04 58 : 21 nginx : worker process nobody 8298 0.3 0.2 15392 9504 ? S Oct04 75 : 16 nginx : worker process root 21354 0.0 0.0 3896 720 pts / 0 S + 19 : 15 0 : 00 egrep ( PID | nginx ) （  ） [ root@ccsafe ~ ] # kill - HUP 8290 [ root@ccsafe ~ ] # Every 10.0 s : netstat - ant | fgrep : | cut - b 77 - 90 | sort | uniq - c 1 CLOSE \\ _WAIT 1138 CLOSING 7161 ESTABLISHED 1427 FIN_WAIT1 396 FIN \\ _WAIT2 5740 LAST_ACK 2 LISTEN 350 SYN \\ _RECV 148 TIME \\ _WAIT ... [ root@ccsafe ~ ] # netstat - ant | fgrep : | cut - b 77 - 90 | sort | uniq - c 1151 CLOSING 8506 ESTABLISHED 1452 FIN_WAIT1 666 FIN \\ _WAIT2 6568 LAST_ACK 2 LISTEN 429 SYN \\ _RECV 92 TIME \\ _WAIT ... LAST_ACK ， CLOSING FIN_WAIT TCP tcp_keepalive_intvl :  tcp_keepalive_probes : TCPkeepalive tcp_keepalive_time : keepalive ， TCPkeepalive [ root@ccsafe ~ ] # sysctl - a | grep tcp_keepalive net . ipv4 . tcp_keepalive_intvl = 30 net . ipv4 . tcp_keepalive_probes = 2 net . ipv4 . tcp_keepalive_time = 160 tcp_retries2 :  (  ) TCP ﹐  [ root@ccsafe ~ ] # sysctl - a | grep tcp_retries net . ipv4 . tcp_retries2 = 15 net . ipv4 . tcp_retries1 = 3 ACKLAST_ACK ， ACKLAST_ACK [ root@ccsafe ~ ] # sysctl - w net . ipv4 . tcp_retries2 = 5 net . ipv4 . tcp_retries2 = 5 keepalive [ root@ccsafe ~ ] # sysctl - w net . ipv4 . tcp_keepalive_intvl = 15 net . ipv4 . tcp_keepalive_intvl = 15 [ root@ccsafe ~ ] # sysctl - p syncookies [ root@ccsafe ~ ] # ! ec echo 0 / proc / sys / net / ipv4 / tcp_syncookies [ root@ccsafe ~ ] # echo 1 / proc / sys / net / ipv4 / tcp_syncookies [ root@ccsafe ~ ] # sysctl - a | grep tcp_keepalive net . ipv4 . tcp_keepalive_intvl = 30 net . ipv4 . tcp_keepalive_probes = 2 net . ipv4 . tcp_keepalive_time = 160 [ root@ccsafe ~ ] # sysctl - a | grep syncookies net . ipv4 . tcp_syncookies = 1 keepalive ， ESTABLISHED [ root@ccsafe ~ ] # echo 1800 / proc / sys / net / ipv4 / tcp_keepalive_time [ root@ccsafe ~ ] # echo 5 / proc / sys / net / ipv4 / tcp_keepalive_probes [ root@ccsafe ~ ] # echo 15 / proc / sys / net / ipv4 / tcp_keepalive_intvl [ root@ccsafe ~ ] # sysctl - a | grep tcp_keepalive net . ipv4 . tcp_keepalive_intvl = 15 net . ipv4 . tcp_keepalive_probes = 5 net . ipv4 . tcp_keepalive_time = 1800 [ root@ccsafe ~ ] # ! wat watch - n 10 netstat -ant|fgrep : |cut -b 77-90|sort |uniq -c Every 10.0 s : netstat - ant | fgrep : | cut - b 77 - 90 | sort | uniq - c 1 CLOSE \\ _WAIT 363 CLOSING 5145 ESTABLISHED 1073 FIN_WAIT1 174 FIN \\ _WAIT2 6042 LAST_ACK 2 LISTEN 301 SYN \\ _RECV 85 TIME \\ _WAIT LAST_ACK ， CLOSING tcp_orphan_retries : TCP ﹐  。 [ root@ccsafe ~ ] # sysctl - a | grep tcp_orphan net . ipv4 . tcp_orphan_retries = 0  ， TCP ，  。  [ root@ccsafe ~ ] # echo 3 / proc / sys / net / ipv4 / tcp_orphan_retries [ root@ccsafe ~ ] # ! wat watch - n 10 netstat -ant|fgrep : |cut -b 77-90|sort |uniq -c Every 10.0 s : netstat - ant | fgrep : | cut - b 77 - 90 | sort | uniq - c 1 CLOSE \\ _WAIT 24 CLOSING 5422 ESTABLISHED 279 FIN \\ _WAIT1 214 FIN \\ _WAIT2 1966 LAST_ACK 2 LISTEN 269 SYN \\ _RECV 74 TIME \\ _WAIT  ，  [ root@ccsafe ~ ] # echo 7 / proc / sys / net / ipv4 / tcp_orphan_retries [ root@ccsafe ~ ] # ! wat watch - n 10 netstat -ant|fgrep : |cut -b 77-90|sort |uniq -c Every 10.0 s : netstat - ant | fgrep : | cut - b 77 - 90 | sort | uniq - c 1 CLOSE \\ _WAIT 175 CLOSING 5373 ESTABLISHED 436 FIN \\ _WAIT1 209 FIN \\ _WAIT2 3184 LAST_ACK 2 LISTEN 283 SYN \\ _RECV 110 TIME \\ _WAIT  ， FIN_WAIT1 。 tcp_fin_timeout [ root@ccsafe ~ ] # echo 2 / proc / sys / net / ipv4 / tcp_orphan_retries [ root@ccsafe ~ ] # sysctl - a | grep tcp_fin net . ipv4 . tcp_fin_timeout = 10 [ root@ccsafe ~ ] # echo 5 / proc / sys / net / ipv4 / tcp_fin_timeout [ root@ccsafe ~ ] # ! wat watch - n 10 netstat -ant|fgrep : |cut -b 77-90|sort |uniq -c Every 10.0 s : netstat - ant | fgrep : | cut - b 77 - 90 | sort | uniq - c 2 CLOSE \\ _WAIT 17 CLOSING 5665 ESTABLISHED 145 FIN \\ _WAIT1 141 FIN \\ _WAIT2 1068 LAST_ACK 2 LISTEN 287 SYN \\ _RECV 68 TIME \\ _WAIT FIN_WAIT ， SYN_RECV 。 synack [ root@ccsafe ~ ] # sysctl - a | grep synack net . ipv4 . tcp_synack_retries = 1 [ root@ccsafe ~ ] # echo 2 / proc / sys / net / ipv4 / tcp_synack_retries [ root@ccsafe ~ ] # ! wat watch - n 10 netstat -ant|fgrep : |cut -b 77-90|sort |uniq -c Every 10.0 s : netstat - ant | fgrep : | cut - b 77 - 90 | sort | uniq - c 3 CLOSE \\ _WAIT 16 CLOSING 5317 ESTABLISHED 200 FIN \\ _WAIT1 158 FIN \\ _WAIT2 1001 LAST_ACK 2 LISTEN 303 SYN \\ _RECV 78 TIME \\ _WAIT [ root@ccsafe ~ ] # sysctl - a | grep keepalive net . ipv4 . tcp_keepalive_intvl = 15 net . ipv4 . tcp_keepalive_probes = 5 net . ipv4 . tcp_keepalive_time = 1800 [ root@ccsafe ~ ] # watch - n 10 netstat -ant|fgrep : |cut -b 77-90|sort |uniq -c Every 10.0 s : netstat - ant | fgrep : | cut - b 77 - 90 | sort | uniq - c 1 CLOSE \\ _WAIT 7 CLOSING 5356 ESTABLISHED 175 FIN \\ _WAIT1 136 FIN \\ _WAIT2 1045 LAST_ACK 2 LISTEN 345 SYN \\ _RECV 64 TIME \\ _WAIT keepalive ， LAST_ACK [ root@ccsafe ~ ] # echo 10 / proc / sys / net / ipv4 / tcp_keepalive_intvl [ root@ccsafe ~ ] # echo 1 / proc / sys / net / ipv4 / tcp_synack_retries [ root@ccsafe ~ ] # ! wat watch - n 10 netstat -ant|fgrep : |cut -b 77-90|sort |uniq -c Every 10.0 s : netstat - ant | fgrep : | cut - b 77 - 90 | sort | uniq - c 1 CLOSE \\ _WAIT 13 CLOSING 5605 ESTABLISHED 212 FIN \\ _WAIT1 131 FIN \\ _WAIT2 1143 LAST_ACK 2 LISTEN 252 SYN \\ _RECV 79 TIME \\ _WAIT  [ root@ccsafe ~ ] # echo 15 / proc / sys / net / ipv4 / tcp_keepalive_intvl [ root@ccsafe ~ ] # watch - n 10 netstat -ant|fgrep : |cut -b 77-90|sort |uniq -c Every 10.0 s : netstat - ant | fgrep : | cut - b 77 - 90 | sort | uniq - c 3 CLOSE \\ _WAIT 14 CLOSING 5862 ESTABLISHED 230 FIN \\ _WAIT1 205 FIN \\ _WAIT2 1064 LAST_ACK 2 LISTEN 244 SYN \\ _RECV 59 TIME \\ _WAIT [ root@ccsafe ~ ] # watch - n 10 netstat -ant|fgrep : |cut -b 77-90|sort |uniq -c Every 10.0 s : netstat - ant | fgrep : | cut - b 77 - 90 | sort | uniq - c 3 CLOSE \\ _WAIT 26 CLOSING 6712 ESTABLISHED 270 FIN \\ _WAIT1 230 FIN \\ _WAIT2 994 LAST \\ _ACK 2 LISTEN 254 SYN \\ _RECV 73 TIME \\ _WAIT [ root@ccsafe ~ ] # LAST_ACKESTABLISHED15 %  close_wait netstat - n | awk /^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]} LAST_ACK 1 SYN_RECV 15 CLOSE_WAIT 7729 ESTABLISHED 471 FIN_WAIT1 3 FIN_WAIT2 52 SYN_SENT 1 TIME_WAIT 725 ， 7200 ， 2 。 ： tcp_keepalive_time = 7200 seconds ( 2 hours ) tcp_keepalive_probes = 9 tcp_keepalive_intvl = 75 seconds  TCP  idle 2 , probe . probe 9  (  75  ) ,,  sysctl - w net . ipv4 . tcp_keepalive_time = 30 sysctl - w net . ipv4 . tcp_keepalive_probes = 2 sysctl - w net . ipv4 . tcp_keepalive_intvl = 2 ， tcp  find_wait1 fin_wait1  net . ipv4 . tcp_orphan_retries = 0  7 ， TCP ，， 7 ， 50  - 16 ， RTO 。  web ，， sockets 。","title":"tcp-issue"},{"location":"tcp-issue/#tcp","text":"Web，TCP，TCP 11。TCP，。TCP 11，TCP。 TCP ，TCP，，Web， ： ：Web，。 ：WebRedisMySQL， 。，Web。 ：。  HTTP，TCP11， 。 ： ，、。。 CLOSED：。 SYN_SENT：（CLOSED- SYN_SENT） CLOSED，TCP，TCPSYN， CLOSESYN_SENT。 ，，。 ESTABLISHED：（SYN_SENT- ESTABLISHED） TCP，ACKSYN，， ACK，SYN_SENTESTABLISHED， ，，TCP， 。：SYN，ACK ：ACK。 ： ！ESTABLISHED，， ，。 LISTEN： Web，Nginx，80，TCP LISTEN，CLOSE。 SYN_RCVD：(LISTEN- SYN_RCVD) ，LISTENNginxSYN，LISTEN SYN_RCVD，，SYN_SENT。SYN， SYNACK。 ESTABLISHED：（SYN_RCVD ESTABLISHED） SYNACK，ACK，ACK， SYN_RCVDESTABLISHED。 ，，TCP，， ，TCP，。 ，seq=x。SYN1。CLOSEDSYN_SENT。 ，CLOSEDLISTEND，SYN，TCPSYN、AC1， ack=x+1，seq=y。LISTENSYN_RCVD。 ，TCPACK1，ack=y+1，seq=x+1， ESTABLISHEN ，EXTABLISHED。 TCP： ， ESTABLISHED 。 。 FIN_WAIT_1:（ESTABLISHED- FIN_WAIT_1）：ESTABLISHED， FIN，，ESTABLISHEDFIN_WAIT_1。 CLOSE_WAIT：(ESTABLISHED- CLOSE_WAIT)，， ，FIN，ACK，ESTABLISHEDCLOSE_WAIT。 FIN_WAIT_2：(FIN_WAIT_1- FIN_WAIT_2)，， ACK，FIN，， FIN_WAIT_1FIN_WAIT_2。 LAST_ACK:(CLOSE_WAIT- LAST_ACK) ，。 “”。，，HTTP，， ，TCP，FIN。 CLOSE_WAITLAST_ACK。？。 TIME_WAIT：（FIN_WAIT_2- TIME_WAIT） FINLAST_ACK，FIN，FIN_WAIT_2TIME_WAIT。 ACK。 CLOSED：(LAST_ACK- CLOSED)， ACK，LAST_ACKCLOSED。，。 ：TIME_WAIT。。 TIME_WAIT： TCP； 。 Linux，60，CLOSED。 ：。， 。， ，TIME_WAIT。","title":"TCP"},{"location":"tcp-issue/#too-many-open-files","text":"java . net . SocketException : Too many open files at java . net . Socket . createImpl ( Socket . java : 388 ) at java . net . Socket . connect ( Socket . java : 517 ) at java . net . Socket . connect ( Socket . java : 469 ) at sun . net . NetworkClient . doConnect ( NetworkClient . java : 163 ) at sun . net . www . http . HttpClient . openServer ( HttpClient . java : 394 ) at sun . net . www . http . HttpClient . openServer ( HttpClient . java : 529 ) at sun . net . www . http . HttpClient . init ( HttpClient . java : 233 ) at sun . net . www . http . HttpClient . New ( HttpClient . java : 306 ) at sun . net . www . http . HttpClient . New ( HttpClient . java : 323 ) at sun . net . www . protocol . http . HttpURLConnection . getNewHttpClient ( HttpURLConnection . java : 852 ) at sun . net . www . protocol . http . HttpURLConnection . plainConnect ( HttpURLConnection . java : 793 ) at sun . net . www . protocol . http . HttpURLConnection . connect ( HttpURLConnection . java : 718 ) at sun . net . www . protocol . http . HttpURLConnection . getOutputStream ( HttpURLConnection . java : 896 ) at a8 . mms . util . Tools . postObject ( Tools . java : 301 ) ：“ Too many open files ” ：， socket  closed_wait ， port  1024 ，  close_wait ， port “ Too many open files ”，。 close_wait  socket ，： ： 、：  ServerSocket  accept ()  Socket  read () ， setSoTimeout ()  （ 0 ，）；，，， 。 ， read () ， 1 ， read ()  1 ，  Socket ，。 、： ， TCP / IP ； ： / proc / sys / fs / file - max ， sysctl . conf ； ulimit  shell ， limits . conf ； lsof ,；：,,,,, ； ，， limits . conf ；  cat / proc / sys / fs / file - max  65536 ，；  ulimit - a ； open files  4096 （ 1024 ) ,  open files  8192 ；： 1 . root ， / etc / security / limits . conf vi / etc / security / limits . conf  xxx - nofile 8192 xxx ， * ，，。 # domain type item value * soft nofile 8192 * hard nofile 8192 # 8192 。 2 .  / etc / pam . d / login  / etc / pam . d / sshd ： session required pam_limits . so 。 3 .  bash  ulimit - a ： 、 ：（,,） sysctl - w net . ipv4 . tcp_keepalive_time = 600 sysctl - w net . ipv4 . tcp_keepalive_probes = 2 sysctl - w net . ipv4 . tcp_keepalive_intvl = 2 ： Linux ，。 、 ，；。 vi / etc / sysctl . conf ，： net . ipv4 . tcp_keepalive_time = 1800 net . ipv4 . tcp_keepalive_probes = 3 net . ipv4 . tcp_keepalive_intvl = 15  / etc / sysctl . conf , network  / etc / rc . d / init . d / network restart ， sysctl ，。 ------------------------------------------------------------ ：  FIN ，， socket  FIN  Client ， Socket  CLOSE_WAIT （ LAST_ACK ）。， CLOSE_WAIT  2 （ 7200 ，  2 ）。 CLOSE_WAIT ，，。，  TCP / IP ， tcp_keepalive_ * ： tcp_keepalive_time ： / proc / sys / net / ipv4 / tcp_keepalive_time INTEGER ， 7200 ( 2  )  keepalive ， TCP  keepalive 。 1800 。 tcp_keepalive_probes ： INTEGER / proc / sys / net / ipv4 / tcp_keepalive_probes INTEGER ， 9 TCP  keepalive 。 ( : SO_KEEPALIVE ., . 5  ) tcp_keepalive_intvl ： INTEGER / proc / sys / net / ipv4 / tcp_keepalive_intvl INTEGER ， 75 ，。（， TCP  keepalive ）。  tcp_keepalive_probes 。 75 ，  11 。 ( ,,. web , 15  ) 【】 1 . “ Too many open files ”。 2 .  TIME_WAIT  sockets 。  Linux  TCP  (  ) ： netstat - n | awk /^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]} ： ESTABLISHED 1423 FIN_WAIT1 1 FIN_WAIT2 262 SYN_SENT 1 TIME_WAIT 962 ulimit - a ","title":"Too many open files"},{"location":"tcp-issue/#time_wait","text":"vi / etc / sysctl . conf  / etc / sysctl . conf ，：  net . ipv4 . tcp_syncookies = 1 net . ipv4 . tcp_tw_reuse = 1 net . ipv4 . tcp_tw_recycle = 1 ： net . ipv4 . tcp_syncookies = 1  SYN Cookies 。 SYN ， cookies ， SYN ，  0 ，； net . ipv4 . tcp_tw_reuse = 1 。 TIME - WAIT sockets  TCP ， 0 ，； net . ipv4 . tcp_tw_recycle = 1  TCP  TIME - WAIT sockets ， 0 ，。 ，： / sbin / sysctl - p","title":"time_wait"},{"location":"tcp-issue/#last_ack","text":"netstat - ant | fgrep : | cut - b 77 - 90 | sort | uniq - c 6 CLOSE \\ _WAIT 7 CLOSING 6838 ESTABLISHED 1037 FIN_WAIT1 357 FIN \\ _WAIT2 5830 LAST_ACK 2 LISTEN 276 SYN \\ _RECV 71 TIME \\ _WAIT [ root@ccsafe ~ ] #  ，  [ root@ccsafe ~ ] # vmstat 2 procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu------ r b swpd free buff cache si so bi bo in cs us sy id wa st 1 0 0 3091812 363032 284132 0 0 0 0 1 1 0 0 100 0 0 0 0 0 3091812 363032 284132 0 0 0 0 13750 3174 0 5 94 0 0 0 0 0 3091936 363032 284132 0 0 0 0 13666 3057 1 5 94 0 0 0 0 0 3092060 363032 284132 0 0 0 16 13749 3030 0 5 95 0 0 0 0 0 3092060 363032 284132 0 0 0 0 13822 3144 0 5 95 0 0 0 0 0 3092060 363032 284132 0 0 0 0 13390 2961 0 5 95 0 0 0 0 0 3092060 363032 284132 0 0 0 0 13541 3182 0 6 94 0 0 socket [ root@ccsafe ~ ] # sar - n SOCK 5 Linux 2.6.18 - 53.1.13 . el5PAE ( ccsafe ) 10 / 21 / 2008 06 : 31 : 43 PM totsck tcpsck udpsck rawsck ip - frag tcp - tw 06 : 31 : 48 PM 6951 13868 1 0 0 430 Average : 6951 13868 1 0 0 430 TCP ， LAST_ACK ESTABLISHED - CLOSE_WAIT - （ ACK ） - LAST_ACK - ( FIN + ACK ) - CLOSED LAST_ACK ，  LAST_ACK ... [ root@ccsafe ~ ] # sysctl - a | grep last_ack net . ipv4 . netfilter . ip_conntrack_tcp_timeout_last_ack = 30 [ root@ccsafe ~ ] # sysctl - w net . ipv4 . netfilter . ip_conntrack_tcp_timeout_last_ack = 10 net . ipv4 . netfilter . ip_conntrack_tcp_timeout_last_ack = 10 [ root@ccsafe ~ ] # sysctl - p [ root@ccsafe ~ ] # watch - n 10 netstat -ant|fgrep : |cut -b 77-90|sort |uniq -c Every 5.0 s : netstat - ant | fgrep : | cut - b 77 - 90 | sort | uniq - c 6 CLOSE \\ _WAIT 9 CLOSING 6420 ESTABLISHED 693 FIN \\ _WAIT1 391 FIN \\ _WAIT2 5081 LAST_ACK 2 LISTEN 203 SYN \\ _RECV 66 TIME \\ _WAIT LAST_ACK [ root@ccsafe ~ ] # netstat - ant | fgrep LAST_ACK | cut - b 49 - 75 | cut - d : - f1 | sort | uniq - c | sort - nr --key=1,7|head -5 101 220.160.210.6 46 222.75.65.69 31 221.0.91.118 24 222.210.8.160 22 60.161.81.28 [ root@ccsafe ~ ] # [ root@ccsafe ~ ] # netstat - an | grep 220.160.210.6 tcp 0 17280 10.1.1.145 : 80 220.160.210.6 : 52787 ESTABLISHED tcp 1 14401 10.1.1.145 : 80 220.160.210.6 : 52513 LAST_ACK tcp 1 14401 10.1.1.145 : 80 220.160.210.6 : 52769 LAST_ACK tcp 1 14401 10.1.1.145 : 80 220.160.210.6 : 52768 LAST_ACK tcp 0 8184 10.1.1.145 : 80 220.160.210.6 : 52515 LAST_ACK tcp 1 14401 10.1.1.145 : 80 220.160.210.6 : 52514 LAST_ACK tcp 0 8184 10.1.1.145 : 80 220.160.210.6 : 52781 LAST_ACK TCP80 ， nginxkeepalive ... [ root@ccsafe ~ ] # / usr / local / nginx / sbin / nginx - t - c / usr / local / nginx / conf / nginx . conf 2008 / 10 / 21 19 : 15 : 31 [ info ] 21352 #0 : the configuration file / usr / local / nginx / conf / nginx . conf syntax is ok 2008 / 10 / 21 19 : 15 : 31 [ info ] 21352 #0 : the configuration file / usr / local / nginx / conf / nginx . conf was tested successfully [ root@ccsafe ~ ] # ps aux | egrep (PID|nginx) USER PID % CPU % MEM VSZ RSS TTY STAT START TIME COMMAND root 8290 0.0 0.0 7572 1124 ? Ss Oct04 0 : 00 nginx : master process / usr / local / nginx / sbin / nginx nobody 8291 0.2 0.3 19704 13776 ? S Oct04 71 : 35 nginx : worker process nobody 8292 0.3 0.2 17604 11680 ? S Oct04 77 : 26 nginx : worker process nobody 8293 0.2 0.4 22528 16636 ? S Oct04 58 : 13 nginx : worker process nobody 8294 0.3 0.4 24944 19020 ? S Oct04 94 : 07 nginx : worker process nobody 8295 0.3 0.5 27496 21508 ? S Oct04 84 : 41 nginx : worker process nobody 8296 0.3 0.1 13388 7496 ? S Oct04 84 : 14 nginx : worker process nobody 8297 0.2 0.0 9196 3268 ? S Oct04 58 : 21 nginx : worker process nobody 8298 0.3 0.2 15392 9504 ? S Oct04 75 : 16 nginx : worker process root 21354 0.0 0.0 3896 720 pts / 0 S + 19 : 15 0 : 00 egrep ( PID | nginx ) （  ） [ root@ccsafe ~ ] # kill - HUP 8290 [ root@ccsafe ~ ] # Every 10.0 s : netstat - ant | fgrep : | cut - b 77 - 90 | sort | uniq - c 1 CLOSE \\ _WAIT 1138 CLOSING 7161 ESTABLISHED 1427 FIN_WAIT1 396 FIN \\ _WAIT2 5740 LAST_ACK 2 LISTEN 350 SYN \\ _RECV 148 TIME \\ _WAIT ... [ root@ccsafe ~ ] # netstat - ant | fgrep : | cut - b 77 - 90 | sort | uniq - c 1151 CLOSING 8506 ESTABLISHED 1452 FIN_WAIT1 666 FIN \\ _WAIT2 6568 LAST_ACK 2 LISTEN 429 SYN \\ _RECV 92 TIME \\ _WAIT ... LAST_ACK ， CLOSING FIN_WAIT TCP tcp_keepalive_intvl :  tcp_keepalive_probes : TCPkeepalive tcp_keepalive_time : keepalive ， TCPkeepalive [ root@ccsafe ~ ] # sysctl - a | grep tcp_keepalive net . ipv4 . tcp_keepalive_intvl = 30 net . ipv4 . tcp_keepalive_probes = 2 net . ipv4 . tcp_keepalive_time = 160 tcp_retries2 :  (  ) TCP ﹐  [ root@ccsafe ~ ] # sysctl - a | grep tcp_retries net . ipv4 . tcp_retries2 = 15 net . ipv4 . tcp_retries1 = 3 ACKLAST_ACK ， ACKLAST_ACK [ root@ccsafe ~ ] # sysctl - w net . ipv4 . tcp_retries2 = 5 net . ipv4 . tcp_retries2 = 5 keepalive [ root@ccsafe ~ ] # sysctl - w net . ipv4 . tcp_keepalive_intvl = 15 net . ipv4 . tcp_keepalive_intvl = 15 [ root@ccsafe ~ ] # sysctl - p syncookies [ root@ccsafe ~ ] # ! ec echo 0 / proc / sys / net / ipv4 / tcp_syncookies [ root@ccsafe ~ ] # echo 1 / proc / sys / net / ipv4 / tcp_syncookies [ root@ccsafe ~ ] # sysctl - a | grep tcp_keepalive net . ipv4 . tcp_keepalive_intvl = 30 net . ipv4 . tcp_keepalive_probes = 2 net . ipv4 . tcp_keepalive_time = 160 [ root@ccsafe ~ ] # sysctl - a | grep syncookies net . ipv4 . tcp_syncookies = 1 keepalive ， ESTABLISHED [ root@ccsafe ~ ] # echo 1800 / proc / sys / net / ipv4 / tcp_keepalive_time [ root@ccsafe ~ ] # echo 5 / proc / sys / net / ipv4 / tcp_keepalive_probes [ root@ccsafe ~ ] # echo 15 / proc / sys / net / ipv4 / tcp_keepalive_intvl [ root@ccsafe ~ ] # sysctl - a | grep tcp_keepalive net . ipv4 . tcp_keepalive_intvl = 15 net . ipv4 . tcp_keepalive_probes = 5 net . ipv4 . tcp_keepalive_time = 1800 [ root@ccsafe ~ ] # ! wat watch - n 10 netstat -ant|fgrep : |cut -b 77-90|sort |uniq -c Every 10.0 s : netstat - ant | fgrep : | cut - b 77 - 90 | sort | uniq - c 1 CLOSE \\ _WAIT 363 CLOSING 5145 ESTABLISHED 1073 FIN_WAIT1 174 FIN \\ _WAIT2 6042 LAST_ACK 2 LISTEN 301 SYN \\ _RECV 85 TIME \\ _WAIT LAST_ACK ， CLOSING tcp_orphan_retries : TCP ﹐  。 [ root@ccsafe ~ ] # sysctl - a | grep tcp_orphan net . ipv4 . tcp_orphan_retries = 0  ， TCP ，  。  [ root@ccsafe ~ ] # echo 3 / proc / sys / net / ipv4 / tcp_orphan_retries [ root@ccsafe ~ ] # ! wat watch - n 10 netstat -ant|fgrep : |cut -b 77-90|sort |uniq -c Every 10.0 s : netstat - ant | fgrep : | cut - b 77 - 90 | sort | uniq - c 1 CLOSE \\ _WAIT 24 CLOSING 5422 ESTABLISHED 279 FIN \\ _WAIT1 214 FIN \\ _WAIT2 1966 LAST_ACK 2 LISTEN 269 SYN \\ _RECV 74 TIME \\ _WAIT  ，  [ root@ccsafe ~ ] # echo 7 / proc / sys / net / ipv4 / tcp_orphan_retries [ root@ccsafe ~ ] # ! wat watch - n 10 netstat -ant|fgrep : |cut -b 77-90|sort |uniq -c Every 10.0 s : netstat - ant | fgrep : | cut - b 77 - 90 | sort | uniq - c 1 CLOSE \\ _WAIT 175 CLOSING 5373 ESTABLISHED 436 FIN \\ _WAIT1 209 FIN \\ _WAIT2 3184 LAST_ACK 2 LISTEN 283 SYN \\ _RECV 110 TIME \\ _WAIT  ， FIN_WAIT1 。 tcp_fin_timeout [ root@ccsafe ~ ] # echo 2 / proc / sys / net / ipv4 / tcp_orphan_retries [ root@ccsafe ~ ] # sysctl - a | grep tcp_fin net . ipv4 . tcp_fin_timeout = 10 [ root@ccsafe ~ ] # echo 5 / proc / sys / net / ipv4 / tcp_fin_timeout [ root@ccsafe ~ ] # ! wat watch - n 10 netstat -ant|fgrep : |cut -b 77-90|sort |uniq -c Every 10.0 s : netstat - ant | fgrep : | cut - b 77 - 90 | sort | uniq - c 2 CLOSE \\ _WAIT 17 CLOSING 5665 ESTABLISHED 145 FIN \\ _WAIT1 141 FIN \\ _WAIT2 1068 LAST_ACK 2 LISTEN 287 SYN \\ _RECV 68 TIME \\ _WAIT FIN_WAIT ， SYN_RECV 。 synack [ root@ccsafe ~ ] # sysctl - a | grep synack net . ipv4 . tcp_synack_retries = 1 [ root@ccsafe ~ ] # echo 2 / proc / sys / net / ipv4 / tcp_synack_retries [ root@ccsafe ~ ] # ! wat watch - n 10 netstat -ant|fgrep : |cut -b 77-90|sort |uniq -c Every 10.0 s : netstat - ant | fgrep : | cut - b 77 - 90 | sort | uniq - c 3 CLOSE \\ _WAIT 16 CLOSING 5317 ESTABLISHED 200 FIN \\ _WAIT1 158 FIN \\ _WAIT2 1001 LAST_ACK 2 LISTEN 303 SYN \\ _RECV 78 TIME \\ _WAIT [ root@ccsafe ~ ] # sysctl - a | grep keepalive net . ipv4 . tcp_keepalive_intvl = 15 net . ipv4 . tcp_keepalive_probes = 5 net . ipv4 . tcp_keepalive_time = 1800 [ root@ccsafe ~ ] # watch - n 10 netstat -ant|fgrep : |cut -b 77-90|sort |uniq -c Every 10.0 s : netstat - ant | fgrep : | cut - b 77 - 90 | sort | uniq - c 1 CLOSE \\ _WAIT 7 CLOSING 5356 ESTABLISHED 175 FIN \\ _WAIT1 136 FIN \\ _WAIT2 1045 LAST_ACK 2 LISTEN 345 SYN \\ _RECV 64 TIME \\ _WAIT keepalive ， LAST_ACK [ root@ccsafe ~ ] # echo 10 / proc / sys / net / ipv4 / tcp_keepalive_intvl [ root@ccsafe ~ ] # echo 1 / proc / sys / net / ipv4 / tcp_synack_retries [ root@ccsafe ~ ] # ! wat watch - n 10 netstat -ant|fgrep : |cut -b 77-90|sort |uniq -c Every 10.0 s : netstat - ant | fgrep : | cut - b 77 - 90 | sort | uniq - c 1 CLOSE \\ _WAIT 13 CLOSING 5605 ESTABLISHED 212 FIN \\ _WAIT1 131 FIN \\ _WAIT2 1143 LAST_ACK 2 LISTEN 252 SYN \\ _RECV 79 TIME \\ _WAIT  [ root@ccsafe ~ ] # echo 15 / proc / sys / net / ipv4 / tcp_keepalive_intvl [ root@ccsafe ~ ] # watch - n 10 netstat -ant|fgrep : |cut -b 77-90|sort |uniq -c Every 10.0 s : netstat - ant | fgrep : | cut - b 77 - 90 | sort | uniq - c 3 CLOSE \\ _WAIT 14 CLOSING 5862 ESTABLISHED 230 FIN \\ _WAIT1 205 FIN \\ _WAIT2 1064 LAST_ACK 2 LISTEN 244 SYN \\ _RECV 59 TIME \\ _WAIT [ root@ccsafe ~ ] # watch - n 10 netstat -ant|fgrep : |cut -b 77-90|sort |uniq -c Every 10.0 s : netstat - ant | fgrep : | cut - b 77 - 90 | sort | uniq - c 3 CLOSE \\ _WAIT 26 CLOSING 6712 ESTABLISHED 270 FIN \\ _WAIT1 230 FIN \\ _WAIT2 994 LAST \\ _ACK 2 LISTEN 254 SYN \\ _RECV 73 TIME \\ _WAIT [ root@ccsafe ~ ] # LAST_ACKESTABLISHED15 % ","title":"last_ack"},{"location":"tcp-issue/#close_wait","text":"netstat - n | awk /^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]} LAST_ACK 1 SYN_RECV 15 CLOSE_WAIT 7729 ESTABLISHED 471 FIN_WAIT1 3 FIN_WAIT2 52 SYN_SENT 1 TIME_WAIT 725 ， 7200 ， 2 。 ： tcp_keepalive_time = 7200 seconds ( 2 hours ) tcp_keepalive_probes = 9 tcp_keepalive_intvl = 75 seconds  TCP  idle 2 , probe . probe 9  (  75  ) ,,  sysctl - w net . ipv4 . tcp_keepalive_time = 30 sysctl - w net . ipv4 . tcp_keepalive_probes = 2 sysctl - w net . ipv4 . tcp_keepalive_intvl = 2 ， tcp ","title":"close_wait"},{"location":"tcp-issue/#find_wait1","text":"fin_wait1  net . ipv4 . tcp_orphan_retries = 0  7 ， TCP ，， 7 ， 50  - 16 ， RTO 。  web ，， sockets 。","title":"find_wait1"},{"location":"tomcat/","text":"java  yum install cjkuni * dejavu * - y  java . lang . Error : Probable fatal error : No fonts found .  ： under Ubuntu you can install fonts by sudo apt - get install ttf - dejavu or if you use CentOS , you can install fonts by yum install dejavu *  CenterOS ， # yum install dejavu * ，。 tomcat ，， linux  TOMCAT_HOME / bin / catalina . sh ， 8 G ： JAVA_OPTS = -server -Xms4G -Xmx4G -XX:MaxNewSize=2G -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:PermSize=1G - XX : MaxPermSize = 1 G - Djava . awt . headless = true - Dfile . encoding = UTF8 - Dsun . jnu . encoding = UTF8 - server  jdk  server ； - Xms java ， Xmx ， - Xmx java ；  80 % - Xss ，。，。  StackOverFlow ， 128 K 。 - XX : PermSize  - XX : MaxPermSize  windows  TOMCAT_HOME / bin / catalina . bat ， set JAVA_OPTS =- Xms512m - Xmx512m - Xss1024k - XX : MaxNewSize = 256 M - XX : MaxPermSize = 1024 M  linux ：  conf / server . xml Connector port = 8080 protocol = HTTP/1.1 maxHttpHeaderSize = 8192  Http 、 Header  maxThreads = 1000  minSpareThreads = 100 Tomcat  socket  maxSpareThreads = 1000 Tomcat  socket  minProcessors = 100 ，， 10 maxProcessors = 1000 ，：， 75 enableLookups = false  DNS  compression = on  compressionMinSize = 2048 ， 2 KB compressableMimeType = text/html,text/xml,text/javascript,text/css,text/plain  connectionTimeout = 20000 ， 0 ，。 30000  URIEncoding = utf-8 URL  acceptCount = 1000 ， maxProcessors ， 100 redirectPort = 8443 ， disableUploadTimeout = true / ， false  maxProcessors  acceptCount 。，， webserver  ， Windows  2000 ， Linux  1000  ： 1 ) bio ,,. 2 ) nio  java  io , no blocking IO . ， server . xml  Connector , protocol  Connector port = 80 protocol = org.apache.coyote.http11.Http11NioProtocol connectionTimeout = 20000 redirectPort = 8443 / ,。 3 ) apr , IO ,.  apr  native ， apr 。，, apr  native  nio , protocol  org . apache . coyote . http11 . Http11AprProtocol Apr  Tomcat （ linux ） ， Tomcat  WEB ， Tomcat Native   APR  tomcat （ Internet ）， Tomcat  300 ，。  APR ， 300 ，。 APR ，， 300  ，。 ， 400 ， / ， Internet ， 0 . 1 % ， 。 APR ，，。 apr 。 ( 1 )  APR tomcat - native apr - 1 . 3 . 8 . tar . gz  / usr / local / apr # tar zxvf apr - 1 . 3 . 8 . tar . gz # cd apr - 1 . 3 . 8 #. / configure ;make;make install apr - util - 1 . 3 . 9 . tar . gz  / usr / local / apr / lib # tar zxvf apr - util - 1 . 3 . 9 . tar . gz # cd apr - util - 1 . 3 . 9 #. / configure -- with - apr =/ usr / local / apr ---- with - java - home = JDK ;make;make install # cd apache - tomcat - 6 . 0 . 20 / bin # tar zxvf tomcat - native . tar . gz # cd tomcat - native / jni / native #. / configure -- with - apr =/ usr / local / apr ;make;make install ( 2 )  Tomcat  APR  tomcat  shell （ startup . sh ），： CATALINA_OPTS = $CATALINA_OPTS -Djava.library.path=/usr/local/apr/lib 。 ( 3 ) : ，。 INFO : Loaded APR based Apache Tomcat Native library server . xml ： Executor name = tomcatThreadPool namePrefix = catalina-exec- maxThreads = 3000 minSpareThreads = 200 / Connector executor = tomcatThreadPool port = 8080 protocol = org.apache.coyote.http11.Http11AprProtocol connectionTimeout = 20000000 redirectPort = 8443 URIEncoding = UTF-8 enableLookups = false useURIValidationHack = false disableUploadTimeout = false maxHttpHeaderSize = 65536 maxPostSize = 52428800 / java javamelody https : // github . com / javamelody / javamelody / wiki / UserGuide # javamelody - setup java tomcat  jre  / etc / sysconfig / clock  。  clock ： ZONE = Asia/Shanghai UTC = false ARC = false ZONE --  UTC -- UTC。 ARC -- alphaARC。　　　　　　 redis session https : // github . com / jcoleman / tomcat - redis - session - manager   java1 . 6 tomcat7 https : // github . com / izerui / tomcat - redis - session - manager tomca7 java1 . 7  redis 2 . 8  grandle  .. / gradle - 2 . 1 / bin / gradle build build . gradle apply plugin : java version = 1.1 repositories { mavenCentral () } dependencies { compile group : org.apache.tomcat , name : tomcat-catalina , version : 7.0.67 compile group : redis.clients , name : jedis , version : 2.5.2 compile group : org.apache.commons , name : commons-pool2 , version : 2.2 // testCompile group : junit , name : junit , version : 4.+ } tomcat conf / context . xml Valve className = com.radiadesign.catalina.session.RedisSessionHandlerValve /  tomcat - redis - session jar  Manager className = com.radiadesign.catalina.session.RedisSessionManager host = 192.168.1.5 port = 6379 database = 0 maxInactiveInterval = 60 / tomca7 java1 . 7 Valve className = com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve / Manager className = com.orangefunction.tomcat.redissessions.RedisSessionManager host = localhost port = 6379 database = 0 maxInactiveInterval = 60 sessionPersistPolicies = PERSIST_POLICY_1,PERSIST_POLICY_2,.. session ， sentinelMaster = SentinelMasterName redis  sentinels = sentinel-host-1:port,sentinel-host-2:port,.. / redis  java . lang . IllegalArgumentException : setAttribute : Non - serializable attribute registerLoginUser session  javacpu  top ， PID  28555  Java  CPU  200 % ，。  ps aux | grep PID ， tomcat 。，？  : ps - mp pid - o THREAD , tid , time 1  28802 ， CPU ！  ID  16 ： printf %x\\n tid 2 ： jstack pid | grep tid - A 30  logroute   cat / etc / logrotate . d / tomcat / usr / local / tomcat_pingtai / logs / catalina . out { copytruncate ， log 。, daily  dateext  rotate 30  30 ， missingok ，，“” notifempty ， } 1 .  cronolog ， http : // cronolog . org . ， . / configure , make , make install ，  src / cronolog ， / usr / local / sbin /   yum install cronolog - y 2 .  bin / catalina . sh  1 ） #  touch $CATALINA_BASE / logs / catalina . out Tomcat7  bin / catalina . sh  touch $CATALINA_OUT 2 ），， $CATALINA_BASE / logs / catalina . out 2 1  2 1 | / usr / sbin / cronolog $CATALINA_BASE/logs/catalina-%Y-%m-%d.out Tomcat7  bin / catalina . sh  $CATALINA_OUT 2 1 。  Tomcat7 ， catalina . sh  CATALINA_OUT = $CATALINA_BASE / logs / catalina . out 3 .  catalina . sh ， Tomcat 。  $ TOMCAT_HOME / logs /  catalina - 2012 - 09 - 16 . out , catalina - 2012 - 09 - 17 . out ...... ，  catalina . out  oracle jdk rpm - ivh jdk - 7 u79 - linux - x64 . rpm / etc / profile   export JAVA_HOME =/ usr / java / latest / export PATH = $ JAVA_HOME / bin : $ PATH export CLASSPATH = .: $ JAVA_HOME / lib / dt . jar : $ JAVA_HOME / lib / tools . jar . / etc / profile java - version tomcat 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 #!/bin/bash # author: Sean Chow (seanlook7@gmail.com) # # # chkconfig: 345 80 15 # description: Multiple tomcats service management script. # Source function library. . /etc/rc.d/init.d/functions # tomcat tcNo = $1 tcName = tomcat $1 basedir = /apps/test/ $tcName tclog = ${ basedir } /logs/catalina. $( date +%Y-%m-%d ) .out RETVAL = 0 start (){ checkrun if [ $RETVAL -eq 0 ] ; then echo -- Starting tomcat... $basedir /bin/startup.sh touch /var/lock/subsys/ ${ tcNo } checklog status else echo -- tomcat already running fi } # tomcat，re，， stop (){ checkrun if [ $RETVAL -eq 1 ] ; then echo -- Shutting down tomcat... $basedir /bin/shutdown.sh if [ $1 ! = re ] ; then checklog else sleep 5 fi rm -f /var/lock/subsys/ ${ tcNo } status else echo -- tomcat not running fi } status (){ checkrun if [ $RETVAL -eq 1 ] ; then echo -n -- Tomcat ( pid ps ax --width = 1000 | grep ${ tcName } | grep org.apache.catalina.startup.Bootstrap start | awk {printf $1 } echo -n ) is running... echo else echo -- Tomcat is stopped fi #echo --------------------------------------------- } # tomcat，vl log (){ status checklog yes } # tomcat，tomcat，tomcat kill (){ checkrun if [ $RETVAL -eq 1 ] ; then read -p -- Do you really want to kill ${ tcName } progress?[no]) answer case $answer in Y | y | YES | yes | Yes ) ps ax --width = 1000 | grep ${ tcName } | grep org.apache.catalina.startup.Bootstrap start | awk {printf $1 } | xargs kill -9 status ;; * ) ;; esac else echo -- exit with $tcName still running... fi } checkrun (){ ps ax --width = 1000 | grep ${ tcName } | grep [o]rg.apache.catalina.startup.Bootstrap start | awk {printf $1 } | wc | awk {print $2} /tmp/tomcat_process_count.txt read line /tmp/tomcat_process_count.txt if [ $line -gt 0 ] ; then RETVAL = 1 return $RETVAL else RETVAL = 0 return $RETVAL fi } # viewlog，[yes]，stopstart， checklog (){ answer = $1 if [ $answer ! = yes ] ; then read -p -- See Catalina.out log to check $2 status?[yes]) answer fi case $answer in Y | y | YES | yes | Yes | ) tail -f ${ tclog } ;; * ) # status # exit 0 ;; esac } checkexist (){ if [ ! -d $basedir ] ; then echo -- tomcat $basedir does not exist. exit 0 fi } case $2 in start ) checkexist start exit 0 ;; stop ) checkexist stop exit 0 ;; restart ) checkexist stop re start exit 0 ;; status ) checkexist status #$basedir/bin/catalina.sh version exit 0 ;; log ) checkexist log exit 0 ;; kill ) checkexist status kill exit 0 ;; * ) echo Usage: $0 {start|stop|restart|status|log|kill} echo service tomcat {0|1|..} {start|stop|restart|status|log|kill} esac exit 0 ： baseDir（tomcat），tomcattomcat0、tomcat1… tomcat，/etc/init.d/，chmod +x /etc/init.d/tomcat root， ， tcNametomcat ，tomcat0（/apps/test/tomcat0） service tomcat 0 start ，； service tomcat 0 stop ，；；， ` kill ` （No） service tomcat 0 restart tomcat， service tomcat 0 status tomcat service tomcat 0 log  ` tail -f `  service tomcat 0 kill  ` kill ` tomcat； TO-DO service tomcat 0 cleanworktmp，。 （2014/11/13），tomcat7091， service tomcat 1 start，7091，service tomcat 1 statusstopped， tomcat，service tomcat 1 kill。，。 tomcat http://10.138.16.232:8080，tomcat，tomcat。： tomcat； /usr/local/tomcat/webapps/ROOT/index.html js !DOCTYPE html html lang= en head meta charset= UTF-8 /head script language= javascript window.location.href= /abc ; #url /script /html nginx+tomat ssl nginx tomcat reverse proxy schema nginx config daemon off ; worker_processes 2 ; error_log / var / log / nginx_error . log info ; user bananos staff ; events { worker_connections 1024 ; } http { include / opt / nginx / conf / mime . types ; default_type application / octet - stream ; log_format main $remote_addr - $remote_user [$time_local] $request $status $bytes_sent $http_referer $http_user_agent $gzip_ratio ; ignore_invalid_headers on ; index index . html ; client_header_timeout 240 ; client_body_timeout 240 ; send_timeout 240 ; client_max_body_size 100 m ; proxy_buffer_size 128 k ; proxy_buffers 8 128 k ; upstream tomcat_server { # Tomcat is listening on default 8080 port server 127 . 0 . 0 . 1 : 8080 fail_timeout = 0 ; } server { server_name localhost ; listen 443 ; ssl on ; ssl_session_timeout 5 m ; ssl_protocols SSLv2 SSLv3 TLSv1 ; # make sure you already have this certificate pair ! ssl_certificate / var / certs / server . crt ; ssl_certificate_key / var / certs / server . key ; ssl_session_cache shared : SSL : 10 m ; # www - root , we re serving static files from here, accessible via https://localhost/ location / { root / var / www ; index index . html index . htm ; } # Our endpoint for tomcat reverse - proxy , assuming your endpoint java - servlet knows # how to handle http : // localhost / gadgets requests location / gadgets { proxy_set_header X - Forwarded - For $ proxy_add_x_forwarded_for ; proxy_set_header Host $ http_host ; proxy_set_header X - Forwarded - Proto https ; proxy_redirect off ; proxy_connect_timeout 240 ; proxy_send_timeout 240 ; proxy_read_timeout 240 ; # note , there is not SSL here ! plain HTTP is used proxy_pass http : // tomcat_server ; } } } Tomcat config And here the magic begins , the main point to not miss here is Tomcat needs to be explicitly told that it ’ s being proxied through 443 ( SSL ) port ! Here is a sample Tomcat config which is usually found at { $CA TALINA_HOME } / conf / server . xml ? xml version = 1.0 encoding = utf-8 ? !-- Licensed to the Apache Software Foundation ( ASF ) under one or more contributor license agreements . See the NOTICE file distributed with this work for additional information regarding copyright ownership . The ASF licenses this file to You under the Apache License , Version 2 . 0 ( the License ) ; you may not use this file except in compliance with the License . You may obtain a copy of the License at http : // www . apache . org / licenses / LICENSE - 2 . 0 Unless required by applicable law or agreed to in writing , software distributed under the License is distributed on an AS IS BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . See the License for the specific language governing permissions and limitations under the License . -- !-- Note : A Server is not itself a Container , so you may not define subcomponents such as Valves at this level . Documentation at / docs / config / server . html -- Server port = 8005 shutdown = SHUTDOWN !-- Security listener . Documentation at / docs / config / listeners . html Listener className = org.apache.catalina.security.SecurityListener / -- !-- APR library loader . Documentation at / docs / apr . html -- Listener className = org.apache.catalina.core.AprLifecycleListener SSLEngine = on / !-- Initialize Jasper prior to webapps are loaded . Documentation at / docs / jasper - howto . html -- Listener className = org.apache.catalina.core.JasperListener / !-- Prevent memory leaks due to use of particular java / javax APIs -- Listener className = org.apache.catalina.core.JreMemoryLeakPreventionListener / Listener className = org.apache.catalina.mbeans.GlobalResourcesLifecycleListener / Listener className = org.apache.catalina.core.ThreadLocalLeakPreventionListener / !-- Global JNDI resources Documentation at / docs / jndi - resources - howto . html -- !-- GlobalNamingResources -- !-- Editable user database that can also be used by UserDatabaseRealm to authenticate users -- !-- Resource name = UserDatabase auth = Container type = org.apache.catalina.UserDatabase description = User database that can be updated and saved factory = org.apache.catalina.users.MemoryUserDatabaseFactory pathname = conf/tomcat-users.xml / / GlobalNamingResources -- !-- A Service is a collection of one or more Connectors that share a single Container Note : A Service is not itself a Container , so you may not define subcomponents such as Valves at this level . Documentation at / docs / config / service . html -- Service name = Catalina !-- The connectors can use a shared executor , you can define one or more named thread pools -- !-- Executor name = tomcatThreadPool namePrefix = catalina-exec- maxThreads = 150 minSpareThreads = 4 / -- !-- A Connector represents an endpoint by which requests are received and responses are returned . Documentation at : Java HTTP Connector : / docs / config / http . html ( blocking non - blocking ) Java AJP Connector : / docs / config / ajp . html APR ( HTTP / AJP ) Connector : / docs / apr . html Define a non - SSL HTTP / 1 . 1 Connector on port 8080 -- Connector port = 8080 protocol = HTTP/1.1 connectionTimeout = 20000 redirectPort = 8443 proxyName = localhost proxyPort = 443 scheme = https / !-- A Connector using the shared thread pool -- !-- Connector executor = tomcatThreadPool port = 8080 protocol = HTTP/1.1 connectionTimeout = 20000 redirectPort = 8443 / -- !-- Define a SSL HTTP / 1 . 1 Connector on port 8443 This connector uses the JSSE configuration , when using APR , the connector should be using the OpenSSL style configuration described in the APR documentation -- !-- Connector port = 8443 protocol = HTTP/1.1 SSLEnabled = true maxThreads = 150 scheme = https secure = true clientAuth = false sslProtocol = TLS / -- !-- Define an AJP 1 . 3 Connector on port 8009 -- !-- Connector port = 8009 protocol = AJP/1.3 redirectPort = 8443 / -- !-- An Engine represents the entry point ( within Catalina ) that processes every request . The Engine implementation for Tomcat stand alone analyzes the HTTP headers included with the request , and passes them on to the appropriate Host ( virtual host ) . Documentation at / docs / config / engine . html -- !-- You should set jvmRoute to support load - balancing via AJP ie : Engine name = Catalina defaultHost = localhost jvmRoute = jvm1 -- Engine name = Catalina defaultHost = localhost !-- For clustering , please take a look at documentation at : / docs / cluster - howto . html ( simple how to ) / docs / config / cluster . html ( reference documentation ) -- !-- Cluster className = org.apache.catalina.ha.tcp.SimpleTcpCluster / -- !-- Use the LockOutRealm to prevent attempts to guess user passwords via a brute - force attack -- !-- Realm className = org.apache.catalina.realm.LockOutRealm -- !-- This Realm uses the UserDatabase configured in the global JNDI resources under the key UserDatabase . Any edits that are performed against this UserDatabase are immediately available for use by the Realm . -- !-- Realm className = org.apache.catalina.realm.UserDatabaseRealm resourceName = UserDatabase / -- !-- / Realm -- Host name = localhost appBase = webapps unpackWARs = true autoDeploy = true !-- SingleSignOn valve , share authentication between web applications Documentation at : / docs / config / valve . html -- !-- Valve className = org.apache.catalina.authenticator.SingleSignOn / -- !-- Access log processes all example . Documentation at : / docs / config / valve . html Note : The pattern used is equivalent to using pattern = common -- Valve className = org.apache.catalina.valves.AccessLogValve directory = logs prefix = localhost_access_log. suffix = .txt pattern = %h %l %u %t % r %s %b resolveHosts = false / / Host / Engine / Service / Server As it turned out proxyPort property was the key to proxying Tomcat via Nginx . tomcat Tomcat  　　 tomcat 。，。 　　。： 　　 1 . OutOfMemoryError ： Java heap space 　　 2 . OutOfMemoryError ： PermGen space 　　 3 . OutOfMemoryError ： unable to create new native thread . 　　 Tomcat  　　， tomcat jvm 。（ -Xms -Xmx -XX ： PermSize -XX ： MaxPermSize ） 　　 tomcat jvm 。 　　：。 　　： JVM  java  JVM  . JVM  Heap size ，  (  -Xms )  1 / 64 ， ( -Xmx )  1 / 4 。 JVM  -Xmn -Xms -Xmx 。 Heap size  Young Generation  Tenured Generaion 。  JVM  98 ％ GC  Heap size  2 ％。 Heap Size  80 ％， -Xms  -Xmx ， -Xmn  1 / 4  -Xmx 。 　　， -Xms -Xmx 。 　　 -Xms ： 　　 -Xmx ： 　　： 　　 1 . （ 32-bt  64-bit ）；（ 32 ， 1 . 5G ~ 2G ； 2003 server  （： 4G  6G ， jdk ： 1 . 6 ） 1612M ， 64 。） 　　 2 . ； 　　 3 . 。 　　 java -Xmx *** M version 。 jdk ，。 　　 -Xms -Xmx  set JAVA_OPTS = -Xms1024m -Xmx1024m  (  -Xms )  1 / 64 ， ( -Xmx )  1 / 4 。 JVM  -Xmn -Xms -Xmx   ， 1G  java jvm ： JAVA_OPTS = -server -Xms800m -Xmx800m -XX:PermSize=64M -XX:MaxNewSize=256m -XX:MaxPermSize=128m -Djava.awt.headless=true JAVA_OPTS = -server -Xms768m -Xmx768m -XX:PermSize=128m -XX:MaxPermSize=256m -XX: NewSize=192m -XX:MaxNewSize=384m CATALINA_OPTS = -server -Xms768m -Xmx768m -XX:PermSize=128m -XX:MaxPermSize=256m -XX:NewSize=192m -XX:MaxNewSize=384m  1G ： JAVA_OPTS = -server -Xms800m -Xmx800m -XX:PermSize=64M -XX:MaxNewSize=256m -XX:MaxPermSize=128m -Djava.awt.headless=true  64 、 2G  : JAVA_OPTS = -server -Xms1024m -Xmx1536m -XX:PermSize=128M -XX:MaxNewSize=256m -XX:MaxPermSize=256m -------------------  1 ： ----------------------------- ： startup . bat  tomcat  Linux ：  / usr / local / apache-tomcat-5 . 5 . 23 / bin  catalina . sh ： JAVA_OPTS = -Xms512m -Xmx1024m  JAVA_OPTS = -server -Xms800m -Xmx800m -XX:MaxNewSize=256m  CATALINA_OPTS = -server -Xms256m -Xmx300m Windows ：  catalina . bat  set JAVA_OPTS = -Xms128m -Xmx350m  set CATALINA_OPTS = -Xmx300M -Xms256M （ jvm ，  tomcat ， CATALINA_OPTS  JAVA_OPTS ）  -client ， -server ，， client ，  server ，。， server  client ，。  windows ， client ， server ， -server ， ，， server ， CPU 。 Linux ， Solaris  server 。 ， cup ， server  -Xms size ，， 1024  1MB ， k ( K )  m ( M )  。 2MB 。“ m ” MB ， KB 。 ： -Xms6400K ， -Xms256M -Xmx size  ，。 1024 ， 2MB 。 k ( K )  m ( M )  。 64MB 。 ： -Xmx81920K ， -Xmx80M  java . lang . OutOfMemoryError : Java heap space ， -Xmx 。 PermSize / MaxPermSize ： Perm ，， PermSize  JVM  Perm ； MaxPermSize   Perm 。，。  startup . bat  tomcat , OK  .  200M  . -------------------  2 ： ------------------------ ： startup . bat  tomcat   Heap size Windows ：  TOMCAT_HOME / bin / catalina . bat ，“ echo Using CATALINA_BASE: $CATALINA_BASE ”： Java  set JAVA_OPTS =% JAVA_OPTS % -server -Xms800m -Xmx800m -XX : MaxNewSize = 256m ： JAVA_OPTS 。 Linux ：  TOMCAT_HOME / bin / catalina . sh “ echo Using CATALINA_BASE: $CATALINA_BASE ”： JAVA_OPTS = $JAVA_OPTS -server -Xms800m -Xmx800m -XX:MaxNewSize=256m ： $ JAVA_OPTS 。 -------------------  3 ： ----------------------------- ： windows  tomcat   startup . bat  tomcat  windows  tomcat  ,  ,  set JAVA_OPTS = -Xms128m -Xmx350m  .  200M  OOM  .. windows  bin \\ tomcat . exe .  ,  catalina . bat  .  :  HKEY_LOCAL_MACHINE \\ SOFTWARE \\ Apache Software Foundation \\ Tomcat Service Manager \\ Tomcat5 \\ Parameters \\ JavaOptions  -Dcatalina . home = C:\\ApacheGroup\\Tomcat 5.0 -Djava . endorsed . dirs = C:\\ApacheGroup\\Tomcat 5.0\\common\\endorsed -Xrs  -Xms300m -Xmx350m  tomcat  ,  -------------------  4 ： ----------------------------- ： windows  tomcat   tomcat  NT Service(NT/2000/XP only)  bin  tomcat . exe   tomcat  （ CMD ）  tomcat  bin   tomcat -uninstall Apache Tomcat 4.1 ，。  set SERVICENAME = Apache Tomcat 4 . 1 set CATALINA_HOME = E : \\ Tomcat 4 . 1 . 24 set CLASSPATH = D : \\ j2sdk1 . 4 . 1_01 \\ lib set JAVACLASSPATH =% CLASSPATH % set JAVACLASSPATH =% JAVACLASSPATH %; � TALINA_HOME % \\ bin \\ bootstrap . jar set JAVACLASSPATH =% JAVACLASSPATH %; � TALINA_HOME % \\ common \\ lib \\ servlet . jar set JAVACLASSPATH =% JAVACLASSPATH %;% JAVA_HOME % \\ lib \\ tools . jar tomcat . exe -install %SERVICENAME% %JAVA_HOME%\\jre\\bin\\server\\jvm.dll -Djava . class . path = %JAVACLASSPATH% -Dcatalina . home = �TALINA_HOME% -Xms512m -Xmx768m -start org . apache . catalina . startup . Bootstrap -params start -stop org . apache . catalina . startup . Bootstrap -params stop -out �TALINA_HOME%\\logs\\stdout.log -err �TALINA_HOME%\\ logs\\stderr.log ， tomcat . exe -install ！。 bat ， “”。 ： 　： PermGen space  Permanent Generation space , ， JVM  Class  Meta  , Class  Loader  PermGen space ， ( Instance )  Heap  , GC ( Garbage Collection )   PermGen space ， CLASS  ,  PermGen space ， web  JSP  pre compile 。 WEB APP  jar ,  jvm  ( 4M )  。 hibernate  spring 。 class ， jvm  gc  PemGen space ， jvm  ( 4M ) ，。 　　： jar  tomcat / shared / lib ， jar 。  -XX ： PermSize -XX ： MaxPermSize 。 　　 -XX ： PermSize  　　 -XX ： PermSize  　　， set JAVA_OPTS = -Xms1024m -Xmx1024m -XX ： PermSize = 128M -XX ： PermSize = 256M 　　： java -Xmx *** M version  -Xmx  -XX ： PermSize   jvm   1 . 5G ， -Xmx1024m -XX ： PermSize = 768M 。 -----------------  1 ： ------------------------- Linux ：  catalina . sh ： JAVA_OPTS = -Xms64m -Xmx256m -XX : PermSize = 128M -XX : MaxNewSize = 256m -XX : MaxPermSize = 256m  “ echo Using CATALINA_BASE: $CATALINA_BASE ”： JAVA_OPTS = -server -XX:PermSize=64M -XX:MaxPermSize=128m Windows： catalina.bat： set JAVA_OPTS=-Xms64m -Xmx256m -XX:PermSize=128M -XX:MaxNewSize=256m -XX:MaxPermSize=256m -----------------2：------------------------ TOMCAT_HOME/bin/catalina.bat（Linuxcatalina.sh），Java “echo Using CATALINA_BASE : $ CATALINA_BASE ”： set JAVA_OPTS=%JAVA_OPTS% -server -XX:PermSize=128M -XX:MaxPermSize=512m “echo Using CATALINA_BASE : $ CATALINA_BASE ”： set JAVA_OPTS=%JAVA_OPTS% -server -XX:PermSize=128M -XX:MaxPermSize=512m catalina.sh： Java JAVA_OPTS= $ JAVA_OPTS -server -XX : PermSize = 128M -XX : MaxPermSize = 512m JAVA_OPTS= $ JAVA_OPTS -server -XX : PermSize = 128M -XX : MaxPermSize = 512m 　　：。 　　，，jvm。 　　JVM（1.5G），。， ，JVM，，。 　　 （blog：http://hi.baidu.com/hexiong/blog/item/16dc9e518fb10c2542a75b3c.html）： 　　322G，2G。1.5GJVM，500M。 500Mdll，400M，：Java， JVMThread，（JVM）， 400，JVM1500M。jdk1.4，256KB，jdk1.5， 1M，，400M400。 　　，，JVM。JVMJNI。 　　： 　　（MaxProcessMemory - JVMMemory - ReservedOsMemory） / （ThreadStackSize） = Number of threads 　　jdk1.5，120M： 　　1.5GB JVM： （2GB-1.5Gb-120MB）/（1MB） = ~380 threads 　　1.0GB JVM： （2GB-1.0Gb-120MB）/（1MB） = ~880 threads 　　2000/XP/2003boot.ini，：/PAE /3G ，3G， 1G。JVM。 　　。 　　：tomcat。 JVM： System.out.println( JVM MAX MEMORY : + Runtime.getRuntime().maxMemory()/1024/1024+ M ); System.out.println( JVM IS USING MEMORY : + Runtime.getRuntime().totalMemory()/1024/1024+ M ); System.out.println( JVM IS FREE MEMORY : + Runtime.getRuntime().freeMemory()/1024/1024+ M ); JVM； 　　maxMemory()java（），，java ，-Xmx，64，maxMemory()64*1024*1024，java 。-Xmx，，java -cp ClassPath -Xmx512m ClassName， 512*1024*0124。 　　totalMemory()java，java 。java-Xms，，java，， ，maxMemory()，totalMemory()。-Xms， -Xms，，。 　　freeMemory()，java-Xms，，java， ，，java100％，， freeMemory()，freeMemory()，java-Xms， -Xms，，，freeMemory()  ---------------------------------------------- JVM 　　Sun HotSpot 1.4.1，：、。Jvm。 ，。jvmclassmethod。， 。 　　。-Xms-Xmx 。 　　128M： 　　java –Xms128m 　　–Xmx256m，-XX:NewRatio。 　　128m，3，1：3，1/432M： java –Xms128m –Xmx128m –XX:NewRatio =3-XX:NewSize-XX:MaxNewsize。 　　64m: java –Xms256m –Xmx256m –Xmn64m 　　4m。，jvm。，jvm。 　　-XX:MaxPerSize。WebLogic Server，。jvm ，，jvm。，-XX:PerSize。 　　32m，64m。 java -Xms512m -Xmx512m -Xmn128m -XX:PermSize=32m -XX:MaxPermSize=64m 　　，HotSpot。。Eden，。 ，Eden，，from，from， to。Fromto。， 。-XX:SurvivorRatio。 　　NewRation，SurvivorRationEden。，64m，Eden32m，16m： java -Xms256m -Xmx256m -Xmn64m -XX:SurvivorRation =2 　　，HotSpot，－－。， 。，Eden。，Eden ，，。，， 。，。 ，-XX:TargetSurvivorRatio（。1M，50500K）。 ，50。sruvivorratio，8090，。 -XX:maxtenuring threshold。 　　eden，MaxTenuring Threshold0。， ，SurvivorRatioEden，： java … -XX:MaxTenuringThreshold=0 –XX:SurvivorRatio＝50000 … ： ，0(Full)，OLD；1，Young， OLDPerm，Java。 URL，： A. JVMJavaEden B. Eden，。 C. JVMEden（1）；Eden， EdenSurvivor/OLD D. SurvivorEdenOLD，OLD，SurvivorOld，Survivor E. OLD，JVMOLD（0） F. ，SurvivorOLDEden，JVMEden， ”out of memory” Java： ms/mx：YOUNG+OLD，msJVMYOUNG+OLD；mxYOUNG+OLD。 ，。 NewSize/MaxNewSize：YOUNG，NewSizeJVMYOUNG；MaxNewSizeYOUNG。 ，。 PermSize/MaxPermSize：Perm，PermSizeJVMPerm；MaxPermSizePerm。 ，。 SurvivorRatio：SurvivorEden ： MEM_ARGS= -Xms512m -Xmx512m -XX : NewSize = 256m -XX : MaxNewSize = 256m -XX : PermSize = 128m -XX : MaxPermSize = 128m -XX : SurvivorRatio = 6 ： YOUNG + OLD : 512M YOUNG : 256M Perm : 128M Eden : YOUNG * 6 /( 6 + 1 + 1 )= 192M Survivor : YOUNG /( 6 + 1 + 1 )= 32M Java  = YOUNG + OLD + Perm = 640M java update - alternatives --config java alternatives --config java --disaplay java","title":"tomcat"},{"location":"tomcat/#java","text":" yum install cjkuni * dejavu * - y  java . lang . Error : Probable fatal error : No fonts found .  ： under Ubuntu you can install fonts by sudo apt - get install ttf - dejavu or if you use CentOS , you can install fonts by yum install dejavu *  CenterOS ， # yum install dejavu * ，。","title":"java"},{"location":"tomcat/#tomcat","text":"，， linux  TOMCAT_HOME / bin / catalina . sh ， 8 G ： JAVA_OPTS = -server -Xms4G -Xmx4G -XX:MaxNewSize=2G -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:PermSize=1G - XX : MaxPermSize = 1 G - Djava . awt . headless = true - Dfile . encoding = UTF8 - Dsun . jnu . encoding = UTF8 - server  jdk  server ； - Xms java ， Xmx ， - Xmx java ；  80 % - Xss ，。，。  StackOverFlow ， 128 K 。 - XX : PermSize  - XX : MaxPermSize  windows  TOMCAT_HOME / bin / catalina . bat ， set JAVA_OPTS =- Xms512m - Xmx512m - Xss1024k - XX : MaxNewSize = 256 M - XX : MaxPermSize = 1024 M  linux ：  conf / server . xml Connector port = 8080 protocol = HTTP/1.1 maxHttpHeaderSize = 8192  Http 、 Header  maxThreads = 1000  minSpareThreads = 100 Tomcat  socket  maxSpareThreads = 1000 Tomcat  socket  minProcessors = 100 ，， 10 maxProcessors = 1000 ，：， 75 enableLookups = false  DNS  compression = on  compressionMinSize = 2048 ， 2 KB compressableMimeType = text/html,text/xml,text/javascript,text/css,text/plain  connectionTimeout = 20000 ， 0 ，。 30000  URIEncoding = utf-8 URL  acceptCount = 1000 ， maxProcessors ， 100 redirectPort = 8443 ， disableUploadTimeout = true / ， false  maxProcessors  acceptCount 。，， webserver  ， Windows  2000 ， Linux  1000  ： 1 ) bio ,,. 2 ) nio  java  io , no blocking IO . ， server . xml  Connector , protocol  Connector port = 80 protocol = org.apache.coyote.http11.Http11NioProtocol connectionTimeout = 20000 redirectPort = 8443 / ,。 3 ) apr , IO ,.  apr  native ， apr 。，, apr  native  nio , protocol  org . apache . coyote . http11 . Http11AprProtocol Apr  Tomcat （ linux ） ， Tomcat  WEB ， Tomcat Native   APR  tomcat （ Internet ）， Tomcat  300 ，。  APR ， 300 ，。 APR ，， 300  ，。 ， 400 ， / ， Internet ， 0 . 1 % ， 。 APR ，，。 apr 。 ( 1 )  APR tomcat - native apr - 1 . 3 . 8 . tar . gz  / usr / local / apr # tar zxvf apr - 1 . 3 . 8 . tar . gz # cd apr - 1 . 3 . 8 #. / configure ;make;make install apr - util - 1 . 3 . 9 . tar . gz  / usr / local / apr / lib # tar zxvf apr - util - 1 . 3 . 9 . tar . gz # cd apr - util - 1 . 3 . 9 #. / configure -- with - apr =/ usr / local / apr ---- with - java - home = JDK ;make;make install # cd apache - tomcat - 6 . 0 . 20 / bin # tar zxvf tomcat - native . tar . gz # cd tomcat - native / jni / native #. / configure -- with - apr =/ usr / local / apr ;make;make install ( 2 )  Tomcat  APR  tomcat  shell （ startup . sh ），： CATALINA_OPTS = $CATALINA_OPTS -Djava.library.path=/usr/local/apr/lib 。 ( 3 ) : ，。 INFO : Loaded APR based Apache Tomcat Native library server . xml ： Executor name = tomcatThreadPool namePrefix = catalina-exec- maxThreads = 3000 minSpareThreads = 200 / Connector executor = tomcatThreadPool port = 8080 protocol = org.apache.coyote.http11.Http11AprProtocol connectionTimeout = 20000000 redirectPort = 8443 URIEncoding = UTF-8 enableLookups = false useURIValidationHack = false disableUploadTimeout = false maxHttpHeaderSize = 65536 maxPostSize = 52428800 /","title":"tomcat"},{"location":"tomcat/#java_1","text":"javamelody https : // github . com / javamelody / javamelody / wiki / UserGuide # javamelody - setup","title":"java"},{"location":"tomcat/#java_2","text":"tomcat  jre  / etc / sysconfig / clock  。  clock ： ZONE = Asia/Shanghai UTC = false ARC = false ZONE --  UTC -- UTC。 ARC -- alphaARC。","title":"java"},{"location":"tomcat/#redis-session","text":"https : // github . com / jcoleman / tomcat - redis - session - manager   java1 . 6 tomcat7 https : // github . com / izerui / tomcat - redis - session - manager tomca7 java1 . 7  redis 2 . 8  grandle  .. / gradle - 2 . 1 / bin / gradle build build . gradle apply plugin : java version = 1.1 repositories { mavenCentral () } dependencies { compile group : org.apache.tomcat , name : tomcat-catalina , version : 7.0.67 compile group : redis.clients , name : jedis , version : 2.5.2 compile group : org.apache.commons , name : commons-pool2 , version : 2.2 // testCompile group : junit , name : junit , version : 4.+ } tomcat conf / context . xml Valve className = com.radiadesign.catalina.session.RedisSessionHandlerValve /  tomcat - redis - session jar  Manager className = com.radiadesign.catalina.session.RedisSessionManager host = 192.168.1.5 port = 6379 database = 0 maxInactiveInterval = 60 / tomca7 java1 . 7 Valve className = com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve / Manager className = com.orangefunction.tomcat.redissessions.RedisSessionManager host = localhost port = 6379 database = 0 maxInactiveInterval = 60 sessionPersistPolicies = PERSIST_POLICY_1,PERSIST_POLICY_2,.. session ， sentinelMaster = SentinelMasterName redis  sentinels = sentinel-host-1:port,sentinel-host-2:port,.. / redis  java . lang . IllegalArgumentException : setAttribute : Non - serializable attribute registerLoginUser session ","title":"redis session"},{"location":"tomcat/#javacpu","text":" top ， PID  28555  Java  CPU  200 % ，。  ps aux | grep PID ， tomcat 。，？  : ps - mp pid - o THREAD , tid , time 1  28802 ， CPU ！  ID  16 ： printf %x\\n tid 2 ： jstack pid | grep tid - A 30","title":"javacpu"},{"location":"tomcat/#_1","text":"logroute   cat / etc / logrotate . d / tomcat / usr / local / tomcat_pingtai / logs / catalina . out { copytruncate ， log 。, daily  dateext  rotate 30  30 ， missingok ，，“” notifempty ， } 1 .  cronolog ， http : // cronolog . org . ， . / configure , make , make install ，  src / cronolog ， / usr / local / sbin /   yum install cronolog - y 2 .  bin / catalina . sh  1 ） #  touch $CATALINA_BASE / logs / catalina . out Tomcat7  bin / catalina . sh  touch $CATALINA_OUT 2 ），， $CATALINA_BASE / logs / catalina . out 2 1  2 1 | / usr / sbin / cronolog $CATALINA_BASE/logs/catalina-%Y-%m-%d.out Tomcat7  bin / catalina . sh  $CATALINA_OUT 2 1 。  Tomcat7 ， catalina . sh  CATALINA_OUT = $CATALINA_BASE / logs / catalina . out 3 .  catalina . sh ， Tomcat 。  $ TOMCAT_HOME / logs /  catalina - 2012 - 09 - 16 . out , catalina - 2012 - 09 - 17 . out ...... ，  catalina . out ","title":""},{"location":"tomcat/#oracle-jdk","text":"rpm - ivh jdk - 7 u79 - linux - x64 . rpm / etc / profile   export JAVA_HOME =/ usr / java / latest / export PATH = $ JAVA_HOME / bin : $ PATH export CLASSPATH = .: $ JAVA_HOME / lib / dt . jar : $ JAVA_HOME / lib / tools . jar . / etc / profile java - version","title":"oracle jdk"},{"location":"tomcat/#tomcat_1","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 #!/bin/bash # author: Sean Chow (seanlook7@gmail.com) # # # chkconfig: 345 80 15 # description: Multiple tomcats service management script. # Source function library. . /etc/rc.d/init.d/functions # tomcat tcNo = $1 tcName = tomcat $1 basedir = /apps/test/ $tcName tclog = ${ basedir } /logs/catalina. $( date +%Y-%m-%d ) .out RETVAL = 0 start (){ checkrun if [ $RETVAL -eq 0 ] ; then echo -- Starting tomcat... $basedir /bin/startup.sh touch /var/lock/subsys/ ${ tcNo } checklog status else echo -- tomcat already running fi } # tomcat，re，， stop (){ checkrun if [ $RETVAL -eq 1 ] ; then echo -- Shutting down tomcat... $basedir /bin/shutdown.sh if [ $1 ! = re ] ; then checklog else sleep 5 fi rm -f /var/lock/subsys/ ${ tcNo } status else echo -- tomcat not running fi } status (){ checkrun if [ $RETVAL -eq 1 ] ; then echo -n -- Tomcat ( pid ps ax --width = 1000 | grep ${ tcName } | grep org.apache.catalina.startup.Bootstrap start | awk {printf $1 } echo -n ) is running... echo else echo -- Tomcat is stopped fi #echo --------------------------------------------- } # tomcat，vl log (){ status checklog yes } # tomcat，tomcat，tomcat kill (){ checkrun if [ $RETVAL -eq 1 ] ; then read -p -- Do you really want to kill ${ tcName } progress?[no]) answer case $answer in Y | y | YES | yes | Yes ) ps ax --width = 1000 | grep ${ tcName } | grep org.apache.catalina.startup.Bootstrap start | awk {printf $1 } | xargs kill -9 status ;; * ) ;; esac else echo -- exit with $tcName still running... fi } checkrun (){ ps ax --width = 1000 | grep ${ tcName } | grep [o]rg.apache.catalina.startup.Bootstrap start | awk {printf $1 } | wc | awk {print $2} /tmp/tomcat_process_count.txt read line /tmp/tomcat_process_count.txt if [ $line -gt 0 ] ; then RETVAL = 1 return $RETVAL else RETVAL = 0 return $RETVAL fi } # viewlog，[yes]，stopstart， checklog (){ answer = $1 if [ $answer ! = yes ] ; then read -p -- See Catalina.out log to check $2 status?[yes]) answer fi case $answer in Y | y | YES | yes | Yes | ) tail -f ${ tclog } ;; * ) # status # exit 0 ;; esac } checkexist (){ if [ ! -d $basedir ] ; then echo -- tomcat $basedir does not exist. exit 0 fi } case $2 in start ) checkexist start exit 0 ;; stop ) checkexist stop exit 0 ;; restart ) checkexist stop re start exit 0 ;; status ) checkexist status #$basedir/bin/catalina.sh version exit 0 ;; log ) checkexist log exit 0 ;; kill ) checkexist status kill exit 0 ;; * ) echo Usage: $0 {start|stop|restart|status|log|kill} echo service tomcat {0|1|..} {start|stop|restart|status|log|kill} esac exit 0 ： baseDir（tomcat），tomcattomcat0、tomcat1… tomcat，/etc/init.d/，chmod +x /etc/init.d/tomcat root， ， tcNametomcat ，tomcat0（/apps/test/tomcat0） service tomcat 0 start ，； service tomcat 0 stop ，；；， ` kill ` （No） service tomcat 0 restart tomcat， service tomcat 0 status tomcat service tomcat 0 log  ` tail -f `  service tomcat 0 kill  ` kill ` tomcat； TO-DO service tomcat 0 cleanworktmp，。 （2014/11/13），tomcat7091， service tomcat 1 start，7091，service tomcat 1 statusstopped， tomcat，service tomcat 1 kill。，。","title":"tomcat"},{"location":"tomcat/#tomcat_2","text":"http://10.138.16.232:8080，tomcat，tomcat。： tomcat； /usr/local/tomcat/webapps/ROOT/index.html js !DOCTYPE html html lang= en head meta charset= UTF-8 /head script language= javascript window.location.href= /abc ; #url /script /html","title":"tomcat"},{"location":"tomcat/#nginxtomat-ssl","text":"nginx tomcat reverse proxy schema nginx config daemon off ; worker_processes 2 ; error_log / var / log / nginx_error . log info ; user bananos staff ; events { worker_connections 1024 ; } http { include / opt / nginx / conf / mime . types ; default_type application / octet - stream ; log_format main $remote_addr - $remote_user [$time_local] $request $status $bytes_sent $http_referer $http_user_agent $gzip_ratio ; ignore_invalid_headers on ; index index . html ; client_header_timeout 240 ; client_body_timeout 240 ; send_timeout 240 ; client_max_body_size 100 m ; proxy_buffer_size 128 k ; proxy_buffers 8 128 k ; upstream tomcat_server { # Tomcat is listening on default 8080 port server 127 . 0 . 0 . 1 : 8080 fail_timeout = 0 ; } server { server_name localhost ; listen 443 ; ssl on ; ssl_session_timeout 5 m ; ssl_protocols SSLv2 SSLv3 TLSv1 ; # make sure you already have this certificate pair ! ssl_certificate / var / certs / server . crt ; ssl_certificate_key / var / certs / server . key ; ssl_session_cache shared : SSL : 10 m ; # www - root , we re serving static files from here, accessible via https://localhost/ location / { root / var / www ; index index . html index . htm ; } # Our endpoint for tomcat reverse - proxy , assuming your endpoint java - servlet knows # how to handle http : // localhost / gadgets requests location / gadgets { proxy_set_header X - Forwarded - For $ proxy_add_x_forwarded_for ; proxy_set_header Host $ http_host ; proxy_set_header X - Forwarded - Proto https ; proxy_redirect off ; proxy_connect_timeout 240 ; proxy_send_timeout 240 ; proxy_read_timeout 240 ; # note , there is not SSL here ! plain HTTP is used proxy_pass http : // tomcat_server ; } } } Tomcat config And here the magic begins , the main point to not miss here is Tomcat needs to be explicitly told that it ’ s being proxied through 443 ( SSL ) port ! Here is a sample Tomcat config which is usually found at { $CA TALINA_HOME } / conf / server . xml ? xml version = 1.0 encoding = utf-8 ? !-- Licensed to the Apache Software Foundation ( ASF ) under one or more contributor license agreements . See the NOTICE file distributed with this work for additional information regarding copyright ownership . The ASF licenses this file to You under the Apache License , Version 2 . 0 ( the License ) ; you may not use this file except in compliance with the License . You may obtain a copy of the License at http : // www . apache . org / licenses / LICENSE - 2 . 0 Unless required by applicable law or agreed to in writing , software distributed under the License is distributed on an AS IS BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . See the License for the specific language governing permissions and limitations under the License . -- !-- Note : A Server is not itself a Container , so you may not define subcomponents such as Valves at this level . Documentation at / docs / config / server . html -- Server port = 8005 shutdown = SHUTDOWN !-- Security listener . Documentation at / docs / config / listeners . html Listener className = org.apache.catalina.security.SecurityListener / -- !-- APR library loader . Documentation at / docs / apr . html -- Listener className = org.apache.catalina.core.AprLifecycleListener SSLEngine = on / !-- Initialize Jasper prior to webapps are loaded . Documentation at / docs / jasper - howto . html -- Listener className = org.apache.catalina.core.JasperListener / !-- Prevent memory leaks due to use of particular java / javax APIs -- Listener className = org.apache.catalina.core.JreMemoryLeakPreventionListener / Listener className = org.apache.catalina.mbeans.GlobalResourcesLifecycleListener / Listener className = org.apache.catalina.core.ThreadLocalLeakPreventionListener / !-- Global JNDI resources Documentation at / docs / jndi - resources - howto . html -- !-- GlobalNamingResources -- !-- Editable user database that can also be used by UserDatabaseRealm to authenticate users -- !-- Resource name = UserDatabase auth = Container type = org.apache.catalina.UserDatabase description = User database that can be updated and saved factory = org.apache.catalina.users.MemoryUserDatabaseFactory pathname = conf/tomcat-users.xml / / GlobalNamingResources -- !-- A Service is a collection of one or more Connectors that share a single Container Note : A Service is not itself a Container , so you may not define subcomponents such as Valves at this level . Documentation at / docs / config / service . html -- Service name = Catalina !-- The connectors can use a shared executor , you can define one or more named thread pools -- !-- Executor name = tomcatThreadPool namePrefix = catalina-exec- maxThreads = 150 minSpareThreads = 4 / -- !-- A Connector represents an endpoint by which requests are received and responses are returned . Documentation at : Java HTTP Connector : / docs / config / http . html ( blocking non - blocking ) Java AJP Connector : / docs / config / ajp . html APR ( HTTP / AJP ) Connector : / docs / apr . html Define a non - SSL HTTP / 1 . 1 Connector on port 8080 -- Connector port = 8080 protocol = HTTP/1.1 connectionTimeout = 20000 redirectPort = 8443 proxyName = localhost proxyPort = 443 scheme = https / !-- A Connector using the shared thread pool -- !-- Connector executor = tomcatThreadPool port = 8080 protocol = HTTP/1.1 connectionTimeout = 20000 redirectPort = 8443 / -- !-- Define a SSL HTTP / 1 . 1 Connector on port 8443 This connector uses the JSSE configuration , when using APR , the connector should be using the OpenSSL style configuration described in the APR documentation -- !-- Connector port = 8443 protocol = HTTP/1.1 SSLEnabled = true maxThreads = 150 scheme = https secure = true clientAuth = false sslProtocol = TLS / -- !-- Define an AJP 1 . 3 Connector on port 8009 -- !-- Connector port = 8009 protocol = AJP/1.3 redirectPort = 8443 / -- !-- An Engine represents the entry point ( within Catalina ) that processes every request . The Engine implementation for Tomcat stand alone analyzes the HTTP headers included with the request , and passes them on to the appropriate Host ( virtual host ) . Documentation at / docs / config / engine . html -- !-- You should set jvmRoute to support load - balancing via AJP ie : Engine name = Catalina defaultHost = localhost jvmRoute = jvm1 -- Engine name = Catalina defaultHost = localhost !-- For clustering , please take a look at documentation at : / docs / cluster - howto . html ( simple how to ) / docs / config / cluster . html ( reference documentation ) -- !-- Cluster className = org.apache.catalina.ha.tcp.SimpleTcpCluster / -- !-- Use the LockOutRealm to prevent attempts to guess user passwords via a brute - force attack -- !-- Realm className = org.apache.catalina.realm.LockOutRealm -- !-- This Realm uses the UserDatabase configured in the global JNDI resources under the key UserDatabase . Any edits that are performed against this UserDatabase are immediately available for use by the Realm . -- !-- Realm className = org.apache.catalina.realm.UserDatabaseRealm resourceName = UserDatabase / -- !-- / Realm -- Host name = localhost appBase = webapps unpackWARs = true autoDeploy = true !-- SingleSignOn valve , share authentication between web applications Documentation at : / docs / config / valve . html -- !-- Valve className = org.apache.catalina.authenticator.SingleSignOn / -- !-- Access log processes all example . Documentation at : / docs / config / valve . html Note : The pattern used is equivalent to using pattern = common -- Valve className = org.apache.catalina.valves.AccessLogValve directory = logs prefix = localhost_access_log. suffix = .txt pattern = %h %l %u %t % r %s %b resolveHosts = false / / Host / Engine / Service / Server As it turned out proxyPort property was the key to proxying Tomcat via Nginx .","title":"nginx+tomat ssl"},{"location":"tomcat/#tomcat_3","text":"Tomcat  　　 tomcat 。，。 　　。： 　　 1 . OutOfMemoryError ： Java heap space 　　 2 . OutOfMemoryError ： PermGen space 　　 3 . OutOfMemoryError ： unable to create new native thread . 　　 Tomcat  　　， tomcat jvm 。（ -Xms -Xmx -XX ： PermSize -XX ： MaxPermSize ） 　　 tomcat jvm 。 　　：。 　　： JVM  java  JVM  . JVM  Heap size ，  (  -Xms )  1 / 64 ， ( -Xmx )  1 / 4 。 JVM  -Xmn -Xms -Xmx 。 Heap size  Young Generation  Tenured Generaion 。  JVM  98 ％ GC  Heap size  2 ％。 Heap Size  80 ％， -Xms  -Xmx ， -Xmn  1 / 4  -Xmx 。 　　， -Xms -Xmx 。 　　 -Xms ： 　　 -Xmx ： 　　： 　　 1 . （ 32-bt  64-bit ）；（ 32 ， 1 . 5G ~ 2G ； 2003 server  （： 4G  6G ， jdk ： 1 . 6 ） 1612M ， 64 。） 　　 2 . ； 　　 3 . 。 　　 java -Xmx *** M version 。 jdk ，。 　　 -Xms -Xmx  set JAVA_OPTS = -Xms1024m -Xmx1024m  (  -Xms )  1 / 64 ， ( -Xmx )  1 / 4 。 JVM  -Xmn -Xms -Xmx   ， 1G  java jvm ： JAVA_OPTS = -server -Xms800m -Xmx800m -XX:PermSize=64M -XX:MaxNewSize=256m -XX:MaxPermSize=128m -Djava.awt.headless=true JAVA_OPTS = -server -Xms768m -Xmx768m -XX:PermSize=128m -XX:MaxPermSize=256m -XX: NewSize=192m -XX:MaxNewSize=384m CATALINA_OPTS = -server -Xms768m -Xmx768m -XX:PermSize=128m -XX:MaxPermSize=256m -XX:NewSize=192m -XX:MaxNewSize=384m  1G ： JAVA_OPTS = -server -Xms800m -Xmx800m -XX:PermSize=64M -XX:MaxNewSize=256m -XX:MaxPermSize=128m -Djava.awt.headless=true  64 、 2G  : JAVA_OPTS = -server -Xms1024m -Xmx1536m -XX:PermSize=128M -XX:MaxNewSize=256m -XX:MaxPermSize=256m -------------------  1 ： ----------------------------- ： startup . bat  tomcat  Linux ：  / usr / local / apache-tomcat-5 . 5 . 23 / bin  catalina . sh ： JAVA_OPTS = -Xms512m -Xmx1024m  JAVA_OPTS = -server -Xms800m -Xmx800m -XX:MaxNewSize=256m  CATALINA_OPTS = -server -Xms256m -Xmx300m Windows ：  catalina . bat  set JAVA_OPTS = -Xms128m -Xmx350m  set CATALINA_OPTS = -Xmx300M -Xms256M （ jvm ，  tomcat ， CATALINA_OPTS  JAVA_OPTS ）  -client ， -server ，， client ，  server ，。， server  client ，。  windows ， client ， server ， -server ， ，， server ， CPU 。 Linux ， Solaris  server 。 ， cup ， server  -Xms size ，， 1024  1MB ， k ( K )  m ( M )  。 2MB 。“ m ” MB ， KB 。 ： -Xms6400K ， -Xms256M -Xmx size  ，。 1024 ， 2MB 。 k ( K )  m ( M )  。 64MB 。 ： -Xmx81920K ， -Xmx80M  java . lang . OutOfMemoryError : Java heap space ， -Xmx 。 PermSize / MaxPermSize ： Perm ，， PermSize  JVM  Perm ； MaxPermSize   Perm 。，。  startup . bat  tomcat , OK  .  200M  . -------------------  2 ： ------------------------ ： startup . bat  tomcat   Heap size Windows ：  TOMCAT_HOME / bin / catalina . bat ，“ echo Using CATALINA_BASE: $CATALINA_BASE ”： Java  set JAVA_OPTS =% JAVA_OPTS % -server -Xms800m -Xmx800m -XX : MaxNewSize = 256m ： JAVA_OPTS 。 Linux ：  TOMCAT_HOME / bin / catalina . sh “ echo Using CATALINA_BASE: $CATALINA_BASE ”： JAVA_OPTS = $JAVA_OPTS -server -Xms800m -Xmx800m -XX:MaxNewSize=256m ： $ JAVA_OPTS 。 -------------------  3 ： ----------------------------- ： windows  tomcat   startup . bat  tomcat  windows  tomcat  ,  ,  set JAVA_OPTS = -Xms128m -Xmx350m  .  200M  OOM  .. windows  bin \\ tomcat . exe .  ,  catalina . bat  .  :  HKEY_LOCAL_MACHINE \\ SOFTWARE \\ Apache Software Foundation \\ Tomcat Service Manager \\ Tomcat5 \\ Parameters \\ JavaOptions  -Dcatalina . home = C:\\ApacheGroup\\Tomcat 5.0 -Djava . endorsed . dirs = C:\\ApacheGroup\\Tomcat 5.0\\common\\endorsed -Xrs  -Xms300m -Xmx350m  tomcat  ,  -------------------  4 ： ----------------------------- ： windows  tomcat   tomcat  NT Service(NT/2000/XP only)  bin  tomcat . exe   tomcat  （ CMD ）  tomcat  bin   tomcat -uninstall Apache Tomcat 4.1 ，。  set SERVICENAME = Apache Tomcat 4 . 1 set CATALINA_HOME = E : \\ Tomcat 4 . 1 . 24 set CLASSPATH = D : \\ j2sdk1 . 4 . 1_01 \\ lib set JAVACLASSPATH =% CLASSPATH % set JAVACLASSPATH =% JAVACLASSPATH %; � TALINA_HOME % \\ bin \\ bootstrap . jar set JAVACLASSPATH =% JAVACLASSPATH %; � TALINA_HOME % \\ common \\ lib \\ servlet . jar set JAVACLASSPATH =% JAVACLASSPATH %;% JAVA_HOME % \\ lib \\ tools . jar tomcat . exe -install %SERVICENAME% %JAVA_HOME%\\jre\\bin\\server\\jvm.dll -Djava . class . path = %JAVACLASSPATH% -Dcatalina . home = �TALINA_HOME% -Xms512m -Xmx768m -start org . apache . catalina . startup . Bootstrap -params start -stop org . apache . catalina . startup . Bootstrap -params stop -out �TALINA_HOME%\\logs\\stdout.log -err �TALINA_HOME%\\ logs\\stderr.log ， tomcat . exe -install ！。 bat ， “”。 ： 　： PermGen space  Permanent Generation space , ， JVM  Class  Meta  , Class  Loader  PermGen space ， ( Instance )  Heap  , GC ( Garbage Collection )   PermGen space ， CLASS  ,  PermGen space ， web  JSP  pre compile 。 WEB APP  jar ,  jvm  ( 4M )  。 hibernate  spring 。 class ， jvm  gc  PemGen space ， jvm  ( 4M ) ，。 　　： jar  tomcat / shared / lib ， jar 。  -XX ： PermSize -XX ： MaxPermSize 。 　　 -XX ： PermSize  　　 -XX ： PermSize  　　， set JAVA_OPTS = -Xms1024m -Xmx1024m -XX ： PermSize = 128M -XX ： PermSize = 256M 　　： java -Xmx *** M version  -Xmx  -XX ： PermSize   jvm   1 . 5G ， -Xmx1024m -XX ： PermSize = 768M 。 -----------------  1 ： ------------------------- Linux ：  catalina . sh ： JAVA_OPTS = -Xms64m -Xmx256m -XX : PermSize = 128M -XX : MaxNewSize = 256m -XX : MaxPermSize = 256m  “ echo Using CATALINA_BASE: $CATALINA_BASE ”： JAVA_OPTS = -server -XX:PermSize=64M -XX:MaxPermSize=128m Windows： catalina.bat： set JAVA_OPTS=-Xms64m -Xmx256m -XX:PermSize=128M -XX:MaxNewSize=256m -XX:MaxPermSize=256m -----------------2：------------------------ TOMCAT_HOME/bin/catalina.bat（Linuxcatalina.sh），Java “echo Using CATALINA_BASE : $ CATALINA_BASE ”： set JAVA_OPTS=%JAVA_OPTS% -server -XX:PermSize=128M -XX:MaxPermSize=512m “echo Using CATALINA_BASE : $ CATALINA_BASE ”： set JAVA_OPTS=%JAVA_OPTS% -server -XX:PermSize=128M -XX:MaxPermSize=512m catalina.sh： Java JAVA_OPTS= $ JAVA_OPTS -server -XX : PermSize = 128M -XX : MaxPermSize = 512m JAVA_OPTS= $ JAVA_OPTS -server -XX : PermSize = 128M -XX : MaxPermSize = 512m 　　：。 　　，，jvm。 　　JVM（1.5G），。， ，JVM，，。 　　 （blog：http://hi.baidu.com/hexiong/blog/item/16dc9e518fb10c2542a75b3c.html）： 　　322G，2G。1.5GJVM，500M。 500Mdll，400M，：Java， JVMThread，（JVM）， 400，JVM1500M。jdk1.4，256KB，jdk1.5， 1M，，400M400。 　　，，JVM。JVMJNI。 　　： 　　（MaxProcessMemory - JVMMemory - ReservedOsMemory） / （ThreadStackSize） = Number of threads 　　jdk1.5，120M： 　　1.5GB JVM： （2GB-1.5Gb-120MB）/（1MB） = ~380 threads 　　1.0GB JVM： （2GB-1.0Gb-120MB）/（1MB） = ~880 threads 　　2000/XP/2003boot.ini，：/PAE /3G ，3G， 1G。JVM。 　　。 　　：tomcat。 JVM： System.out.println( JVM MAX MEMORY : + Runtime.getRuntime().maxMemory()/1024/1024+ M ); System.out.println( JVM IS USING MEMORY : + Runtime.getRuntime().totalMemory()/1024/1024+ M ); System.out.println( JVM IS FREE MEMORY : + Runtime.getRuntime().freeMemory()/1024/1024+ M ); JVM； 　　maxMemory()java（），，java ，-Xmx，64，maxMemory()64*1024*1024，java 。-Xmx，，java -cp ClassPath -Xmx512m ClassName， 512*1024*0124。 　　totalMemory()java，java 。java-Xms，，java，， ，maxMemory()，totalMemory()。-Xms， -Xms，，。 　　freeMemory()，java-Xms，，java， ，，java100％，， freeMemory()，freeMemory()，java-Xms， -Xms，，，freeMemory()  ---------------------------------------------- JVM 　　Sun HotSpot 1.4.1，：、。Jvm。 ，。jvmclassmethod。， 。 　　。-Xms-Xmx 。 　　128M： 　　java –Xms128m 　　–Xmx256m，-XX:NewRatio。 　　128m，3，1：3，1/432M： java –Xms128m –Xmx128m –XX:NewRatio =3-XX:NewSize-XX:MaxNewsize。 　　64m: java –Xms256m –Xmx256m –Xmn64m 　　4m。，jvm。，jvm。 　　-XX:MaxPerSize。WebLogic Server，。jvm ，，jvm。，-XX:PerSize。 　　32m，64m。 java -Xms512m -Xmx512m -Xmn128m -XX:PermSize=32m -XX:MaxPermSize=64m 　　，HotSpot。。Eden，。 ，Eden，，from，from， to。Fromto。， 。-XX:SurvivorRatio。 　　NewRation，SurvivorRationEden。，64m，Eden32m，16m： java -Xms256m -Xmx256m -Xmn64m -XX:SurvivorRation =2 　　，HotSpot，－－。， 。，Eden。，Eden ，，。，， 。，。 ，-XX:TargetSurvivorRatio（。1M，50500K）。 ，50。sruvivorratio，8090，。 -XX:maxtenuring threshold。 　　eden，MaxTenuring Threshold0。， ，SurvivorRatioEden，： java … -XX:MaxTenuringThreshold=0 –XX:SurvivorRatio＝50000 … ： ，0(Full)，OLD；1，Young， OLDPerm，Java。 URL，： A. JVMJavaEden B. Eden，。 C. JVMEden（1）；Eden， EdenSurvivor/OLD D. SurvivorEdenOLD，OLD，SurvivorOld，Survivor E. OLD，JVMOLD（0） F. ，SurvivorOLDEden，JVMEden， ”out of memory” Java： ms/mx：YOUNG+OLD，msJVMYOUNG+OLD；mxYOUNG+OLD。 ，。 NewSize/MaxNewSize：YOUNG，NewSizeJVMYOUNG；MaxNewSizeYOUNG。 ，。 PermSize/MaxPermSize：Perm，PermSizeJVMPerm；MaxPermSizePerm。 ，。 SurvivorRatio：SurvivorEden ： MEM_ARGS= -Xms512m -Xmx512m -XX : NewSize = 256m -XX : MaxNewSize = 256m -XX : PermSize = 128m -XX : MaxPermSize = 128m -XX : SurvivorRatio = 6 ： YOUNG + OLD : 512M YOUNG : 256M Perm : 128M Eden : YOUNG * 6 /( 6 + 1 + 1 )= 192M Survivor : YOUNG /( 6 + 1 + 1 )= 32M Java  = YOUNG + OLD + Perm = 640M","title":"tomcat"},{"location":"tomcat/#java_3","text":"update - alternatives --config java alternatives --config java --disaplay java","title":"java"},{"location":"trafficserver/","text":"   2    (  ) 1 . （） [ root @ CMN - NC - X - X ~ ]# fdisk - l / dev / sdb Disk / dev / sdb : 146 . 0 GB , 145999527936 bytes 255 heads , 63 sectors / track , 17750 cylinders Units = cylinders of 16065 * 512 = 8225280 bytes Sector size ( logical / physical ) : 512 bytes / 512 bytes I / O size ( minimum / optimal ) : 512 bytes / 512 bytes Disk identifier : 0 x0001610e Device Boot Start End Blocks Id System 2 . cat / etc / udev / rules . d / 60 - raw . rules ###  2   raw1   raw2 raw3 ….. ACTION == ” add ”, KERNEL == ” sdb ”, RUN += ” / bin / raw / dev / raw / raw1 % N ” KERNEL == ” raw1 ″, OWNER = ” ats ”, GROUP = ” ats ”, MODE = ” 640 ″ #  sdb   / dev / raw / raw1  3 . start_udev  ll / dev / raw / raw1 4 . traffic server storage . config    / dev / raw / raw1 5 . traffic_line - x 6 . echo “ show : cache - stats ” | traffic_shell   Bytes Used — 0 GB Cache Size — 135 GB  ( ATS  FAQ   )   (   )  for i in { d .. l } ; do fdisk / dev / sd $ i EOF d w EOF done  (  ATS  ats  )   for i in { c .. l } ;do chmod a+rw /dev/sd$i;done     storage . config     ATS  2      CDN     ()   (FTP) ATS()  (8085) traffic_line -x     logs_xml.config   ()  LogObject Format = “access” / # ( ) Filename = “shencan” / #(shencan.log) ATS  CollationHosts = “X.X.X.X:8085″ / #IP Filters = “IMG” / # Filters ( IMGFilters) /LogObject         ()     Filters4  psct   clusters ats   ats  1     cache   ats   ats   3 . 2 . 4  206 range   （  web ）  3 . 3 . 4   range 206    1  。  squid  2  （ ）   ats   squid   ats   ats    ats   ats   ats      haproxy （ hash   cache ）   （ ats   ） http : // trafficserver . apache . org / docs / trunk / admin / cluster - howto / index . en . html     15   ats   ats cache   haproxy  hash  dns   ats cache    cache   ats   ats cache   cache  （ ats   object ）  （ 3  ats  A B C 3 ）  object  A  A （ A B C ） object   A    cache object    object  B （ A B C ）  B  A （ A   object ）  （ A B C  ）     ats  2  1 . Management - Only Clustering 2 . Full Clustering   cache    （）  （ 2  ） 2   1 （）  2   traffic_line - s proxy . config . proxy_name - v CPIS - OPT （ ） traffic_line - s proxy . local . cluster . type - v 1 （ 1  full cluersing  2 .  management - only  3 .  ） traffic_line - s proxy . config . cluster . ethernet_interface - v bond0  traffic_line - x reload  / etc / init . d / trafficserver restart  OK 2    10 s  traffic_line - r proxy . process . cluster . nodes  OK   ats   ##  $ traffic_line - s proxy . config . cluster . threads - v 10 $ traffic_line - s proxy . config . cluster . num_of_cluster_connections - v 10 #  3 . 3 . 4 - dev    qq  MISS   HIT  OK   qq   HIT  HIT CPIS - OPT    T （ down   ats  T ） traffic_line - s proxy . local . cluster . type - v 3  3     Blog 1 .（）  http : // mirrors . aliyun . com / apache / trafficserver / yum install gcc gcc - devel gcc - c ++ openssl openssl - devel tcl tcl - devel libxml2 libxml2 - devel pcre pcre - devel tar - jxf trafficserver - 6 . 1 . 1 . tar . bz2 cd trafficserver - 6 . 1 . 1 （ http_load jtest ， push . pl ）  useradd - s / sbin / nologin trafficserver . / configure – prefix =/ usr / local / trafficserver – with - user = trafficeserver – with - group = trafficeserver make - j 8 make - j 8 install  echo “ export PATH = $ PATH : / usr / local / trafficserver / bin ” / etc / profile 2 . records . config (  ) ， （ ） CONFIG proxy . config . cache . ram_cache . size INT 26843545600 （） CONFIG proxy . config . http . server_port INT 80 （  8080 ） CONFIG proxy . config . http . insert_request_via_str INT 1 （ via ） CONFIG proxy . config . http . insert_response_via_str INT 1 （ via ） CONFIG proxy . config . log . custom_logs_enabled INT 1 （ ） CONFIG proxy . config . dns . resolv_conf STRING / etc / resolv . conf （ dns ） CONFIG proxy . config . http . cache . when_to_revalidate INT 0 （ squid mod_offline ） 3 . remap . config （）  regex_map http : // ( . * ) http : // $1 4 . logs_xml . config  （ var / log / trafficserver / ） LogFormat Name = “ access ” / Format = “ % cqtq % ttms % { X - Forwarded - For } cqh % crc /% pssc % pscl % cqhm % cquuc % cqhv % phr /% pqsi % psc t \\” % { Referer } cqh \\” \\” % { User - Agent } cqh \\” % shn % sscl ” / / LogFormat 5 . storage . config （ cache ）  stotage_ssd . config  ssd    / export / data 100 GB / dev / raw / raw1 # cache ，，  5 ， trafficserver ，，，  CONFIG proxy . config . exec_thread . autoconfig INT 1 CONFIG proxy . config . exec_thread . autoconfig . scale FLOAT 2 . 0 CONFIG proxy . config . exec_thread . limit INT 2 #  CONFIG proxy . config . cluster . ethernet_interface STRING eth0 #  CONFIG proxy . config . http . server_port INT 8080 # ， 80 LOCAL proxy . local . incoming_ip_to_bind STRING 0 . 0 . 0 . 0 #  IP ，， 0 . 0 . 0 . 0 CONFIG proxy . config . http . cache . http INT 1 #  CONFIG proxy . config . cache . ram_cache . size INT 512 M # RAM  CONFIG proxy . config . reverse_proxy . enabled INT 1 #  CONFIG proxy . config . url_remap . remap_required INT 1 # 1 ， 0  +  CONFIG proxy . config . url_remap . pristine_host_hdr INT 0 CONFIG proxy . config . ssl . enabled INT 0 #  SSL CONFIG proxy . config . ssl . server . cert . filename STRING server . pem CONFIG proxy . config . http . server_max_connections INT 2000 #  CONFIG proxy . config . http . keep_alive_no_activity_timeout_out INT 60 #  6 . trafficserver trafficserver start (  ) 7 . trafficserver  traffic_shell  traffic_line   cache  qps echo “ show : proxy - stats ” | traffic_shell    traffic_shell  show    traffic_line - x  cache  [ root @ XMEN - CT - CDN - 55 ~ ]# cat purg . sh # !/ bin / bash URL = $1 host = ` echo $ URL | awk - F ” / ” ‘{ print $3 }’` url = ` echo $ URL | cut - d ” / ” - f4 - ` curl - X PURGE - I - H Host :$ host http : // 127 . 0 . 0 . 1 / $ url  cache  traffic_server - Cclear   ATS  PUSH  (  cache  )  PUSH ： PUSH  TS ， HTTP 。 TS  PUSH ， ， PUSH ， 。 ， PUSH ，， acl  PUSH 。  PUSH ： traffic_line - s proxy . config . http . push_method_enabled - v 1  quick_filter ， PUSH 。 traffic_line - s proxy . config . http . quick_filter . mask - v 130 ： traffic_line - x ，， map ，，  PUSH ，。 TS  tools ， push . pl   TS  push ， telnet ： zym6400 trafficserver # telnet localhost 80 Trying 127 . 0 . 0 . 1 ... Connected to localhost . localdomain . Escape character is ^] . PUSH http : // cdn . zymlinux . net / trafficserver / 2 HTTP / 1 . 0  200 ok   zym6400 trafficserver # telnet localhost 80 Trying 127 . 0 . 0 . 1 ... Connected to localhost . localdomain . Escape character is ^] . GET http : // cdn . zymlinux . net / trafficserver / 2 HTTP / 1 . 0  200 ok    H  40GB-cdn 、 ：Nginx  OSPF ，ECMP ， Nginx ，Nginx 。Nginx  OSPF ，1  vip  Nginx ， Nginx ， ECMP 。Nginx  Url  Cache，。，。Cache  Nginx ， Cache 、SSD、。  ： ： 1.  ：， OSPF ，， VIP ，，，，。 2.  ： Nginx ， Http ， ACL，， Url ，。 OSPF ，。 3.  ：，：  RAM， SSD， Disk。，，， SSD ，。 1 ) ：，。 2 ) SSD ：，，。 3 ) ：，。 、  : 1)  irqbalance , iptables , selinux 2) ， /etc/sysctl.conf  fs . nr_open = 2097152 fs . file - max = 2097152 net . ipv4 . tcp_mem = 3097431 4129911 6194862 net . ipv4 . tcp_rmem = 4096 87380 6291456 net . ipv4 . tcp_wmem = 4096 65536 4194304 net . ipv4 . tcp_max_tw_buckets = 26214400 net . ipv4 . tcp_timestamps = 0 net . ipv4 . tcp_tw_recycle = 0 net . ipv4 . tcp_tw_reuse = 0 net . ipv4 . tcp_syncookies = 0 net . ipv4 . tcp_fin_timeout = 15 net . ipv4 . ip_local_port_range = 1024 65535 net . ipv4 . tcp_max_syn_backlog = 65535 net . core . somaxconn = 65535 net . core . netdev_max_backlog = 200000 vm . swappiness = 0 kernel . panic = 30 cat / etc / security / limits . conf * soft nofile 2097152 * hard nofile 2097152 * soft nproc 65535 * hard nproc 65535 * soft memlock 1048576 * soft memlock 1048576 3) , irq  /etc/init.d/ chmod + x / etc / init . d / irq chkconfig irq on service irq start ATS {#ats} Cache ServerATS （1）  {#} yum install pkgconfig libtool gcc gcc - c ++ make openssl - devel tcl - devel expat - devel pcre - devel libcap - devel flex - devel hwloc - devel lua - devel ncurses - devel curl - devel boost - devel tar xf trafficserver - 4 . 2 . 3 . tar . bz2 cd trafficserver - 4 . 2 . 3 sed - i s/ApacheTrafficServer/iTS/g mgmt / RecordsConfig . cc . / configure --prefix=/usr/local/trafficserver \\ --with-user=nobody \\ --with-group=nobody \\ --with-ncurses \\ --enable-debug \\ --enable-test-tools \\ --enable-interim-cache \\ --enable-experimental-plugins \\ --enable-example-plugins \\ --enable-hwloc make make install ln - s / usr / local / trafficserver / bin /* /usr/local/bin/ mkdir /data/logs -p ; chown nobody:nobody /data/logs -R chown nobody /usr/local/trafficserver/ -R （2）  {#} ， cat / etc / udev / rules . d / 51 - cache - disk . rules SUBSYSTEM == block , KERNEL == sd[a-q] , MODE == 660 OWNER : = nobody GROUP : = nobody  udevadm trigger --subsystem-match=block   ll / dev / sd * （3）  {#} ATS 7，  plugin.config  # healthchecks Plugin / usr / local / trafficserver / libexec / trafficserver / healthchecks . so etc / trafficserver / healthchecks . config  etc/trafficserver  healthchecks.config ,(plugins/experimental/healthchecks/README) / __hc / usr / local / trafficserver / hc / ping . html text / plain 200 404  ping.html mkdir / usr / local / trafficserver / hc ; echo OK / usr / local / trafficserver / hc / ping . html （4） tsar {#tsar} tar ： https://github.com/alibaba/tsar cd tsar cd modules / sed - i s/mgmtapisocket/mgmtapi.socket/g * . c sed - i s/eventapisocket/eventapi.socket/g * . c cd .. make make install ln - s / usr / local / trafficserver / var / trafficserver / mgmtapi . sock / var / run / trafficserver / ln - s / usr / local / trafficserver / var / trafficserver / eventapi . sock / var / run / trafficserver /  {#} ： （1） quagga {#quagga} yum install quagga cat / etc / quagga / zebra . conf hostname cnbzgpngx22cdnp01 password 123456 . itv enable password 123456 . itv cat / etc / quagga / ospfd . conf ! -*- ospf -*- hostname cnbzgpngx22cdnp01 password 123456 . itv log stdout interface bond0 ip ospf network broadcast ip ospf hello - interval 1 # hello  ip ospf dead - interval 4 #  ip ospf priority 0 #  0 DRother interface bond00 interface lo router ospf ospf router - id 10 . 191 . 172 . 131 log - adjacency - changes auto - cost reference - bandwidth 1000 # ， network 10 . 191 . 172 . 128 / 27 area 0 . 0 . 0 . 0 #  nginx  VIP network 10 . 191 . 172 . 130 / 32 area 0 . 0 . 0 . 0 line vty  / etc / init . d / zebra start ; / etc / init . d / ospfd start VIP cat / etc / sysconfig / network - scripts / ifcfg - lo : 0 DEVICE = lo : 0 IPADDR = 10 . 191 . 172 . 130 NETMASK = 255 . 255 . 255 . 255 ifup lo : 0 （2） OSPF {#ospf} router id 1 . 1 . 1 . 1 # ospf 1 maximum load - balancing 6 area 0 . 0 . 0 . 0 network 1 . 1 . 1 . 1 0 . 0 . 0 . 0 network 10 . 191 . 172 . 128 0 . 0 . 0 . 31 nterface Vlan - interface22 ip address 10 . 191 . 172 . 129 255 . 255 . 255 . 224 ospf timer hello 1 # hello  ospf timer dead 4 #  ospf network - type broadcast ospf dr - priority 100 VIP  [ CnXXXCdnHHXXXSw01 ] display ospf routing OSPF Process 1 with Router ID 1 . 1 . 1 . 1 Routing Table Routing for network Destination Cost Type NextHop AdvRouter Area 10 . 191 . 172 . 128 / 27 1 Transit 0 . 0 . 0 . 0 1 . 1 . 1 . 1 0 . 0 . 0 . 0 10 . 191 . 172 . 130 / 32 101 Stub 10 . 191 . 172 . 131 10 . 191 . 172 . 131 0 . 0 . 0 . 0 10 . 191 . 172 . 130 / 32 101 Stub 10 . 191 . 172 . 132 10 . 191 . 172 . 132 0 . 0 . 0 . 0 10 . 191 . 172 . 130 / 32 101 Stub 10 . 191 . 172 . 133 10 . 191 . 172 . 133 0 . 0 . 0 . 0 1 . 1 . 1 . 1 / 32 0 Stub 0 . 0 . 0 . 0 1 . 1 . 1 . 1 0 . 0 . 0 . 0 Total nets : 5 Intra area : 5 Inter area : 0 ASE : 0 NSSA : 0 [ CnXXXCdnHHXXXSw01 ] （3） tengine {#tengine} yum install tengine","title":"trafficserver"},{"location":"trafficserver/#_1","text":"  2    (  ) 1 . （） [ root @ CMN - NC - X - X ~ ]# fdisk - l / dev / sdb Disk / dev / sdb : 146 . 0 GB , 145999527936 bytes 255 heads , 63 sectors / track , 17750 cylinders Units = cylinders of 16065 * 512 = 8225280 bytes Sector size ( logical / physical ) : 512 bytes / 512 bytes I / O size ( minimum / optimal ) : 512 bytes / 512 bytes Disk identifier : 0 x0001610e Device Boot Start End Blocks Id System 2 . cat / etc / udev / rules . d / 60 - raw . rules ###  2   raw1   raw2 raw3 ….. ACTION == ” add ”, KERNEL == ” sdb ”, RUN += ” / bin / raw / dev / raw / raw1 % N ” KERNEL == ” raw1 ″, OWNER = ” ats ”, GROUP = ” ats ”, MODE = ” 640 ″ #  sdb   / dev / raw / raw1  3 . start_udev  ll / dev / raw / raw1 4 . traffic server storage . config    / dev / raw / raw1 5 . traffic_line - x 6 . echo “ show : cache - stats ” | traffic_shell   Bytes Used — 0 GB Cache Size — 135 GB  ( ATS  FAQ   )   (   )  for i in { d .. l } ; do fdisk / dev / sd $ i EOF d w EOF done  (  ATS  ats  )   for i in { c .. l } ;do chmod a+rw /dev/sd$i;done     storage . config     ATS  2    ","title":""},{"location":"trafficserver/#_2","text":"CDN     ()   (FTP) ATS()  (8085) traffic_line -x     logs_xml.config   ()  LogObject Format = “access” / # ( ) Filename = “shencan” / #(shencan.log) ATS  CollationHosts = “X.X.X.X:8085″ / #IP Filters = “IMG” / # Filters ( IMGFilters) /LogObject         ()     Filters4  psct  ","title":""},{"location":"trafficserver/#clusters","text":"ats   ats  1     cache   ats   ats   3 . 2 . 4  206 range   （  web ）  3 . 3 . 4   range 206    1  。  squid  2  （ ）   ats   squid   ats   ats    ats   ats   ats      haproxy （ hash   cache ）   （ ats   ） http : // trafficserver . apache . org / docs / trunk / admin / cluster - howto / index . en . html     15   ats   ats cache   haproxy  hash  dns   ats cache    cache   ats   ats cache   cache  （ ats   object ）  （ 3  ats  A B C 3 ）  object  A  A （ A B C ） object   A    cache object    object  B （ A B C ）  B  A （ A   object ）  （ A B C  ）     ats  2  1 . Management - Only Clustering 2 . Full Clustering   cache    （）  （ 2  ） 2   1 （）  2   traffic_line - s proxy . config . proxy_name - v CPIS - OPT （ ） traffic_line - s proxy . local . cluster . type - v 1 （ 1  full cluersing  2 .  management - only  3 .  ） traffic_line - s proxy . config . cluster . ethernet_interface - v bond0  traffic_line - x reload  / etc / init . d / trafficserver restart  OK 2    10 s  traffic_line - r proxy . process . cluster . nodes  OK   ats   ##  $ traffic_line - s proxy . config . cluster . threads - v 10 $ traffic_line - s proxy . config . cluster . num_of_cluster_connections - v 10 #  3 . 3 . 4 - dev    qq  MISS   HIT  OK   qq   HIT  HIT CPIS - OPT    T （ down   ats  T ） traffic_line - s proxy . local . cluster . type - v 3  3 ","title":"clusters"},{"location":"trafficserver/#_3","text":"  Blog 1 .（）  http : // mirrors . aliyun . com / apache / trafficserver / yum install gcc gcc - devel gcc - c ++ openssl openssl - devel tcl tcl - devel libxml2 libxml2 - devel pcre pcre - devel tar - jxf trafficserver - 6 . 1 . 1 . tar . bz2 cd trafficserver - 6 . 1 . 1 （ http_load jtest ， push . pl ）  useradd - s / sbin / nologin trafficserver . / configure – prefix =/ usr / local / trafficserver – with - user = trafficeserver – with - group = trafficeserver make - j 8 make - j 8 install  echo “ export PATH = $ PATH : / usr / local / trafficserver / bin ” / etc / profile 2 . records . config (  ) ， （ ） CONFIG proxy . config . cache . ram_cache . size INT 26843545600 （） CONFIG proxy . config . http . server_port INT 80 （  8080 ） CONFIG proxy . config . http . insert_request_via_str INT 1 （ via ） CONFIG proxy . config . http . insert_response_via_str INT 1 （ via ） CONFIG proxy . config . log . custom_logs_enabled INT 1 （ ） CONFIG proxy . config . dns . resolv_conf STRING / etc / resolv . conf （ dns ） CONFIG proxy . config . http . cache . when_to_revalidate INT 0 （ squid mod_offline ） 3 . remap . config （）  regex_map http : // ( . * ) http : // $1 4 . logs_xml . config  （ var / log / trafficserver / ） LogFormat Name = “ access ” / Format = “ % cqtq % ttms % { X - Forwarded - For } cqh % crc /% pssc % pscl % cqhm % cquuc % cqhv % phr /% pqsi % psc t \\” % { Referer } cqh \\” \\” % { User - Agent } cqh \\” % shn % sscl ” / / LogFormat 5 . storage . config （ cache ）  stotage_ssd . config  ssd    / export / data 100 GB / dev / raw / raw1 # cache ，，  5 ， trafficserver ，，，  CONFIG proxy . config . exec_thread . autoconfig INT 1 CONFIG proxy . config . exec_thread . autoconfig . scale FLOAT 2 . 0 CONFIG proxy . config . exec_thread . limit INT 2 #  CONFIG proxy . config . cluster . ethernet_interface STRING eth0 #  CONFIG proxy . config . http . server_port INT 8080 # ， 80 LOCAL proxy . local . incoming_ip_to_bind STRING 0 . 0 . 0 . 0 #  IP ，， 0 . 0 . 0 . 0 CONFIG proxy . config . http . cache . http INT 1 #  CONFIG proxy . config . cache . ram_cache . size INT 512 M # RAM  CONFIG proxy . config . reverse_proxy . enabled INT 1 #  CONFIG proxy . config . url_remap . remap_required INT 1 # 1 ， 0  +  CONFIG proxy . config . url_remap . pristine_host_hdr INT 0 CONFIG proxy . config . ssl . enabled INT 0 #  SSL CONFIG proxy . config . ssl . server . cert . filename STRING server . pem CONFIG proxy . config . http . server_max_connections INT 2000 #  CONFIG proxy . config . http . keep_alive_no_activity_timeout_out INT 60 #  6 . trafficserver trafficserver start (  ) 7 . trafficserver  traffic_shell  traffic_line   cache  qps echo “ show : proxy - stats ” | traffic_shell    traffic_shell  show    traffic_line - x  cache  [ root @ XMEN - CT - CDN - 55 ~ ]# cat purg . sh # !/ bin / bash URL = $1 host = ` echo $ URL | awk - F ” / ” ‘{ print $3 }’` url = ` echo $ URL | cut - d ” / ” - f4 - ` curl - X PURGE - I - H Host :$ host http : // 127 . 0 . 0 . 1 / $ url  cache  traffic_server - Cclear   ATS  PUSH  (  cache  )  PUSH ： PUSH  TS ， HTTP 。 TS  PUSH ， ， PUSH ， 。 ， PUSH ，， acl  PUSH 。  PUSH ： traffic_line - s proxy . config . http . push_method_enabled - v 1  quick_filter ， PUSH 。 traffic_line - s proxy . config . http . quick_filter . mask - v 130 ： traffic_line - x ，， map ，，  PUSH ，。 TS  tools ， push . pl   TS  push ， telnet ： zym6400 trafficserver # telnet localhost 80 Trying 127 . 0 . 0 . 1 ... Connected to localhost . localdomain . Escape character is ^] . PUSH http : // cdn . zymlinux . net / trafficserver / 2 HTTP / 1 . 0  200 ok   zym6400 trafficserver # telnet localhost 80 Trying 127 . 0 . 0 . 1 ... Connected to localhost . localdomain . Escape character is ^] . GET http : // cdn . zymlinux . net / trafficserver / 2 HTTP / 1 . 0  200 ok    H ","title":""},{"location":"trafficserver/#40gb-cdn","text":"、 ：Nginx  OSPF ，ECMP ， Nginx ，Nginx 。Nginx  OSPF ，1  vip  Nginx ， Nginx ， ECMP 。Nginx  Url  Cache，。，。Cache  Nginx ， Cache 、SSD、。  ： ： 1.  ：， OSPF ，， VIP ，，，，。 2.  ： Nginx ， Http ， ACL，， Url ，。 OSPF ，。 3.  ：，：  RAM， SSD， Disk。，，， SSD ，。 1 ) ：，。 2 ) SSD ：，，。 3 ) ：，。 、  : 1)  irqbalance , iptables , selinux 2) ， /etc/sysctl.conf  fs . nr_open = 2097152 fs . file - max = 2097152 net . ipv4 . tcp_mem = 3097431 4129911 6194862 net . ipv4 . tcp_rmem = 4096 87380 6291456 net . ipv4 . tcp_wmem = 4096 65536 4194304 net . ipv4 . tcp_max_tw_buckets = 26214400 net . ipv4 . tcp_timestamps = 0 net . ipv4 . tcp_tw_recycle = 0 net . ipv4 . tcp_tw_reuse = 0 net . ipv4 . tcp_syncookies = 0 net . ipv4 . tcp_fin_timeout = 15 net . ipv4 . ip_local_port_range = 1024 65535 net . ipv4 . tcp_max_syn_backlog = 65535 net . core . somaxconn = 65535 net . core . netdev_max_backlog = 200000 vm . swappiness = 0 kernel . panic = 30 cat / etc / security / limits . conf * soft nofile 2097152 * hard nofile 2097152 * soft nproc 65535 * hard nproc 65535 * soft memlock 1048576 * soft memlock 1048576 3) , irq  /etc/init.d/ chmod + x / etc / init . d / irq chkconfig irq on service irq start ATS {#ats} Cache ServerATS （1）  {#} yum install pkgconfig libtool gcc gcc - c ++ make openssl - devel tcl - devel expat - devel pcre - devel libcap - devel flex - devel hwloc - devel lua - devel ncurses - devel curl - devel boost - devel tar xf trafficserver - 4 . 2 . 3 . tar . bz2 cd trafficserver - 4 . 2 . 3 sed - i s/ApacheTrafficServer/iTS/g mgmt / RecordsConfig . cc . / configure --prefix=/usr/local/trafficserver \\ --with-user=nobody \\ --with-group=nobody \\ --with-ncurses \\ --enable-debug \\ --enable-test-tools \\ --enable-interim-cache \\ --enable-experimental-plugins \\ --enable-example-plugins \\ --enable-hwloc make make install ln - s / usr / local / trafficserver / bin /* /usr/local/bin/ mkdir /data/logs -p ; chown nobody:nobody /data/logs -R chown nobody /usr/local/trafficserver/ -R （2）  {#} ， cat / etc / udev / rules . d / 51 - cache - disk . rules SUBSYSTEM == block , KERNEL == sd[a-q] , MODE == 660 OWNER : = nobody GROUP : = nobody  udevadm trigger --subsystem-match=block   ll / dev / sd * （3）  {#} ATS 7，  plugin.config  # healthchecks Plugin / usr / local / trafficserver / libexec / trafficserver / healthchecks . so etc / trafficserver / healthchecks . config  etc/trafficserver  healthchecks.config ,(plugins/experimental/healthchecks/README) / __hc / usr / local / trafficserver / hc / ping . html text / plain 200 404  ping.html mkdir / usr / local / trafficserver / hc ; echo OK / usr / local / trafficserver / hc / ping . html （4） tsar {#tsar} tar ： https://github.com/alibaba/tsar cd tsar cd modules / sed - i s/mgmtapisocket/mgmtapi.socket/g * . c sed - i s/eventapisocket/eventapi.socket/g * . c cd .. make make install ln - s / usr / local / trafficserver / var / trafficserver / mgmtapi . sock / var / run / trafficserver / ln - s / usr / local / trafficserver / var / trafficserver / eventapi . sock / var / run / trafficserver /  {#} ： （1） quagga {#quagga} yum install quagga cat / etc / quagga / zebra . conf hostname cnbzgpngx22cdnp01 password 123456 . itv enable password 123456 . itv cat / etc / quagga / ospfd . conf ! -*- ospf -*- hostname cnbzgpngx22cdnp01 password 123456 . itv log stdout interface bond0 ip ospf network broadcast ip ospf hello - interval 1 # hello  ip ospf dead - interval 4 #  ip ospf priority 0 #  0 DRother interface bond00 interface lo router ospf ospf router - id 10 . 191 . 172 . 131 log - adjacency - changes auto - cost reference - bandwidth 1000 # ， network 10 . 191 . 172 . 128 / 27 area 0 . 0 . 0 . 0 #  nginx  VIP network 10 . 191 . 172 . 130 / 32 area 0 . 0 . 0 . 0 line vty  / etc / init . d / zebra start ; / etc / init . d / ospfd start VIP cat / etc / sysconfig / network - scripts / ifcfg - lo : 0 DEVICE = lo : 0 IPADDR = 10 . 191 . 172 . 130 NETMASK = 255 . 255 . 255 . 255 ifup lo : 0 （2） OSPF {#ospf} router id 1 . 1 . 1 . 1 # ospf 1 maximum load - balancing 6 area 0 . 0 . 0 . 0 network 1 . 1 . 1 . 1 0 . 0 . 0 . 0 network 10 . 191 . 172 . 128 0 . 0 . 0 . 31 nterface Vlan - interface22 ip address 10 . 191 . 172 . 129 255 . 255 . 255 . 224 ospf timer hello 1 # hello  ospf timer dead 4 #  ospf network - type broadcast ospf dr - priority 100 VIP  [ CnXXXCdnHHXXXSw01 ] display ospf routing OSPF Process 1 with Router ID 1 . 1 . 1 . 1 Routing Table Routing for network Destination Cost Type NextHop AdvRouter Area 10 . 191 . 172 . 128 / 27 1 Transit 0 . 0 . 0 . 0 1 . 1 . 1 . 1 0 . 0 . 0 . 0 10 . 191 . 172 . 130 / 32 101 Stub 10 . 191 . 172 . 131 10 . 191 . 172 . 131 0 . 0 . 0 . 0 10 . 191 . 172 . 130 / 32 101 Stub 10 . 191 . 172 . 132 10 . 191 . 172 . 132 0 . 0 . 0 . 0 10 . 191 . 172 . 130 / 32 101 Stub 10 . 191 . 172 . 133 10 . 191 . 172 . 133 0 . 0 . 0 . 0 1 . 1 . 1 . 1 / 32 0 Stub 0 . 0 . 0 . 0 1 . 1 . 1 . 1 0 . 0 . 0 . 0 Total nets : 5 Intra area : 5 Inter area : 0 ASE : 0 NSSA : 0 [ CnXXXCdnHHXXXSw01 ] （3） tengine {#tengine} yum install tengine","title":"40GB-cdn"},{"location":"varnish/","text":"varnish 、Varnish 1 、varnish varnish：ManagementChild ( Cache ) 。 Management 、VCL、varnish、varnish。 Management Child，Child，ManagementChild。 Child ，： Acceptor ：； Worker ：childworker，，worker； Expiry ：； Varnish “  ( workspace ) ”。varnish， session。 2 、varnish ，Child ( shared memory log ) ，， ，，，。，worker 。 90M，，，。varnishvarnishlog、 varnishncsavarnishstat。 3 、 VCL Varnish Configuration Language ( VCL ) varnish，“” ( domain specific ) ， 、、set、if， 。VCL . vcl，varnish。， vcl_recv、 vcl_fetch， (  ) ，，varnish 。 VCL ，managementC，gccC。，management varnish，child。child，VCL。，varnish ，，。varnish， ，varnishadmvcl . discard。 4 、varnish varnish，varnishd - s。 ： ( 1 ) file：，mmap ()  (  ) ； ( 2 ) malloc：malloc () varnish； ( 3 ) persistent ( experimental ) ：file， ( varnish ) ；； varnish，，，filevarnish 。persistent，persistent， ，，。 ，，malloc，，file 。，，varnishd - s，， 1K，，100，1G。， ，varnish。 varnishd， - s： malloc [, size ]  file [, path [, size [, granularity ]]]  persistent , path , size { experimental } filegranularity，，。 、varnish 、 HTTPvarnish 1 、HTTP HTTP ，： ( 1 ) Expires ：web/，GMT；，； JavaScripts； ( 2 ) Cache - Control ：，，public、private、 no - cache ( ， ) 、no - store、max - age、s - maxagemust - revalidate； Cache - ControlExpires ； ( 3 ) Etag ：，web； ( 4 ) Last - Mofified ：，Last - Modified - SinceIf - None - Match ，web ； ( 5 ) If - Modified - Since ：，web，，， 304 ( not modified ) ； ( 6 ) If - None - Match ：；webwebEtag， (  ) ； If - None - Match ； ，304，，； ( 7 ) Vary ：，，Vary: Accept - Encoding ， Accept - Encoding - header； ( 8 ) Age ：，；； max - age，“max - ageAge”； 、 Varnish ( state engine ) VCL ，varnishmanagement、C、child。 varnish ( state ) ，VCL，VCL“” ，“”。 1 、 VCL VCL，，，return ( x ) varnish。 varnish，HTTP，、HTT。 ，varnish。VCL，，vcl_recv 。vcl_recv，varnishvcl_recv。，vcl_recv， vcl_recv ( terminating ) ，vcl_recv。，varnishvarnish vcl_recvvcl_recv。 2 、 VCL VCLCPerl ，，CPerl，。 ： ( 1 ) //、# /* comment */  ( 2 ) sub $ name  ( 3 ) ， ( 4 ) ， ( 5 )  ( 6 ) ：= (  ) 、== (  ) 、~ (  ) 、 !(  ) 、 (  ) 、 ||(  ) VCL ，，，VCLHTTP。 VCL returnVCLVarnish，，VCL。， “”，，Varnish，。 3 、 VCL VCL ，bans，VCLVarnish。 regsub ( str , regex , sub ) regsuball ( str , regex , sub ) ：；regsuball () str regexsub，regsub () ； ban ( expression ) ： ban_url ( regex ) ：BansURLregex； purge：，HTTPPURGE； hash_data ( str ) ： return () ：VCLVarnish，Varnish；：lookup、pass、 pipe、hit_for_pass、fetch、deliverhash；，； return ( restart ) ：VCL，vcl_recv；req . restarts，max_restarts 。 4 、vcl_recv vcl_recvVarnish，： ( 1 ) ；URLwww . ； ( 2 ) ；URL、 POST； ( 3 ) webURL； ( 4 ) Web； ，return () Varnish： pass：，； pipe：，“”，；， keep - alive，； lookup：，，； error：Varnish，、web； vcl_recv，。， 。 Varnishvcl_recv ，： ( 1 ) HTTP，GETHEAD； ( 2 ) ； ，vcl_recvreturn () ，vcl_recv，。 ： sub vcl_recv { if ( req . http . User - Agent ~ iPad || req . http . User - Agent ~ iPhone || req . http . User - Agent ~ Android ) { set req . http . X - Device = mobile ; } else { set req . http . X - Device = desktop ; } } VCLX - Device ，mobiledesktop，web，。 5 、vcl_fetch ，vcl_recv，vcl_fetch。VCL passvcl_fetch。vcl_fetch，beresp . ttl 。 return () arnish： ( 1 ) deliver：， ( vcl_deliver ) ； ( 2 ) hit_for_pass：，vcl_pass； ( 3 ) restart：VCL，；max_restarts； ( 4 ) error code [ reason ] ：； vcl_fetchSet - Cookie 。 、 1 、  ( TTL ) ，， 。，，，Varnish ：HTTP  ( HTTP purging ) 、  ( banning )  ( forced cache misses ) 。 ，Varnish 2 purge () Varnish 3 ban () ，Varnish 3 purge， ，vcl_hitvcl_missVarnish 2 set obj . ttl = 0 s。 ，： ( 1 ) ，？ ( 2 ) ，？ ( 3 ) ？ ( 4 ) ，？ 2 、 purge ( variants ) ，，。 HTTPPURGE purge，，vcl_hitvcl_miss，Vary :- ， 。 ，return ( restart ) 。VCL。 acl purgers { 127.0.0.1 ; 192.168.0.0 / 24 ; } sub vcl_recv { if ( req . request == PURGE ) { if (! client . ip ~ purgers ) { error 405 Method not allowed ; } return ( lookup ); } } sub vcl_hit { if ( req . request == PURGE ) { purge ; error 200 Purged ; } } sub vcl_miss { if ( req . request == PURGE ) { purge ; error 404 Not in cache ; } } sub vcl_pass { if ( req . request == PURGE ) { error 502 PURGE on a passed object ; } } HTTP，URLPURGE，： # curl - I PURGE http : // varniship / path / to / someurl 3 、 vcl_recvreturn ( pass ) ，。purge， ，。req . has_always_miss = ture，Varnish “”，vcl_missvcl_fetch，。 ，，，req . has_always_miss = true， 。 4 、 Banning ban ()  ( filter ) ，， 。 Varnish，banbanban ( ban - list ) ，VCL， 。 banVCL，Varnish ( cache hash ) ， ，ban“ / downloadsURL”，“nginx”。： ban req . http . host == magedu.com req . url ~ \\.gif$ banban(ban-list)，ban。 ban，ban。Varnish， ban。ban，ban， ban，ban。 ban，。，ban， ；，ban。banVarnish banban，，ban。 。 、Varnish Varnish，， 。，Varnish()， 。 .probe，req.backend.healthy，varnishlog Backend_healthvarnishadmdebug.health。 backend web1 { .host = www . magedu . com ; .probe = { .url = /.healthtest . html ; .interval = 1s; .window = 5; .threshold = 2; } } .probe： (1) .url：URL，“/”； (2) .request: ，，.url；： .request = GET /.healthtest . html HTTP / 1.1 Host : www . magedu . com Connection : close ; (3) .window：，8； (4) .threshold：.window，；3； (5) .initial：Varnish，.threshold； (6) .expected_response：，200； (7) .interval：，5； (8) .timeout：，2； ，1www.magedu.com，URLhttp://www.magedu.com/.healthtest.html，5 2(200)。 Varnish，“”(graced copy)，，VCL。 ，VCLreq.backend.healthy，req.grace 。 、Varnish Varnishdirector，() 。director，director“”(director)。director ，VCL，VCLdirector。 backend web1 { .host = backweb1 . magedu . com ; .port = 80 ; } director webservers random { .retries = 5; { .backend = web1; .weight = 2; } { .backend = { .host = backweb2 . magedu . com ; .port = 80 ; } .weight = 3; } } ，web1，webserversdirectors“”(backweb2.magedu.com)。webservers random，。 Varnishdirectorround-robinrandom。，round-robin， ，“”，；random， .weight，director.retires。 Varnish 2.1.0，randomclienthash。clientdirectorclient.identity， client.identity。client.identitycliet.ip，VCL 。，hashdirectorhash，URL， 。，clienthash，。 、varnish 1、 Varnish，，， 。param.show，param.set。， ，，varnish。，-pvarnishd。， ，。 2、 (shared memory log)shm-log，，80M。varnish(round-robin) 。shm-log，I/O，tmpfs，/etc/fstab /var/lib/varnish()。 3、(Trheading model) varnishchild，。： cache-worker：，； cache-main：，cache； ban lurker：，bans； acceptor：，； epoll/kqueue：，2，； expire：，； backend poll：，； varnish，cache-worker，，。， ，2。 4、(Threading parameters) varnish，，workervarnish。： thread_pool_add_delay 2 [milliseconds] thread_pool_add_threshold 2 [requests] thread_pool_fail_delay 200 [milliseconds] thread_pool_max 500 [threads] thread_pool_min 5 [threads] thread_pool_purge_delay 1000 [milliseconds] thread_pool_stack 65536 [bytes] thread_pool_timeout 120 [seconds] thread_pool_workspace 16384 [bytes] thread_pools 2 [pools] thread_stats_rate 10 [requests] thread_pool_maxthread_pool_min，。，， thread_pool_min*thread_poolsworker，thread_pool_max*thread_pools。， ，varnishstatn_wrk_queuedvarnish，， thread_pool_max。varnishworker5000。 ，varnish。， 。2，varnish。 5、 、Varnish 1、varnishadm ：varnishadm [-t timeout] [-S secret_file] [-T address:port] [-n name] [command [...]] varnishd，varnish： -n name —— “name”； -T address:port —— ； ， command ，；，varnishadm command 。 ，。 # varnishadm -S /etc/varnish/secret -T 127.0.0.1:6082 storage.list sub vcl_deliver { if (obj.hits 0) { set resp.http.X-Cache = HIT ; } else { set resp.http.X-Cache = MISS ; } } sub vcl_deliver { if (obj.hits 0) { set resp.http.X-Cache = HIT via + + server.hostname; } else { set resp.http.X-Cache = MISS via + + server.hostname; } } sub vcl_recv { if (req.url ~ ^/test . html$ ) { return(pass); } } sub vcl_fetch { if (req.request == GET req.url ~ \\. ( html | jpg | jpeg ) $ ) { set beresp.ttl = 3600s; } } sub vcl_fetch { if (beresp.http.cache-control !~ s - maxage ) { if (req.url ~ \\. jpg ( \\? | $ ) ) { set beresp.ttl = 30s; unset beresp.http.Set-Cookie; } if (req.url ~ \\. html ( \\? | $ ) ) { set beresp.ttl = 10s; unset beresp.http.Set-Cookie; } } else { if (beresp.ttl 0s) { unset beresp.http.Set-Cookie; } } } sub vcl_error { synthetic html body ! -- Something was wrong ! -- /body /html ; set obj.status = 200; return (deliver); } Cache-Control = Cache - Control : 1#cache-directive cache-directive = cache-request-directive | cache-response-directive cache-request-directive = no - cache | no - store (backup) | max - age = delta-seconds | max - stale [ = delta-seconds ] | min - fresh = delta-seconds | no - transform | only - if - cached | cache-extension cache-response-directive = public | private [ = 1 #field - name ] | no - cache [ = 1 #field - name ] | no - store | no - transform | must - revalidate | proxy - revalidate | max - age = delta-seconds | s - maxage = delta - seconds | cache - extension sub vcl_deliver { set resp . http . X - Age = resp . http . Age ; unset resp . http . Age ; if ( obj . hits 0 ) { set resp . http . X - Cache = “ HIT ” ; } else { set resp . http . X - Cache = “ MISS ” ; } } acl purgers { “ 127.0.0.1 ” ; “ 192.168.0.0 ”/ 24 ; } sub vcl_recv { if ( req . request == “ PURGE ” ) { if (! client . ip ~ purgers ) { error 405 “ Method not allowed” ; } return ( lookup ); } } sub vcl_hit { if ( req . request == “ PURGE ” ) { purge ; error 200 “ Purged ” ; } } sub vcl_miss { if ( req . request == “ PURGE ” ) { purge ; error 404 “ Not in cache” ; } } sub vcl_pass { if ( req . request == “ PURGE ” ) { error 502 “ PURGE on a passed object” ; } } sed / pattern / string / g curl - H PURGE URL regsub ( str , regex , sub ) regsub ( $ req . url , www\\.maged\\.com , www . mageedu . com ) purge : ； ban () URL rewrite VCL - functions regsub ( str , regex , sub ) regsuball ( str , regex , sub ) ban_url ( regex ) ban ( expression ) purge ; return ( restart ) return () hash_data ()  vcl_recv { } cookie # Drop any cookies sent to Wordpress . sub vcl_recv { if (!( req . url ~ wp-(login|admin) )) { unset req . http . cookie ; } } # Drop any cookies Wordpress tries to send back to the client . sub vcl_fetch { if (!( req . url ~ wp-(login|admin) )) { unset beresp . http . set - cookie ; } }","title":"varnish"},{"location":"varnish/#varnish","text":"、Varnish 1 、varnish varnish：ManagementChild ( Cache ) 。 Management 、VCL、varnish、varnish。 Management Child，Child，ManagementChild。 Child ，： Acceptor ：； Worker ：childworker，，worker； Expiry ：； Varnish “  ( workspace ) ”。varnish， session。 2 、varnish ，Child ( shared memory log ) ，， ，，，。，worker 。 90M，，，。varnishvarnishlog、 varnishncsavarnishstat。 3 、 VCL Varnish Configuration Language ( VCL ) varnish，“” ( domain specific ) ， 、、set、if， 。VCL . vcl，varnish。， vcl_recv、 vcl_fetch， (  ) ，，varnish 。 VCL ，managementC，gccC。，management varnish，child。child，VCL。，varnish ，，。varnish， ，varnishadmvcl . discard。 4 、varnish varnish，varnishd - s。 ： ( 1 ) file：，mmap ()  (  ) ； ( 2 ) malloc：malloc () varnish； ( 3 ) persistent ( experimental ) ：file， ( varnish ) ；； varnish，，，filevarnish 。persistent，persistent， ，，。 ，，malloc，，file 。，，varnishd - s，， 1K，，100，1G。， ，varnish。 varnishd， - s： malloc [, size ]  file [, path [, size [, granularity ]]]  persistent , path , size { experimental } filegranularity，，。 、varnish 、 HTTPvarnish 1 、HTTP HTTP ，： ( 1 ) Expires ：web/，GMT；，； JavaScripts； ( 2 ) Cache - Control ：，，public、private、 no - cache ( ， ) 、no - store、max - age、s - maxagemust - revalidate； Cache - ControlExpires ； ( 3 ) Etag ：，web； ( 4 ) Last - Mofified ：，Last - Modified - SinceIf - None - Match ，web ； ( 5 ) If - Modified - Since ：，web，，， 304 ( not modified ) ； ( 6 ) If - None - Match ：；webwebEtag， (  ) ； If - None - Match ； ，304，，； ( 7 ) Vary ：，，Vary: Accept - Encoding ， Accept - Encoding - header； ( 8 ) Age ：，；； max - age，“max - ageAge”； 、 Varnish ( state engine ) VCL ，varnishmanagement、C、child。 varnish ( state ) ，VCL，VCL“” ，“”。 1 、 VCL VCL，，，return ( x ) varnish。 varnish，HTTP，、HTT。 ，varnish。VCL，，vcl_recv 。vcl_recv，varnishvcl_recv。，vcl_recv， vcl_recv ( terminating ) ，vcl_recv。，varnishvarnish vcl_recvvcl_recv。 2 、 VCL VCLCPerl ，，CPerl，。 ： ( 1 ) //、# /* comment */  ( 2 ) sub $ name  ( 3 ) ， ( 4 ) ， ( 5 )  ( 6 ) ：= (  ) 、== (  ) 、~ (  ) 、 !(  ) 、 (  ) 、 ||(  ) VCL ，，，VCLHTTP。 VCL returnVCLVarnish，，VCL。， “”，，Varnish，。 3 、 VCL VCL ，bans，VCLVarnish。 regsub ( str , regex , sub ) regsuball ( str , regex , sub ) ：；regsuball () str regexsub，regsub () ； ban ( expression ) ： ban_url ( regex ) ：BansURLregex； purge：，HTTPPURGE； hash_data ( str ) ： return () ：VCLVarnish，Varnish；：lookup、pass、 pipe、hit_for_pass、fetch、deliverhash；，； return ( restart ) ：VCL，vcl_recv；req . restarts，max_restarts 。 4 、vcl_recv vcl_recvVarnish，： ( 1 ) ；URLwww . ； ( 2 ) ；URL、 POST； ( 3 ) webURL； ( 4 ) Web； ，return () Varnish： pass：，； pipe：，“”，；， keep - alive，； lookup：，，； error：Varnish，、web； vcl_recv，。， 。 Varnishvcl_recv ，： ( 1 ) HTTP，GETHEAD； ( 2 ) ； ，vcl_recvreturn () ，vcl_recv，。 ： sub vcl_recv { if ( req . http . User - Agent ~ iPad || req . http . User - Agent ~ iPhone || req . http . User - Agent ~ Android ) { set req . http . X - Device = mobile ; } else { set req . http . X - Device = desktop ; } } VCLX - Device ，mobiledesktop，web，。 5 、vcl_fetch ，vcl_recv，vcl_fetch。VCL passvcl_fetch。vcl_fetch，beresp . ttl 。 return () arnish： ( 1 ) deliver：， ( vcl_deliver ) ； ( 2 ) hit_for_pass：，vcl_pass； ( 3 ) restart：VCL，；max_restarts； ( 4 ) error code [ reason ] ：； vcl_fetchSet - Cookie 。 、 1 、  ( TTL ) ，， 。，，，Varnish ：HTTP  ( HTTP purging ) 、  ( banning )  ( forced cache misses ) 。 ，Varnish 2 purge () Varnish 3 ban () ，Varnish 3 purge， ，vcl_hitvcl_missVarnish 2 set obj . ttl = 0 s。 ，： ( 1 ) ，？ ( 2 ) ，？ ( 3 ) ？ ( 4 ) ，？ 2 、 purge ( variants ) ，，。 HTTPPURGE purge，，vcl_hitvcl_miss，Vary :- ， 。 ，return ( restart ) 。VCL。 acl purgers { 127.0.0.1 ; 192.168.0.0 / 24 ; } sub vcl_recv { if ( req . request == PURGE ) { if (! client . ip ~ purgers ) { error 405 Method not allowed ; } return ( lookup ); } } sub vcl_hit { if ( req . request == PURGE ) { purge ; error 200 Purged ; } } sub vcl_miss { if ( req . request == PURGE ) { purge ; error 404 Not in cache ; } } sub vcl_pass { if ( req . request == PURGE ) { error 502 PURGE on a passed object ; } } HTTP，URLPURGE，： # curl - I PURGE http : // varniship / path / to / someurl 3 、 vcl_recvreturn ( pass ) ，。purge， ，。req . has_always_miss = ture，Varnish “”，vcl_missvcl_fetch，。 ，，，req . has_always_miss = true， 。 4 、 Banning ban ()  ( filter ) ，， 。 Varnish，banbanban ( ban - list ) ，VCL， 。 banVCL，Varnish ( cache hash ) ， ，ban“ / downloadsURL”，“nginx”。： ban req . http . host == magedu.com req . url ~ \\.gif$ banban(ban-list)，ban。 ban，ban。Varnish， ban。ban，ban， ban，ban。 ban，。，ban， ；，ban。banVarnish banban，，ban。 。 、Varnish Varnish，， 。，Varnish()， 。 .probe，req.backend.healthy，varnishlog Backend_healthvarnishadmdebug.health。 backend web1 { .host = www . magedu . com ; .probe = { .url = /.healthtest . html ; .interval = 1s; .window = 5; .threshold = 2; } } .probe： (1) .url：URL，“/”； (2) .request: ，，.url；： .request = GET /.healthtest . html HTTP / 1.1 Host : www . magedu . com Connection : close ; (3) .window：，8； (4) .threshold：.window，；3； (5) .initial：Varnish，.threshold； (6) .expected_response：，200； (7) .interval：，5； (8) .timeout：，2； ，1www.magedu.com，URLhttp://www.magedu.com/.healthtest.html，5 2(200)。 Varnish，“”(graced copy)，，VCL。 ，VCLreq.backend.healthy，req.grace 。 、Varnish Varnishdirector，() 。director，director“”(director)。director ，VCL，VCLdirector。 backend web1 { .host = backweb1 . magedu . com ; .port = 80 ; } director webservers random { .retries = 5; { .backend = web1; .weight = 2; } { .backend = { .host = backweb2 . magedu . com ; .port = 80 ; } .weight = 3; } } ，web1，webserversdirectors“”(backweb2.magedu.com)。webservers random，。 Varnishdirectorround-robinrandom。，round-robin， ，“”，；random， .weight，director.retires。 Varnish 2.1.0，randomclienthash。clientdirectorclient.identity， client.identity。client.identitycliet.ip，VCL 。，hashdirectorhash，URL， 。，clienthash，。 、varnish 1、 Varnish，，， 。param.show，param.set。， ，，varnish。，-pvarnishd。， ，。 2、 (shared memory log)shm-log，，80M。varnish(round-robin) 。shm-log，I/O，tmpfs，/etc/fstab /var/lib/varnish()。 3、(Trheading model) varnishchild，。： cache-worker：，； cache-main：，cache； ban lurker：，bans； acceptor：，； epoll/kqueue：，2，； expire：，； backend poll：，； varnish，cache-worker，，。， ，2。 4、(Threading parameters) varnish，，workervarnish。： thread_pool_add_delay 2 [milliseconds] thread_pool_add_threshold 2 [requests] thread_pool_fail_delay 200 [milliseconds] thread_pool_max 500 [threads] thread_pool_min 5 [threads] thread_pool_purge_delay 1000 [milliseconds] thread_pool_stack 65536 [bytes] thread_pool_timeout 120 [seconds] thread_pool_workspace 16384 [bytes] thread_pools 2 [pools] thread_stats_rate 10 [requests] thread_pool_maxthread_pool_min，。，， thread_pool_min*thread_poolsworker，thread_pool_max*thread_pools。， ，varnishstatn_wrk_queuedvarnish，， thread_pool_max。varnishworker5000。 ，varnish。， 。2，varnish。 5、 、Varnish 1、varnishadm ：varnishadm [-t timeout] [-S secret_file] [-T address:port] [-n name] [command [...]] varnishd，varnish： -n name —— “name”； -T address:port —— ； ， command ，；，varnishadm command 。 ，。 # varnishadm -S /etc/varnish/secret -T 127.0.0.1:6082 storage.list sub vcl_deliver { if (obj.hits 0) { set resp.http.X-Cache = HIT ; } else { set resp.http.X-Cache = MISS ; } } sub vcl_deliver { if (obj.hits 0) { set resp.http.X-Cache = HIT via + + server.hostname; } else { set resp.http.X-Cache = MISS via + + server.hostname; } } sub vcl_recv { if (req.url ~ ^/test . html$ ) { return(pass); } } sub vcl_fetch { if (req.request == GET req.url ~ \\. ( html | jpg | jpeg ) $ ) { set beresp.ttl = 3600s; } } sub vcl_fetch { if (beresp.http.cache-control !~ s - maxage ) { if (req.url ~ \\. jpg ( \\? | $ ) ) { set beresp.ttl = 30s; unset beresp.http.Set-Cookie; } if (req.url ~ \\. html ( \\? | $ ) ) { set beresp.ttl = 10s; unset beresp.http.Set-Cookie; } } else { if (beresp.ttl 0s) { unset beresp.http.Set-Cookie; } } } sub vcl_error { synthetic html body ! -- Something was wrong ! -- /body /html ; set obj.status = 200; return (deliver); } Cache-Control = Cache - Control : 1#cache-directive cache-directive = cache-request-directive | cache-response-directive cache-request-directive = no - cache | no - store (backup) | max - age = delta-seconds | max - stale [ = delta-seconds ] | min - fresh = delta-seconds | no - transform | only - if - cached | cache-extension cache-response-directive = public | private [ = 1 #field - name ] | no - cache [ = 1 #field - name ] | no - store | no - transform | must - revalidate | proxy - revalidate | max - age = delta-seconds | s - maxage = delta - seconds | cache - extension sub vcl_deliver { set resp . http . X - Age = resp . http . Age ; unset resp . http . Age ; if ( obj . hits 0 ) { set resp . http . X - Cache = “ HIT ” ; } else { set resp . http . X - Cache = “ MISS ” ; } } acl purgers { “ 127.0.0.1 ” ; “ 192.168.0.0 ”/ 24 ; } sub vcl_recv { if ( req . request == “ PURGE ” ) { if (! client . ip ~ purgers ) { error 405 “ Method not allowed” ; } return ( lookup ); } } sub vcl_hit { if ( req . request == “ PURGE ” ) { purge ; error 200 “ Purged ” ; } } sub vcl_miss { if ( req . request == “ PURGE ” ) { purge ; error 404 “ Not in cache” ; } } sub vcl_pass { if ( req . request == “ PURGE ” ) { error 502 “ PURGE on a passed object” ; } } sed / pattern / string / g curl - H PURGE URL regsub ( str , regex , sub ) regsub ( $ req . url , www\\.maged\\.com , www . mageedu . com ) purge : ； ban () URL rewrite VCL - functions regsub ( str , regex , sub ) regsuball ( str , regex , sub ) ban_url ( regex ) ban ( expression ) purge ; return ( restart ) return () hash_data ()  vcl_recv { } cookie # Drop any cookies sent to Wordpress . sub vcl_recv { if (!( req . url ~ wp-(login|admin) )) { unset req . http . cookie ; } } # Drop any cookies Wordpress tries to send back to the client . sub vcl_fetch { if (!( req . url ~ wp-(login|admin) )) { unset beresp . http . set - cookie ; } }","title":"varnish"},{"location":"vpn/","text":"openvpn  192.168.1.0 / 24 vpn 10.8.0.0 / 24  192.168.9.0 / 24   route add - net 10.8.0.0 netmask 255.255.255.0 gw vpn192 .168.9.0 / 24 IP yum install openvpn easy - rsa - y cd / usr / share / easy - rsa / 3 vim vars export KEY_COUNTRY = CN export KEY_PROVINCE = SH export KEY_CITY = ShangHai export KEY_ORG = Company export KEY_EMAIL = liangguangyu@dachuizichan.com export KEY_OU = MyOrganization source vars . / easyrsa init - pki # pki . / easyrsa build - ca nopass #  ， Common Name ，  ，  cp pki / ca . crt / etc / openvpn / . / easyrsa gen - dh # Diffle Human ，  cp pki / dh . pem / etc / openvpn / . / easyrsa build - server - full server nopass # server ，  . / easyrsa build - client - full npt02 nopass # client  . / easyrsa build - client - full nix02 nopass . / easyrsa build - client - full nix22 nopass  / etc / openvpn / ccd  cd pki / private / cp * / etc / openvpn /  cd .. / .. / pki / issued cp * / etc / openvpn / cp / usr / share / doc / openvpn - 2.4.5 / sample / sample - config - files / server . conf / etc / openvpn / cat / etc / openvpn / server . conf local ip # IP port 1194 proto tcp dev tun ca / etc / openvpn / ca . crt cert / etc / openvpn / server . crt key / etc / openvpn / server . key dh / etc / openvpn / dh . pem server 10.8.0.0 255.255.255.0 # IP client - config - dir / etc / openvpn / ccd route 192.168.69.0 255.255.255.0 route 192.168.73.0 255.255.255.0 route 192.168.81.0 255.255.255.0 push route 192.168.69.0 255.255.255.0 #  push route 192.168.73.0 255.255.255.0 #  push route 192.168.81.0 255.255.255.0 #  #duplicate - cn client . key client . crt client - to - client keepalive 10 120 comp - lzo max - clients 10 user nobody group nobody persist - key persist - tun status / var / log / openvpn - status . log log / var / log / openvpn . log verb 3 #  cat / etc / openvpn / ccd / npt02 # iroute 192.168.69.0 255.255.255.0 cat / etc / openvpn / ccd / nix02 iroute 192.168.73.0 255.255.255.0 cat / etc / openvpn / ccd / npt22 iroute 192.168.81.0 255.255.255.0 net . ipv4 . ip_forward = 1 / etc / sysctl . conf sysctl - p ip iptables - t nat - A POSTROUTING - s 10.8.0.0 / 24 - o eth0 - j MASQUERADE tun0eth0 （ 192.168.9.0 / 24 ） service iptables save / etc / init . d / openvpn start  ca . crt nix02 . crt nix02 . key  .  nix02 . crt nix02 . key dacui . ovpn  ： client proto tcp dev tun remote ip 11947 persist - key persist - tun comp - lzo ca ca . crt cert nix02 . crt key nix02 . key verb 3 windows C : \\ Program Files \\ OpenVPN \\ config \\   pptpd yum install ppp pptpd / etc / pptpd . conf localip 10 . 0 . 0 . 1 remoteip 10 . 0 . 0 . 100 - 200  IP ， ABC ， IP ， IP ， remoteip ，  10 . 0 . 0 . 100 ， localip 。 / etc / ppp / pptpd - options ms - dns 202 . 96 . 128 . 86 ms - dns 202 . 96 . 128 . 166  DNS  / etc / ppp / chap - secrets ：，，， ip  chap - secret service pptpd start chkconfig pptpd on   / var / log / messages net . ipv4 . ip_forward = 1 sysctl - p pptp  pptp ， 1723 ， 47 ，， GRE  47 ， 47 ， ， 1723 ， ,  iptable ， iptables - A INPUT - p tcp --dport 1723 -j ACCEPT iptables - A INPUT - p 47 - j ACCEPT ，，： iptables - t nat - A PREROUTING - i eth0 - p tcp --dport 1723 -j DNAT --to SERVER_IP iptables - t nat - A PREROUTING - i eth0 - p 47 - j DNAT --to SERVER_IP  iptables - t nat - A POSTROUTING - o eth0 - j MASQUERADE  iptables - t nat - A POSTROUTING - s 10 . 0 . 0 . 0 / 24 - o eth0 - j SNAT --to 115.115.115.115 ， ip ， 10 . 0 . 0 . 0 / 24  VPN ， 115 . 115 . 115 . 115 ， NAT 。 VPN  ，， mss iptables - A FORWARD - p tcp --syn -s 10.0.0.0/24 -j TCPMSS --set-mss 1356 ，。  iptables - A FORWARD - p tcp - s 10 . 0 . 0 . 0 / 24 - d 180 . 97 . 163 . 157 - j ACCEPT  180 . 97 . 163 . 157 iptables - A FORWARD - p tcp - s 10 . 0 . 0 . 0 / 24 - j DROP shadowsocks https://copr.fedorainfracloud.org/coprs/librehat/shadowsocks/ centos6 [librehat-shadowsocks] name = Copr repo for shadowsocks owned by librehat baseurl = https://copr-be.cloud.fedoraproject.org/results/librehat/shadowsocks/epel-6-$basearch/ type = rpm-md skip_if_unavailable = True gpgcheck = 1 gpgkey = https://copr-be.cloud.fedoraproject.org/results/librehat/shadowsocks/pubkey.gpg repo_gpgcheck = 0 enabled = 1 enabled_metadata = 1 centos7 [librehat-shadowsocks] name = Copr repo for shadowsocks owned by librehat baseurl = https://copr-be.cloud.fedoraproject.org/results/librehat/shadowsocks/epel-7-$basearch/ type = rpm-md skip_if_unavailable = True gpgcheck = 1 gpgkey = https://copr-be.cloud.fedoraproject.org/results/librehat/shadowsocks/pubkey.gpg repo_gpgcheck = 0 enabled = 1 enabled_metadata = 1","title":"vpn"},{"location":"vpn/#openvpn","text":" 192.168.1.0 / 24 vpn 10.8.0.0 / 24  192.168.9.0 / 24   route add - net 10.8.0.0 netmask 255.255.255.0 gw vpn192 .168.9.0 / 24 IP yum install openvpn easy - rsa - y cd / usr / share / easy - rsa / 3 vim vars export KEY_COUNTRY = CN export KEY_PROVINCE = SH export KEY_CITY = ShangHai export KEY_ORG = Company export KEY_EMAIL = liangguangyu@dachuizichan.com export KEY_OU = MyOrganization source vars . / easyrsa init - pki # pki . / easyrsa build - ca nopass #  ， Common Name ，  ，  cp pki / ca . crt / etc / openvpn / . / easyrsa gen - dh # Diffle Human ，  cp pki / dh . pem / etc / openvpn / . / easyrsa build - server - full server nopass # server ，  . / easyrsa build - client - full npt02 nopass # client  . / easyrsa build - client - full nix02 nopass . / easyrsa build - client - full nix22 nopass  / etc / openvpn / ccd  cd pki / private / cp * / etc / openvpn /  cd .. / .. / pki / issued cp * / etc / openvpn / cp / usr / share / doc / openvpn - 2.4.5 / sample / sample - config - files / server . conf / etc / openvpn / cat / etc / openvpn / server . conf local ip # IP port 1194 proto tcp dev tun ca / etc / openvpn / ca . crt cert / etc / openvpn / server . crt key / etc / openvpn / server . key dh / etc / openvpn / dh . pem server 10.8.0.0 255.255.255.0 # IP client - config - dir / etc / openvpn / ccd route 192.168.69.0 255.255.255.0 route 192.168.73.0 255.255.255.0 route 192.168.81.0 255.255.255.0 push route 192.168.69.0 255.255.255.0 #  push route 192.168.73.0 255.255.255.0 #  push route 192.168.81.0 255.255.255.0 #  #duplicate - cn client . key client . crt client - to - client keepalive 10 120 comp - lzo max - clients 10 user nobody group nobody persist - key persist - tun status / var / log / openvpn - status . log log / var / log / openvpn . log verb 3 #  cat / etc / openvpn / ccd / npt02 # iroute 192.168.69.0 255.255.255.0 cat / etc / openvpn / ccd / nix02 iroute 192.168.73.0 255.255.255.0 cat / etc / openvpn / ccd / npt22 iroute 192.168.81.0 255.255.255.0 net . ipv4 . ip_forward = 1 / etc / sysctl . conf sysctl - p ip iptables - t nat - A POSTROUTING - s 10.8.0.0 / 24 - o eth0 - j MASQUERADE tun0eth0 （ 192.168.9.0 / 24 ） service iptables save / etc / init . d / openvpn start  ca . crt nix02 . crt nix02 . key  .  nix02 . crt nix02 . key dacui . ovpn  ： client proto tcp dev tun remote ip 11947 persist - key persist - tun comp - lzo ca ca . crt cert nix02 . crt key nix02 . key verb 3 windows C : \\ Program Files \\ OpenVPN \\ config \\  ","title":"openvpn"},{"location":"vpn/#pptpd","text":"yum install ppp pptpd / etc / pptpd . conf localip 10 . 0 . 0 . 1 remoteip 10 . 0 . 0 . 100 - 200  IP ， ABC ， IP ， IP ， remoteip ，  10 . 0 . 0 . 100 ， localip 。 / etc / ppp / pptpd - options ms - dns 202 . 96 . 128 . 86 ms - dns 202 . 96 . 128 . 166  DNS  / etc / ppp / chap - secrets ：，，， ip  chap - secret service pptpd start chkconfig pptpd on   / var / log / messages net . ipv4 . ip_forward = 1 sysctl - p pptp  pptp ， 1723 ， 47 ，， GRE  47 ， 47 ， ， 1723 ， ,  iptable ， iptables - A INPUT - p tcp --dport 1723 -j ACCEPT iptables - A INPUT - p 47 - j ACCEPT ，，： iptables - t nat - A PREROUTING - i eth0 - p tcp --dport 1723 -j DNAT --to SERVER_IP iptables - t nat - A PREROUTING - i eth0 - p 47 - j DNAT --to SERVER_IP  iptables - t nat - A POSTROUTING - o eth0 - j MASQUERADE  iptables - t nat - A POSTROUTING - s 10 . 0 . 0 . 0 / 24 - o eth0 - j SNAT --to 115.115.115.115 ， ip ， 10 . 0 . 0 . 0 / 24  VPN ， 115 . 115 . 115 . 115 ， NAT 。 VPN  ，， mss iptables - A FORWARD - p tcp --syn -s 10.0.0.0/24 -j TCPMSS --set-mss 1356 ，。  iptables - A FORWARD - p tcp - s 10 . 0 . 0 . 0 / 24 - d 180 . 97 . 163 . 157 - j ACCEPT  180 . 97 . 163 . 157 iptables - A FORWARD - p tcp - s 10 . 0 . 0 . 0 / 24 - j DROP","title":"pptpd"},{"location":"vpn/#shadowsocks","text":"https://copr.fedorainfracloud.org/coprs/librehat/shadowsocks/ centos6 [librehat-shadowsocks] name = Copr repo for shadowsocks owned by librehat baseurl = https://copr-be.cloud.fedoraproject.org/results/librehat/shadowsocks/epel-6-$basearch/ type = rpm-md skip_if_unavailable = True gpgcheck = 1 gpgkey = https://copr-be.cloud.fedoraproject.org/results/librehat/shadowsocks/pubkey.gpg repo_gpgcheck = 0 enabled = 1 enabled_metadata = 1 centos7 [librehat-shadowsocks] name = Copr repo for shadowsocks owned by librehat baseurl = https://copr-be.cloud.fedoraproject.org/results/librehat/shadowsocks/epel-7-$basearch/ type = rpm-md skip_if_unavailable = True gpgcheck = 1 gpgkey = https://copr-be.cloud.fedoraproject.org/results/librehat/shadowsocks/pubkey.gpg repo_gpgcheck = 0 enabled = 1 enabled_metadata = 1","title":"shadowsocks"},{"location":"zabbix/","text":"docker zabbixLLD，docker。dockernot supported， zabbix Administration -- General  Regular expressions  linux Discovery list  Network interfaces for discovery /var/lib/docker/devicemapper/mnt/，。 5： Character string included # Any character string included #，（，）,（.）,（/） Character string not included # Result is TRUE #， Result is FALSE #，zabbix Administration -- General  Regular expressions  mysql   zabbix agent  vim / etc / zabbix / . my . cnf [ mysql ] host = localhost user = root password = xxx port = 3326 socket = / var / lib / mysql / mysql3326 . sock [ mysqladmin ] host = localhost user = root password = xxxx port = 3326 socket = / var / lib / mysql / mysql3326 . sock sed - i s@/var/lib/zabbix@/etc/zabbix@g / etc / zabbix / zabbix_agentd . d / userparameter_mysql . conf / etc / init . d / zabbix - agent restart  web  mysql  mysql  vim / etc / zabbix / zabbix_agentd . d / userparameter_mysql . conf UserParameter = mysql . replication , echo show slave status\\G; | HOME =/ etc / zabbix mysql | grep - E Slave_IO_Running|Slave_SQL_Running | awk {print $$2} | grep - c Yes zabbix_get - s 192 . 168 . 100 . 223 - k mysql.replication  2 ，, Slave_IO_Running  Slave_SQL_Running  Yes 。 ---------------------------------------------------------- MySQL ， Zabbix ，。 Zabbix  MySQL  ， Zabbix  MySQL ， percona 。 https : // www . percona . com / doc / percona - monitoring - plugins / 1 . 1 / zabbix / index . html  MySQL 。 1 . percona  # rpm - ivh http : // www . percona . com / downloads / percona - release / redhat / 0 . 1 - 3 / percona - release - 0 . 1 - 3 . noarch . rpm 2 . percona  php 。 php  mysql ， zabbix agent ， php  php - mysql 。 [ root @ linux - node1 ~ ]# yum install zabbix22 - agentphp php - mysql 3 . percona  zabbix  [ root @ linux - node1 ~ ]# yum install - ypercona - zabbix - templates [ root @ linux - node1 ~ ]# rpm - qlpercona - zabbix - templates / var / lib / zabbix / percona / var / lib / zabbix / percona / scripts / var / lib / zabbix / percona / scripts / get_mysql_stats_wrapper . sh / var / lib / zabbix / percona / scripts / ss_get_mysql_stats . php / var / lib / zabbix / percona / templates / var / lib / zabbix / percona / templates / userparameter_percona_mysql . conf / var / lib / zabbix / percona / templates / zabbix_agent_template_percona_mysql_server_ht_2 . 0 . 9 - sver1 . 1 . 6 . xml  shell ， php ， zabbix ， Zabbix  xml 。 ， Zabbix 。 # vim / etc / zabbix_agentd . conf Include =/ etc / zabbix_agentd . conf . d / # mkdir / etc / zabbix_agentd . conf . d / 4 . Zabbix  # cp / var / lib / zabbix / percona / templates / userparameter_percona_mysql . conf / etc / zabbix_agentd . conf . d / 5 . PHP  MySQL  # vim / var / lib / zabbix / percona / scripts / ss_get_mysql_stats . php . cnf ? php $ mysql_user = root ; $ mysql_pass = s3cret ; //mysql。 6 . # / var / lib / zabbix / percona / scripts / get_mysql_stats_wrapper . sh gg 7 . ， MySQL ， get_mysql_stats_wrapper . sh 。 mysql  socket ， 。，， 1 ，。 # / var / lib / zabbix / percona / scripts / get_mysql_stats_wrapper . sh running - slave 1 8 . zabbix   / var / lib / zabbix / percona / templates / zabbix_agent_template_percona_mysql_server_ht_2 . 0 . 9 - sver1 . 1 . 6 . xml  ， zabbix  Configuration - Templates - Import  MySQL ，，！  MySQL   MySQL ， MySQL ，，， ， MySQL 。 mysql grant select , process , replicationclient on * . * to monitor @ 192.168.1.11 identified by monitor@xx ; mysql flush privileges ; process ， SHOWPROCESSLIST  KILL 。， SHOW PROCESSLIST ， 。 replication client  master server 、 slave server 。  MySQL Slave  ， MySQL Master  Slave ， Slave ，，  Slave ，。 ，： stop slave ; reset slave all ; RESET SLAVE ALL 、、。 ， show slave status 。 mongo 1 、 zabbix  key vim / usr / local / zabbix / etc / zabbix_agentd . conf UserParameter = MongoDB . Status [ * ], / bin / echo db.serverStatus().$1 | / usr / local / mongodb / bin / mongo admin | grep \\ $2\\ | awk - F : {print $$2} | awk - F , {print $$1} db . serverStatus () . $1  1 （） MongoDB . Status [ * ], / bin / echo db.serverStatus().$1 | / usr / local / mongodb / bin / mongo admin -- port 10040 - u admin - p f8hIXm3g? | grep \\ $2\\ | sed s/,/ \\n /g | grep \\ $2\\ | awk - F : {print $$2} | awk - F , {print $$1}  db . serverStatus ()   $1  grep $2  \\  \\ ， echo db.serverStatus() |/ usr / local / mongodb / bin / mongo -- port 10040 -- quiet { host : TENCENT64.site , -- server  hostname version : 2.0.5 , -- mongo  process : mongod , --  uptime : 1238418 , -- （： S ） uptimeEstimate : 1230730 , --  MongoDB  localTime : ISODate ( 2012-09-14T09:09:52.657Z ) , -- server  globalLock : { totalTime : 1238418105923 , -- （： ms ） lockTime : 75055831911 , -- （： ms ） ratio : 0 . 06060621332329477 , -- lockTime  totalTime  currentQueue : { total : 0 , --  readers : 0 , --  writers : 0 --  }, activeClients : { total : 1 , --  server  client  readers : 1 , --  client  writers : 0 --  client  } }, mem : { bits : 64 , -- 64  resident : 18363 , -- 。 virtual : 478810 , --  supported : true , --  mapped : 233311 , -- ，。 mappedWithJournal : 466622 , note : virtual minus mapped is large. could indicate a memory leak }, connections : { current : 737 , -- 。 server  available : 82 -- 。 }, extra_info : { note : fields vary by platform , heap_usage_bytes : 3838448 , -- 。 Linux page_faults : 31058356 -- 。 Linux }, indexCounters : { btree : { accesses : 68229146 , -- Btree （） hits : 68229146 , --  Btree 。（） misses : 0 , --  Btree 。（）（） resets : 0 , --  0  missRatio : 0 -- （） } }, backgroundFlushing : { flushes : 20640 , --  total_ms : 2453287 , --  average_ms : 118 . 8608042635659 , --  last_ms : 1 , --  last_finished : ISODate ( 2012-09-14T09:09:35.656Z ) --  }, cursors : { totalOpen : 0 , -- server  client （ cursor ） clientCursors_size : 0 , -- timedOut : 24 -- server （ cursor ） }, network : { bytesIn : NumberLong ( 1929833164782 ) , -- （ bytes ） bytesOut : 553137147925 , -- （ bytes ） numRequests : 2475184328 --  }, opcounters : { insert : 687531883 , -- server  insert  query : 711010343 , -- server  query  update : 0 , -- server  update  delete : 0 , -- server  delete  getmore : 6484 , -- server  getMore  command : 1287537 -- server  }, asserts : { regular : 0 , -- server （ assert ） warning : 1 , -- server  msg : 0 , -- 。 user : 4 , -- 。，：；。 rollovers : 0 -- server ， assert counters have rolled over  }, writeBacksQueued : false , --  mongos  retry  dur : { commits : 30 , --  journal  commit  journaledMB : 0 , --  journal （： MB ） writeToDataFilesMB : 0 , --  journal （： MB ） compression : 0 , -- commitsInWriteLock : 0 , --  commits  earlyCommits : 0 , -- schedule  commit  timeMs : { dt : 3064 , prepLogBuffer : 0 , --  journal  writeToJournal : 0 , --  journal  writeToDataFiles : 0 , -- journal  remapPrivateView : 0 -- The amount of time spent remapping copy - on - write memory mapped views } }, ok : 1 -- serverStatus  } . / zabbix_get - s 127 . 0 . 0 . 1 - k MongoDB . Status [ opcounters , query ]   command ，，，，，， 10  insert 、 query 、 update 、 delete 、 getmore 、 command  ， virtual ， resident  ， bytesIN ， bytesOut ， numRequests  ， available 、 current    mapped ， MB 5 、 locks ，， key ， key [ root @ mongodb bin ]# echo db.serverStatus().locks | mongo admin MongoDB shell version : 2 . 6 . 3 connecting to : admin { . : { timeLockedMicros : { R : NumberLong ( 572504 ) , W : NumberLong ( 480751 ) }, timeAcquiringMicros : { R : NumberLong ( 480946 ) , W : NumberLong ( 70198 ) } }, admin : { timeLockedMicros : { r : NumberLong ( 142364 ) , w : NumberLong ( 0 ) }, timeAcquiringMicros : { r : NumberLong ( 15018 ) , w : NumberLong ( 0 ) } }, local : { timeLockedMicros : { r : NumberLong ( 271651 ) , w : NumberLong ( 271 ) }, timeAcquiringMicros : { r : NumberLong ( 120699 ) , w : NumberLong ( 5 ) } }, test : { timeLockedMicros : { r : NumberLong ( 93725 ) , w : NumberLong ( 114935 ) }, timeAcquiringMicros : { r : NumberLong ( 67411 ) , w : NumberLong ( 41 ) } } } bye  key UserParameter = MongoDB . Status . locks [ * ], / bin / echo db.serverStatus().locks.$1.$2.$3 | / usr / local / mongodb / bin / mongo admin |/ usr / bin / tail - n 2 | / usr / bin / head - n 1 | awk - F ( {print $$2} | awk - F ) {print $$1} ： http : // www . zhengdazhi . com / archives / 662 fping key fping 192 . 168 . 1 . 20 2 / dev / null | grep - c alive  1-1,11。， 1，。1-0，0. 60。，60。 nginx #  # !/ usr / bin / env bash case $2 in net ) count = $ ( sudo grep $ ( date +%Y:%H:%M ) / var / log / nginx / access_ $1 . log | wc - l ) if [ $c ount - eq 0 ] ;then echo 0 else sudo grep $ ( date +%Y:%H:%M ) / var / log / nginx / access_ $1 . log | awk {sum +=$10}END{print sum} fi ;; connect ) sudo grep $ ( date +%Y:%H:%M ) / var / log / nginx / access_ $1 . log | wc - l ;; esac key ： UserParameter = domain_stats [ * ], / etc / zabbix / domain_stats . sh $1 $2  zabbix_get - s 192 . 168 . 1 . 5 - k domain_stats [ data , net ] 1172557 zabbix_get - s 192 . 168 . 1 . 5 - k domain_stats [ data , connect ] 0 redis UserParameter = Redis . Info [ * ], / etc / zabbix / redisinfo . sh $1 $2 # ! / bin / bash REDISCLI = /usr/local/src/redis-cli HOST = 116.213.204.14 PORT = 6379 if [[ $# == 1 ]] ;then case $1 in version ) result = `$ REDISCLI - h $ HOST - p $ PORT info | grep - w redis_version | awk - F : {print $2} ` echo $ result ;; uptime ) result = `$ REDISCLI - h $ HOST - p $ PORT info | grep - w uptime_in_seconds | awk - F : {print $2} ` echo $ result ;; connected_clients ) result = `$ REDISCLI - h $ HOST - p $ PORT info | grep - w connected_clients | awk - F : {print $2} ` echo $ result ;; blocked_clients ) result = `$ REDISCLI - h $ HOST - p $ PORT info | grep - w blocked_clients | awk - F : {print $2} ` echo $ result ;; used_memory ) result = `$ REDISCLI - h $ HOST - p $ PORT info | grep - w used_memory | awk - F : {print $2} ` echo $ result ;; used_memory_rss ) result = `$ REDISCLI - h $ HOST - p $ PORT info | grep - w used_memory_rss | awk - F : {print $2} ` echo $ result ;; used_memory_peak ) result = `$ REDISCLI - h $ HOST - p $ PORT info | grep - w used_memory_peak | awk - F : {print $2} ` echo $ result ;; used_memory_lua ) result = `$ REDISCLI - h $ HOST - p $ PORT info | grep - w used_memory_lua | awk - F : {print $2} ` echo $ result ;; used_cpu_sys ) result = `$ REDISCLI - h $ HOST - p $ PORT info | grep - w used_cpu_sys | awk - F : {print $2} ` echo $ result ;; used_cpu_user ) result = `$ REDISCLI - h $ HOST - p $ PORT info | grep - w used_cpu_user | awk - F : {print $2} ` echo $ result ;; used_cpu_sys_children ) result = `$ REDISCLI - h $ HOST - p $ PORT info | grep - w used_cpu_sys_children | awk - F : {print $2} ` echo $ result ;; used_cpu_user_children ) result = `$ REDISCLI - h $ HOST - p $ PORT info | grep - w used_cpu_user_children | awk - F : {print $2} ` echo $ result ;; rdb_last_bgsave_status ) result = `$ REDISCLI - h $ HOST - p $ PORT info | grep - w rdb_last_bgsave_status | awk - F : {print $2} | grep - c ok ` echo $ result ;; aof_last_bgrewrite_status ) result = `$ REDISCLI - h $ HOST - p $ PORT info | grep - w aof_last_bgrewrite_status | awk - F : {print $2} | grep - c ok ` echo $ result ;; aof_last_write_status ) result = `$ REDISCLI - h $ HOST - p $ PORT info | grep - w aof_last_write_status | awk - F : {print $2} | grep - c ok ` echo $ result ;; * ) echo - e \\033[33mUsage: $0 {connected_clients|blocked_clients|used_memory|used_memory_rss| used_memory_peak | used_memory_lua | used_cpu_sys | used_cpu_user | used_cpu_sys_children | used_cpu_user_children | rdb_last_bgsave_status | aof_last_bgrewrite_status | aof_last_write_status }\\ 033 [ 0 m ;; esac elif [[ $# == 2 ]] ;then case $2 in keys ) result = `$ REDISCLI - h $ HOST - p $ PORT info | grep - w $1 | grep - w keys | awk - F =|, {print $2} ` echo $ result ;; expires ) result = `$ REDISCLI - h $ HOST - p $ PORT info | grep - w $1 | grep - w keys | awk - F =|, {print $4} ` echo $ result ;; avg_ttl ) result = `$ REDISCLI - h $ HOST - p $ PORT info | grep - w $1 | grep - w avg_ttl | awk - F =|, {print $6} ` echo $ result ;; * ) echo - e \\033[33mUsage: $0 {db0 keys|db0 expires|db0 avg_ttl}\\033[0m ;; esac fi zabbix 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 #!/usr/bin/env python # coding=utf-8 import json import urllib import urllib2 from datetime import datetime import cookielib import smtplib from email.mime.multipart import MIMEMultipart from email.mime.text import MIMEText from email.mime.image import MIMEImage def zab_api ( data ): url = http://116.213.207.5:15080/zabbix/api_jsonrpc.php header = { Content-Type : application/json } request = urllib2 . Request ( url , data , header ) result = urllib2 . urlopen ( request ) response = json . loads ( result . read ()) result . close () return response auth_data = json . dumps ({ jsonrpc : 2.0 , method : user.login , params : { user : admin , password : dachui$5zabbix }, id : 2 }) auth = zab_api ( auth_data )[ result ] hostget = json . dumps ({ jsonrpc : 2.0 , method : host.get , params : { output : [ hostid , host ], selectInterfaces : [ interfaceid , ip ] }, id : 2 , auth : auth }) def getgraphid ( hostid ): graph1 = json . dumps ({ jsonrpc : 2.0 , method : graph.get , params : { output : extend , hostids : hostid , sortfield : name }, auth : auth , id : 1 }) for graph in zab_api ( graph1 )[ result ]: print graph [ name ], : , graph [ graphid ] def getcookie (): cookiejar = cookielib . CookieJar () urlOpener = urllib2 . build_opener ( urllib2 . HTTPCookieProcessor ( cookiejar )) values = { name : admin , password : dachui$5zabbix , autologin : 1 , enter : Sign in } data = urllib . urlencode ( values ) request = urllib2 . Request ( http://116.213.207.5:15080/zabbix/index.php , data ) try : urlOpener . open ( request , timeout = 10 ) return urlOpener except urllib2 . HTTPError , e : print e def getgraph ( graid ): gr_url = http://116.213.207.5:15080/zabbix/chart2.php # http://116.213.207.5:15080/zabbix/chart6.php  stime = datetime . now () . strftime ( %Y%m %d %H%M%S ) values = { graphid : graid , period : 86400 , stime : stime , width : 800 , height : 200 } data = urllib . urlencode ( values ) request = urllib2 . Request ( gr_url , data ) url = getcookie () . open ( request ) image = url . read () imagename = img/ %s .png % graid f = open ( imagename , wb ) f . write ( image ) def SendMail ( imglist ): msgRoot = MIMEMultipart ( related ) msgRoot [ Subject ] = zabbix report msgRoot [ From ] = liangguangyu@dachuizichan.com to_list = [ liangguangyu@dachuizichan.com , 2219722370@qq.com ] msgRoot [ To ] = , . join ( to_list ) for img in imglist : imagename = img/ %s .png % img msgImage = MIMEImage ( open ( imagename , rb ) . read ()) msgImage . add_header ( Content-ID , str ( img )) msgRoot . attach ( msgImage ) sendText = html body p web cpu： /p + \\ p img src= cid:525 /p + \\ p img src= cid:550 /p + \\ p web ： /p + \\ p img src= cid:534 /p + \\ p img src= cid:553 /p + \\ p web ： /p + \\ p img src= cid:568 /p + \\ p img src= cid:575 /p + \\ p web ： /p + \\ p img src= cid:626 /p + \\ p img src= cid:628 /p + \\ p mysql cpu： /p + \\ p img src= cid:557 /p + \\ p img src= cid:564 /p + \\ p mysql ： /p + \\ p img src= cid:560 /p + \\ p img src= cid:567 /p + \\ p mysql ： /p + \\ p img src= cid:583 /p + \\ p img src= cid:590 /p + \\ p mysql ： /p + \\ p img src= cid:614 /p + \\ p img src= cid:631 /p + \\ /body /html msgText = MIMEText ( sendText , html , utf-8 ) msgRoot . attach ( msgText ) smtp = smtplib . SMTP_SSL () smtp . connect ( smtp.exmail.qq.com , 465 ) smtp . login ( liangguangyu@dachuizichan.com , lianggyA01 ) smtp . sendmail ( msgRoot [ From ], to_list , msgRoot . as_string ()) smtp . quit () # for hostmsg in zab_api(hostget)[ result ]: # print hostmsg[ host ], : , hostmsg[ hostid ] # Zabbix server : 10084 # 192.168.1.6 : 10105 # 192.168.1.7 : 10106 # 192.168.1.2 : 10107 # 192.168.1.3 : 10108 # web cpu:525 mem:534 net:568 connect:626 # slave cpu:550 mem:553 net:575 connect:628 #mysql cpu:557 mem:560 net:583 qps: 614 # mysql-slae cpu:564 mem:567 net:590 qps:631 #getgraphid( 10084 ) imglist = [ 525 , 534 , 568 , 626 , 550 , 553 , 575 , 628 , 557 , 560 , 583 , 614 , 564 , 567 , 590 , 631 ] for graphid in imglist : getgraph ( graphid ) SendMail ( imglist )  http : // www . cnyunwei . com / thread - 29593 - 1 - 1. html  https : // qy . weixin . qq . com /  python  #!/usr/bin/python # coding: utf-8 import urllib2 import json import sys reload ( sys ) sys . setdefaultencoding ( utf-8 ) def gettoken ( corpid , corpsecret ): gettoken_url = https://qyapi.weixin.qq.com/cgi-bin/gettoken?corpid= + corpid + corpsecret= + corpsecret try : token_file = urllib2 . urlopen ( gettoken_url ) except urllib2 . HTTPError as e : print e . code print e . read () . decode ( utf8 ) sys . exit () token_data = token_file . read () . decode ( utf-8 ) token_json = json . loads ( token_data ) token_json . keys () token = token_json [ access_token ] return token def senddata ( access_token , content ): send_url = https://qyapi.weixin.qq.com/cgi-bin/message/send?access_token= + access_token send_values = { touser : @all , #@all msgtype : text , agentid : 1 , #id， text : { content : content }, safe : 0 } send_data = json . dumps ( send_values , ensure_ascii = False ) send_request = urllib2 . Request ( send_url , send_data ) response = json . loads ( urllib2 . urlopen ( send_request ) . read ()) print str ( response ) if __name__ == __main__ : content = str ( sys . argv [ 3 ]) corpid = wxc8b10c89ac3d8f9b #CorpID corpsecret = Y9dS4chGDIpFmqDP_tT_FQlDHWMuFcjM_RzTnakwf7rnmhNE8mveeQuD44qTEp4x #corpsecretSecret accesstoken = gettoken ( corpid , corpsecret ) senddata ( accesstoken , content ) mv weixin . sh / usr / local / zabbix / share / zabbix / alertscripts chown zabbix . zabbix / usr / local / zabbix / share / zabbix / alertscripts / weixin . sh chmod + x / usr / local / zabbix / share / zabbix / alertscripts / weixin . sh  zabbix 3.1 、 4. png 3.2 、， administrator  5. png 3.3 、 6. png ， ， nginx / etc / nginx / conf . d / default . conf  location / ngx_status { stub_status on ; access_log off ; allow 127.0.0.1 ; deny all ; } curl http : // 127.0.0.1 / ngx_status Active connections : 362 server accepts handled requests 6823 6823 6821 Reading : 0 Writing : 362 Waiting : 0 1 ： http ，  ： 2 2 ：  ： 20  ： 20  ： 50 3 ：  ， nginx  ， nginx  ngx_status . sh ： #! / bin / bash # DateTime : 2015 - 10 - 25 # AUTHOR ：  # WEBSITE : http : // www . ttlsa . com # Description ： zabbixnginx # Note ：  ， ping ‎ HOST = 127.0.0.1 PORT = 80 # nginx function ping { / sbin / pidof nginx | wc - l } # nginx function active { / usr / bin / curl - s http://$HOST:$PORT/ngx_status/ | grep Active | awk {print $NF} } function reading { / usr / bin / curl - s http://$HOST:$PORT/ngx_status/ | grep Reading | awk {print $2} } function writing { / usr / bin / curl - s http://$HOST:$PORT/ngx_status/ | grep Writing | awk {print $4} } function waiting { / usr / bin / curl - s http://$HOST:$PORT/ngx_status/ | grep Waiting | awk {print $6} } function accepts { / usr / bin / curl - s http://$HOST:$PORT/ngx_status/ | awk NR == 3 | awk {print $1} } function handled { / usr / bin / curl - s http://$HOST:$PORT/ngx_status/ | awk NR == 3 | awk {print $2} } function requests { / usr / bin / curl - s http://$HOST:$PORT/ngx_status/ | awk NR == 3 | awk {print $3} } # function $ 1 #cat / usr / local / zabbix - 3.0.0 / etc / zabbix_agentd . conf | grep nginx UserParameter = nginx . status [ * ] , / usr / local / zabbix - 3.0.0 / scripts / ngx - status . sh $ 1  # zabbix_get - s 10.10.1.121 - k nginx.status[accepts] 9570756 #zabbix_get - s 10.10.1.121 - k nginx.status[ping] 1 zabbix mysql  http : // www . woqutech . com / ? p = 1200 zabbix  mysql ， IO ，。 zabbix  http : // www . zabbix . com / https : // github . com / leonanu / moss / （ lamp ） （ yum ） yum - y install gcc gcc - c ++ autoconf httpd php mysql mysql - server php - mysql httpd - manual mod_ssl mod_perl mod_auth_mysql php - gd php - xml php - mbstring php - ldap php - pear php - xmlrpc php - bcmath mysql - connector - odbc mysql - devel libdbi - dbd - mysql net - snmp - devel curl - devel unixODBC - devel OpenIPMI - devel java - devel libssh2 - devel openldap  php sed - i s/;date.timezone =/date.timezone = Asia\\/Shanghai/g / etc / php . ini sed - i s#max_execution_time = 30#max_execution_time = 300#g / etc / php . ini sed - i s#post_max_size = 8M#post_max_size = 32M#g / etc / php . ini sed - i s#max_input_time = 60#max_input_time = 300#g / etc / php . ini sed - i s#memory_limit = 128M#memory_limit = 128M#g / etc / php . ini # sed - i /;mbstring.func_overload = 0/ambstring.func_overload = 2 \\n / etc / php . ini  mysql ， apache chkconfig mysqld on chkconfig httpd on service mysqld start service httpd start （ yum ） groupadd zabbix - g 201 useradd - g zabbix - u 201 - m zabbix cd / usr / local / src / zabbix - 2 . 4 . 6 . / configure -- prefix =/ usr / local / zabbix -- sysconfdir =/ etc / zabbix -- enable - server -- enable - proxy -- enable - agent -- enable - ipv6 -- with - mysql =/ usr / bin / mysql_config -- with - net - snmp -- with - libcurl -- with - openipmi -- with - unixodbc -- with - ldap -- with - ssh2 -- enable - java （） make make install  mysql  mysql - uroot - e create database zabbix character set utf8; mysql - uroot - e grant all privileges on zabbix.* to zabbix@localhost identified by zabbix ; mysql - uroot - e flush privileges; mysql - uzabbix - pzabbix zabbix . / database / mysql / schema . sql mysql - uzabbix - pzabbix zabbix . / database / mysql / images . sql mysql - uzabbix - pzabbix zabbix . / database / mysql / data . sql zabbix  web  log  cp - r . / frontends / php / / var / www / html / zabbix chown - R apache . apache / var / www / html / zabbix mkdir / var / log / zabbix chown zabbix . zabbix / var / log / zabbix  cp misc / init . d / fedora / core / zabbix_ * / etc / init . d / chmod 755 / etc / init . d / zabbix_ *  sed - i s#BASEDIR=/usr/local#BASEDIR=/usr/local/zabbix#g / etc / init . d / zabbix_server sed - i s#BASEDIR=/usr/local#BASEDIR=/usr/local/zabbix#g / etc / init . d / zabbix_agentd sed - i s#tmp/zabbix_server.log#var/log/zabbix/zabbix_server.log#g / etc / zabbix / zabbix_server . conf sed - i s/ServerActive\\=127.0.0.1/ServerActive\\=127.0.0.1:10051/g / etc / zabbix / zabbix_agentd . conf sed - i s#tmp/zabbix_agentd.log#var/log/zabbix/zabbix_agentd.log#g / etc / zabbix / zabbix_agentd . conf sed - i #UnsafeUserParameters=0#aUnsafeUserParameters=1 \\n / etc / zabbix / zabbix_agentd . conf chkconfig zabbix_server on chkconfig zabbix_agentd on service zabbix_server start service zabbix_agentd start ---------------------------------------------------------------------------- yum  rpm - ivh http : // repo . zabbix . com / zabbix / 2 . 4 / rhel / 6 / x86_64 / zabbix - release - 2 . 4 - 1 . el6 . noarch . rpm yum install zabbix - server - mysql zabbix - web - mysql zabbix - server # cd / usr / share / doc / zabbix - server - mysql - 2 . 4 . 0 / create # mysql - uroot zabbix schema . sql # mysql - uroot zabbix images . sql # mysql - uroot zabbix data . sql # vi / etc / zabbix / zabbix_server . conf DBHost = localhost DBName = zabbix DBUser = zabbix DBPassword = zabbix StartPollers = 10 StartPollersUnreachable = 80 StartTrappers = 15 StartPingers = 4 StartDiscoverers = 0 HousekeepingFrequency = 1 CacheSize = 384 M CacheUpdateFrequency = 300 StartDBSyncers = 8 HistoryCacheSize = 512 M TrendCacheSize = 384 M HistoryTextCacheSize = 512 M Timeout = 30 LogSlowQueries = 1000 Include =/ usr / local / zabbix / etc / zabbix_server . conf . d / # AlertScriptsPath =/ usr / local / zabbix / alertscripts # ExternalScripts =/ usr / local / zabbix / externalscripts # FpingLocation =/ usr / local / sbin / fping # service zabbix - server start http zabbix  discovery   dns ，，， cat / etc / zabbix / zabbix_agentd . d / http_time . conf UserParameter = HttpUrl , / usr / bin / python / etc / zabbix / httpurl . py UserParameter = http_dns [ * ], curl - o / dev / null - s - w % { time_namelookup } $ 1 UserParameter = http_connect [ * ], curl - o / dev / null - s - w % { time_connect } $ 1 UserParameter = http_transfer [ * ], curl - o / dev / null - s - w % { time_starttransfer } $ 1 UserParameter = http_total [ * ], curl - o / dev / null - s - w % { time_total } $ 1 cat / etc / zabbix / httpurl . py  / etc / zabbix / zabbix_agentd . d /  #!/usr/bin/env python from json import dumps url_list = [ http://60.205.128.141/3m/17zuoye/1106/live/config/Server.json , http://doc5.3mang.com ] data = {} list2 = [] for url in url_list : Url = {} Url [ {#HTTP_URL} ] = url list2 . append ( Url ) data [ data ] = list2 jsonStr = dumps ( data , sort_keys = True , indent = 4 ) print jsonStr curl ： url_effective The URL that was fetched last . This is most meaningful if you ve told curl to follow location: headers. filename_effective The ultimate filename that curl writes out to . This is only meaningful if curl is told to write to a file with the -- remote - name or -- output option . It s most useful in combination with the -- remote - header - name option . ( Added in 7.25 . 1 ) http_code http ， 200  , 301  , 404  , 500 。 ( The numerical response code that was found in the last retrieved HTTP ( S ) or FTP ( s ) transfer . In 7.18 . 2 the alias response_code was added to show the same info . ) http_connect The numerical code that was found in the last response ( from a proxy ) to a curl CONNECT request . ( Added in 7.12 . 4 ) time_total ，。。 （ The total time , in seconds , that the full operation lasted . The time will be displayed with millisecond resolution . ） time_namelookup DNS  ,  DNS 。 ( The time , in seconds , it took from the start until the name resolving was completed . ) time_connect  ,  TCP  ,  DNS ，， time_connect  time_namelookup 。，。 ( The time , in seconds , it took from the start until the TCP connect to the remote host ( or proxy ) was completed . ) time_appconnect ， SSL / SSH 。 ( The time , in seconds , it took from the start until the SSL / SSH / etc connect / handshake to the remote host was completed . ( Added in 7.19 . 0 )) time_pretransfer 。 ( The time , in seconds , it took from the start until the file transfer was just about to begin . This includes all pre - transfer commands and negotiations that are specific to the particular protocol ( s ) involved . ) time_redirect ， DNS ，，，。 ( The time , in seconds , it took for all redirection steps include name lookup , connect , pretransfer and transfer before the final transaction was started . time_redirect shows the complete execution time for multiple redirections . ( Added in 7.12 . 3 )) time_starttransfer 。 client ， Web  ( The time , in seconds , it took from the start until the first byte was just about to be transferred. This includes time_pretransfer and also the time the server needed to calculate the result . ) size_download 。 ( The total amount of bytes that were downloaded . ) size_upload 。 ( The total amount of bytes that were uploaded . ) size_header  header  ( The total amount of bytes of the downloaded headers . ) size_request 。 ( The total amount of bytes that were sent in the HTTP request . ) speed_download ， - 。 ( The average download speed that curl measured for the complete download . Bytes per second . ) speed_upload  ,  - 。 ( The average upload speed that curl measured for the complete upload . Bytes per second . ) content_type  content - Type ，， ( text / html ; charset = UTF - 8 ) ； ( The Content - Type of the requested document , if there was any . ) num_connects Number of new connects made in the recent transfer . ( Added in 7.12 . 3 ) num_redirects Number of redirects that were followed in the request . ( Added in 7.12 . 3 ) redirect_url When a HTTP request was made without - L to follow redirects , this variable will show the actual URL a redirect would take you to . ( Added in 7.18 . 2 ) ftp_entry_path The initial path libcurl ended up in when logging on to the remote FTP server . ( Added in 7.15 . 4 ) ssl_verify_result ssl ， 0 。 ( The result of the SSL peer certificate verification that was requested . 0 means the verification was successful . ( Added in 7.19 . 0 )) agent rpm - ivh http : // repo . zabbix . com / zabbix / 2 . 4 / rhel / 6 / x86_64 / zabbix - release - 2 . 4 - 1 . el6 . noarch . rpm ， # !/ bin / bash SERVERIP = 1 . 1 . 1 . 1 localip = $ ( ifconfig eth0 | grep inet addr | awk {print $2} | awk - F : {print $2} ) [ $ UID - ne 0 ] exit ;echo You not is root!!! iptables - F / etc / init . d / iptables stop chkconfig iptables off sed - i . bak s/SELINUX=enforcing/SELINUX=disabled/g / etc / selinux / config cat / etc / yum . repos . d / zabbix . repo EOF [ zabbix ] baseurl = http : // mirrors . aliyun . com / zabbix / zabbix / 2 . 4 / rhel / 6 / \\ $ba search gpgcheck = 0 EOF yum install zabbix - agent - y sed - i . bak s/Hostname=Zabbix server/Hostname=$localip/g / etc / zabbix / zabbix_agentd . conf sed - i s/Server=127.0.0.1/Server=$SERVERIP/g / etc / zabbix / zabbix_agentd . conf sed - i s/ServerActive=127.0.0.1/ServerActive=$SERVERIP:10051/g / etc / zabbix / zabbix_agentd . conf sed - i 261a\\UnsafeUserParameters=1 / etc / zabbix / zabbix_agentd . conf sed - i 168a\\HostMetadataItem=system.uname / etc / zabbix / zabbix_agentd . conf chkconfig zabbix - agent on service zabbix - agent start windows zabbix_agentd . exe – c c :\\ zabbix \\ zabbix_agentd . conf - i zabbix_agentd . exe – c c :\\ zabbix \\ zabbix_agentd . conf – s  events #!/bin/bash #this script name is delete_events.sh host= localhost socket= /data/perconadata5.6/mysql.sock user= zabbix pass= zabbix port= 3306 time=`date -d last-month +%Y-%m-01` mysql -u $user -p $pass -h $host -S $socket -P $port EOF use zabbix; delete from events where clock = UNIX_TIMESTAMP( ${time} ) limit 40000; EOF ------------------------------------------------------------------------------ zabbix.service zabbix_server stop http service httpd stop : mysql -u root(zabbix) -p use zabbix :  SELECT table_name AS Tables , round(((data_length + index_length) / 1024 / 1024), 2) Size in MB FROM information_schema.TABLES WHERE table_schema = zabbix ORDER BY (data_length + index_length) DESC; truncate table history; truncate table history_uint; truncate table alerts; truncate table trends_uint; truncate table trends; truncate table history_text; truncate table events; delete,,ID.","title":"zabbix"},{"location":"zabbix/#docker","text":"zabbixLLD，docker。dockernot supported， zabbix Administration -- General  Regular expressions  linux Discovery list  Network interfaces for discovery /var/lib/docker/devicemapper/mnt/，。 5： Character string included # Any character string included #，（，）,（.）,（/） Character string not included # Result is TRUE #， Result is FALSE #，zabbix Administration -- General  Regular expressions ","title":"docker"},{"location":"zabbix/#mysql","text":"  zabbix agent  vim / etc / zabbix / . my . cnf [ mysql ] host = localhost user = root password = xxx port = 3326 socket = / var / lib / mysql / mysql3326 . sock [ mysqladmin ] host = localhost user = root password = xxxx port = 3326 socket = / var / lib / mysql / mysql3326 . sock sed - i s@/var/lib/zabbix@/etc/zabbix@g / etc / zabbix / zabbix_agentd . d / userparameter_mysql . conf / etc / init . d / zabbix - agent restart  web  mysql  mysql  vim / etc / zabbix / zabbix_agentd . d / userparameter_mysql . conf UserParameter = mysql . replication , echo show slave status\\G; | HOME =/ etc / zabbix mysql | grep - E Slave_IO_Running|Slave_SQL_Running | awk {print $$2} | grep - c Yes zabbix_get - s 192 . 168 . 100 . 223 - k mysql.replication  2 ，, Slave_IO_Running  Slave_SQL_Running  Yes 。 ---------------------------------------------------------- MySQL ， Zabbix ，。 Zabbix  MySQL  ， Zabbix  MySQL ， percona 。 https : // www . percona . com / doc / percona - monitoring - plugins / 1 . 1 / zabbix / index . html  MySQL 。 1 . percona  # rpm - ivh http : // www . percona . com / downloads / percona - release / redhat / 0 . 1 - 3 / percona - release - 0 . 1 - 3 . noarch . rpm 2 . percona  php 。 php  mysql ， zabbix agent ， php  php - mysql 。 [ root @ linux - node1 ~ ]# yum install zabbix22 - agentphp php - mysql 3 . percona  zabbix  [ root @ linux - node1 ~ ]# yum install - ypercona - zabbix - templates [ root @ linux - node1 ~ ]# rpm - qlpercona - zabbix - templates / var / lib / zabbix / percona / var / lib / zabbix / percona / scripts / var / lib / zabbix / percona / scripts / get_mysql_stats_wrapper . sh / var / lib / zabbix / percona / scripts / ss_get_mysql_stats . php / var / lib / zabbix / percona / templates / var / lib / zabbix / percona / templates / userparameter_percona_mysql . conf / var / lib / zabbix / percona / templates / zabbix_agent_template_percona_mysql_server_ht_2 . 0 . 9 - sver1 . 1 . 6 . xml  shell ， php ， zabbix ， Zabbix  xml 。 ， Zabbix 。 # vim / etc / zabbix_agentd . conf Include =/ etc / zabbix_agentd . conf . d / # mkdir / etc / zabbix_agentd . conf . d / 4 . Zabbix  # cp / var / lib / zabbix / percona / templates / userparameter_percona_mysql . conf / etc / zabbix_agentd . conf . d / 5 . PHP  MySQL  # vim / var / lib / zabbix / percona / scripts / ss_get_mysql_stats . php . cnf ? php $ mysql_user = root ; $ mysql_pass = s3cret ; //mysql。 6 . # / var / lib / zabbix / percona / scripts / get_mysql_stats_wrapper . sh gg 7 . ， MySQL ， get_mysql_stats_wrapper . sh 。 mysql  socket ， 。，， 1 ，。 # / var / lib / zabbix / percona / scripts / get_mysql_stats_wrapper . sh running - slave 1 8 . zabbix   / var / lib / zabbix / percona / templates / zabbix_agent_template_percona_mysql_server_ht_2 . 0 . 9 - sver1 . 1 . 6 . xml  ， zabbix  Configuration - Templates - Import  MySQL ，，！  MySQL   MySQL ， MySQL ，，， ， MySQL 。 mysql grant select , process , replicationclient on * . * to monitor @ 192.168.1.11 identified by monitor@xx ; mysql flush privileges ; process ， SHOWPROCESSLIST  KILL 。， SHOW PROCESSLIST ， 。 replication client  master server 、 slave server 。  MySQL Slave  ， MySQL Master  Slave ， Slave ，，  Slave ，。 ，： stop slave ; reset slave all ; RESET SLAVE ALL 、、。 ， show slave status 。","title":"mysql"},{"location":"zabbix/#mongo","text":"1 、 zabbix  key vim / usr / local / zabbix / etc / zabbix_agentd . conf UserParameter = MongoDB . Status [ * ], / bin / echo db.serverStatus().$1 | / usr / local / mongodb / bin / mongo admin | grep \\ $2\\ | awk - F : {print $$2} | awk - F , {print $$1} db . serverStatus () . $1  1 （） MongoDB . Status [ * ], / bin / echo db.serverStatus().$1 | / usr / local / mongodb / bin / mongo admin -- port 10040 - u admin - p f8hIXm3g? | grep \\ $2\\ | sed s/,/ \\n /g | grep \\ $2\\ | awk - F : {print $$2} | awk - F , {print $$1}  db . serverStatus ()   $1  grep $2  \\  \\ ， echo db.serverStatus() |/ usr / local / mongodb / bin / mongo -- port 10040 -- quiet { host : TENCENT64.site , -- server  hostname version : 2.0.5 , -- mongo  process : mongod , --  uptime : 1238418 , -- （： S ） uptimeEstimate : 1230730 , --  MongoDB  localTime : ISODate ( 2012-09-14T09:09:52.657Z ) , -- server  globalLock : { totalTime : 1238418105923 , -- （： ms ） lockTime : 75055831911 , -- （： ms ） ratio : 0 . 06060621332329477 , -- lockTime  totalTime  currentQueue : { total : 0 , --  readers : 0 , --  writers : 0 --  }, activeClients : { total : 1 , --  server  client  readers : 1 , --  client  writers : 0 --  client  } }, mem : { bits : 64 , -- 64  resident : 18363 , -- 。 virtual : 478810 , --  supported : true , --  mapped : 233311 , -- ，。 mappedWithJournal : 466622 , note : virtual minus mapped is large. could indicate a memory leak }, connections : { current : 737 , -- 。 server  available : 82 -- 。 }, extra_info : { note : fields vary by platform , heap_usage_bytes : 3838448 , -- 。 Linux page_faults : 31058356 -- 。 Linux }, indexCounters : { btree : { accesses : 68229146 , -- Btree （） hits : 68229146 , --  Btree 。（） misses : 0 , --  Btree 。（）（） resets : 0 , --  0  missRatio : 0 -- （） } }, backgroundFlushing : { flushes : 20640 , --  total_ms : 2453287 , --  average_ms : 118 . 8608042635659 , --  last_ms : 1 , --  last_finished : ISODate ( 2012-09-14T09:09:35.656Z ) --  }, cursors : { totalOpen : 0 , -- server  client （ cursor ） clientCursors_size : 0 , -- timedOut : 24 -- server （ cursor ） }, network : { bytesIn : NumberLong ( 1929833164782 ) , -- （ bytes ） bytesOut : 553137147925 , -- （ bytes ） numRequests : 2475184328 --  }, opcounters : { insert : 687531883 , -- server  insert  query : 711010343 , -- server  query  update : 0 , -- server  update  delete : 0 , -- server  delete  getmore : 6484 , -- server  getMore  command : 1287537 -- server  }, asserts : { regular : 0 , -- server （ assert ） warning : 1 , -- server  msg : 0 , -- 。 user : 4 , -- 。，：；。 rollovers : 0 -- server ， assert counters have rolled over  }, writeBacksQueued : false , --  mongos  retry  dur : { commits : 30 , --  journal  commit  journaledMB : 0 , --  journal （： MB ） writeToDataFilesMB : 0 , --  journal （： MB ） compression : 0 , -- commitsInWriteLock : 0 , --  commits  earlyCommits : 0 , -- schedule  commit  timeMs : { dt : 3064 , prepLogBuffer : 0 , --  journal  writeToJournal : 0 , --  journal  writeToDataFiles : 0 , -- journal  remapPrivateView : 0 -- The amount of time spent remapping copy - on - write memory mapped views } }, ok : 1 -- serverStatus  } . / zabbix_get - s 127 . 0 . 0 . 1 - k MongoDB . Status [ opcounters , query ]   command ，，，，，， 10  insert 、 query 、 update 、 delete 、 getmore 、 command  ， virtual ， resident  ， bytesIN ， bytesOut ， numRequests  ， available 、 current    mapped ， MB 5 、 locks ，， key ， key [ root @ mongodb bin ]# echo db.serverStatus().locks | mongo admin MongoDB shell version : 2 . 6 . 3 connecting to : admin { . : { timeLockedMicros : { R : NumberLong ( 572504 ) , W : NumberLong ( 480751 ) }, timeAcquiringMicros : { R : NumberLong ( 480946 ) , W : NumberLong ( 70198 ) } }, admin : { timeLockedMicros : { r : NumberLong ( 142364 ) , w : NumberLong ( 0 ) }, timeAcquiringMicros : { r : NumberLong ( 15018 ) , w : NumberLong ( 0 ) } }, local : { timeLockedMicros : { r : NumberLong ( 271651 ) , w : NumberLong ( 271 ) }, timeAcquiringMicros : { r : NumberLong ( 120699 ) , w : NumberLong ( 5 ) } }, test : { timeLockedMicros : { r : NumberLong ( 93725 ) , w : NumberLong ( 114935 ) }, timeAcquiringMicros : { r : NumberLong ( 67411 ) , w : NumberLong ( 41 ) } } } bye  key UserParameter = MongoDB . Status . locks [ * ], / bin / echo db.serverStatus().locks.$1.$2.$3 | / usr / local / mongodb / bin / mongo admin |/ usr / bin / tail - n 2 | / usr / bin / head - n 1 | awk - F ( {print $$2} | awk - F ) {print $$1} ： http : // www . zhengdazhi . com / archives / 662","title":"mongo"},{"location":"zabbix/#fping-key","text":"fping 192 . 168 . 1 . 20 2 / dev / null | grep - c alive","title":"fping key"},{"location":"zabbix/#_1","text":"1-1,11。， 1，。1-0，0. 60。，60。","title":""},{"location":"zabbix/#nginx","text":"#  # !/ usr / bin / env bash case $2 in net ) count = $ ( sudo grep $ ( date +%Y:%H:%M ) / var / log / nginx / access_ $1 . log | wc - l ) if [ $c ount - eq 0 ] ;then echo 0 else sudo grep $ ( date +%Y:%H:%M ) / var / log / nginx / access_ $1 . log | awk {sum +=$10}END{print sum} fi ;; connect ) sudo grep $ ( date +%Y:%H:%M ) / var / log / nginx / access_ $1 . log | wc - l ;; esac key ： UserParameter = domain_stats [ * ], / etc / zabbix / domain_stats . sh $1 $2  zabbix_get - s 192 . 168 . 1 . 5 - k domain_stats [ data , net ] 1172557 zabbix_get - s 192 . 168 . 1 . 5 - k domain_stats [ data , connect ] 0","title":"nginx"},{"location":"zabbix/#redis","text":"UserParameter = Redis . Info [ * ], / etc / zabbix / redisinfo . sh $1 $2 # ! / bin / bash REDISCLI = /usr/local/src/redis-cli HOST = 116.213.204.14 PORT = 6379 if [[ $# == 1 ]] ;then case $1 in version ) result = `$ REDISCLI - h $ HOST - p $ PORT info | grep - w redis_version | awk - F : {print $2} ` echo $ result ;; uptime ) result = `$ REDISCLI - h $ HOST - p $ PORT info | grep - w uptime_in_seconds | awk - F : {print $2} ` echo $ result ;; connected_clients ) result = `$ REDISCLI - h $ HOST - p $ PORT info | grep - w connected_clients | awk - F : {print $2} ` echo $ result ;; blocked_clients ) result = `$ REDISCLI - h $ HOST - p $ PORT info | grep - w blocked_clients | awk - F : {print $2} ` echo $ result ;; used_memory ) result = `$ REDISCLI - h $ HOST - p $ PORT info | grep - w used_memory | awk - F : {print $2} ` echo $ result ;; used_memory_rss ) result = `$ REDISCLI - h $ HOST - p $ PORT info | grep - w used_memory_rss | awk - F : {print $2} ` echo $ result ;; used_memory_peak ) result = `$ REDISCLI - h $ HOST - p $ PORT info | grep - w used_memory_peak | awk - F : {print $2} ` echo $ result ;; used_memory_lua ) result = `$ REDISCLI - h $ HOST - p $ PORT info | grep - w used_memory_lua | awk - F : {print $2} ` echo $ result ;; used_cpu_sys ) result = `$ REDISCLI - h $ HOST - p $ PORT info | grep - w used_cpu_sys | awk - F : {print $2} ` echo $ result ;; used_cpu_user ) result = `$ REDISCLI - h $ HOST - p $ PORT info | grep - w used_cpu_user | awk - F : {print $2} ` echo $ result ;; used_cpu_sys_children ) result = `$ REDISCLI - h $ HOST - p $ PORT info | grep - w used_cpu_sys_children | awk - F : {print $2} ` echo $ result ;; used_cpu_user_children ) result = `$ REDISCLI - h $ HOST - p $ PORT info | grep - w used_cpu_user_children | awk - F : {print $2} ` echo $ result ;; rdb_last_bgsave_status ) result = `$ REDISCLI - h $ HOST - p $ PORT info | grep - w rdb_last_bgsave_status | awk - F : {print $2} | grep - c ok ` echo $ result ;; aof_last_bgrewrite_status ) result = `$ REDISCLI - h $ HOST - p $ PORT info | grep - w aof_last_bgrewrite_status | awk - F : {print $2} | grep - c ok ` echo $ result ;; aof_last_write_status ) result = `$ REDISCLI - h $ HOST - p $ PORT info | grep - w aof_last_write_status | awk - F : {print $2} | grep - c ok ` echo $ result ;; * ) echo - e \\033[33mUsage: $0 {connected_clients|blocked_clients|used_memory|used_memory_rss| used_memory_peak | used_memory_lua | used_cpu_sys | used_cpu_user | used_cpu_sys_children | used_cpu_user_children | rdb_last_bgsave_status | aof_last_bgrewrite_status | aof_last_write_status }\\ 033 [ 0 m ;; esac elif [[ $# == 2 ]] ;then case $2 in keys ) result = `$ REDISCLI - h $ HOST - p $ PORT info | grep - w $1 | grep - w keys | awk - F =|, {print $2} ` echo $ result ;; expires ) result = `$ REDISCLI - h $ HOST - p $ PORT info | grep - w $1 | grep - w keys | awk - F =|, {print $4} ` echo $ result ;; avg_ttl ) result = `$ REDISCLI - h $ HOST - p $ PORT info | grep - w $1 | grep - w avg_ttl | awk - F =|, {print $6} ` echo $ result ;; * ) echo - e \\033[33mUsage: $0 {db0 keys|db0 expires|db0 avg_ttl}\\033[0m ;; esac fi","title":"redis"},{"location":"zabbix/#zabbix","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 #!/usr/bin/env python # coding=utf-8 import json import urllib import urllib2 from datetime import datetime import cookielib import smtplib from email.mime.multipart import MIMEMultipart from email.mime.text import MIMEText from email.mime.image import MIMEImage def zab_api ( data ): url = http://116.213.207.5:15080/zabbix/api_jsonrpc.php header = { Content-Type : application/json } request = urllib2 . Request ( url , data , header ) result = urllib2 . urlopen ( request ) response = json . loads ( result . read ()) result . close () return response auth_data = json . dumps ({ jsonrpc : 2.0 , method : user.login , params : { user : admin , password : dachui$5zabbix }, id : 2 }) auth = zab_api ( auth_data )[ result ] hostget = json . dumps ({ jsonrpc : 2.0 , method : host.get , params : { output : [ hostid , host ], selectInterfaces : [ interfaceid , ip ] }, id : 2 , auth : auth }) def getgraphid ( hostid ): graph1 = json . dumps ({ jsonrpc : 2.0 , method : graph.get , params : { output : extend , hostids : hostid , sortfield : name }, auth : auth , id : 1 }) for graph in zab_api ( graph1 )[ result ]: print graph [ name ], : , graph [ graphid ] def getcookie (): cookiejar = cookielib . CookieJar () urlOpener = urllib2 . build_opener ( urllib2 . HTTPCookieProcessor ( cookiejar )) values = { name : admin , password : dachui$5zabbix , autologin : 1 , enter : Sign in } data = urllib . urlencode ( values ) request = urllib2 . Request ( http://116.213.207.5:15080/zabbix/index.php , data ) try : urlOpener . open ( request , timeout = 10 ) return urlOpener except urllib2 . HTTPError , e : print e def getgraph ( graid ): gr_url = http://116.213.207.5:15080/zabbix/chart2.php # http://116.213.207.5:15080/zabbix/chart6.php  stime = datetime . now () . strftime ( %Y%m %d %H%M%S ) values = { graphid : graid , period : 86400 , stime : stime , width : 800 , height : 200 } data = urllib . urlencode ( values ) request = urllib2 . Request ( gr_url , data ) url = getcookie () . open ( request ) image = url . read () imagename = img/ %s .png % graid f = open ( imagename , wb ) f . write ( image ) def SendMail ( imglist ): msgRoot = MIMEMultipart ( related ) msgRoot [ Subject ] = zabbix report msgRoot [ From ] = liangguangyu@dachuizichan.com to_list = [ liangguangyu@dachuizichan.com , 2219722370@qq.com ] msgRoot [ To ] = , . join ( to_list ) for img in imglist : imagename = img/ %s .png % img msgImage = MIMEImage ( open ( imagename , rb ) . read ()) msgImage . add_header ( Content-ID , str ( img )) msgRoot . attach ( msgImage ) sendText = html body p web cpu： /p + \\ p img src= cid:525 /p + \\ p img src= cid:550 /p + \\ p web ： /p + \\ p img src= cid:534 /p + \\ p img src= cid:553 /p + \\ p web ： /p + \\ p img src= cid:568 /p + \\ p img src= cid:575 /p + \\ p web ： /p + \\ p img src= cid:626 /p + \\ p img src= cid:628 /p + \\ p mysql cpu： /p + \\ p img src= cid:557 /p + \\ p img src= cid:564 /p + \\ p mysql ： /p + \\ p img src= cid:560 /p + \\ p img src= cid:567 /p + \\ p mysql ： /p + \\ p img src= cid:583 /p + \\ p img src= cid:590 /p + \\ p mysql ： /p + \\ p img src= cid:614 /p + \\ p img src= cid:631 /p + \\ /body /html msgText = MIMEText ( sendText , html , utf-8 ) msgRoot . attach ( msgText ) smtp = smtplib . SMTP_SSL () smtp . connect ( smtp.exmail.qq.com , 465 ) smtp . login ( liangguangyu@dachuizichan.com , lianggyA01 ) smtp . sendmail ( msgRoot [ From ], to_list , msgRoot . as_string ()) smtp . quit () # for hostmsg in zab_api(hostget)[ result ]: # print hostmsg[ host ], : , hostmsg[ hostid ] # Zabbix server : 10084 # 192.168.1.6 : 10105 # 192.168.1.7 : 10106 # 192.168.1.2 : 10107 # 192.168.1.3 : 10108 # web cpu:525 mem:534 net:568 connect:626 # slave cpu:550 mem:553 net:575 connect:628 #mysql cpu:557 mem:560 net:583 qps: 614 # mysql-slae cpu:564 mem:567 net:590 qps:631 #getgraphid( 10084 ) imglist = [ 525 , 534 , 568 , 626 , 550 , 553 , 575 , 628 , 557 , 560 , 583 , 614 , 564 , 567 , 590 , 631 ] for graphid in imglist : getgraph ( graphid ) SendMail ( imglist )","title":"zabbix"},{"location":"zabbix/#_2","text":"http : // www . cnyunwei . com / thread - 29593 - 1 - 1. html  https : // qy . weixin . qq . com /  python  #!/usr/bin/python # coding: utf-8 import urllib2 import json import sys reload ( sys ) sys . setdefaultencoding ( utf-8 ) def gettoken ( corpid , corpsecret ): gettoken_url = https://qyapi.weixin.qq.com/cgi-bin/gettoken?corpid= + corpid + corpsecret= + corpsecret try : token_file = urllib2 . urlopen ( gettoken_url ) except urllib2 . HTTPError as e : print e . code print e . read () . decode ( utf8 ) sys . exit () token_data = token_file . read () . decode ( utf-8 ) token_json = json . loads ( token_data ) token_json . keys () token = token_json [ access_token ] return token def senddata ( access_token , content ): send_url = https://qyapi.weixin.qq.com/cgi-bin/message/send?access_token= + access_token send_values = { touser : @all , #@all msgtype : text , agentid : 1 , #id， text : { content : content }, safe : 0 } send_data = json . dumps ( send_values , ensure_ascii = False ) send_request = urllib2 . Request ( send_url , send_data ) response = json . loads ( urllib2 . urlopen ( send_request ) . read ()) print str ( response ) if __name__ == __main__ : content = str ( sys . argv [ 3 ]) corpid = wxc8b10c89ac3d8f9b #CorpID corpsecret = Y9dS4chGDIpFmqDP_tT_FQlDHWMuFcjM_RzTnakwf7rnmhNE8mveeQuD44qTEp4x #corpsecretSecret accesstoken = gettoken ( corpid , corpsecret ) senddata ( accesstoken , content ) mv weixin . sh / usr / local / zabbix / share / zabbix / alertscripts chown zabbix . zabbix / usr / local / zabbix / share / zabbix / alertscripts / weixin . sh chmod + x / usr / local / zabbix / share / zabbix / alertscripts / weixin . sh  zabbix 3.1 、 4. png 3.2 、， administrator  5. png 3.3 、 6. png ， ，","title":""},{"location":"zabbix/#nginx_1","text":"/ etc / nginx / conf . d / default . conf  location / ngx_status { stub_status on ; access_log off ; allow 127.0.0.1 ; deny all ; } curl http : // 127.0.0.1 / ngx_status Active connections : 362 server accepts handled requests 6823 6823 6821 Reading : 0 Writing : 362 Waiting : 0 1 ： http ，  ： 2 2 ：  ： 20  ： 20  ： 50 3 ：  ， nginx  ， nginx  ngx_status . sh ： #! / bin / bash # DateTime : 2015 - 10 - 25 # AUTHOR ：  # WEBSITE : http : // www . ttlsa . com # Description ： zabbixnginx # Note ：  ， ping ‎ HOST = 127.0.0.1 PORT = 80 # nginx function ping { / sbin / pidof nginx | wc - l } # nginx function active { / usr / bin / curl - s http://$HOST:$PORT/ngx_status/ | grep Active | awk {print $NF} } function reading { / usr / bin / curl - s http://$HOST:$PORT/ngx_status/ | grep Reading | awk {print $2} } function writing { / usr / bin / curl - s http://$HOST:$PORT/ngx_status/ | grep Writing | awk {print $4} } function waiting { / usr / bin / curl - s http://$HOST:$PORT/ngx_status/ | grep Waiting | awk {print $6} } function accepts { / usr / bin / curl - s http://$HOST:$PORT/ngx_status/ | awk NR == 3 | awk {print $1} } function handled { / usr / bin / curl - s http://$HOST:$PORT/ngx_status/ | awk NR == 3 | awk {print $2} } function requests { / usr / bin / curl - s http://$HOST:$PORT/ngx_status/ | awk NR == 3 | awk {print $3} } # function $ 1 #cat / usr / local / zabbix - 3.0.0 / etc / zabbix_agentd . conf | grep nginx UserParameter = nginx . status [ * ] , / usr / local / zabbix - 3.0.0 / scripts / ngx - status . sh $ 1  # zabbix_get - s 10.10.1.121 - k nginx.status[accepts] 9570756 #zabbix_get - s 10.10.1.121 - k nginx.status[ping] 1","title":"nginx"},{"location":"zabbix/#zabbix_1","text":"mysql  http : // www . woqutech . com / ? p = 1200 zabbix  mysql ， IO ，。 zabbix  http : // www . zabbix . com / https : // github . com / leonanu / moss / （ lamp ） （ yum ） yum - y install gcc gcc - c ++ autoconf httpd php mysql mysql - server php - mysql httpd - manual mod_ssl mod_perl mod_auth_mysql php - gd php - xml php - mbstring php - ldap php - pear php - xmlrpc php - bcmath mysql - connector - odbc mysql - devel libdbi - dbd - mysql net - snmp - devel curl - devel unixODBC - devel OpenIPMI - devel java - devel libssh2 - devel openldap  php sed - i s/;date.timezone =/date.timezone = Asia\\/Shanghai/g / etc / php . ini sed - i s#max_execution_time = 30#max_execution_time = 300#g / etc / php . ini sed - i s#post_max_size = 8M#post_max_size = 32M#g / etc / php . ini sed - i s#max_input_time = 60#max_input_time = 300#g / etc / php . ini sed - i s#memory_limit = 128M#memory_limit = 128M#g / etc / php . ini # sed - i /;mbstring.func_overload = 0/ambstring.func_overload = 2 \\n / etc / php . ini  mysql ， apache chkconfig mysqld on chkconfig httpd on service mysqld start service httpd start （ yum ） groupadd zabbix - g 201 useradd - g zabbix - u 201 - m zabbix cd / usr / local / src / zabbix - 2 . 4 . 6 . / configure -- prefix =/ usr / local / zabbix -- sysconfdir =/ etc / zabbix -- enable - server -- enable - proxy -- enable - agent -- enable - ipv6 -- with - mysql =/ usr / bin / mysql_config -- with - net - snmp -- with - libcurl -- with - openipmi -- with - unixodbc -- with - ldap -- with - ssh2 -- enable - java （） make make install  mysql  mysql - uroot - e create database zabbix character set utf8; mysql - uroot - e grant all privileges on zabbix.* to zabbix@localhost identified by zabbix ; mysql - uroot - e flush privileges; mysql - uzabbix - pzabbix zabbix . / database / mysql / schema . sql mysql - uzabbix - pzabbix zabbix . / database / mysql / images . sql mysql - uzabbix - pzabbix zabbix . / database / mysql / data . sql zabbix  web  log  cp - r . / frontends / php / / var / www / html / zabbix chown - R apache . apache / var / www / html / zabbix mkdir / var / log / zabbix chown zabbix . zabbix / var / log / zabbix  cp misc / init . d / fedora / core / zabbix_ * / etc / init . d / chmod 755 / etc / init . d / zabbix_ *  sed - i s#BASEDIR=/usr/local#BASEDIR=/usr/local/zabbix#g / etc / init . d / zabbix_server sed - i s#BASEDIR=/usr/local#BASEDIR=/usr/local/zabbix#g / etc / init . d / zabbix_agentd sed - i s#tmp/zabbix_server.log#var/log/zabbix/zabbix_server.log#g / etc / zabbix / zabbix_server . conf sed - i s/ServerActive\\=127.0.0.1/ServerActive\\=127.0.0.1:10051/g / etc / zabbix / zabbix_agentd . conf sed - i s#tmp/zabbix_agentd.log#var/log/zabbix/zabbix_agentd.log#g / etc / zabbix / zabbix_agentd . conf sed - i #UnsafeUserParameters=0#aUnsafeUserParameters=1 \\n / etc / zabbix / zabbix_agentd . conf chkconfig zabbix_server on chkconfig zabbix_agentd on service zabbix_server start service zabbix_agentd start ---------------------------------------------------------------------------- yum  rpm - ivh http : // repo . zabbix . com / zabbix / 2 . 4 / rhel / 6 / x86_64 / zabbix - release - 2 . 4 - 1 . el6 . noarch . rpm yum install zabbix - server - mysql zabbix - web - mysql zabbix - server # cd / usr / share / doc / zabbix - server - mysql - 2 . 4 . 0 / create # mysql - uroot zabbix schema . sql # mysql - uroot zabbix images . sql # mysql - uroot zabbix data . sql # vi / etc / zabbix / zabbix_server . conf DBHost = localhost DBName = zabbix DBUser = zabbix DBPassword = zabbix StartPollers = 10 StartPollersUnreachable = 80 StartTrappers = 15 StartPingers = 4 StartDiscoverers = 0 HousekeepingFrequency = 1 CacheSize = 384 M CacheUpdateFrequency = 300 StartDBSyncers = 8 HistoryCacheSize = 512 M TrendCacheSize = 384 M HistoryTextCacheSize = 512 M Timeout = 30 LogSlowQueries = 1000 Include =/ usr / local / zabbix / etc / zabbix_server . conf . d / # AlertScriptsPath =/ usr / local / zabbix / alertscripts # ExternalScripts =/ usr / local / zabbix / externalscripts # FpingLocation =/ usr / local / sbin / fping # service zabbix - server start","title":"zabbix"},{"location":"zabbix/#http","text":"zabbix  discovery   dns ，，， cat / etc / zabbix / zabbix_agentd . d / http_time . conf UserParameter = HttpUrl , / usr / bin / python / etc / zabbix / httpurl . py UserParameter = http_dns [ * ], curl - o / dev / null - s - w % { time_namelookup } $ 1 UserParameter = http_connect [ * ], curl - o / dev / null - s - w % { time_connect } $ 1 UserParameter = http_transfer [ * ], curl - o / dev / null - s - w % { time_starttransfer } $ 1 UserParameter = http_total [ * ], curl - o / dev / null - s - w % { time_total } $ 1 cat / etc / zabbix / httpurl . py  / etc / zabbix / zabbix_agentd . d /  #!/usr/bin/env python from json import dumps url_list = [ http://60.205.128.141/3m/17zuoye/1106/live/config/Server.json , http://doc5.3mang.com ] data = {} list2 = [] for url in url_list : Url = {} Url [ {#HTTP_URL} ] = url list2 . append ( Url ) data [ data ] = list2 jsonStr = dumps ( data , sort_keys = True , indent = 4 ) print jsonStr curl ： url_effective The URL that was fetched last . This is most meaningful if you ve told curl to follow location: headers. filename_effective The ultimate filename that curl writes out to . This is only meaningful if curl is told to write to a file with the -- remote - name or -- output option . It s most useful in combination with the -- remote - header - name option . ( Added in 7.25 . 1 ) http_code http ， 200  , 301  , 404  , 500 。 ( The numerical response code that was found in the last retrieved HTTP ( S ) or FTP ( s ) transfer . In 7.18 . 2 the alias response_code was added to show the same info . ) http_connect The numerical code that was found in the last response ( from a proxy ) to a curl CONNECT request . ( Added in 7.12 . 4 ) time_total ，。。 （ The total time , in seconds , that the full operation lasted . The time will be displayed with millisecond resolution . ） time_namelookup DNS  ,  DNS 。 ( The time , in seconds , it took from the start until the name resolving was completed . ) time_connect  ,  TCP  ,  DNS ，， time_connect  time_namelookup 。，。 ( The time , in seconds , it took from the start until the TCP connect to the remote host ( or proxy ) was completed . ) time_appconnect ， SSL / SSH 。 ( The time , in seconds , it took from the start until the SSL / SSH / etc connect / handshake to the remote host was completed . ( Added in 7.19 . 0 )) time_pretransfer 。 ( The time , in seconds , it took from the start until the file transfer was just about to begin . This includes all pre - transfer commands and negotiations that are specific to the particular protocol ( s ) involved . ) time_redirect ， DNS ，，，。 ( The time , in seconds , it took for all redirection steps include name lookup , connect , pretransfer and transfer before the final transaction was started . time_redirect shows the complete execution time for multiple redirections . ( Added in 7.12 . 3 )) time_starttransfer 。 client ， Web  ( The time , in seconds , it took from the start until the first byte was just about to be transferred. This includes time_pretransfer and also the time the server needed to calculate the result . ) size_download 。 ( The total amount of bytes that were downloaded . ) size_upload 。 ( The total amount of bytes that were uploaded . ) size_header  header  ( The total amount of bytes of the downloaded headers . ) size_request 。 ( The total amount of bytes that were sent in the HTTP request . ) speed_download ， - 。 ( The average download speed that curl measured for the complete download . Bytes per second . ) speed_upload  ,  - 。 ( The average upload speed that curl measured for the complete upload . Bytes per second . ) content_type  content - Type ，， ( text / html ; charset = UTF - 8 ) ； ( The Content - Type of the requested document , if there was any . ) num_connects Number of new connects made in the recent transfer . ( Added in 7.12 . 3 ) num_redirects Number of redirects that were followed in the request . ( Added in 7.12 . 3 ) redirect_url When a HTTP request was made without - L to follow redirects , this variable will show the actual URL a redirect would take you to . ( Added in 7.18 . 2 ) ftp_entry_path The initial path libcurl ended up in when logging on to the remote FTP server . ( Added in 7.15 . 4 ) ssl_verify_result ssl ， 0 。 ( The result of the SSL peer certificate verification that was requested . 0 means the verification was successful . ( Added in 7.19 . 0 ))","title":"http"},{"location":"zabbix/#agent","text":"rpm - ivh http : // repo . zabbix . com / zabbix / 2 . 4 / rhel / 6 / x86_64 / zabbix - release - 2 . 4 - 1 . el6 . noarch . rpm ， # !/ bin / bash SERVERIP = 1 . 1 . 1 . 1 localip = $ ( ifconfig eth0 | grep inet addr | awk {print $2} | awk - F : {print $2} ) [ $ UID - ne 0 ] exit ;echo You not is root!!! iptables - F / etc / init . d / iptables stop chkconfig iptables off sed - i . bak s/SELINUX=enforcing/SELINUX=disabled/g / etc / selinux / config cat / etc / yum . repos . d / zabbix . repo EOF [ zabbix ] baseurl = http : // mirrors . aliyun . com / zabbix / zabbix / 2 . 4 / rhel / 6 / \\ $ba search gpgcheck = 0 EOF yum install zabbix - agent - y sed - i . bak s/Hostname=Zabbix server/Hostname=$localip/g / etc / zabbix / zabbix_agentd . conf sed - i s/Server=127.0.0.1/Server=$SERVERIP/g / etc / zabbix / zabbix_agentd . conf sed - i s/ServerActive=127.0.0.1/ServerActive=$SERVERIP:10051/g / etc / zabbix / zabbix_agentd . conf sed - i 261a\\UnsafeUserParameters=1 / etc / zabbix / zabbix_agentd . conf sed - i 168a\\HostMetadataItem=system.uname / etc / zabbix / zabbix_agentd . conf chkconfig zabbix - agent on service zabbix - agent start windows zabbix_agentd . exe – c c :\\ zabbix \\ zabbix_agentd . conf - i zabbix_agentd . exe – c c :\\ zabbix \\ zabbix_agentd . conf – s","title":"agent"},{"location":"zabbix/#_3","text":"events #!/bin/bash #this script name is delete_events.sh host= localhost socket= /data/perconadata5.6/mysql.sock user= zabbix pass= zabbix port= 3306 time=`date -d last-month +%Y-%m-01` mysql -u $user -p $pass -h $host -S $socket -P $port EOF use zabbix; delete from events where clock = UNIX_TIMESTAMP( ${time} ) limit 40000; EOF ------------------------------------------------------------------------------ zabbix.service zabbix_server stop http service httpd stop : mysql -u root(zabbix) -p use zabbix :  SELECT table_name AS Tables , round(((data_length + index_length) / 1024 / 1024), 2) Size in MB FROM information_schema.TABLES WHERE table_schema = zabbix ORDER BY (data_length + index_length) DESC; truncate table history; truncate table history_uint; truncate table alerts; truncate table trends_uint; truncate table trends; truncate table history_text; truncate table events; delete,,ID.","title":""},{"location":"zabbix2/","text":"grafana grafana  grafana - zabbix ， ,  grafana  grafana - zabbix ， 2  yum install https : // grafanarel . s3 . amazonaws . com / builds / grafana - 2 . 5 . 0 - 1 . x86_64 . rpm   / usr / sbin / grafana - server  / etc / init . d / grafana - server  / etc / sysconfig / grafana - server  / etc / grafana / grafana . ini systemd  grafana - server . service  / var / log / grafana / grafana . log sqlite3  / var / lib / grafana / grafana . db  shell # sudo service grafana - server start   grafana  grafana - server  3000  shell # sudo / sbin / chkconfig --add grafana-server #### CentOS7 #### shell # sudo systemctl daemon - reload shell # sudo systemctl start grafana - server shell # sudo systemctl status grafana - server shell # sudo systemctl enable grafana - server . service  grafana - zabbix  wget https : // github . com / alexanderzobnin / grafana - zabbix / archive / v2 . 5 . 1 . tar . gz tar - zxf grafana - zabbix - 2 . 5 . 1 . tar . gz cd grafana - zabbix - 2 . 5 . 1 / cp - r zabbix / / usr / share / grafana / public / app / plugins / datasource / cd / usr / share / grafana / public / app / plugins / datasource / zabbix /  plugin . json { pluginType : datasource , name : Zabbix , type : zabbix , serviceName : ZabbixAPIDatasource , module : app/plugins/datasource/zabbix/datasource , partials : { config : app/plugins/datasource/zabbix/partials/config.html } , username : guangyu.liang , zabbix web   password : 1qaz2wsx , metrics : true , annotations : true }  http : // ip : 3000 / login  admin  admin http : // www . 2 cto . com / net / 201601 / 487722 . html （）  mail zabbix  PidFile =/ tmp / zabbix_agentd . pid LogFile =/ tmp / zabbix_agentd . log #Server=192.168.20.27 ServerActive = 192.168.20.27 : 10051 #Hostname=rongxin01 HostnameItem = system . hostname EnableRemoteCommands = 1 LogRemoteCommands = 1 RefreshActiveChecks = 60 BufferSize = 10000 StartAgents = 5 MaxLinesPerSecond = 200 Timeout = 30 Include =/ usr / local / zabbix / etc / zabbix_agentd . conf . d / LoadModulePath =/ usr / local / zabbix / share / zabbix / modules mail   sendmail  postfix / etc / init . d / sendmail stop chkconfig sendmail off tar – zxf mailx - 12.5 . tar . gz make make install UCBINSTALL =/ usr / bin / install cp / usr / local / bin / mailx / bin / mail vi / etc / nail . rc set from = test001 @ sina . com set smtp = smtp : //smtp.sina.cn:25 set smtp - auth - user = test001 @ sina . com set smtp - auth - password = test001  echo this is test | mail - v - s subject lgy_root @163. com vim / etc / zabbix / zabbix_server . conf AlertScriptsPath =/ usr / local / zabbix / share / zabbix / alertscripts vim / usr / local / zabbix / alertscripts / sendmail . sh #!/bin/bash echo $3 | / bin / mail - s $2 $ 1 2 、 sendEmail #!/bin/bash export smtpemailfrom = monitor @3 mang . com export zabbixemailto = $ 1 ( ， ) export zabbixsubject = $ 2 export zabbixbody = $ 3 export smtpserver = smtp . ym .163 . com export smtplogin = monitor @3 mang . com export smtppass = 123 qwe / usr / local / bin / sendEmail - o tls = no - f $ smtpemailfrom - t $ zabbixemailto - u $ zabbixsubject - m $ zabbixbody - s $ smtpserver : 25 - xu $ smtplogin - xp $ smtppass zabbix key zabbix  zabbix agent ， agent ， agent ，  agent （ active ）。 agent ： zabbix server  zabbix agent 。 agent （ active ）： zabbix agent  zabbix server 。  key ， mass update ， key   keys   zabbix agent  key ，， zabbix agent  key ，  key 。 agent . hostname  (  ) agent . ping  ( 1 : : ) -  nodata ()  agent . version zabbix agent  kernel . maxfiles  open files  kernel . maxproc  log [ file , regexp , encoding , maxlines , mode , output ]  file -  regexp -  encoding -  maxlines - zabbix agent  server  proxy 。  zabbxi_agentd . conf ’ MaxLinesPerSecond ’ mode - : all (  ) , skip (  ) . mode  2 . 0  output - ，. : log [ / var / log / syslog ] log [ / var / log / syslog , error ] log [ / home / zabbix / logs / logfile ,,, 100 ] logrt [ file_pattern , regexp , encoding , maxlines , mode , output ] Monitoring of log file with log rotation support . file_pattern -  net . dns [ ip , zone , type , timeout , count ]  DNS  0 – DNS  1 - DNS  ip - DNS  ip  (  DNS , ignored onWindows ) zone -  type -  (  SOA ) , type : ANY , A , NS , CNAME , MB , MG , MR , PTR , MD , MF , MX , SOA , NULL , WKS (  windows ) , HINFO , MINFO , TXT , SRV SRV timeout ( ignored on Windows ) –  (  1  ) count ( ignored on Windows ) –  (  2 )  key : net . dns [ 8 . 8 . 8 . 8 , zabbix . com , MX , 2 , 1 ] net . dns . record [ ip , zone , type , timeout , count ]  DNS  DNS . ip - DNS  ip  (  DNS , ignored on Windows ) zone -  type -  (  SOA , net . dns ) timeout ( ignored on Windows ) –  (  1  ) count ( ignored on Windows ) –  (  2 )  key : net . dns . record [ 8 . 8 . 8 . 8 , ttlsa . com , MX , 2 , 1 ] net . if . collisions [ if ] Out - of - window collision . Number of collisions . Integer . if -  net . if . discovery . discovery . JSON  net . if . in [ if , mode ] . if -  mode - : bytes -  (  ) packets -  errors -  dropped -   keys : net . if . in [ eth0 , errors ] net . if . in [ eth0 ] net . if . out [ if , mode ] （ net . if . in ） net . if . total [ if , mode ]  / （ net . if . in ） net . tcp . listen [ port ]  0 – （ not listen ） 1 – in LISTEN stateport : net . tcp . listen [ 80 ] net . tcp . port [ ip , port ]  TCP  0 – cannot connect 1 – can connect ip - IP  (  127 . 0 . 0 . 1 ) port -  : net . tcp . port [, 80 ]  web  net . tcp . service [ service , ip , port ] ， 0 –  1 –  service - : ssh , ntp , ldap , smtp , ftp , http , pop , nntp , imap , tcp , https , telnet ip - IP  (  127 . 0 . 0 . 1 ) port -  (  )  key : net . tcp . service [ ftp ,, 45 ] net . tcp . service . perf [ service , ip , port ]  0 –  ; seconds –  service - : ssh , ntp , ldap , smtp , ftp , http , pop , nntp , imap , tcp , https , telnet ip - IP  (  127 . 0 . 0 . 1 ) port -  (  )  key : net . tcp . service . perf [ ssh ] net . udp . listen [ port ] proc . mem [ name , user , mode , cmdline ]  (  ) . name -  (  “ all processes ” ) user -  ( “ all users ” ) mode - : avg , max , min , sum (  ) cmdline -  (  )  keys : proc . mem [, root ] – root  proc . mem [ zabbix_server , zabbix ] – zabbix  zabbix_server  proc . mem [, oracle , max , oracleZABBIX ] proc . num [ name , user , state , cmdline ]  name -  ( “ all processes ” ) user -  (  “ all users ” ) state - : all (  ) , run , sleep , zomb cmdline -  (  )  keys : proc . num [, mysql ] – MySQL  proc . num [ apache2 , www - data ] – www - data  apache2  proc . num [, oracle , sleep , oracleZABBIX ] ： Windows  name  user  sensor [ device , sensor , mode ]  device -  sensor -  mode - : avg , max , min  key : sensor [ w83781d - i2c - 0 - 2 d , temp1 ] Prior to Zabbix 1 . 8 . 4 , the sensor [ temp1 ] format was used . On Linux 2 . 6 + ,  / sys / class / hwmon . On OpenBSD ,  hw . sensors MIB . keys : sensor [ cpu0 , temp0 ] – CPU0  sensor [ cpu [ 0 - 2 ]$, temp , avg ] – cpu  Zabbix 1 . 8 . 4  OpenBSD system . boottime . unix  system . cpu . intr  system . cpu . load [ cpu , mode ] CPU  cpu - : all (  ) , percpu (  cpu  ) mode - : avg1 ( 1   ) , avg5 ( 5  ) , avg15 ( 15  )  key : system . cpu . load [, avg5 ] system . cpu . num [ type ] CPU  type - : online (  ) , max : system . cpu . num system . cpu . switches : system [ switches ] system . cpu . util [ cpu , type , mode ] CPU  cpu - cpu  (  cpu ) type - : idle , nice , user (  ) , system ( windows ）, iowait , interrupt , softirq , steal mode - : avg1 ( ， ) , avg5 ( 5 , avg15 ( 15  )  key : system . cpu . util [ 0 , user , avg5 ] system . hostname [ type ]  type (  windows  ) – : netbios (  ) or host system . hw . chassis [ info ]  info - full (  ) , model , serial , type  vendor : system . hw . chassis Hewlett - Packard HP Pro 3010 Small Form Factor PC CZXXXXXXXX Desktop ] ： root ，。 system . hw . cpu [ cpu , info ]  CPU  /  cpu - cpu  all (  ) info - full (  ) , curfreq , maxfreq , model  vendor : system . hw . cpu [ 0 , vendor ] AuthenticAMD  / proc / cpuinfo 、 / sys / devices / system / cpu / [ cpunum ] / cpufreq / cpuinfo_max_freq .  CPU  curfreq  maxfreq ,  ( Hz ) . system . hw . devices [ type ]  PCI  USB  type - pci (  ) or usb : system . hw . devices [ pci ] 00 : 00 . 0 Host bridge : Advanced Micro Devices [ AMD ] RS780 Host Bridge [..]  lspci  lsusb (  ) system . hw . macaddr [ interface , format ]  MAC  interface - all (  )  format - full (  ) 、 short : system . hw . macaddr [ eth0$ , full ] [ eth0 ] 00 : 11 : 22 : 33 : 44 : 55  mac   format  short ， MAC  system . localtime [ type ] . system . run [ command , mode ]  command -  mode - wait ( ,  ) , nowait (  )  512 KB ，。  : system . run [ ls - l / ] –  / . Note : , agent  EnableRemoteCommands = 1  system . stat [ resource , type ]  ent system . sw . arch  : system . sw . arch i686 system . sw . os [ info ]  info - full ( default ) , short , name : system . sw . os [ short ] Ubuntu 2 . 6 . 35 - 28 . 50 - generic 2 . 6 . 35 . 11 ： / proc / version [ short ] / proc / version_signature [ name ] / etc / issue . net system . sw . packages [ package , manager , format ]  package - all (  )  manager - all (  ) or a package manager format - full (  ) ， short : system . sw . packages [ mini , dpkg , short ] system . swap . in [ device , type ]  IN （） device -  (  all ) type - : count ( swapins  ) , sectors ( sectors swapped in ) , pages ( pages swapped in ) .  key : system . swap . in [, pages ] : Linux 2 . 4 : / proc / swaps , / proc / partitions , / proc / stat Linux 2 . 6 : / proc / swaps , / proc / diskstats , / proc / vmstat system . swap . out [ device , type ] Swap out ( f  ) . device - swap  (  all ) type - count ( number of swapouts ) , sectors ( sectors swapped out ) , pages ( pages swapped out ) .   key : system . swap . out [, pages ] : Linux 2 . 4 : / proc / swaps , / proc / partitions , / proc / stat Linux 2 . 6 : / proc / swaps , / proc / diskstats , / proc / vmstat system . swap . size [ device , type ]  device -  (  all ) type - free ( free swap space , default ) , pfree ( free swap space , in percent ) , pused ( used swap space , in percent ) , total ( total swap space ) , used ( used swap space )  system . swap . size [, pfree ] –  swap  system . uname . system . uptime  (  )  s / uptime  system . users . num  agent  who  vfs . dev . read [ device , type , mode ] ，（ type ） device -  (  “ all ” ) type - : sectors , operations , bytes , sps , ops , bps ( ,  ) . sps , ops , bps stand for : sectors , operations , bytes per second , respectively mode - : avg1 , avg5 , avg15 . :  type  sps , ops , bps ，。  TYPE ： FreeBSD – bps Linux – sps OpenBSD – operations Solaris – bytes  key : vfs . dev . read [, operations ] vfs . dev . write [ device , type , mode ] ， device -  (  all ) type - sectors , operations , bytes , sps , ops , bps mode - one of avg1 ( default ) , avg5 , avg15 . example : vfs . dev . write [, operations ] Old naming : io vfs . file . cksum [ file ]  UNIX cksum . file -  vfs . file . contents [ file , encoding ] ， LF / CR characters . file -  : vfs . file . contents [ / etc / passwd ]  64 KB . vfs . file . exists [ file ]  1 –  0 –  file -  vfs . file . md5sum [ file ]  MD5  MD5  file -  vfs . file . regexp [ file , regexp , encoding , start line , end line , output ] ， file -  regexp - GNU  encoding -  start line - ， end line - ， : vfs . file . regexp [ / etc / passwd , zabbix ] vfs . file . regexp [ / path / to / some / file ,” ( [ 0 - 9 ] + ) $”,, 3 , 5 ,\\ 1 ] vfs . file . regexp [ / etc / passwd , ^ zabbix :.: ( [ 0 - 9 ] + ) ,,,,\\ 1 ] vfs . file . regmatch [ file , regexp , encoding , start line , end line ]  0 –  1 –  file -  regexp - GNU  encoding -  start line - ， end line - ， : vfs . file . regmatch [ / var / log / app . log , error ] vfs . file . size [ file ]  fzabbix  vfs . file . time [ file , mode ]  Unix . mode - modify ( ,  ) , access – , change –  : vfs . file . time [ / etc / passwd , modify ] ： vfs . fs . discovery   lld . JSON  vfs . fs . inode [ fs , mode ] inodes  fs -  mode - total (  ) , free , used , pfree (  ) , pused (  ) : vfs . fs . inode [ / , pfree ] vfs . fs . size [ fs , mode ] ， fs -  mode - total (  ) , free , used , pfree (  ) , pused (  ) . : vfs . fs . size [ / tmp , free ] vm . memory . size [ mode ]  mode - total (  ) , active , anon , buffers , cached , exec , file , free , inactive , pinned , shared , wired , used , pused , available  vm . memory . size [] ： ： total -  ： : active , anon , buffers , cached , exec , file , free , inactive , pinned , shared , wired . ：，，: used , pused , available , pavailable . web . page . get [ host , path , port ]  host -  /  path - ， / port - ， 80 . : web . page . get [ web . page . perf [ host , path , port ] ， 0  host -  /  path - html ， / port - , 80 web . page . regexp [ host , path , port , regexp , length , output ]   (  ) . host -  path - html  (  / ) port -  (  80 ) regexp - GNU  length -  output - . zabbix api For Zabbix proxy database only schema . sql should be imported ( no images . sql nor data . sql ) zabbix_proxy  schema . sql zabbix - key https : // www . zabbix . com / documentation / 2.4 / manual / config / items / itemtypes / zabbix_agent api https : // www . zabbix . com / documentation / 2.4 / manual / api zabbix  https : // www . zabbix . com / documentation / 2.4 / manual / appendix / install / db_scripts post  data  # coding:utf-8 import json import urllib2 def zab_api ( data ): url = http://monitor.3mang.com/zabbix/api_jsonrpc.php header = { Content-Type : application/json } request = urllib2 . Request ( url , data , header ) # for key in header: # request.add_header(key, header[key]) result = urllib2 . urlopen ( request ) response = json . loads ( result . read ()) result . close () return response auth_data = json . dumps ({ jsonrpc : 2.0 , method : user.login , params : { user : guangyu.liang , password : 1qaz2wsx }, id : 2 }) auth = zab_api ( auth_data )[ result ] hostget = json . dumps ({ jsonrpc : 2.0 , method : host.get , params : { output : [ hostid , host ], selectInterfaces : [ interfaceid , ip ] }, id : 2 , auth : auth }) hostgroup = json . dumps ({ jsonrpc : 2.0 , method : hostgroup.get , params : { output : extend , filter : { name : [ Linux servers , windows ]} }, id : 2 , auth : auth }) # print json.dumps(zab_api(hostgroup)[ result ], indent=4) for i in zab_api ( hostgroup )[ result ]: print , i [ name ], , groupid is: , i [ groupid ] template = json . dumps ({ jsonrpc : 2.0 , method : template.get , params : { output : extend , filter : { host : [ Template OS Linux , Template OS Windows ]} }, id : 3 , auth : auth }) # print json.dumps(zab_api(template)[ result ], indent=4) for i in zab_api ( template )[ result ]: print , i [ host ], , templateid is: , i [ templateid ] hostcreate = json . dumps ({ jsonrpc : 2.0 , method : host.create , params : { host : api test , interfaces : [ { type : 1 , # 1 - agent; 2 - SNMP; 3 - IPMI; 4 - JMX. main : 1 , useip : 1 , ip : 192.168.3.1 , dns : , port : 10050 } ], groups : [{ groupid : 2 }], templates : [{ templateid : 10001 }], inventory_mode : 1 , # -1 - disabled; 0 - (default) manual; 1 - automatic. # inventory : { # macaddress_a : 01234 , # macaddress_b : 56768 # } }, id : 4 , auth : auth }) # print zab_api(hostcreate) 1. user . login  zabbix server ： https : // www . zabbix . com / documentation / 2.2 / manual / api / reference / user / login python ： [ root @yang python ] # cat auth.py #!/usr/bin/env python2.7 #coding=utf-8 import json import urllib2 # based url and required header url = http://1.1.1.1/zabbix/api_jsonrpc.php header = { Content-Type : application/json } # auth user and password data = json . dumps ( { jsonrpc : 2.0 , method : user.login , params : { user : Admin , password : zabbix }, id : 0 }) # create request object request = urllib2 . Request ( url , data ) for key in header : request . add_header ( key , header [ key ]) # auth and get authid try : result = urllib2 . urlopen ( request ) except URLError as e : print Auth Failed, Please Check Your Name AndPassword: , e . code else : response = json . loads ( result . read ()) result . close () print Auth Successful. The Auth ID Is: , response [ result ] python ： [ root @yang python ] # python auth.py Auth Successful . The Auth ID Is : a0b82aae0842c2041386a61945af1180 curl ： curl - i - X POST - H Content-Type:application/json - d { jsonrpc : 2.0 , method : user.login , params :{ user : admin , password : zabbix }, auth : null , id : 0 } http://1.1.1.1/zabbix/api_jsonrpc.php curl ： { jsonrpc : 2.0 , result : b895ce91ba84fe247e444817c6773cc3 , id : 0 } 2. hostgroup . get  ID ，。 zabbix server   ID 。 ： https : // www . zabbix . com / documentation / 2.2 / manual / api / reference / hostgroup / get python ： [ root @yang python ] # catget_hostgroup_list.py #!/usr/bin/env python2.7 #coding=utf-8 import json import urllib2 # based url and required header url = http://1.1.1.1/zabbix/api_jsonrpc.php header = { Content-Type : application/json } # request json data = json . dumps ( { jsonrpc : 2.0 , method : hostgroup.get , params :{ output :[ groupid , name ], }, auth : 3c0e88885a8cf8af9502b5c850b992bd , # theauth id is what auth script returns, remeber it is string id : 1 , }) # create request object request = urllib2 . Request ( url , data ) for key in header : request . add_header ( key , header [ key ]) # get host list try : result = urllib2 . urlopen ( request ) except URLError as e : if hasattr ( e , reason ): print We failed to reach a server. print Reason: , e . reason elif hasattr ( e , code ): print The server could not fulfill the request. print Error code: , e . code else : response = json . loads ( result . read ()) result . close () print Number Of Hosts: , len ( response [ result ]) #print response for group in response [ result ]: print Group ID: , group [ groupid ], \\t GroupName: , group [ name ] python ： [ root @yang python ] # pythonget_hostgroup_list.py Number Of Hosts : 12 Group ID : 11 Group Name : DB Schedule Group ID : 14 Group Name : DG - WY - KD - Server Group ID : 5 Group Name : Discovered hosts Group ID : 7 Group Name : Hypervisors Group ID : 2 Group Name : Linux servers Group ID : 8 Group Name : monitored_linux Group ID : 9 Group Name : qsmind Group ID : 12 Group Name : qssec Group ID : 13 Group Name : switch Group ID : 1 Group Name : Templates Group ID : 6 Group Name : Virtual machines Group ID : 4 Group Name : Zabbix servers curl ： curl - i - X POST - H Content-Type:application/json - d { jsonrpc : 2.0 , method : hostgroup.get , params : { output :[ groupid , name ]}, auth : 11d2b45415d5de6770ce196879dbfcf1 , id : 0 } http://1.1.1.1/zabbix/ api_jsonrpc . php curl ： { jsonrpc : 2.0 , result :[{ groupid : 11 , name : DBSchedule },{ groupid : 14 , name : DG-WY-KD-Server }, { groupid : 5 , name : Discoveredhosts },{ groupid : 7 , name : Hypervisors },{ groupid : 2 , name : Linuxservers }, { groupid : 8 , name : monitored_linux },{ groupid : 9 , name : qsmind },{ groupid : 12 , name : qssec }, { groupid : 13 , name : switch },{ groupid : 1 , name : Templates },{ groupid : 6 , name : Virtualmachines }, { groupid : 4 , name : Zabbixservers }], id : 0 } 3. itemsid . get  ID  3  id ， id ， items 。 ： https : // www . zabbix . com / documentation / 2.2 / manual / api / reference / item python ： #!/usr/bin/env python2.7 #coding=utf-8 import json import urllib2 # based url and required header url = http://1.1.1.1/zabbix/api_jsonrpc.php header = { Content-Type : application/json } # request json data = json . dumps ( { jsonrpc : 2.0 , method : host.get , params :{ output :[ hostid , name ], groupids : 14 , }, auth : 3c0e88885a8cf8af9502b5c850b992bd , # theauth id is what auth script returns, remeber it is string id : 1 , }) # create request object request = urllib2 . Request ( url , data ) for key in header : request . add_header ( key , header [ key ]) # get host list try : result = urllib2 . urlopen ( request ) except URLError as e : if hasattr ( e , reason ): print We failed to reach a server. print Reason: , e . reason elif hasattr ( e , code ): print The server could not fulfill the request. print Error code: , e . code else : response = json . loads ( result . read ()) result . close () print Number Of Hosts: , len ( response [ result ]) for host in response [ result ]: print Host ID: , host [ hostid ], HostName: , host [ name ] [ root @yang python ] # cat get_items.py #!/usr/bin/env python2.7 #coding=utf-8 import json import urllib2 # based url and required header url = http://1.1.1.1/zabbix/api_jsonrpc.php header = { Content-Type : application/json } # request json data = json . dumps ( { jsonrpc : 2.0 , method : item.get , params :{ output :[ itemids , key_ ], hostids : 10146 , }, auth : 3c0e88885a8cf8af9502b5c850b992bd , # theauth id is what auth script returns, remeber it is string id : 1 , }) # create request object request = urllib2 . Request ( url , data ) for key in header : request . add_header ( key , header [ key ]) # get host list try : result = urllib2 . urlopen ( request ) except URLError as e : if hasattr ( e , reason ): print We failed to reach a server. print Reason: , e . reason elif hasattr ( e , code ): print The server could not fulfill the request. print Error code: , e . code else : response = json . loads ( result . read ()) result . close () print Number Of Hosts: , len ( response [ result ]) for host in response [ result ]: print host #print Host ID: ,host[ hostid ], HostName: ,host[ name ] python ： [ root @yang python ] # python get_items.py Number Of Hosts : 54 { u itemid : u 24986 , u key_ : u agent.hostname } { u itemid : u 24987 , u key_ : u agent.ping } { u itemid : u 24988 , u key_ : u agent.version } { u itemid : u 24989 , u key_ : u kernel.maxfiles } { u itemid : u 24990 , u key_ : u kernel.maxproc } { u itemid : u 25157 , u key_ : u net.if.in[eth0] } { u itemid : u 25158 , u key_ : u net.if.in[eth1] } … … curl ： curl - i - X POST - H Content-Type:application/json - d { jsonrpc : 2.0 , method : item.get , params : { output : itemids , hostids : 10146 , search :{ key_ : net.if.out[eth2] }}, auth : 11d2b45415d5de6770ce196879dbfcf1 , id : 0 } http://1.1.1.1/zabbix/api_jsonrpc.php #key curl ： { jsonrpc : 2.0 , result :[{ itemid : 25154 }], id : 0 } 5. history . get  4  items id ，，。 ： https : // www . zabbix . com / documentation / 2.2 / manual / api / reference / history / get python ： [ root @yang python ] # catget_items_history.py #!/usr/bin/env python2.7 #coding=utf-8 import json import urllib2 # based url and required header url = http://1.1.1.1/zabbix/api_jsonrpc.php header = { Content-Type : application/json } # request json data = json . dumps ( { jsonrpc : 2.0 , method : history.get , params :{ output : extend , history : 3 , itemids : 25159 , limit : 10 }, auth : 3c0e88885a8cf8af9502b5c850b992bd , # theauth id is what auth script returns, remeber it is string id : 1 , }) # create request object request = urllib2 . Request ( url , data ) for key in header : request . add_header ( key , header [ key ]) # get host list try : result = urllib2 . urlopen ( request ) except URLError as e : if hasattr ( e , reason ): print We failed to reach a server. print Reason: , e . reason elif hasattr ( e , code ): print The server could not fulfill the request. print Error code: , e . code else : response = json . loads ( result . read ()) result . close () print Number Of Hosts: , len ( response [ result ]) for host in response [ result ]: print host #print Host ID: ,host[ hostid ], HostName: ,host[ name ] python ： [ root @yang python ] # pythonget_items_history.py Number Of Hosts : 10 { u itemid : u 25159 , u ns : u 420722133 , u value : u 3008 , u clock : u 1410744079 } { u itemid : u 25159 , u ns : u 480606614 , u value : u 5720 , u clock : u 1410744139 } { u itemid : u 25159 , u ns : u 40905600 , u value : u 6144 , u clock : u 1410744200 } { u itemid : u 25159 , u ns : u 175337062 , u value : u 2960 , u clock : u 1410744259 } { u itemid : u 25159 , u ns : u 202705084 , u value : u 3032 , u clock : u 1410744319 } { u itemid : u 25159 , u ns : u 263158421 , u value : u 2864 , u clock : u 1410744379 } { u itemid : u 25159 , u ns : u 702285081 , u value : u 7600 , u clock : u 1410744439 } { u itemid : u 25159 , u ns : u 231191890 , u value : u 3864 , u clock : u 1410744499 } { u itemid : u 25159 , u ns : u 468566742 , u value : u 3112 , u clock : u 1410744559 } { u itemid : u 25159 , u ns : u 421679098 , u value : u 2952 , u clock : u 1410744619 } curl ： curl - i - X POST - H Content-Type:application/json - d { jsonrpc : 2.0 , method : history.get , params : { history : 3 , itemids : 25154 , output : extend , limit : 10 }, auth : 11d2b45415d5de6770ce196879dbfcf1 , id : 0 } http : // 1.1 . 1.1 / zabbix / api_jsonrpc . php curl ： { jsonrpc : 2.0 , result :[{ itemid : 25154 , clock : 1410744134 , value : 4840 , ns : 375754276 }, { itemid : 25154 , clock : 1410744314 , value : 5408 , ns : 839852515 },{ itemid : 25154 , clock : 1410744374 , value : 7040 , ns : 964558609 },{ itemid : 25154 , clock : 1410744554 , value : 4072 , ns : 943177771 },{ itemid : 25154 , clock : 1410744614 , value : 8696 , ns : 995289716 },{ itemid : 25154 , clock : 1410744674 , value : 6144 , ns : 992462863 },{ itemid : 25154 , clock : 1410744734 , value : 6472 , ns : 152634327 },{ itemid : 25154 , clock : 1410744794 , value : 4312 , ns : 479599424 },{ itemid : 25154 , clock : 1410744854 , value : 4456 , ns : 263314898 },{ itemid : 25154 , clock : 1410744914 , value : 8656 , ns : 840460009 }], id : 0 } 6. history . get  curl  limit  1 。 ，。 http : // www . iyunv . com / thread - 25496 - 1 - 1. html jmx ： zabbixserverJMX，ZabbixJavagateway，ZabbixJavagateway“JMXmanagementAPI” ，“-Dcom.sun.management.jmxremote”JMX。 ZabbixserverJavagatewayStartJavaPollers；JavagatewaySTART_POLLERS ，zabbixTimeout，，JavagatewayJMXcounter。 StartJavaPollersSTART_POLLERS。 ZabbixJavagateway。 ZabbixJMX zabbix-server yum -y install zabbix-java-gateway ，。 zabbix-java-gateway/etc/zabbix/zabbix_java_gateway.conf，，： #  LISTEN_IP=”0.0.0.0″ #  LISTEN_PORT=10052 # PID_FILE PID_FILE=”/var/run/zabbix/zabbix_java.pid” #  START_POLLERS=5 zabbix-java-gateway: service zabbix-java-gateway start zabbix-server，/etc/zabbix/zabbix_server.conf ，： # JavaGatewayIP JavaGateway=192.168.89.204 # JavaGateway JavaGatewayPort=10052 # javaGateway StartJavaPollers=5 ，zabbix-server： service zabbix-server restart  JMX JMXJMX，，JAVA，，JMX： enableJMX Apache Tomcat windows，TOMCAT_HOME/bin/catalina.bat，： set CATALINA_OPTS=%CATALINA_OPTS% -Djava.rmi.server.hostname=JMX_HOST set CATALINA_OPTS=%CATALINA_OPTS% -Djavax.management.builder.initial= set CATALINA_OPTS=%CATALINA_OPTS% -Dcom.sun.management.jmxremote=true set CATALINA_OPTS=%CATALINA_OPTS% -Dcom.sun.management.jmxremote.port=JMX_PORT set CATALINA_OPTS=%CATALINA_OPTS% -Dcom.sun.management.jmxremote.ssl=false set CATALINA_OPTS=%CATALINA_OPTS% -Dcom.sun.management.jmxremote.authenticate=false linux，TOMCAT_HOME/bin/catalina.sh，： CATALINA_OPTS= ${ CATALINA_OPTS } -Djava.rmi.server.hostname=JMX_HOST” CATALINA_OPTS= ${ CATALINA_OPTS } -Djavax.management.builder.initial=“ CATALINA_OPTS= ${ CATALINA_OPTS } -Dcom.sun.management.jmxremote=true” CATALINA_OPTS= ${ CATALINA_OPTS } -Dcom.sun.management.jmxremote.port=JMX_PORT“ CATALINA_OPTS=“ ${ CATALINA_OPTS } -Dcom.sun.management.jmxremote.ssl=false” CATALINA_OPTS=” ${ CATALINA_OPTS } -Dcom.sun.management.jmxremote.authenticate=false“ JMX_HOSTtomcatIP，zabbix-server，JMX_PORTJMX，12345，tomcat，JMX。 tomcat 1.  tomcat  Extras  JMX Remote jar 。 tomcat/lib . #wget –S http://mirror.bit.edu.cn/apache/tomcat/tomcat-6/v6.0.39/bin/extras/catalina-jmx-remote.jar # mv catalina-jmx-remote.jar /webapp/tomcat6/lib/ 2.  tomcat/bin  catalina.sh ，： CATALINA_OPTS= -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=fa lse -Djava.rmi.server.hostname=ip 3.tomcat # cd /usr/local/tomcat/bin/ # ./startup.sh 4.cmdline-jmxclient-0.10.3.jar #wget http://repo.typesafe.com/typesafe/repo/cmdline-jmxclient/cmdline-jmxclient/0.10.3/cmdline-jmxclient-0.10.3.jar 5.  # java -jar cmdline-jmxclient-0.10.3.jar - localhost:12345 java.lang:type=Memory NonHeapMemoryUsage 01/26/2014 11:55:55 +0800 org.archive.jmx.Client NonHeapMemoryUsage: committed: 52690944 init: 24313856 max: 136314880 used: 52454776 discover rule ， tcp  portscan . py zabbix ， netstat - p chmod + s / bin / netstat  sudo #!/usr/bin/env python import os import json data = {} tcp_list = [] port_list = [] command = netstat -ntl | awk {print $4} | grep 0.0.0.0 | awk -F : {print $2} line = os . popen ( command ) . readlines () for port in line : port_dict = {} port = port . replace ( \\n , ) if int ( port ) 20000 : continue port_dict [ {#TCP_PORT} ] = port . replace ( \\n , ) tcp_list . append ( port_dict ) data [ data ] = tcp_list jsonStr = json . dumps ( data , sort_keys = True , indent = 4 ) print jsonStr ： { data : [ { {#TCP_PORT} : 843 }, { {#TCP_PORT} : 3035 }, { {#TCP_PORT} : 10050 } ] }  win  zabbix_agent  zabbix_agentd . conf UnsafeUserParameters = 1 UserParameter = tcpportlisten , python / etc / zabbix / portscan . py  zabbix_agent 。  zabbix_server  zabbix_get 。 zabbix_get - s ip - k tcpportlisten  agent 。  discover  Discovery (  ) ， Create discovery rule (  ) zabbix  discovery  -  1  | ㄨ、 Linux  tcp port discover  Item zabbix  discovery  -  2  | ㄨ、 Linux  trigger zabbix  discovery  -  3  | ㄨ、 Linux  { Template OS Linux : net . tcp . listen [{ #TCP_PORT}].count(#3,0,eq)} 1 ， Template OS Linux ，， . count ( #3,0,eq)} 1  0 ， io disk_scan . py #!/usr/bin/env python from json import dumps from commands import getoutput result = {} disklist = [] disks = getoutput ( egrep \\\\ bsd[a-z] \\\\ b| \\\\ bxvd[a-z] \\\\ b| \\\\ bvd[a-z] \\\\ b /proc/diskstats | awk {print $3} ) for disk in disks . split ( \\n ): if len ( disk ) != 0 : disklist . append ({ {#DISK_NAME} : disk }) result [ data ] = disklist print dumps ( result , indent = 4 , sort_keys = True ) vi / usr / local / zabbix / etc / zabbix_agentd . conf UserParameter = disk . discovery , / usr / bin / python / etc / zabbix / disk_scan . py UserParameter = custom . vfs . dev . read . ops [ * ], cat / proc / diskstats | grep $ 1 | head - 1 | awk {print $$4} //  UserParameter = custom . vfs . dev . read . ms [ * ], cat / proc / diskstats | grep $ 1 | head - 1 | awk {print $$7} //  UserParameter = custom . vfs . dev . write . ops [ * ], cat / proc / diskstats | grep $ 1 | head - 1 | awk {print $$8} //  UserParameter = custom . vfs . dev . write . ms [ * ], cat / proc / diskstats | grep $ 1 | head - 1 | awk {print $$11} //  UserParameter = custom . vfs . dev . io . active [ * ], cat / proc / diskstats | grep $ 1 | head - 1 | awk {print $$12} UserParameter = custom . vfs . dev . io . ms [ * ], cat / proc / diskstats | grep $ 1 | head - 1 | awk {print $$13} //  IO  UserParameter = custom . vfs . dev . read . sectors [ * ], cat / proc / diskstats | grep $ 1 | head - 1 | awk {print $$6} // （ 512 B ） UserParameter = custom . vfs . dev . write . sectors [ * ], cat / proc / diskstats | grep $ 1 | head - 1 | awk {print $$10} // （ 512 B ） UserParameter = custom . vfs . dev . iowait [ * ], iostat - x 1 2 | grep $ 1 | tail - n 1 | awk {print $$10} tcp /etc/zabbix/zabbix_agentd.d/tcp_net.conf UserParameter=TIME_WAIT,netstat -an | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}' | grep TIME_WAIT |awk '{print $2}' UserParameter=CLOSE_WAIT,netstat -an | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}' | grep CLOSE_WAIT |awk '{print $2}' UserParameter=FIN_WAIT1,netstat -an | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}' | grep FIN_WAIT1 |awk '{print $2}' UserParameter=ESTABLISHED,netstat -an | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}' | grep ESTABLISHED |awk '{print $2}' UserParameter=SYN_RECV,netstat -an | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}' | grep SYN_RECV |awk '{print $2}' UserParameter=LAST_ACK,netstat -an | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}' | grep LAST_ACK |awk '{print $2}' UserParameter=LISTEN,netstat -an | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}' | grep LISTEN |awk '{print $2}' zabbix_proxy yum install zabbix - proxy zabbix - proxy - mysql mysql - server - y mysql create database zabbix_proxy ; grant all on zabbix_proxy . * to zabbix @ 127.0.0.1 identified by zbpass ; delete from mysql . user where user = ; flush privileges ;  mysql zabbix_proxy / usr / share / doc / zabbix - proxy - mysql - 2 . 4 . 8 / create / schema . sql cat / etc / zabbix / zabbix_proxy . conf  Server = 172 . 16 . 10 . 126 #  Zabbix Server Hostname =  ip DBHost = localhost #  DBName = zabbix_proxy #  DBUser = zbuser #  DBPassword = zbpass #  agent  server  proxy  ip  key  agent  not found  proxy  agent  ztree https : // github . com / spide4k / zatree 1 ： git clone https : // github . com / spide4k / zatree . git zatree 2 ：， zatree  zabbix  php  php - xml 、 php - gd 、 php - mysql  zabbix web ， zatree - zabbix - 2 . 4 . 5 . tar . gz ， 3 ： zabbix   conf / zabbix . conf . php   4 ： web interface , zatree / zabbix_config . php user = xxx , // web  zabbix  password = xxx , // web  http_user = xxx , // httpsweb  http_password = xxx , // httpsweb     zabbix / zatree / graph . php   411 - 416  div align = center style = font-size:12px; font size = 5px color = red ,,, / font br font size = 2px color = red  zatree / graph . php  / font br img src = static/yunweibang-weixin.jpg / br a href = https://github.com/spide4k/zatree target = _blank Zatree / a version 2 . 4 for Zabbix 2 . 4 . x ,  QQ : 271659981 , : yunweibang / div  《 zabbix 》， zabbix server ， Host 。 ， Active agent  zabbix server ， zabbix server  agent  host 。 ，。 zabbix agent ， server  trigger ， ，。 2 .  2 . 1   server ip 1 2 # cat / usr / local / zabbix - 2 . 2 . 2 / etc / zabbix_agentd . conf | grep - E ^ ServerActive ServerActive = 66 . 175 . 222 . 232  Hostname 1 2 # cat / usr / local / zabbix - 2 . 2 . 1 / etc / zabbix_agentd . conf | grep - E ^ Hostname Hostname = auto - reg - for - ttlsa - 01 ： zabbix_agentd . conf  Hostname ， zabbix  Hostname ， agent （ hostname ）  metadataitem 1 2 cat / usr / local / zabbix - 2 . 2 . 1 / etc / zabbix_agentd . conf | grep HostMetadataItem = HostMetadataItem = system . uname 2 . 2  action ： configuration action Event source （ Auto registration ） Create Action ， action 2 . 2 . 1 action  hostmetadata  Action ，， 2 . 2 . 2 Conditions  hostmetadata Host metadata  Linux  2 . 2 . 3 ， metadata ，。 2 . 2 . 3 operations  hostmetadata  active host ， server ：  agent  host   agent  linux servers  agent  link  Template OS linux 3 .   / tmp / zabbix_server . log ： 1 16585 : 20150203 : 161110 . 910 enabling Zabbix agent checks on host auto-reg-for-ttlsa-01 : host became available ， host ， host ： hostmetadata 4 . HostMetadataItem  HostMetadata ：，。 linux  windows ， template  4 . 1 HostMetadataItem  1 HostMetadataItem = system . uname  key 4 . 2 HostMetadata  1 HostMetadata : Linux hehehehehehehehe xxxxx   metadata ，。 key  UserParameter = mysql . ping , mysqladmin - uroot ping | grep - c alive  1  MySQL ， 0  MySQL  UserParameter = key [ * ], command Key . [ * ] Command ， key [] $1  $9 ， 9 。 $0 .  1 .  $2 ，$ $2 ， awk ’{ print $ $2 }’，， ， zabbix ，。， zabbix 。 2 . zabbix ，： \\ ” ` * ? [ ] { } ~ $ ! ; ( ) | # @ 3 .  zabbix 2 . 0 ， zabbix 。 UserParameter = mysql . ping [ * ], mysqladmin - u $1 - p $2 ping | grep - c alive  MYSQL ，。 mysql . ping [ zabbix , our_password ] ? UserParameter = wc [ * ], grep - c $2 $1  wc [ / etc / passwd , root ] wc [ / etc / services , zabbix ] --------------------------------------------------------------------------------  mcu  cpu  UserParameter = proce . cpu [ * ], top - b - n 1 | grep $1 | awk {print $$9} UserParameter = proce . mem [ * ], sudo cat / proc / ` ps aux | grep $1 | grep - v grep | awk {print $$2} ` / smaps | grep - i pss | awk {sum += $$2}END{print sum*1024}","title":"zabbix2"},{"location":"zabbix2/#grafana","text":"grafana  grafana - zabbix ， ,  grafana  grafana - zabbix ， 2  yum install https : // grafanarel . s3 . amazonaws . com / builds / grafana - 2 . 5 . 0 - 1 . x86_64 . rpm   / usr / sbin / grafana - server  / etc / init . d / grafana - server  / etc / sysconfig / grafana - server  / etc / grafana / grafana . ini systemd  grafana - server . service  / var / log / grafana / grafana . log sqlite3  / var / lib / grafana / grafana . db  shell # sudo service grafana - server start   grafana  grafana - server  3000  shell # sudo / sbin / chkconfig --add grafana-server #### CentOS7 #### shell # sudo systemctl daemon - reload shell # sudo systemctl start grafana - server shell # sudo systemctl status grafana - server shell # sudo systemctl enable grafana - server . service  grafana - zabbix  wget https : // github . com / alexanderzobnin / grafana - zabbix / archive / v2 . 5 . 1 . tar . gz tar - zxf grafana - zabbix - 2 . 5 . 1 . tar . gz cd grafana - zabbix - 2 . 5 . 1 / cp - r zabbix / / usr / share / grafana / public / app / plugins / datasource / cd / usr / share / grafana / public / app / plugins / datasource / zabbix /  plugin . json { pluginType : datasource , name : Zabbix , type : zabbix , serviceName : ZabbixAPIDatasource , module : app/plugins/datasource/zabbix/datasource , partials : { config : app/plugins/datasource/zabbix/partials/config.html } , username : guangyu.liang , zabbix web   password : 1qaz2wsx , metrics : true , annotations : true }  http : // ip : 3000 / login  admin  admin http : // www . 2 cto . com / net / 201601 / 487722 . html （）","title":"grafana"},{"location":"zabbix2/#mail","text":"zabbix  PidFile =/ tmp / zabbix_agentd . pid LogFile =/ tmp / zabbix_agentd . log #Server=192.168.20.27 ServerActive = 192.168.20.27 : 10051 #Hostname=rongxin01 HostnameItem = system . hostname EnableRemoteCommands = 1 LogRemoteCommands = 1 RefreshActiveChecks = 60 BufferSize = 10000 StartAgents = 5 MaxLinesPerSecond = 200 Timeout = 30 Include =/ usr / local / zabbix / etc / zabbix_agentd . conf . d / LoadModulePath =/ usr / local / zabbix / share / zabbix / modules mail   sendmail  postfix / etc / init . d / sendmail stop chkconfig sendmail off tar – zxf mailx - 12.5 . tar . gz make make install UCBINSTALL =/ usr / bin / install cp / usr / local / bin / mailx / bin / mail vi / etc / nail . rc set from = test001 @ sina . com set smtp = smtp : //smtp.sina.cn:25 set smtp - auth - user = test001 @ sina . com set smtp - auth - password = test001  echo this is test | mail - v - s subject lgy_root @163. com vim / etc / zabbix / zabbix_server . conf AlertScriptsPath =/ usr / local / zabbix / share / zabbix / alertscripts vim / usr / local / zabbix / alertscripts / sendmail . sh #!/bin/bash echo $3 | / bin / mail - s $2 $ 1 2 、 sendEmail #!/bin/bash export smtpemailfrom = monitor @3 mang . com export zabbixemailto = $ 1 ( ， ) export zabbixsubject = $ 2 export zabbixbody = $ 3 export smtpserver = smtp . ym .163 . com export smtplogin = monitor @3 mang . com export smtppass = 123 qwe / usr / local / bin / sendEmail - o tls = no - f $ smtpemailfrom - t $ zabbixemailto - u $ zabbixsubject - m $ zabbixbody - s $ smtpserver : 25 - xu $ smtplogin - xp $ smtppass","title":" mail"},{"location":"zabbix2/#zabbix-key","text":"zabbix  zabbix agent ， agent ， agent ，  agent （ active ）。 agent ： zabbix server  zabbix agent 。 agent （ active ）： zabbix agent  zabbix server 。  key ， mass update ， key   keys   zabbix agent  key ，， zabbix agent  key ，  key 。 agent . hostname  (  ) agent . ping  ( 1 : : ) -  nodata ()  agent . version zabbix agent  kernel . maxfiles  open files  kernel . maxproc  log [ file , regexp , encoding , maxlines , mode , output ]  file -  regexp -  encoding -  maxlines - zabbix agent  server  proxy 。  zabbxi_agentd . conf ’ MaxLinesPerSecond ’ mode - : all (  ) , skip (  ) . mode  2 . 0  output - ，. : log [ / var / log / syslog ] log [ / var / log / syslog , error ] log [ / home / zabbix / logs / logfile ,,, 100 ] logrt [ file_pattern , regexp , encoding , maxlines , mode , output ] Monitoring of log file with log rotation support . file_pattern -  net . dns [ ip , zone , type , timeout , count ]  DNS  0 – DNS  1 - DNS  ip - DNS  ip  (  DNS , ignored onWindows ) zone -  type -  (  SOA ) , type : ANY , A , NS , CNAME , MB , MG , MR , PTR , MD , MF , MX , SOA , NULL , WKS (  windows ) , HINFO , MINFO , TXT , SRV SRV timeout ( ignored on Windows ) –  (  1  ) count ( ignored on Windows ) –  (  2 )  key : net . dns [ 8 . 8 . 8 . 8 , zabbix . com , MX , 2 , 1 ] net . dns . record [ ip , zone , type , timeout , count ]  DNS  DNS . ip - DNS  ip  (  DNS , ignored on Windows ) zone -  type -  (  SOA , net . dns ) timeout ( ignored on Windows ) –  (  1  ) count ( ignored on Windows ) –  (  2 )  key : net . dns . record [ 8 . 8 . 8 . 8 , ttlsa . com , MX , 2 , 1 ] net . if . collisions [ if ] Out - of - window collision . Number of collisions . Integer . if -  net . if . discovery . discovery . JSON  net . if . in [ if , mode ] . if -  mode - : bytes -  (  ) packets -  errors -  dropped -   keys : net . if . in [ eth0 , errors ] net . if . in [ eth0 ] net . if . out [ if , mode ] （ net . if . in ） net . if . total [ if , mode ]  / （ net . if . in ） net . tcp . listen [ port ]  0 – （ not listen ） 1 – in LISTEN stateport : net . tcp . listen [ 80 ] net . tcp . port [ ip , port ]  TCP  0 – cannot connect 1 – can connect ip - IP  (  127 . 0 . 0 . 1 ) port -  : net . tcp . port [, 80 ]  web  net . tcp . service [ service , ip , port ] ， 0 –  1 –  service - : ssh , ntp , ldap , smtp , ftp , http , pop , nntp , imap , tcp , https , telnet ip - IP  (  127 . 0 . 0 . 1 ) port -  (  )  key : net . tcp . service [ ftp ,, 45 ] net . tcp . service . perf [ service , ip , port ]  0 –  ; seconds –  service - : ssh , ntp , ldap , smtp , ftp , http , pop , nntp , imap , tcp , https , telnet ip - IP  (  127 . 0 . 0 . 1 ) port -  (  )  key : net . tcp . service . perf [ ssh ] net . udp . listen [ port ] proc . mem [ name , user , mode , cmdline ]  (  ) . name -  (  “ all processes ” ) user -  ( “ all users ” ) mode - : avg , max , min , sum (  ) cmdline -  (  )  keys : proc . mem [, root ] – root  proc . mem [ zabbix_server , zabbix ] – zabbix  zabbix_server  proc . mem [, oracle , max , oracleZABBIX ] proc . num [ name , user , state , cmdline ]  name -  ( “ all processes ” ) user -  (  “ all users ” ) state - : all (  ) , run , sleep , zomb cmdline -  (  )  keys : proc . num [, mysql ] – MySQL  proc . num [ apache2 , www - data ] – www - data  apache2  proc . num [, oracle , sleep , oracleZABBIX ] ： Windows  name  user  sensor [ device , sensor , mode ]  device -  sensor -  mode - : avg , max , min  key : sensor [ w83781d - i2c - 0 - 2 d , temp1 ] Prior to Zabbix 1 . 8 . 4 , the sensor [ temp1 ] format was used . On Linux 2 . 6 + ,  / sys / class / hwmon . On OpenBSD ,  hw . sensors MIB . keys : sensor [ cpu0 , temp0 ] – CPU0  sensor [ cpu [ 0 - 2 ]$, temp , avg ] – cpu  Zabbix 1 . 8 . 4  OpenBSD system . boottime . unix  system . cpu . intr  system . cpu . load [ cpu , mode ] CPU  cpu - : all (  ) , percpu (  cpu  ) mode - : avg1 ( 1   ) , avg5 ( 5  ) , avg15 ( 15  )  key : system . cpu . load [, avg5 ] system . cpu . num [ type ] CPU  type - : online (  ) , max : system . cpu . num system . cpu . switches : system [ switches ] system . cpu . util [ cpu , type , mode ] CPU  cpu - cpu  (  cpu ) type - : idle , nice , user (  ) , system ( windows ）, iowait , interrupt , softirq , steal mode - : avg1 ( ， ) , avg5 ( 5 , avg15 ( 15  )  key : system . cpu . util [ 0 , user , avg5 ] system . hostname [ type ]  type (  windows  ) – : netbios (  ) or host system . hw . chassis [ info ]  info - full (  ) , model , serial , type  vendor : system . hw . chassis Hewlett - Packard HP Pro 3010 Small Form Factor PC CZXXXXXXXX Desktop ] ： root ，。 system . hw . cpu [ cpu , info ]  CPU  /  cpu - cpu  all (  ) info - full (  ) , curfreq , maxfreq , model  vendor : system . hw . cpu [ 0 , vendor ] AuthenticAMD  / proc / cpuinfo 、 / sys / devices / system / cpu / [ cpunum ] / cpufreq / cpuinfo_max_freq .  CPU  curfreq  maxfreq ,  ( Hz ) . system . hw . devices [ type ]  PCI  USB  type - pci (  ) or usb : system . hw . devices [ pci ] 00 : 00 . 0 Host bridge : Advanced Micro Devices [ AMD ] RS780 Host Bridge [..]  lspci  lsusb (  ) system . hw . macaddr [ interface , format ]  MAC  interface - all (  )  format - full (  ) 、 short : system . hw . macaddr [ eth0$ , full ] [ eth0 ] 00 : 11 : 22 : 33 : 44 : 55  mac   format  short ， MAC  system . localtime [ type ] . system . run [ command , mode ]  command -  mode - wait ( ,  ) , nowait (  )  512 KB ，。  : system . run [ ls - l / ] –  / . Note : , agent  EnableRemoteCommands = 1  system . stat [ resource , type ]  ent system . sw . arch  : system . sw . arch i686 system . sw . os [ info ]  info - full ( default ) , short , name : system . sw . os [ short ] Ubuntu 2 . 6 . 35 - 28 . 50 - generic 2 . 6 . 35 . 11 ： / proc / version [ short ] / proc / version_signature [ name ] / etc / issue . net system . sw . packages [ package , manager , format ]  package - all (  )  manager - all (  ) or a package manager format - full (  ) ， short : system . sw . packages [ mini , dpkg , short ] system . swap . in [ device , type ]  IN （） device -  (  all ) type - : count ( swapins  ) , sectors ( sectors swapped in ) , pages ( pages swapped in ) .  key : system . swap . in [, pages ] : Linux 2 . 4 : / proc / swaps , / proc / partitions , / proc / stat Linux 2 . 6 : / proc / swaps , / proc / diskstats , / proc / vmstat system . swap . out [ device , type ] Swap out ( f  ) . device - swap  (  all ) type - count ( number of swapouts ) , sectors ( sectors swapped out ) , pages ( pages swapped out ) .   key : system . swap . out [, pages ] : Linux 2 . 4 : / proc / swaps , / proc / partitions , / proc / stat Linux 2 . 6 : / proc / swaps , / proc / diskstats , / proc / vmstat system . swap . size [ device , type ]  device -  (  all ) type - free ( free swap space , default ) , pfree ( free swap space , in percent ) , pused ( used swap space , in percent ) , total ( total swap space ) , used ( used swap space )  system . swap . size [, pfree ] –  swap  system . uname . system . uptime  (  )  s / uptime  system . users . num  agent  who  vfs . dev . read [ device , type , mode ] ，（ type ） device -  (  “ all ” ) type - : sectors , operations , bytes , sps , ops , bps ( ,  ) . sps , ops , bps stand for : sectors , operations , bytes per second , respectively mode - : avg1 , avg5 , avg15 . :  type  sps , ops , bps ，。  TYPE ： FreeBSD – bps Linux – sps OpenBSD – operations Solaris – bytes  key : vfs . dev . read [, operations ] vfs . dev . write [ device , type , mode ] ， device -  (  all ) type - sectors , operations , bytes , sps , ops , bps mode - one of avg1 ( default ) , avg5 , avg15 . example : vfs . dev . write [, operations ] Old naming : io vfs . file . cksum [ file ]  UNIX cksum . file -  vfs . file . contents [ file , encoding ] ， LF / CR characters . file -  : vfs . file . contents [ / etc / passwd ]  64 KB . vfs . file . exists [ file ]  1 –  0 –  file -  vfs . file . md5sum [ file ]  MD5  MD5  file -  vfs . file . regexp [ file , regexp , encoding , start line , end line , output ] ， file -  regexp - GNU  encoding -  start line - ， end line - ， : vfs . file . regexp [ / etc / passwd , zabbix ] vfs . file . regexp [ / path / to / some / file ,” ( [ 0 - 9 ] + ) $”,, 3 , 5 ,\\ 1 ] vfs . file . regexp [ / etc / passwd , ^ zabbix :.: ( [ 0 - 9 ] + ) ,,,,\\ 1 ] vfs . file . regmatch [ file , regexp , encoding , start line , end line ]  0 –  1 –  file -  regexp - GNU  encoding -  start line - ， end line - ， : vfs . file . regmatch [ / var / log / app . log , error ] vfs . file . size [ file ]  fzabbix  vfs . file . time [ file , mode ]  Unix . mode - modify ( ,  ) , access – , change –  : vfs . file . time [ / etc / passwd , modify ] ： vfs . fs . discovery   lld . JSON  vfs . fs . inode [ fs , mode ] inodes  fs -  mode - total (  ) , free , used , pfree (  ) , pused (  ) : vfs . fs . inode [ / , pfree ] vfs . fs . size [ fs , mode ] ， fs -  mode - total (  ) , free , used , pfree (  ) , pused (  ) . : vfs . fs . size [ / tmp , free ] vm . memory . size [ mode ]  mode - total (  ) , active , anon , buffers , cached , exec , file , free , inactive , pinned , shared , wired , used , pused , available  vm . memory . size [] ： ： total -  ： : active , anon , buffers , cached , exec , file , free , inactive , pinned , shared , wired . ：，，: used , pused , available , pavailable . web . page . get [ host , path , port ]  host -  /  path - ， / port - ， 80 . : web . page . get [ web . page . perf [ host , path , port ] ， 0  host -  /  path - html ， / port - , 80 web . page . regexp [ host , path , port , regexp , length , output ]   (  ) . host -  path - html  (  / ) port -  (  80 ) regexp - GNU  length -  output - .","title":"zabbix key"},{"location":"zabbix2/#zabbix-api","text":"For Zabbix proxy database only schema . sql should be imported ( no images . sql nor data . sql ) zabbix_proxy  schema . sql zabbix - key https : // www . zabbix . com / documentation / 2.4 / manual / config / items / itemtypes / zabbix_agent api https : // www . zabbix . com / documentation / 2.4 / manual / api zabbix  https : // www . zabbix . com / documentation / 2.4 / manual / appendix / install / db_scripts post  data  # coding:utf-8 import json import urllib2 def zab_api ( data ): url = http://monitor.3mang.com/zabbix/api_jsonrpc.php header = { Content-Type : application/json } request = urllib2 . Request ( url , data , header ) # for key in header: # request.add_header(key, header[key]) result = urllib2 . urlopen ( request ) response = json . loads ( result . read ()) result . close () return response auth_data = json . dumps ({ jsonrpc : 2.0 , method : user.login , params : { user : guangyu.liang , password : 1qaz2wsx }, id : 2 }) auth = zab_api ( auth_data )[ result ] hostget = json . dumps ({ jsonrpc : 2.0 , method : host.get , params : { output : [ hostid , host ], selectInterfaces : [ interfaceid , ip ] }, id : 2 , auth : auth }) hostgroup = json . dumps ({ jsonrpc : 2.0 , method : hostgroup.get , params : { output : extend , filter : { name : [ Linux servers , windows ]} }, id : 2 , auth : auth }) # print json.dumps(zab_api(hostgroup)[ result ], indent=4) for i in zab_api ( hostgroup )[ result ]: print , i [ name ], , groupid is: , i [ groupid ] template = json . dumps ({ jsonrpc : 2.0 , method : template.get , params : { output : extend , filter : { host : [ Template OS Linux , Template OS Windows ]} }, id : 3 , auth : auth }) # print json.dumps(zab_api(template)[ result ], indent=4) for i in zab_api ( template )[ result ]: print , i [ host ], , templateid is: , i [ templateid ] hostcreate = json . dumps ({ jsonrpc : 2.0 , method : host.create , params : { host : api test , interfaces : [ { type : 1 , # 1 - agent; 2 - SNMP; 3 - IPMI; 4 - JMX. main : 1 , useip : 1 , ip : 192.168.3.1 , dns : , port : 10050 } ], groups : [{ groupid : 2 }], templates : [{ templateid : 10001 }], inventory_mode : 1 , # -1 - disabled; 0 - (default) manual; 1 - automatic. # inventory : { # macaddress_a : 01234 , # macaddress_b : 56768 # } }, id : 4 , auth : auth }) # print zab_api(hostcreate) 1. user . login  zabbix server ： https : // www . zabbix . com / documentation / 2.2 / manual / api / reference / user / login python ： [ root @yang python ] # cat auth.py #!/usr/bin/env python2.7 #coding=utf-8 import json import urllib2 # based url and required header url = http://1.1.1.1/zabbix/api_jsonrpc.php header = { Content-Type : application/json } # auth user and password data = json . dumps ( { jsonrpc : 2.0 , method : user.login , params : { user : Admin , password : zabbix }, id : 0 }) # create request object request = urllib2 . Request ( url , data ) for key in header : request . add_header ( key , header [ key ]) # auth and get authid try : result = urllib2 . urlopen ( request ) except URLError as e : print Auth Failed, Please Check Your Name AndPassword: , e . code else : response = json . loads ( result . read ()) result . close () print Auth Successful. The Auth ID Is: , response [ result ] python ： [ root @yang python ] # python auth.py Auth Successful . The Auth ID Is : a0b82aae0842c2041386a61945af1180 curl ： curl - i - X POST - H Content-Type:application/json - d { jsonrpc : 2.0 , method : user.login , params :{ user : admin , password : zabbix }, auth : null , id : 0 } http://1.1.1.1/zabbix/api_jsonrpc.php curl ： { jsonrpc : 2.0 , result : b895ce91ba84fe247e444817c6773cc3 , id : 0 } 2. hostgroup . get  ID ，。 zabbix server   ID 。 ： https : // www . zabbix . com / documentation / 2.2 / manual / api / reference / hostgroup / get python ： [ root @yang python ] # catget_hostgroup_list.py #!/usr/bin/env python2.7 #coding=utf-8 import json import urllib2 # based url and required header url = http://1.1.1.1/zabbix/api_jsonrpc.php header = { Content-Type : application/json } # request json data = json . dumps ( { jsonrpc : 2.0 , method : hostgroup.get , params :{ output :[ groupid , name ], }, auth : 3c0e88885a8cf8af9502b5c850b992bd , # theauth id is what auth script returns, remeber it is string id : 1 , }) # create request object request = urllib2 . Request ( url , data ) for key in header : request . add_header ( key , header [ key ]) # get host list try : result = urllib2 . urlopen ( request ) except URLError as e : if hasattr ( e , reason ): print We failed to reach a server. print Reason: , e . reason elif hasattr ( e , code ): print The server could not fulfill the request. print Error code: , e . code else : response = json . loads ( result . read ()) result . close () print Number Of Hosts: , len ( response [ result ]) #print response for group in response [ result ]: print Group ID: , group [ groupid ], \\t GroupName: , group [ name ] python ： [ root @yang python ] # pythonget_hostgroup_list.py Number Of Hosts : 12 Group ID : 11 Group Name : DB Schedule Group ID : 14 Group Name : DG - WY - KD - Server Group ID : 5 Group Name : Discovered hosts Group ID : 7 Group Name : Hypervisors Group ID : 2 Group Name : Linux servers Group ID : 8 Group Name : monitored_linux Group ID : 9 Group Name : qsmind Group ID : 12 Group Name : qssec Group ID : 13 Group Name : switch Group ID : 1 Group Name : Templates Group ID : 6 Group Name : Virtual machines Group ID : 4 Group Name : Zabbix servers curl ： curl - i - X POST - H Content-Type:application/json - d { jsonrpc : 2.0 , method : hostgroup.get , params : { output :[ groupid , name ]}, auth : 11d2b45415d5de6770ce196879dbfcf1 , id : 0 } http://1.1.1.1/zabbix/ api_jsonrpc . php curl ： { jsonrpc : 2.0 , result :[{ groupid : 11 , name : DBSchedule },{ groupid : 14 , name : DG-WY-KD-Server }, { groupid : 5 , name : Discoveredhosts },{ groupid : 7 , name : Hypervisors },{ groupid : 2 , name : Linuxservers }, { groupid : 8 , name : monitored_linux },{ groupid : 9 , name : qsmind },{ groupid : 12 , name : qssec }, { groupid : 13 , name : switch },{ groupid : 1 , name : Templates },{ groupid : 6 , name : Virtualmachines }, { groupid : 4 , name : Zabbixservers }], id : 0 } 3. itemsid . get  ID  3  id ， id ， items 。 ： https : // www . zabbix . com / documentation / 2.2 / manual / api / reference / item python ： #!/usr/bin/env python2.7 #coding=utf-8 import json import urllib2 # based url and required header url = http://1.1.1.1/zabbix/api_jsonrpc.php header = { Content-Type : application/json } # request json data = json . dumps ( { jsonrpc : 2.0 , method : host.get , params :{ output :[ hostid , name ], groupids : 14 , }, auth : 3c0e88885a8cf8af9502b5c850b992bd , # theauth id is what auth script returns, remeber it is string id : 1 , }) # create request object request = urllib2 . Request ( url , data ) for key in header : request . add_header ( key , header [ key ]) # get host list try : result = urllib2 . urlopen ( request ) except URLError as e : if hasattr ( e , reason ): print We failed to reach a server. print Reason: , e . reason elif hasattr ( e , code ): print The server could not fulfill the request. print Error code: , e . code else : response = json . loads ( result . read ()) result . close () print Number Of Hosts: , len ( response [ result ]) for host in response [ result ]: print Host ID: , host [ hostid ], HostName: , host [ name ] [ root @yang python ] # cat get_items.py #!/usr/bin/env python2.7 #coding=utf-8 import json import urllib2 # based url and required header url = http://1.1.1.1/zabbix/api_jsonrpc.php header = { Content-Type : application/json } # request json data = json . dumps ( { jsonrpc : 2.0 , method : item.get , params :{ output :[ itemids , key_ ], hostids : 10146 , }, auth : 3c0e88885a8cf8af9502b5c850b992bd , # theauth id is what auth script returns, remeber it is string id : 1 , }) # create request object request = urllib2 . Request ( url , data ) for key in header : request . add_header ( key , header [ key ]) # get host list try : result = urllib2 . urlopen ( request ) except URLError as e : if hasattr ( e , reason ): print We failed to reach a server. print Reason: , e . reason elif hasattr ( e , code ): print The server could not fulfill the request. print Error code: , e . code else : response = json . loads ( result . read ()) result . close () print Number Of Hosts: , len ( response [ result ]) for host in response [ result ]: print host #print Host ID: ,host[ hostid ], HostName: ,host[ name ] python ： [ root @yang python ] # python get_items.py Number Of Hosts : 54 { u itemid : u 24986 , u key_ : u agent.hostname } { u itemid : u 24987 , u key_ : u agent.ping } { u itemid : u 24988 , u key_ : u agent.version } { u itemid : u 24989 , u key_ : u kernel.maxfiles } { u itemid : u 24990 , u key_ : u kernel.maxproc } { u itemid : u 25157 , u key_ : u net.if.in[eth0] } { u itemid : u 25158 , u key_ : u net.if.in[eth1] } … … curl ： curl - i - X POST - H Content-Type:application/json - d { jsonrpc : 2.0 , method : item.get , params : { output : itemids , hostids : 10146 , search :{ key_ : net.if.out[eth2] }}, auth : 11d2b45415d5de6770ce196879dbfcf1 , id : 0 } http://1.1.1.1/zabbix/api_jsonrpc.php #key curl ： { jsonrpc : 2.0 , result :[{ itemid : 25154 }], id : 0 } 5. history . get  4  items id ，，。 ： https : // www . zabbix . com / documentation / 2.2 / manual / api / reference / history / get python ： [ root @yang python ] # catget_items_history.py #!/usr/bin/env python2.7 #coding=utf-8 import json import urllib2 # based url and required header url = http://1.1.1.1/zabbix/api_jsonrpc.php header = { Content-Type : application/json } # request json data = json . dumps ( { jsonrpc : 2.0 , method : history.get , params :{ output : extend , history : 3 , itemids : 25159 , limit : 10 }, auth : 3c0e88885a8cf8af9502b5c850b992bd , # theauth id is what auth script returns, remeber it is string id : 1 , }) # create request object request = urllib2 . Request ( url , data ) for key in header : request . add_header ( key , header [ key ]) # get host list try : result = urllib2 . urlopen ( request ) except URLError as e : if hasattr ( e , reason ): print We failed to reach a server. print Reason: , e . reason elif hasattr ( e , code ): print The server could not fulfill the request. print Error code: , e . code else : response = json . loads ( result . read ()) result . close () print Number Of Hosts: , len ( response [ result ]) for host in response [ result ]: print host #print Host ID: ,host[ hostid ], HostName: ,host[ name ] python ： [ root @yang python ] # pythonget_items_history.py Number Of Hosts : 10 { u itemid : u 25159 , u ns : u 420722133 , u value : u 3008 , u clock : u 1410744079 } { u itemid : u 25159 , u ns : u 480606614 , u value : u 5720 , u clock : u 1410744139 } { u itemid : u 25159 , u ns : u 40905600 , u value : u 6144 , u clock : u 1410744200 } { u itemid : u 25159 , u ns : u 175337062 , u value : u 2960 , u clock : u 1410744259 } { u itemid : u 25159 , u ns : u 202705084 , u value : u 3032 , u clock : u 1410744319 } { u itemid : u 25159 , u ns : u 263158421 , u value : u 2864 , u clock : u 1410744379 } { u itemid : u 25159 , u ns : u 702285081 , u value : u 7600 , u clock : u 1410744439 } { u itemid : u 25159 , u ns : u 231191890 , u value : u 3864 , u clock : u 1410744499 } { u itemid : u 25159 , u ns : u 468566742 , u value : u 3112 , u clock : u 1410744559 } { u itemid : u 25159 , u ns : u 421679098 , u value : u 2952 , u clock : u 1410744619 } curl ： curl - i - X POST - H Content-Type:application/json - d { jsonrpc : 2.0 , method : history.get , params : { history : 3 , itemids : 25154 , output : extend , limit : 10 }, auth : 11d2b45415d5de6770ce196879dbfcf1 , id : 0 } http : // 1.1 . 1.1 / zabbix / api_jsonrpc . php curl ： { jsonrpc : 2.0 , result :[{ itemid : 25154 , clock : 1410744134 , value : 4840 , ns : 375754276 }, { itemid : 25154 , clock : 1410744314 , value : 5408 , ns : 839852515 },{ itemid : 25154 , clock : 1410744374 , value : 7040 , ns : 964558609 },{ itemid : 25154 , clock : 1410744554 , value : 4072 , ns : 943177771 },{ itemid : 25154 , clock : 1410744614 , value : 8696 , ns : 995289716 },{ itemid : 25154 , clock : 1410744674 , value : 6144 , ns : 992462863 },{ itemid : 25154 , clock : 1410744734 , value : 6472 , ns : 152634327 },{ itemid : 25154 , clock : 1410744794 , value : 4312 , ns : 479599424 },{ itemid : 25154 , clock : 1410744854 , value : 4456 , ns : 263314898 },{ itemid : 25154 , clock : 1410744914 , value : 8656 , ns : 840460009 }], id : 0 } 6. history . get  curl  limit  1 。 ，。 http : // www . iyunv . com / thread - 25496 - 1 - 1. html","title":"zabbix api"},{"location":"zabbix2/#jmx","text":"： zabbixserverJMX，ZabbixJavagateway，ZabbixJavagateway“JMXmanagementAPI” ，“-Dcom.sun.management.jmxremote”JMX。 ZabbixserverJavagatewayStartJavaPollers；JavagatewaySTART_POLLERS ，zabbixTimeout，，JavagatewayJMXcounter。 StartJavaPollersSTART_POLLERS。 ZabbixJavagateway。 ZabbixJMX zabbix-server yum -y install zabbix-java-gateway ，。 zabbix-java-gateway/etc/zabbix/zabbix_java_gateway.conf，，： #  LISTEN_IP=”0.0.0.0″ #  LISTEN_PORT=10052 # PID_FILE PID_FILE=”/var/run/zabbix/zabbix_java.pid” #  START_POLLERS=5 zabbix-java-gateway: service zabbix-java-gateway start zabbix-server，/etc/zabbix/zabbix_server.conf ，： # JavaGatewayIP JavaGateway=192.168.89.204 # JavaGateway JavaGatewayPort=10052 # javaGateway StartJavaPollers=5 ，zabbix-server： service zabbix-server restart  JMX JMXJMX，，JAVA，，JMX： enableJMX Apache Tomcat windows，TOMCAT_HOME/bin/catalina.bat，： set CATALINA_OPTS=%CATALINA_OPTS% -Djava.rmi.server.hostname=JMX_HOST set CATALINA_OPTS=%CATALINA_OPTS% -Djavax.management.builder.initial= set CATALINA_OPTS=%CATALINA_OPTS% -Dcom.sun.management.jmxremote=true set CATALINA_OPTS=%CATALINA_OPTS% -Dcom.sun.management.jmxremote.port=JMX_PORT set CATALINA_OPTS=%CATALINA_OPTS% -Dcom.sun.management.jmxremote.ssl=false set CATALINA_OPTS=%CATALINA_OPTS% -Dcom.sun.management.jmxremote.authenticate=false linux，TOMCAT_HOME/bin/catalina.sh，： CATALINA_OPTS= ${ CATALINA_OPTS } -Djava.rmi.server.hostname=JMX_HOST” CATALINA_OPTS= ${ CATALINA_OPTS } -Djavax.management.builder.initial=“ CATALINA_OPTS= ${ CATALINA_OPTS } -Dcom.sun.management.jmxremote=true” CATALINA_OPTS= ${ CATALINA_OPTS } -Dcom.sun.management.jmxremote.port=JMX_PORT“ CATALINA_OPTS=“ ${ CATALINA_OPTS } -Dcom.sun.management.jmxremote.ssl=false” CATALINA_OPTS=” ${ CATALINA_OPTS } -Dcom.sun.management.jmxremote.authenticate=false“ JMX_HOSTtomcatIP，zabbix-server，JMX_PORTJMX，12345，tomcat，JMX。 tomcat 1.  tomcat  Extras  JMX Remote jar 。 tomcat/lib . #wget –S http://mirror.bit.edu.cn/apache/tomcat/tomcat-6/v6.0.39/bin/extras/catalina-jmx-remote.jar # mv catalina-jmx-remote.jar /webapp/tomcat6/lib/ 2.  tomcat/bin  catalina.sh ，： CATALINA_OPTS= -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=fa lse -Djava.rmi.server.hostname=ip 3.tomcat # cd /usr/local/tomcat/bin/ # ./startup.sh 4.cmdline-jmxclient-0.10.3.jar #wget http://repo.typesafe.com/typesafe/repo/cmdline-jmxclient/cmdline-jmxclient/0.10.3/cmdline-jmxclient-0.10.3.jar 5.  # java -jar cmdline-jmxclient-0.10.3.jar - localhost:12345 java.lang:type=Memory NonHeapMemoryUsage 01/26/2014 11:55:55 +0800 org.archive.jmx.Client NonHeapMemoryUsage: committed: 52690944 init: 24313856 max: 136314880 used: 52454776","title":"jmx"},{"location":"zabbix2/#discover-rule","text":"， tcp  portscan . py zabbix ， netstat - p chmod + s / bin / netstat  sudo #!/usr/bin/env python import os import json data = {} tcp_list = [] port_list = [] command = netstat -ntl | awk {print $4} | grep 0.0.0.0 | awk -F : {print $2} line = os . popen ( command ) . readlines () for port in line : port_dict = {} port = port . replace ( \\n , ) if int ( port ) 20000 : continue port_dict [ {#TCP_PORT} ] = port . replace ( \\n , ) tcp_list . append ( port_dict ) data [ data ] = tcp_list jsonStr = json . dumps ( data , sort_keys = True , indent = 4 ) print jsonStr ： { data : [ { {#TCP_PORT} : 843 }, { {#TCP_PORT} : 3035 }, { {#TCP_PORT} : 10050 } ] }  win  zabbix_agent  zabbix_agentd . conf UnsafeUserParameters = 1 UserParameter = tcpportlisten , python / etc / zabbix / portscan . py  zabbix_agent 。  zabbix_server  zabbix_get 。 zabbix_get - s ip - k tcpportlisten  agent 。  discover  Discovery (  ) ， Create discovery rule (  ) zabbix  discovery  -  1  | ㄨ、 Linux  tcp port discover  Item zabbix  discovery  -  2  | ㄨ、 Linux  trigger zabbix  discovery  -  3  | ㄨ、 Linux  { Template OS Linux : net . tcp . listen [{ #TCP_PORT}].count(#3,0,eq)} 1 ， Template OS Linux ，， . count ( #3,0,eq)} 1  0 ，","title":"discover rule"},{"location":"zabbix2/#io","text":"disk_scan . py #!/usr/bin/env python from json import dumps from commands import getoutput result = {} disklist = [] disks = getoutput ( egrep \\\\ bsd[a-z] \\\\ b| \\\\ bxvd[a-z] \\\\ b| \\\\ bvd[a-z] \\\\ b /proc/diskstats | awk {print $3} ) for disk in disks . split ( \\n ): if len ( disk ) != 0 : disklist . append ({ {#DISK_NAME} : disk }) result [ data ] = disklist print dumps ( result , indent = 4 , sort_keys = True ) vi / usr / local / zabbix / etc / zabbix_agentd . conf UserParameter = disk . discovery , / usr / bin / python / etc / zabbix / disk_scan . py UserParameter = custom . vfs . dev . read . ops [ * ], cat / proc / diskstats | grep $ 1 | head - 1 | awk {print $$4} //  UserParameter = custom . vfs . dev . read . ms [ * ], cat / proc / diskstats | grep $ 1 | head - 1 | awk {print $$7} //  UserParameter = custom . vfs . dev . write . ops [ * ], cat / proc / diskstats | grep $ 1 | head - 1 | awk {print $$8} //  UserParameter = custom . vfs . dev . write . ms [ * ], cat / proc / diskstats | grep $ 1 | head - 1 | awk {print $$11} //  UserParameter = custom . vfs . dev . io . active [ * ], cat / proc / diskstats | grep $ 1 | head - 1 | awk {print $$12} UserParameter = custom . vfs . dev . io . ms [ * ], cat / proc / diskstats | grep $ 1 | head - 1 | awk {print $$13} //  IO  UserParameter = custom . vfs . dev . read . sectors [ * ], cat / proc / diskstats | grep $ 1 | head - 1 | awk {print $$6} // （ 512 B ） UserParameter = custom . vfs . dev . write . sectors [ * ], cat / proc / diskstats | grep $ 1 | head - 1 | awk {print $$10} // （ 512 B ） UserParameter = custom . vfs . dev . iowait [ * ], iostat - x 1 2 | grep $ 1 | tail - n 1 | awk {print $$10}","title":"io"},{"location":"zabbix2/#tcp","text":"/etc/zabbix/zabbix_agentd.d/tcp_net.conf UserParameter=TIME_WAIT,netstat -an | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}' | grep TIME_WAIT |awk '{print $2}' UserParameter=CLOSE_WAIT,netstat -an | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}' | grep CLOSE_WAIT |awk '{print $2}' UserParameter=FIN_WAIT1,netstat -an | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}' | grep FIN_WAIT1 |awk '{print $2}' UserParameter=ESTABLISHED,netstat -an | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}' | grep ESTABLISHED |awk '{print $2}' UserParameter=SYN_RECV,netstat -an | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}' | grep SYN_RECV |awk '{print $2}' UserParameter=LAST_ACK,netstat -an | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}' | grep LAST_ACK |awk '{print $2}' UserParameter=LISTEN,netstat -an | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}' | grep LISTEN |awk '{print $2}'","title":"tcp"},{"location":"zabbix2/#zabbix_proxy","text":"yum install zabbix - proxy zabbix - proxy - mysql mysql - server - y mysql create database zabbix_proxy ; grant all on zabbix_proxy . * to zabbix @ 127.0.0.1 identified by zbpass ; delete from mysql . user where user = ; flush privileges ;  mysql zabbix_proxy / usr / share / doc / zabbix - proxy - mysql - 2 . 4 . 8 / create / schema . sql cat / etc / zabbix / zabbix_proxy . conf  Server = 172 . 16 . 10 . 126 #  Zabbix Server Hostname =  ip DBHost = localhost #  DBName = zabbix_proxy #  DBUser = zbuser #  DBPassword = zbpass #  agent  server  proxy  ip  key  agent  not found  proxy  agent ","title":"zabbix_proxy"},{"location":"zabbix2/#ztree","text":"https : // github . com / spide4k / zatree 1 ： git clone https : // github . com / spide4k / zatree . git zatree 2 ：， zatree  zabbix  php  php - xml 、 php - gd 、 php - mysql  zabbix web ， zatree - zabbix - 2 . 4 . 5 . tar . gz ， 3 ： zabbix   conf / zabbix . conf . php   4 ： web interface , zatree / zabbix_config . php user = xxx , // web  zabbix  password = xxx , // web  http_user = xxx , // httpsweb  http_password = xxx , // httpsweb     zabbix / zatree / graph . php   411 - 416  div align = center style = font-size:12px; font size = 5px color = red ,,, / font br font size = 2px color = red  zatree / graph . php  / font br img src = static/yunweibang-weixin.jpg / br a href = https://github.com/spide4k/zatree target = _blank Zatree / a version 2 . 4 for Zabbix 2 . 4 . x ,  QQ : 271659981 , : yunweibang / div","title":"ztree"},{"location":"zabbix2/#_1","text":"《 zabbix 》， zabbix server ， Host 。 ， Active agent  zabbix server ， zabbix server  agent  host 。 ，。 zabbix agent ， server  trigger ， ，。 2 .  2 . 1   server ip 1 2 # cat / usr / local / zabbix - 2 . 2 . 2 / etc / zabbix_agentd . conf | grep - E ^ ServerActive ServerActive = 66 . 175 . 222 . 232  Hostname 1 2 # cat / usr / local / zabbix - 2 . 2 . 1 / etc / zabbix_agentd . conf | grep - E ^ Hostname Hostname = auto - reg - for - ttlsa - 01 ： zabbix_agentd . conf  Hostname ， zabbix  Hostname ， agent （ hostname ）  metadataitem 1 2 cat / usr / local / zabbix - 2 . 2 . 1 / etc / zabbix_agentd . conf | grep HostMetadataItem = HostMetadataItem = system . uname 2 . 2  action ： configuration action Event source （ Auto registration ） Create Action ， action 2 . 2 . 1 action  hostmetadata  Action ，， 2 . 2 . 2 Conditions  hostmetadata Host metadata  Linux  2 . 2 . 3 ， metadata ，。 2 . 2 . 3 operations  hostmetadata  active host ， server ：  agent  host   agent  linux servers  agent  link  Template OS linux 3 .   / tmp / zabbix_server . log ： 1 16585 : 20150203 : 161110 . 910 enabling Zabbix agent checks on host auto-reg-for-ttlsa-01 : host became available ， host ， host ： hostmetadata 4 . HostMetadataItem  HostMetadata ：，。 linux  windows ， template  4 . 1 HostMetadataItem  1 HostMetadataItem = system . uname  key 4 . 2 HostMetadata  1 HostMetadata : Linux hehehehehehehehe xxxxx   metadata ，。","title":""},{"location":"zabbix2/#key","text":" UserParameter = mysql . ping , mysqladmin - uroot ping | grep - c alive  1  MySQL ， 0  MySQL  UserParameter = key [ * ], command Key . [ * ] Command ， key [] $1  $9 ， 9 。 $0 .  1 .  $2 ，$ $2 ， awk ’{ print $ $2 }’，， ， zabbix ，。， zabbix 。 2 . zabbix ，： \\ ” ` * ? [ ] { } ~ $ ! ; ( ) | # @ 3 .  zabbix 2 . 0 ， zabbix 。 UserParameter = mysql . ping [ * ], mysqladmin - u $1 - p $2 ping | grep - c alive  MYSQL ，。 mysql . ping [ zabbix , our_password ] ? UserParameter = wc [ * ], grep - c $2 $1  wc [ / etc / passwd , root ] wc [ / etc / services , zabbix ] --------------------------------------------------------------------------------  mcu  cpu  UserParameter = proce . cpu [ * ], top - b - n 1 | grep $1 | awk {print $$9} UserParameter = proce . mem [ * ], sudo cat / proc / ` ps aux | grep $1 | grep - v grep | awk {print $$2} ` / smaps | grep - i pss | awk {sum += $$2}END{print sum*1024}","title":"key"}]}